<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Buezwqwg</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Buezwqwg</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>youremail@example.com (Buezwqwg)</managingEditor>
    <webMaster>youremail@example.com (Buezwqwg)</webMaster>
    <copyright>© 2024 Buezwqwg</copyright>
    <lastBuildDate>Wed, 13 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Foreign Exchange</title>
      <link>http://localhost:1313/docs/economic/foreignexchange/</link>
      <pubDate>Wed, 13 Nov 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/economic/foreignexchange/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Last Edit: 11/13/2024&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;交易量最大的市场&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;货币 
    &lt;div id=&#34;%E8%B4%A7%E5%B8%81&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E8%B4%A7%E5%B8%81&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/docs/Economic_Static/ForeignExchange/ForeignExchange%E5%A4%96%E6%B1%87.png&#34; alt=&#34;Img&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/economic/foreignexchange/feature.png" />
    </item>
    
    <item>
      <title>MCMS 6. Plastics</title>
      <link>http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms6.plastics/</link>
      <pubDate>Sun, 10 Nov 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms6.plastics/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Last Edit: 11/10/24&lt;/p&gt;
&lt;/blockquote&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Polymer 聚合物 
    &lt;div id=&#34;polymer-%E8%81%9A%E5%90%88%E7%89%A9&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#polymer-%E8%81%9A%E5%90%88%E7%89%A9&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;前缀“poly-”意指“很多”，暗示了这些聚合物分子结构中有许多重复的部分。&lt;/li&gt;
&lt;li&gt;而“mer”指的是“重复单元”或“基元”，这是一种分子的基本单元&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Basic Structure 
    &lt;div id=&#34;basic-structure&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#basic-structure&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;与Crystal Structure不同，他们的基本结构是Cubics。并且其会在三维空间（即沿着三个方向）重复排列，形成一个规则的晶体结构&lt;/li&gt;
&lt;li&gt;Polymer的结构则不同，它的基元通常只在One Dimnesion上重复，这种重复形成了一条长链&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/docs/EMCS_Static/ECMS6.Plastics/ECMS6.Plastics.png&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms6.plastics/feature.png" />
    </item>
    
    <item>
      <title>Linear Regression</title>
      <link>http://localhost:1313/docs/d2l_dive-into-deep-learning/linearregression/</link>
      <pubDate>Mon, 04 Nov 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/d2l_dive-into-deep-learning/linearregression/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Last Edit: 11/4/2024&lt;/p&gt;
&lt;/blockquote&gt;
&lt;video width=&#34;640&#34; height=&#34;360&#34; controls&gt;
  &lt;source src=&#34;LinearRegression.mp4&#34; type=&#34;video/mp4&#34;&gt;
  Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;Full Code is Provided&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-from&#34; data-lang=&#34;from&#34;&gt;import numpy as np
import torch
import random

class LinearRegression(Scene):
    def construct(self):
        def data_generator(w,b,num):
            X = torch.normal(0, 1, (num, len(w)))
            y = torch.matmul(X, w) + b
            y += torch.normal(0, 0.01, y.shape)
            return X, y.reshape((-1, 1))

        true_w = torch.tensor([2,-3.4])
        true_b = 4.2
        features, labels = data_generator(true_w,true_b,1000)
        normal_data = features[:,[0]].numpy()
        #plt.hist(normal_data,bins=100,density=True,color=&amp;#39;lightblue&amp;#39;)  
         

        head = Text(&amp;#34;Linear Regression - Buezwqwg&amp;#34;)
        head.set_color(BLUE)
        self.play(Create(head))

        head_0 = Text(&amp;#34;In one process of Linear Regression, there bascially includes 5 steps&amp;#34;,font_size=30)
        self.play(Uncreate(head),Write(head_0))
        self.play(head_0.animate.move_to(UP*3.5))
        head_1 = Text(&amp;#34;1. Initial Parameters&amp;#34;,font_size=30)
        head_2 = Text(&amp;#34;2. Defining Model and Loss Function&amp;#34;,font_size=30)
        head_3 = Text(&amp;#34;3. Optimization&amp;#34;,font_size=30)
        head_4 = Text(&amp;#34;4. Loop&amp;#34;,font_size=30)
        head = VGroup(head_1,head_2,head_3,head_4)
        head.arrange(DOWN)
        self.play(Write(head))

        # --------------------------------------------------------------------------------------------

        head_5 = Text(&amp;#34;In this animate, we start with generating the data&amp;#34;,font_size=30)
        head_5.move_to(UP*3.5)
        self.play(Uncreate(head),Uncreate(head_0),Write(head_5))
        code_text = &amp;#39;&amp;#39;&amp;#39;
        def data_generator(w, b, num):
            X = torch.normal(0, 1, (num, len(w)))
            y = torch.matmul(X, w) + b
            y += torch.normal(0, 0.01, y.shape)
            return X, y.reshape((-1, 1))
            
        true_w = torch.tensor([2,-3.4])
        true_b = 4.2
        features, labels = data_generator(true_w,true_b,1000)
        &amp;#39;&amp;#39;&amp;#39;
        code = Code(code=code_text,insert_line_no=False,language=&amp;#34;Python&amp;#34;,font=&amp;#34;Monospace&amp;#34;)
        self.play(Write(code),Uncreate(head_5),run_time=3)
        self.wait(3)
        self.play(Unwrite(code))
        axes = Axes(
            x_range=[-4, 4, 1],
            y_range=[0, 0.5, 0.1],
            axis_config={&amp;#34;color&amp;#34;: BLUE},
        ).add_coordinates()

        # 正态分布函数 y = (1/sqrt(2*pi)) * exp(-x^2 / 2)
        normal_curve = axes.plot(
            lambda x: (1 / (2 * PI) ** 0.5) * np.exp(-x**2 / 2),
            color=YELLOW
        )

        # 绘制均值为0的竖线
        mean_line = DashedLine(
            start=axes.c2p(0, 0),
            end=axes.c2p(0, (1 / (2 * PI) ** 0.5)),
            color=RED
        )

        # 添加图形和标注
        self.play(Create(axes))
        self.play(Create(normal_curve), Create(mean_line))
        
        # 标注均值和标准差
        mean_label = MathTex(r&amp;#34;\mu=0&amp;#34;).next_to(mean_line, DOWN)
        std_label = MathTex(r&amp;#34;\sigma=1&amp;#34;).next_to(normal_curve, UP, buff=0.5)
        self.play(Write(mean_label), Write(std_label))

        # 展示最终效果
        self.wait(2)
        self.play(Unwrite(mean_label),Unwrite(std_label),Uncreate(axes),Uncreate(normal_curve),Uncreate(mean_line))

        # --------------------------------------------------------------------------------------------

        head = Text(&amp;#34;Displaying the distribution of features&amp;#34;)
        feature_one = features[:,[0]].tolist()
        feature_two = features[:,[1]].tolist()
        labels = labels.tolist()
        axes_1 = Axes(
            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1
            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1
            x_length=5,  # x轴的长度
            y_length=5,  # y轴的长度
            axis_config={&amp;#34;color&amp;#34;: BLUE},  # 坐标轴的颜色
        )
        axes_2 = Axes(
            x_range=[min(feature_two)[0], max(feature_two)[0], 1],  # x轴范围：从-5到5，步长为1
            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1
            x_length=5,  # x轴的长度
            y_length=5,  # y轴的长度
            axis_config={&amp;#34;color&amp;#34;: BLUE},  # 坐标轴的颜色
        )
        axes = VGroup(axes_1,axes_2)
        axes.arrange(RIGHT,buff=1)
        self.play(Create(axes))

        points_1 = []
        for i in range(len(labels)):
            dot_position = axes_1.coords_to_point(feature_one[i][0], labels[i][0])
            points_1.append(Dot(point=dot_position, radius=0.05, color=YELLOW))
        animations_1 = [Create(dot) for dot in points_1]
        points_2 = []
        for i in range(len(labels)):
            dot_position = axes_2.coords_to_point(feature_two[i][0], labels[i][0])
            points_2.append(Dot(point=dot_position, radius=0.05, color=YELLOW))
        animations_2 = [Create(dot) for dot in points_2]
        self.play(Succession(*animations_1, lag_ratio=0.005),Succession(*animations_2, lag_ratio=0.005))

        # 抽取样本-------------------------------------------------------------------------------------------- 

        head = Text(&amp;#39;Shuffle the data and divided into samples(batches)&amp;#39;,font_size=30)
        self.play(Uncreate(axes),Write(head),Uncreate(VGroup(*points_1)),Uncreate(VGroup(*points_2)))
        head.move_to(UP*3.5)
        code_text = &amp;#39;&amp;#39;&amp;#39;
        def data_iter(batch_size,features,labels):
            num = len(features)
            index = list(range(num))
            random.shuffle(index)
            for i in range(0,num,batch_size):
                batch_index = torch.tensor(index[i:min(i+batch_size,num)])
                yield features[batch_index], labels[batch_index]
        &amp;#39;&amp;#39;&amp;#39;
        code = Code(code=code_text,insert_line_no=False,language=&amp;#34;Python&amp;#34;,font=&amp;#34;Monospace&amp;#34;)
        self.play(Write(code))
        self.wait(2)
        self.play(Uncreate(code),Unwrite(head))

        def data_iter(batch_size,features,labels):
            num = len(features)
            index = list(range(num))
            random.shuffle(index)
            for i in range(0,num,batch_size):
                batch_index = torch.tensor(index[i:min(i+batch_size,num)])
                return batch_index.tolist()



        axes_1 = Axes(
            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1
            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1
            x_length=2.5,  # x轴的长度
            y_length=2.5,  # y轴的长度
            axis_config={&amp;#34;color&amp;#34;: BLUE},  # 坐标轴的颜色
        )
        

        axes_2 = Axes(
            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1
            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1
            x_length=2.5,  # x轴的长度
            y_length=2.5,  # y轴的长度
            axis_config={&amp;#34;color&amp;#34;: BLUE},  # 坐标轴的颜色
        )
        
        axes_3 = Axes(
            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1
            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1
            x_length=2.5,  # x轴的长度
            y_length=2.5,  # y轴的长度
            axis_config={&amp;#34;color&amp;#34;: BLUE},  # 坐标轴的颜色
        )
        axes_4 = Axes(
            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1
            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1
            x_length=2.5,  # x轴的长度
            y_length=2.5,  # y轴的长度
            axis_config={&amp;#34;color&amp;#34;: BLUE},  # 坐标轴的颜色
        )
        axes_5 = Axes(
            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1
            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1
            x_length=2.5,  # x轴的长度
            y_length=2.5,  # y轴的长度
            axis_config={&amp;#34;color&amp;#34;: BLUE},  # 坐标轴的颜色
        )
        axes = VGroup(axes_1,axes_2,axes_3,axes_4,axes_5)
        axes.arrange(RIGHT)

        sample_1 = data_iter(10,features,labels)
        points_1 = []
        for i in sample_1:
            dot_position = axes_1.coords_to_point(features[i][0],labels[i][0])
            points_1.append(Dot(point=dot_position, radius=0.05, color=YELLOW))
        animations_1 = [Create(dot) for dot in points_1]

        sample_2 = data_iter(10,features,labels)
        points_2 = []
        for i in sample_2:
            dot_position = axes_2.coords_to_point(features[i][0],labels[i][0])
            points_2.append(Dot(point=dot_position, radius=0.05, color=YELLOW))
        animations_2 = [Create(dot) for dot in points_2]

        sample_3 = data_iter(10,features,labels)
        points_3 = []
        for i in sample_3:
            dot_position = axes_3.coords_to_point(features[i][0],labels[i][0])
            points_3.append(Dot(point=dot_position, radius=0.05, color=YELLOW))
        animations_3 = [Create(dot) for dot in points_3]

        sample_4 = data_iter(10,features,labels)
        points_4 = []
        for i in sample_4:
            dot_position = axes_4.coords_to_point(features[i][0],labels[i][0])
            points_4.append(Dot(point=dot_position, radius=0.05, color=YELLOW))
        animations_4 = [Create(dot) for dot in points_4]

        sample_5 = data_iter(10,features,labels)
        points_5 = []
        for i in sample_5:
            dot_position = axes_5.coords_to_point(features[i][0],labels[i][0])
            points_5.append(Dot(point=dot_position, radius=0.05, color=YELLOW))
        animations_5 = [Create(dot) for dot in points_5]   
        head = Text(&amp;#34;Display five of Sample Batches (Batch Size = 10)&amp;#34;,font_size=30)
        head.set_color(BLUE)
        head.move_to(UP*2.5)
        self.play(Write(head))
        self.play(Create(axes),Succession(*animations_1, lag_ratio=0.05),Succession(*animations_2, lag_ratio=0.05),Succession(*animations_3, lag_ratio=0.05),Succession(*animations_4, lag_ratio=0.05),Succession(*animations_5, lag_ratio=0.05))
        self.wait(3)
        self.play(Uncreate(axes),Uncreate(head),Uncreate(VGroup(*points_1)),Uncreate(VGroup(*points_2)),Uncreate(VGroup(*points_3)),Uncreate(VGroup(*points_4)),Uncreate(VGroup(*points_5)))

        # 定义模型-------------------------------------------------------------------------------------------- 

        head_1 = Text(&amp;#39;Define the Function&amp;#39;)
        head_1.set_color(BLUE)
        code_text_1 = &amp;#39;&amp;#39;&amp;#39;
        def linreg(X, w, b):
            return torch.matmul(X, w) + b
        &amp;#39;&amp;#39;&amp;#39;
        code_1 = Code(code=code_text_1,insert_line_no=False,language=&amp;#34;Python&amp;#34;,font=&amp;#34;Monospace&amp;#34;)
        head_2 = Text(&amp;#39;Define the Loss Function&amp;#39;)
        head_2.set_color(BLUE)
        code_text_2 = &amp;#39;&amp;#39;&amp;#39;
        def squared_loss(y_hat, y):
            return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2
        &amp;#39;&amp;#39;&amp;#39;


        code_2 = Code(code=code_text_2,insert_line_no=False,language=&amp;#34;Python&amp;#34;,font=&amp;#34;Monospace&amp;#34;)
        head = VGroup(head_1,code_1,head_2,code_2)
        head.arrange(DOWN,buff=1)
        self.play(Write(head))
        self.wait(2)
        self.play(Unwrite(head))

        # 展示MSE--------------------------------------------------------------------------------------------    
        head = MathTex(r&amp;#34;Lose~Function~MSE~:(y_i - \hat{y}_i)^2&amp;#34;)
        head.set_color(BLUE)
        head.move_to(UP*3)
        self.play(Write(head))
        axes = Axes(
            x_range=[-10, 10, 2.5],
            y_range=[0, 100, 20],
            x_length=10,
            y_length=5,
            axis_config={&amp;#34;color&amp;#34;: GREEN},
        )
        
        # 定义MSE函数
        mse_curve = axes.plot(lambda x: (x**2), color=BLUE, x_range=[-10, 10])
        mse_der = axes.plot(lambda x: (2*x), color=RED, x_range=[-10, 10])
        # 将元素添加到场景中
        self.play(Create(axes),Create(mse_curve))
        self.wait(2)
        self.play(Uncreate(head))
        head = Text(&amp;#34;The MSE Derivative indicates that loss will be increasing as it increase&amp;#34;,font_size=30)
        head.set_color(BLUE)
        head.move_to(UP*3)
        self.play(Write(head),Create(mse_der))
        self.wait(3)
        self.play(Uncreate(head),Uncreate(mse_der),Uncreate(mse_curve),Uncreate(axes))


        # 展示SGD--------------------------------------------------------------------------------------------
        head = Text(&amp;#34;Now Conduct the Optimization Method&amp;#34;)
        head.move_to(UP*3)
        head.set_color(BLUE)
        code_text = &amp;#39;&amp;#39;&amp;#39;
        def sgd(params, lr, batch_size):
        with torch.no_grad():
            for param in params:
                param -= lr * param.grad / batch_size
                param.grad.zero_()
        &amp;#39;&amp;#39;&amp;#39;
        code = Code(code=code_text,insert_line_no=False,language=&amp;#34;Python&amp;#34;,font=&amp;#34;Monospace&amp;#34;)
        head_2 = Text(&amp;#39;Apply this optimization method for each batch&amp;#39;)
        head_2.set_color(BLUE)
        sgd = MathTex(r&amp;#34;(w,b)\leftarrow (w,b)-\eta g&amp;#34;)
        main = VGroup(head,code,head_2,sgd)
        main.arrange(DOWN,buff=0.7)
        self.play(Write(main))
        self.wait(2)
        self.play(Uncreate(main),run_time=0.1)
        
        # 计算梯度--------------------------------------------------------------------------------------------
        head = Text(&amp;#34;Now Calculate the Gradient&amp;#34;)
        head.set_color(BLUE)
        head.move_to(UP*3)
        grad = MathTex(r&amp;#34;\frac{\partial \text{MSE}}{\partial w} = \frac{1}{n} \sum_{i=1}^{n} \frac{\partial}{\partial w} \left( y_i - (w x_i + b) \right)^2&amp;#34;)
        grad_1 = MathTex(r&amp;#34;= \frac{1}{n} \sum_{i=1}^{n} 2(y_i - (wx_i + b)) \cdot (-x_i)&amp;#34;)
        grad_2 = MathTex(r&amp;#34;= -\frac{1}{n} \sum_{i=1}^{n} 2(y_i - \hat{y}_i) \cdot x_i&amp;#34;)

        main = VGroup(head,grad,grad_1,grad_2)
        main.arrange(DOWN,buff=0.7)
        self.play(Write(main))
        self.wait(2)
        self.play(Uncreate(main),run_time=0.01)
        head = Text(&amp;#34;Then apllies the formula for 1000/10=100 Times&amp;#34;,font_size=45)
        head.set_color(BLUE)
        grad = MathTex(r&amp;#39;w := w + \eta \cdot \frac{1}{n} \sum_{i=1}^{n} 2(y_i - \hat{y}_i) \cdot x_i&amp;#39;)
        grad_1 = MathTex(r&amp;#34;b := b + \eta \cdot \frac{1}{n} \sum_{i=1}^{n} 2(y_i - \hat{y}_i)&amp;#34;)
        main = VGroup(head,grad,grad_1)
        main.arrange(DOWN,buff=0.7)
        self.play(Write(main))
        self.wait(3)
        self.play(Uncreate(main),run_time=0.01)

        # 总结--------------------------------------------------------------------------------------------
        code_text = &amp;#39;&amp;#39;&amp;#39;
        lr = 0.03
        num_epochs = 3
        net = linreg
        loss = squared_loss

        for epoch in range(num_epochs):
            for X, y in data_iter(batch_size, features, labels):
                l = loss(net(X, w, b), y)
                l.sum().backward()
                sgd([w, b], lr, batch_size)
            with torch.no_grad():
                train_l = loss(net(features, w, b), labels)
                print(f&amp;#39;epoch {epoch + 1}, loss {float(train_l.mean()):f}&amp;#39;)
        &amp;#39;&amp;#39;&amp;#39;
        code = Code(code=code_text,insert_line_no=False,language=&amp;#34;Python&amp;#34;,font=&amp;#34;Monospace&amp;#34;)
        head = Text(&amp;#34;Then applies the whole process in epochs and that&amp;#39;s linear regression&amp;#34;,font_size=30)
        main = VGroup(head,code)
        main.arrange(DOWN,buff=1)
        self.play(Write(main))
---
&lt;/code&gt;&lt;/pre&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/d2l_dive-into-deep-learning/linearregression/feature.png" />
    </item>
    
    <item>
      <title>Foreign Exchange</title>
      <link>http://localhost:1313/docs/linearalgebra/la6.determiants/</link>
      <pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/linearalgebra/la6.determiants/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Last Edit: 10/24/24&lt;/p&gt;
&lt;/blockquote&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction to Determinate 
    &lt;div id=&#34;introduction-to-determinate&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction-to-determinate&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;行列式是一个每个方阵都具有的数值&lt;/li&gt;
&lt;li&gt;Determinate measures the factor by which the area of a given region increases or decreases&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/docs/LinearAlgebra_Static/LA6.Determinants/LA6.Determinats.png&#34; alt=&#34;Img&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/linearalgebra/la6.determiants/feature.png" />
    </item>
    
    <item>
      <title>Projectile Motion when air resisitance is propftional to velocity</title>
      <link>http://localhost:1313/docs/projectilemotion/</link>
      <pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/projectilemotion/</guid>
      <description>&lt;video width=&#34;640&#34; height=&#34;360&#34; controls&gt;
  &lt;source src=&#34;Projectile.mp4&#34; type=&#34;video/mp4&#34;&gt;
  Your browser does not support the video tag.
&lt;/video&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/projectilemotion/feature.png" />
    </item>
    
    <item>
      <title>Monte Carlo Approach to Calculate π</title>
      <link>http://localhost:1313/docs/montecarlomethod/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/montecarlomethod/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;“这种方法虽然简单，却展示了数学中的一种用随机的蛮力对抗精确逻辑的思想方法，一种用数量得到质量的计算思想” - 三体&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/montecarlomethod/feature.png" />
    </item>
    
    <item>
      <title>MCMS 5. Further On Stress Strain</title>
      <link>http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms5.furtheronstressstrain/</link>
      <pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms5.furtheronstressstrain/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Last Edit: 10/16/24&lt;/p&gt;
&lt;/blockquote&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Stress-Strain Curve 
    &lt;div id=&#34;stress-strain-curve&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#stress-strain-curve&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/docs/EMCS_Static/ECMS5.FurtherOnStressStrain/MCMS5.FurtherOnStressStrain.png&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当回头重新看Stress-Strain Curve的时候可以发现一些特殊的点&lt;/li&gt;
&lt;li&gt;如Proportion Limit，Ultimate Tensile Strength两个点&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Proportional Limit 
    &lt;div id=&#34;proportional-limit&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#proportional-limit&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在曲线的最初阶段，存在一个接近于Linear的区域，其代表了Linear Elastic的Region&lt;/li&gt;
&lt;li&gt;而也必会存在一个点象征着Linear Elastic Region的结束&lt;/li&gt;
&lt;li&gt;但犹豫一些测量的误差或者精度上的问题，将导致最终的这一个Linear Elastic结束的点无法被确定，所以需要一个约定俗成的方法&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;0.2% Offset Yield Strength 
    &lt;div id=&#34;02-offset-yield-strength&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#02-offset-yield-strength&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/docs/EMCS_Static/ECMS5.FurtherOnStressStrain/MCMS5.FurtherOnStressStrain-1.png&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms5.furtheronstressstrain/feature.png" />
    </item>
    
    <item>
      <title>The Three Body Problem</title>
      <link>http://localhost:1313/notes/thethreebodyproblem/</link>
      <pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/notes/thethreebodyproblem/</guid>
      <description>&lt;h1 class=&#34;relative group&#34;&gt;元数据 
    &lt;div id=&#34;%E5%85%83%E6%95%B0%E6%8D%AE&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E5%85%83%E6%95%B0%E6%8D%AE&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;[!abstract] 三体（全集）&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/notes/thethreebodyproblem/feature.jpg" />
    </item>
    
    <item>
      <title>Ontario Lake</title>
      <link>http://localhost:1313/blogs/ontariolake/</link>
      <pubDate>Mon, 14 Oct 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/blogs/ontariolake/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/blog/OntarioLake/Ontario%20Lake-1.jpg&#34; alt=&#34;Img&#34; /&gt;
      
    &lt;/figure&gt;


    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/blog/OntarioLake/Ontario%20Lake-2.jpg&#34; alt=&#34;Img&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/blogs/ontariolake/feature.jpg" />
    </item>
    
    <item>
      <title>ECMS 4. The Structure Property</title>
      <link>http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms4.thestructureproperty/</link>
      <pubDate>Wed, 25 Sep 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms4.thestructureproperty/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Last Edit: 9/25/24&lt;/p&gt;
&lt;/blockquote&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Young’s modulus change with Density 
    &lt;div id=&#34;youngs-modulus-change-with-density&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#youngs-modulus-change-with-density&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/docs/EMCS_Static/ECMS4.TheStructureProperty/ECMS4.TheStructure-Property-24.png&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms4.thestructureproperty/feature.png" />
    </item>
    
    <item>
      <title>ECMS 2. Elastic Behavior</title>
      <link>http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms2.elasticbehavior/</link>
      <pubDate>Tue, 24 Sep 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms2.elasticbehavior/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Last Edit 9/24/24&lt;/p&gt;
&lt;/blockquote&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Hooke’s Law 
    &lt;div id=&#34;hookes-law&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#hookes-law&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;$$F=kx$$&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms2.elasticbehavior/feature.png" />
    </item>
    
    <item>
      <title>ECMS 3. Plastic Deformation</title>
      <link>http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms3.plasticdeformation/</link>
      <pubDate>Mon, 23 Sep 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms3.plasticdeformation/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Last Edit: 9/23/24&lt;/p&gt;
&lt;/blockquote&gt;


&lt;h4 class=&#34;relative group&#34;&gt;Plastice Deformation (Permanent Deformation) 
    &lt;div id=&#34;plastice-deformation-permanent-deformation&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#plastice-deformation-permanent-deformation&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;we use the term &lt;strong&gt;plastic&lt;/strong&gt; to describe permanent deformation&lt;/li&gt;
&lt;li&gt;之所以是Plastic，是因为它derives from the Greek &lt;strong&gt;plastikos&lt;/strong&gt; meaning to sculpt&lt;/li&gt;
&lt;/ul&gt;


&lt;h5 class=&#34;relative group&#34;&gt;Changes After Plastic Deformation 
    &lt;div id=&#34;changes-after-plastic-deformation&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#changes-after-plastic-deformation&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;在Plastic Deformation后，Atomic Spacing将保持\(r=r_0\)&lt;/li&gt;
&lt;li&gt;但是Sequence of atoms将进入一个New Equilibrium&lt;/li&gt;
&lt;li&gt;即在Marcro Perspective上发生Shape的Deform&lt;/li&gt;
&lt;li&gt;Tensile Strain将会保持一定非零大小&lt;/li&gt;
&lt;/ul&gt;


&lt;h5 class=&#34;relative group&#34;&gt;Micro Perspective of Plastic Deformation 
    &lt;div id=&#34;micro-perspective-of-plastic-deformation&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#micro-perspective-of-plastic-deformation&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h5&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/docs/EMCS_Static/ECMS3.PlasticDeformations/ECMS3.PlasticDeformations.png&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;


    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/docs/EMCS_Static/ECMS3.PlasticDeformations/ECMS3.PlasticDeformations-1.png&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;


    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/docs/EMCS_Static/ECMS3.PlasticDeformations/ECMS3.PlasticDeformations-2.png&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/emcs_engineering-chemistry--materials-science/ecms3.plasticdeformation/feature.png" />
    </item>
    
    <item>
      <title>Inflation 通货膨胀</title>
      <link>http://localhost:1313/docs/economic/inflation/</link>
      <pubDate>Thu, 04 Jul 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/economic/inflation/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Last Edit 7/4/24&lt;/p&gt;
&lt;/blockquote&gt;


&lt;h1 class=&#34;relative group&#34;&gt;通货膨胀 
    &lt;div id=&#34;%E9%80%9A%E8%B4%A7%E8%86%A8%E8%83%80&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E9%80%9A%E8%B4%A7%E8%86%A8%E8%83%80&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;钱的贬值&lt;/li&gt;
&lt;/ul&gt;


&lt;h1 class=&#34;relative group&#34;&gt;CPI Consumer Price Index 消费者物价指数 
    &lt;div id=&#34;cpi-consumer-price-index-%E6%B6%88%E8%B4%B9%E8%80%85%E7%89%A9%E4%BB%B7%E6%8C%87%E6%95%B0&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#cpi-consumer-price-index-%E6%B6%88%E8%B4%B9%E8%80%85%E7%89%A9%E4%BB%B7%E6%8C%87%E6%95%B0&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;美国CPI 
    &lt;div id=&#34;%E7%BE%8E%E5%9B%BDcpi&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E7%BE%8E%E5%9B%BDcpi&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;![Img](/docs/Economic_Static/Inflation/Inflation (2).png)&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/economic/inflation/feature.png" />
    </item>
    
    <item>
      <title>D2L 3.1 Linear Regression</title>
      <link>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.1_linearregression/</link>
      <pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.1_linearregression/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Last Edit 4/15/24&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Regression 回归，是能为一个或多个自变量与因变量之间关系建模的一种方式&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.1_linearregression/feature.png" />
    </item>
    
    <item>
      <title>D2L 3.2 Object-Oriented Design for Implementation</title>
      <link>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.2_object-orienteddesignforimplementation/</link>
      <pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.2_object-orienteddesignforimplementation/</guid>
      <description>&lt;p&gt;从零开始实现整个方法， 包括数据流水线、模型、损失函数和小批量随机梯度下降优化器。 虽然现代的深度学习框架几乎可以自动化地进行所有这些工作，但从零开始实现可以确保我们真正知道自己在做什么。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.2_object-orienteddesignforimplementation/feature.png" />
    </item>
    
    <item>
      <title>D2L 3.3 A concise implementation of linear regression</title>
      <link>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.3_syntheticregressiondat/</link>
      <pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.3_syntheticregressiondat/</guid>
      <description>&lt;p&gt;本节将介绍如何通过使用深度学习框架来简洁地实现[[3.2_Object-OrientedDesignforImplementation]]中的线性回归模型&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.3_syntheticregressiondat/feature.png" />
    </item>
    
    <item>
      <title>D2L 3.4 Softmax Regression</title>
      <link>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.4_softmaxregression/</link>
      <pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.4_softmaxregression/</guid>
      <description>&lt;p&gt;回归可以用于预测_多少_的问题。 比如预测房屋被售出价格，或者棒球队可能获得的胜场数，又或者患者住院的天数。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.4_softmaxregression/feature.png" />
    </item>
    
    <item>
      <title>D2L 3.5 Image classification datasets</title>
      <link>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.5_imageclassificationdatasets/</link>
      <pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.5_imageclassificationdatasets/</guid>
      <description>&lt;p&gt;MNIST数据集 (&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_references/zreferences.html#id90&#34;title=&#34;LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., &amp;amp; others. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278–2324.&#34; target=&#34;_blank&#34;&gt;LeCun &lt;em&gt;et al.&lt;/em&gt;, 1998&lt;/a&gt;) 是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单。 我们将使用类似但更复杂的Fashion-MNIST数据集 (&lt;a href=&#34;https://zh-v2.d2l.ai/chapter_references/zreferences.html#id189&#34;title=&#34;Xiao, H., Rasul, K., &amp;amp; Vollgraf, R. (2017). Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747.&#34; target=&#34;_blank&#34;&gt;Xiao &lt;em&gt;et al.&lt;/em&gt;, 2017&lt;/a&gt;)。&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.5_imageclassificationdatasets/feature.png" />
    </item>
    
    <item>
      <title>D2L 3.6 Implementation of softmax regression from scratch</title>
      <link>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.6_implementationofsoftmaxregressionfromscratch/</link>
      <pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.6_implementationofsoftmaxregressionfromscratch/</guid>
      <description>&lt;h2 class=&#34;relative group&#34;&gt;3.6.1 初始化模型参数 
    &lt;div id=&#34;361-%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#361-%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;和之前线性回归的例子一样，这里的每个样本都将用固定长度的向量表示。 原始数据集中的每个样本都是28×28的图像。 本节将展平每个图像，把它们看作长度为784的向量&lt;/li&gt;
&lt;li&gt;在3.5中，我们选择了一个拥有10个类别的数据集，所以softmax网络的输出维度为10&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;初始化权重w 
    &lt;div id=&#34;%E5%88%9D%E5%A7%8B%E5%8C%96%E6%9D%83%E9%87%8Dw&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%9D%83%E9%87%8Dw&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;与线性回归一样，我们使用正态分布初始化权重w，偏置初始化为0&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;num_inputs = 784
num_outputs = 10

W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)
b = torch.zeros(num_outputs, requires_grad=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 class=&#34;relative group&#34;&gt;3.6.2 定义softmax操作 
    &lt;div id=&#34;362-%E5%AE%9A%E4%B9%89softmax%E6%93%8D%E4%BD%9C&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#362-%E5%AE%9A%E4%B9%89softmax%E6%93%8D%E4%BD%9C&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;实现softmax操作由三个步骤组成&lt;/li&gt;
&lt;li&gt;对每个项求幂&lt;/li&gt;
&lt;li&gt;对每一行求和，得到其规范化常数&lt;/li&gt;
&lt;li&gt;每一行除以其规范化常数，保持结果的和为1
$$softmax(X)&lt;em&gt;{ij}=\frac{exp(X&lt;/em&gt;{ij})}{\sum_kexp(X_{ik})}$$&lt;/li&gt;
&lt;li&gt;分母或规范化常数，有时也称为_配分函数_（其对数称为对数-配分函数）。 该名称来自&lt;a href=&#34;https://en.wikipedia.org/wiki/Partition_function_%28statistical_mechanics%29&#34; target=&#34;_blank&#34;&gt;统计物理学&lt;/a&gt;中一个模拟粒子群分布的方程&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;def softmax(X):
    X_exp = torch.exp(X)
    partition = X_exp.sum(1, keepdim=True)
    return X_exp / partition  # 这里应用了广播机制
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;keepdim=True: 在进行张量操作时，保持原始张量的维度&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.6_implementationofsoftmaxregressionfromscratch/feature.png" />
    </item>
    
    <item>
      <title>D2L 4.1 MultilayerPerceptron</title>
      <link>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.2_implementationofmultilayerperceptronfromscratch/</link>
      <pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.2_implementationofmultilayerperceptronfromscratch/</guid>
      <description>&lt;p&gt;在了解多层感知机前，需要先了解[[Perceptron 感知机]]&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.2_implementationofmultilayerperceptronfromscratch/feature.png" />
    </item>
    
    <item>
      <title>D2L 4.1 MultilayerPerceptron</title>
      <link>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.3_simpleimplementationofmultilayerperceptron/</link>
      <pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.3_simpleimplementationofmultilayerperceptron/</guid>
      <description>&lt;p&gt;在了解多层感知机前，需要先了解[[Perceptron 感知机]]&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.3_simpleimplementationofmultilayerperceptron/feature.png" />
    </item>
    
    <item>
      <title>D2L 4.3 Simple Implementation of Multilayer Perceptron</title>
      <link>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.1_multilayerperceptron/</link>
      <pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.1_multilayerperceptron/</guid>
      <description>&lt;p&gt;通过更高级的API进一步简洁训练过程&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;4.3.1 模型 
    &lt;div id=&#34;431-%E6%A8%A1%E5%9E%8B&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#431-%E6%A8%A1%E5%9E%8B&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;net = nn.Sequential(nn.Flatten(),
                    nn.Linear(784, 256),
                    nn.ReLU(),
                    nn.Linear(256, 10))

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

net.apply(init_weights);
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;初始化神经网络&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;batch_size, lr, num_epochs = 256, 0.1, 10
loss = nn.CrossEntropyLoss(reduction=&amp;#39;none&amp;#39;)
trainer = torch.optim.SGD(net.parameters(), lr=lr)

train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
&lt;/code&gt;&lt;/pre&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.1_multilayerperceptron/feature.png" />
    </item>
    
    <item>
      <title>D2L 4.4 Model Selection, Underfitting, and Overfitting</title>
      <link>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.4_modelselectionunderfittingandoverfitting/</link>
      <pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.4_modelselectionunderfittingandoverfitting/</guid>
      <description>&lt;p&gt;深度学习的目的是发现Pattern，即做到模型的Generalization 泛化&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/d2l_dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.4_modelselectionunderfittingandoverfitting/feature.png" />
    </item>
    
    <item>
      <title>网易云年度总结</title>
      <link>http://localhost:1313/blogs/wangyiyun/</link>
      <pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/blogs/wangyiyun/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img
        class=&#34;my-0 rounded-md&#34;
        loading=&#34;lazy&#34;
        srcset=&#34;
        /blogs/wangyiyun/1_hu17702828048897762413.jpg 330w,
        /blogs/wangyiyun/1_hu360113685819379410.jpg 660w,
        /blogs/wangyiyun/1_hu13608319589208325737.jpg 1024w,
        /blogs/wangyiyun/1_hu6717855714386122734.jpg 2x&#34;
        src=&#34;http://localhost:1313/blogs/wangyiyun/1_hu360113685819379410.jpg&#34;
        alt=&#34;Img&#34;
      /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/blogs/wangyiyun/feature.jpg" />
    </item>
    
    <item>
      <title>外滩2021</title>
      <link>http://localhost:1313/blogs/theband/</link>
      <pubDate>Sun, 26 Dec 2021 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/blogs/theband/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img
        class=&#34;my-0 rounded-md&#34;
        loading=&#34;lazy&#34;
        srcset=&#34;
        /blogs/theband/1_hu12727092779758697027.jpg 330w,
        /blogs/theband/1_hu6728190700059376434.jpg 660w,
        /blogs/theband/1_hu5333335250471856356.jpg 1024w,
        /blogs/theband/1_hu8413573821294788432.jpg 2x&#34;
        src=&#34;http://localhost:1313/blogs/theband/1_hu6728190700059376434.jpg&#34;
        alt=&#34;Img&#34;
      /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/blogs/theband/feature.jpg" />
    </item>
    
    <item>
      <title>2021 桌搭</title>
      <link>http://localhost:1313/blogs/desk2021/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/blogs/desk2021/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/blog/FoxCsgo/FoxCsgo-1.png&#34; alt=&#34;Img&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/blogs/desk2021/feature.jpg" />
    </item>
    
    <item>
      <title>5e 600分对决</title>
      <link>http://localhost:1313/blogs/5e600/</link>
      <pubDate>Tue, 12 Oct 2021 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/blogs/5e600/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img
        class=&#34;my-0 rounded-md&#34;
        loading=&#34;lazy&#34;
        srcset=&#34;
        /blogs/5e600/1_hu9666354151374759163.jpg 330w,
        /blogs/5e600/1_hu16441751272499849929.jpg 660w,
        /blogs/5e600/1_hu13471086248097805267.jpg 1024w,
        /blogs/5e600/1_hu2577903920060232791.jpg 2x&#34;
        src=&#34;http://localhost:1313/blogs/5e600/1_hu16441751272499849929.jpg&#34;
        alt=&#34;Img&#34;
      /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/blogs/5e600/feature.jpg" />
    </item>
    
    <item>
      <title>沙漠之狐</title>
      <link>http://localhost:1313/blogs/foxcsgo/</link>
      <pubDate>Fri, 03 Sep 2021 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/blogs/foxcsgo/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/blog/FoxCsgo/FoxCsgo-1.png&#34; alt=&#34;Img&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/blogs/foxcsgo/feature.png" />
    </item>
    
    <item>
      <title>小时候</title>
      <link>http://localhost:1313/blogs/qiuqiu/young/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/blogs/qiuqiu/young/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/blog/Qiuqiu/Young/Young-1.jpg&#34; alt=&#34;Img&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/blogs/qiuqiu/young/feature.jpg" />
    </item>
    
    <item>
      <title>小时候</title>
      <link>http://localhost:1313/blogs/zhuzi/young/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/blogs/zhuzi/young/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/blog/Zhuzi/Young/Young-1.jpg&#34; alt=&#34;Img&#34; /&gt;
      
    &lt;/figure&gt;


    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/blog/Zhuzi/Young/Young-2.jpg&#34; alt=&#34;Img&#34; /&gt;
      
    &lt;/figure&gt;


    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/blog/Zhuzi/Young/Young-3.jpg&#34; alt=&#34;Img&#34; /&gt;
      
    &lt;/figure&gt;


    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/blog/Zhuzi/Young/Young-4.jpg&#34; alt=&#34;Img&#34; /&gt;
      
    &lt;/figure&gt;


    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/blog/Zhuzi/Young/Young-5.jpg&#34; alt=&#34;Img&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/blogs/zhuzi/young/feature.jpg" />
    </item>
    
    <item>
      <title>Fundation Christams</title>
      <link>http://localhost:1313/blogs/fundationchristams/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/blogs/fundationchristams/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/blog/FundationChristams/FundationChristams-1.jpg&#34; alt=&#34;Img&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/blogs/fundationchristams/feature.jpg" />
    </item>
    
    <item>
      <title>Faker</title>
      <link>http://localhost:1313/credits/faker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/credits/faker/</guid>
      <description></description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/credits/faker/feature.jpg" />
    </item>
    
    <item>
      <title>SS</title>
      <link>http://localhost:1313/credits/ss/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/credits/ss/</guid>
      <description></description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/credits/ss/feature.jpg" />
    </item>
    
    <item>
      <title>法老</title>
      <link>http://localhost:1313/credits/%E6%B3%95%E8%80%81/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/credits/%E6%B3%95%E8%80%81/</guid>
      <description></description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/credits/%E6%B3%95%E8%80%81/feature.jpg" />
    </item>
    
    <item>
      <title>邓紫棋</title>
      <link>http://localhost:1313/credits/%E9%82%93%E7%B4%AB%E6%A3%8B/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>youremail@example.com (Buezwqwg)</author>
      <guid>http://localhost:1313/credits/%E9%82%93%E7%B4%AB%E6%A3%8B/</guid>
      <description></description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/credits/%E9%82%93%E7%B4%AB%E6%A3%8B/feature.jpg" />
    </item>
    
  </channel>
</rss>
