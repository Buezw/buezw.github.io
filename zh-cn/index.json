


[{"content":"","date":"Mar 21 2025","externalUrl":null,"permalink":"/tags/docs/","section":"Tags","summary":"","title":"Docs","type":"tags"},{"content":"","date":"Mar 21 2025","externalUrl":null,"permalink":"/docs/","section":"Docs","summary":"","title":"Docs","type":"docs"},{"content":"","date":"Mar 21 2025","externalUrl":null,"permalink":"/tags/ef/","section":"Tags","summary":"","title":"EF","type":"tags"},{"content":" Last Edit: 3/21/25\nCoulomb\u0026rsquo;s Law 库仑定律 #\r电荷之间相互作用力遵循的公式 Coulomb\u0026rsquo;s Law 描述了两个 Charged Partials 之间的 Electrostatic Force（或Electric Force） Electrostatic Force专指静止或相对静止的电荷之间的作用力 Electric Force则为更广义的术语，指电场对电荷施加的作用力\n$$ F = \\frac{1}{4 \\pi \\varepsilon_0} \\frac{|q_1||q_2|}{r^2} \\quad (\\text{Coulomb\u0026rsquo;s law}) $$\n\\(\\varepsilon_0 = 8.85 \\times 10^{-12} , \\text{C}^2/\\text{N} \\cdot \\text{m}^2\\) Vacancies Permittivity Constant 真空介电常数 Permittivity Constant 体现了材料对电场的响应能力。真空介电常数是固定值，而不同材料的介电常数决定了其在电场中的行为特性\n\\(\\frac{1}{4πε0}=k = 8.99 \\times 10^9 , \\text{N} \\cdot \\text{m}^2/\\text{C}^2\\) 通常被 Electrostatic constant 静电常数 \\(k\\) 替代 由于两个Charged Particle之间的作用力是一条直线，所以其Electrostatic Force Vector 要么直接指向第二个Particle（相反的电荷符号），要么直接远离第二个粒子（相同的电荷符号） 如果多个 Electrostatic Force 作用在一个粒子上，则 Net Force 是各个力的 Vector Sum ex. Electrostatic Force’s Net Force #\rIn the figure four particles form a square with edge length \\(a = 3.64 × 10⁻²\\) m. The charges are \\(q₁ = q₄ = 1.77 × 10⁻¹⁵\\) C and \\(q₂ = q₃ = q\\)\n(a) What is q if the net electrostatic force on particle 1 is zero?\nShell Theorem 壳定理 #\rShell Theorem #1 #\r对于一个带电粒子，如果它位于一个带电球壳的外部，且球壳的电荷均匀分布在表面上，该粒子受到的力等效于球壳的电荷全部集中在球壳的中心（即外部粒子感受到的电场与球壳的半径无关，只与球壳的总电荷有关） Shell Theorem #2 #\r对于一个带电粒子，如果它位于一个带电球壳的内部，且球壳的电荷均匀分布在表面上，那么该粒子不会受到来自球壳的净电场作用力。 （即在球壳内部，电场为零） Charge on Conducting Spherical Shell 导体球壳 #\r一个中空的球形壳体，由导电材料制成 在一个导体球壳上，Charges会均匀地分布在其外表面，而不是内表面，这是因为导体内电荷会相互排斥，最终达到平衡分布 Conductor \u0026amp; Insulator 导体和绝缘体 #\r我们通常可以根据Charge穿过它们的能力对材料进行分类 Conducting Path 传导路径 #\r用羊毛摩擦铜棒时，电荷会从羊毛转移到铜棒，使铜棒带电。 如果此时握着铜棒，并接触一个与金属管道相连的水龙头，那么铜棒cannot be charged，这是因为人、铜棒、水龙头与地球表面通过管道形成了一条导电路径。多余的电荷会通过这条路径流向地球（地球是一个巨大的导体）。因此，铜棒上的电荷会扩散到地球表面，最终使铜棒变得电中性。 Grounding 接地 #\r通过设置一条导体路径连接物体和地球，可以消除物体上的多余电荷，这个过程称为Grounding Discharge 放电 #\r这一个Grounding的将Exceed的Charge Neutralize的过程被称为Discharge Charged Particles 带电粒子 #\r原子由带正电的质子、带负电的电子和电中性中子组成 质子和中子紧密地堆积在一个原子核中 单个电子的电荷和单个质子的电荷具有相同的大小，但符号相反 Conduction electrons 价电子 #\r在导体中Conduction electrons（价电子）因其与原子核的吸引力较弱而变得自由移动。 当导体原子形成固体结构时，这些导电电子在导体中形成“电子海”，可以在整个导体内自由流动 而在在绝缘体中，原子的电子与原子核结合得非常紧密，几乎没有自由电子 Induced Charge 感应电荷 #\rInduced Charge指的是由于邻近电荷的影响，导体内的电荷重新分布，形成正负电荷分离的现象 如图将一个Charged Plastic Rod放置到Neutral的Copper Rod旁边，Positive Charge将会被吸引到Copper Rod的左侧，Negative Charge则会被排斥到右侧，此时虽然Copper Rod是Neutral的，但其有一个 Induced Charge 感应电荷 需要注意的是，在Induced Charge形成的过程中，并不是Positive Charge移动了，而是因为原来均匀分布在整个Copper Rod上的Positive \u0026amp; Negative Charge中的Negative Charge移动了，所以才会有Positive Charge的出现 换句话说，Positive Charge不是“增加”来的，而是因为失去了Negative Charge，所以显得“正” Charge is Quantized 量化电荷 #\r在Benjamin Franklin的时代，电荷被认为是一种连续的流体——这个想法有很多用途。然而，我们现在知道流体本身，例如空气和水，不是连续的，而是由原子和分子组成的;物质是离散的 实验表明，Electrical fluid也不是连续的，而是由某种基本电荷的倍数组成。任何可以检测到的正电荷或负电荷 q 都可以写成 $$ q = n e, \\quad n = \\pm 1, \\pm 2, \\pm 3, \\ldots $$\nCharge of three Particles #\rParticle Symbol Charge Antiparticle Symbol Charge Electron e or e⁻ -e Positron e⁺ +e Proton p +e Antiproton p̅ -e Neutron n 0 Antineutron n̅ 0 Electron的Symbol为e是因为其通常表示电子作为一种粒子的名称，而不特别强调它的电荷性质\nCharge on two quarks #\rQuark Symbol Charge Antiparticle Symbol Charge Up u \\(+\\frac{2}{3}e\\) Antiup \\(\\bar{u}\\) \\(-\\frac{2}{3}e\\) Down d \\(-\\frac{1}{3}e\\) Antidown \\(\\bar{d}\\) \\(+\\frac{1}{3}e\\) 由于Quark不能单独存在（被限制在强相互作用中），我们通常不将它们的电荷视为基本电荷 Charge is Conserved 电荷守恒 #\r摩擦不会产生电荷，而只会将其从一个物体转移到另一个物体，从而在此过程中破坏每个物体的电中性 任何孤立系统的净电荷总是守恒的，无论系统内部发生什么变化（如粒子的生成、湮灭或分裂），系统的总电荷量不会改变，下面给出一些常见的例子说明这一现象 Electron Capture 电子捕获 #\r母核中的质子“捕获”原子的一个内部电子以形成中子（保留在子核中）并释放中微子 $$ p + e^- \\rightarrow n + \\nu $$\n","date":"Mar 21 2025","externalUrl":null,"permalink":"/docs/electrical-fundamentals/ef1.coulombslaw/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/21/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eCoulomb\u0026rsquo;s Law 库仑定律 \r\n    \u003cdiv id=\"coulombs-law-%E5%BA%93%E4%BB%91%E5%AE%9A%E5%BE%8B\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#coulombs-law-%E5%BA%93%E4%BB%91%E5%AE%9A%E5%BE%8B\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e电荷之间相互作用力遵循的公式\u003c/li\u003e\n\u003cli\u003eCoulomb\u0026rsquo;s Law 描述了两个 Charged Partials 之间的 Electrostatic Force（或Electric Force）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/electrical-fundamentals/ef1.coulombslaw/image_hu7098555360533024946.png 330w,\r\n        /docs/electrical-fundamentals/ef1.coulombslaw/image_hu7648078660818927912.png 660w,\r\n        /docs/electrical-fundamentals/ef1.coulombslaw/image_hu3052726973708541951.png 1024w,\r\n        /docs/electrical-fundamentals/ef1.coulombslaw/image_hu8723941724131963656.png 2x\"\r\n        src=\"/docs/electrical-fundamentals/ef1.coulombslaw/image_hu7648078660818927912.png\"\r\n        alt=\"image.png\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 1. Coulomb's Law Edited","type":"docs"},{"content":" Last Edit: 3/21/25\nElectric Field 电场 #\r在科学中存在多个 Field的概念，其中包含了 Teperature Field，Pressure Field 等 而 Electric Field 则是一个 Vector Field，矢量场，其包含了大小与方向 具体来说，定义 Electric Field的方式是在 Electric Field \\(\\vec{E}\\) 的某个点 P 处放置一个 Small Positive Charge 的 \\(q_0\\)，其为 Test Charge We want the charge to be small so that it does not disturb the object’s charge distribution\nElectric Field Strength 电场强度 #\r一个表示电场强弱的物理量 电场 \\(\\vec{E}\\) 在点 P 由带电对象产生，对试验电荷 \\(q_0\\) 产生了静电力 \\(\\vec{F}\\) 由于 \\(p_0\\) 是一个正的Charge，所以电场的方向是电力的方向，而电场的大小有 $$ \\vec{E} = \\frac{\\vec{F}}{q_0} $$\nElectric Field 的国际单位系统 (SI) 单位是牛顿每库仑（N/C） Electric Field Lines 电场线 #\r由于需要一种方式可视化电场，Eletric Field Lines出现了 Electric Field Line 的方向是由正电荷指向负电荷 根据 Electric Field 的性质，电场线的密集程度反映了电场的强度。电场线越密集，电场强度越大 ex. Graph Interpretation of Electric Field #\rIn the figure the electric field lines on the left have twice the separation as those on the right. (a) If the magnitude of the field at A is 39 N/C, what is the magnitude of the force on a proton at A? (b) What is the magnitude of the field at B?\nThe Electric Field Due to a charged Particle #\r为了找到 Charged Particle（通常称为点电荷）产生的 Electric Field，我们在粒子距离 r 的位置放置一个正测试电荷 前面知道 Coulomb\u0026rsquo;s Law 有 $$ F = \\frac{1}{4 \\pi \\varepsilon_0} \\frac{|q||q_0|}{r^2} $$\n将 \\(\\vec F\\) 代入到 \\(\\vec E\\) 中便可以得到 $$ \\vec{E} = \\frac{\\vec{F}}{q_0} = \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r^2}\\quad \\text{(charged particle)} $$\nPrinciple of superposition 电场的叠加原理 #\r如果在某点有多个电荷产生的电场，可以通过叠加原理来计算该点的总电场。文中用到了叠加原理，表达式为 $$ \\vec{E} = \\vec{E}_1 + \\vec{E}_2 + \\cdots + \\vec{E}_n $$\n这说明总电场是各个单独电场向量的矢量和 ex. Electric Field Superposition #\rIn the figure the four particles are fixed in place and have charges \\(q_1 = q_2 = 4e\\), \\(q_3 = 2e\\), and \\(q_4 = -8e\\). Distance d=4.75d = 4.75 µm. What is the magnitude of the net electric field at point P due to the particles?\nA Point Charge in an Electric Field #\r当一个 Particle 有着 q 的 Charge 被放置在 Electric Field \\(\\vec E\\) 中的时候，Electric Field 会对其产生\\(\\vec F=q\\vec E\\) 的Electrostatic Force Millikan Oil-drop Experiment #\r罗伯特·A·密立根在1910年进行的著名实验油滴实验，用于测量电子的基本电荷e ","date":"Mar 21 2025","externalUrl":null,"permalink":"/docs/electrical-fundamentals/ef2.electricfield/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/21/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eElectric Field 电场 \r\n    \u003cdiv id=\"electric-field-%E7%94%B5%E5%9C%BA\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#electric-field-%E7%94%B5%E5%9C%BA\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e在科学中存在多个 Field的概念，其中包含了 Teperature Field，Pressure Field 等\u003c/li\u003e\n\u003cli\u003e而 Electric Field 则是一个 Vector Field，矢量场，其包含了大小与方向\u003c/li\u003e\n\u003cli\u003e具体来说，定义 Electric Field的方式是在 Electric Field \\(\\vec{E}\\) 的某个点 P 处放置一个 Small Positive Charge 的 \\(q_0\\)，其为 Test Charge\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003eWe want the charge to be small so that it does not disturb the object’s charge distribution\u003c/p\u003e","title":"EF 2. Electric Field Edited","type":"docs"},{"content":"","date":"Mar 21 2025","externalUrl":null,"permalink":"/docs/electrical-fundamentals/","section":"Docs","summary":"","title":"Electrical Fundamentals","type":"docs"},{"content":"","date":"Mar 7 2025","externalUrl":null,"permalink":"/tags/c/","section":"Tags","summary":"","title":"C","type":"tags"},{"content":" Last Edit: 3/7/25\nNode Analysis #\r在 Kirchhoff\u0026rsquo;s Voltage Law, KVL 中，规定了在一个完整的 Closed loop 中，所有 Voltage rises 和Voltage drops 的代数和必须等于零 这是因为电压是势能差，一个完整的回路回到起点后，总能量变化应该为零，这是电荷守恒和能量守恒的直接体现 然而，对于 Partial path 或 Non-closed segment 非闭合段，其电压之和不一定为零，而是等于这些局部路径两端 Node 的电压差 以上图为例，在 Node 1 到 2 之间，Potential Difference 为 \\(V_s=V_1+V_a\\) 而需要注意的是，在 Node Analysis 中，由 Battery 提供的初始 Voltage 被视为负值，有 \\(-V_s+V_1+V_a=0\\) 这是因为，当电路闭合的时候，Battery 推动 Electron 从负极向正极移动，并且在到达正极的时候获取了最高的 Electric Potential，之后在通过 Resistor 和其他负载的时候，Electron 会消耗这些 Potential Energy 以克服阻力，这视为 Potential 的下降 但是规定的符号与能量变换相反，即 Battery 提供 Electric Potential 的过程视为负号，用电器小号 Potential 的过程视为正号 总结上图中的 \\(V_1,V_3,V_5\\)，可以得出 $$ I_1 = \\frac{V_1}{9k} = \\frac{V_s - V_a}{9k},I_3 = \\frac{V_3}{3k} = \\frac{V_a - V_b}{3k},I_5 = \\frac{V_5}{9k} = \\frac{V_b - V_c}{9k} $$\n对于 \\(6k\\Omega\\) 和 \\(4k\\Omega\\) 来说，由于 Ground 是电路中所有 Node Potential 的参考零点，所以其本身为 0 V，也就是说 \\(0=V_a-V_{6k\\Omega}\\)，而它所对应的 Current 也就是 $$ I_2=\\frac{V_{6k\\Omega}}{6k}=\\frac{V_a-0}{6k} $$\nPD \u0026amp; Current Direction #\r现在有以下 Circuit Voltage 即 Potential Difference 是一个参考量，即根据参考点的不同具有不同的数据，图中的 4 V 和 -2 V 即为相较于 Ground 也就是 0 V 参考的 而 Current 的 Direction 又和 Fragment 两端的 Node 的 Potential Difference 有关，呈现出的规律为 Current Will flow from higher to lower potential 在这张图中即为，R1 从上往下，R2 从左往右，R3 从下往上 Circuits containing only Independent Current Sources #\r在没有 Voltage Source 而是 Current Source 的时候，Circuit 的行为主要由 Current Source 驱动，而不是 Voltage Source 上图中即存在两个 Current Source，\\(i_A\\) 和 \\(i_B\\) 而对于 Node 来说，Node 1 根据 KCL 有 \\(i_A=i_1+i_2\\)，Node 2 有 \\(i_2=i_B+i_3\\) 现在进一步假设 \\(I_A = 1,mA, R_1 = 12,k\\Omega, R_2 = 6,k\\Omega, I_B = 4,mA, R_3 = 6,k\\Omega\\) 已知 \\({i}_1 = \\frac{v_1}{R_1},{i}_2 = \\frac{v_1 - v_2}{R_2},{i}_3 = \\frac{v_2}{R_3}\\)，将他们带入原来的 Equation 中，有 $$ i_A = \\frac{v_1}{R_1} + \\frac{v_1 - v_2}{R_2},i_B = \\frac{v_1 - v_2}{R_2} + \\frac{v_2}{R_3} $$\n带入数据得到 $$ 1\\times 10^3=\\frac{v_1}{12k}+\\frac{v_1-v_2}{6k},-4\\times10^3=\\frac{v_1-v_2}{6k}=\\frac{v_2}{6k} $$\n解方程组后可以得到 \\(V_1=-6V,V_2=-15V\\)，也就可以对应解出 \\(I_1,I_2\\) 了 同时也可以发现，如果一个 Circuit 中有 N 个 Node，则对应存在 N-1 个 Equation 需要解\n","date":"Mar 7 2025","externalUrl":null,"permalink":"/docs/electrical-fundamentals/ef10.nodalandloopanalysis/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/7/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eNode Analysis \r\n    \u003cdiv id=\"node-analysis\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#node-analysis\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e在 Kirchhoff\u0026rsquo;s Voltage Law, KVL 中，规定了在一个完整的 Closed loop 中，所有 Voltage rises 和Voltage drops 的代数和必须等于零\u003c/li\u003e\n\u003cli\u003e这是因为电压是势能差，一个完整的回路回到起点后，总能量变化应该为零，这是电荷守恒和能量守恒的直接体现\u003c/li\u003e\n\u003cli\u003e然而，对于 \u003cstrong\u003ePartial path\u003c/strong\u003e 或 \u003cstrong\u003eNon-closed segment\u003c/strong\u003e 非闭合段，其电压之和不一定为零，而是等于这些局部路径两端 Node 的电压差\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/electrical-fundamentals/ef10.nodalandloopanalysis/image_hu14836653746222108356.png 330w,\r\n        /docs/electrical-fundamentals/ef10.nodalandloopanalysis/image_hu13701235930078814582.png 660w,\r\n        /docs/electrical-fundamentals/ef10.nodalandloopanalysis/image_hu13007749878243609150.png 1024w,\r\n        /docs/electrical-fundamentals/ef10.nodalandloopanalysis/image_hu2375413442522557764.png 2x\"\r\n        src=\"/docs/electrical-fundamentals/ef10.nodalandloopanalysis/image_hu13701235930078814582.png\"\r\n        alt=\"image.png\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 10. Nodal and Loop Analysis","type":"docs"},{"content":"https://learningc.org/cover\n","date":"Mar 7 2025","externalUrl":null,"permalink":"/docs/learning-programming-with-c/","section":"Docs","summary":"\u003cp\u003e\u003ca href=\"https://learningc.org/cover\" target=\"_blank\"\u003ehttps://learningc.org/cover\u003c/a\u003e\u003c/p\u003e","title":"Learning Programming with C","type":"docs"},{"content":"","date":"Mar 7 2025","externalUrl":null,"permalink":"/tags/lpc/","section":"Tags","summary":"","title":"LPC","type":"tags"},{"content":" Last Edit: 3/7/25\n前面提到过了 Array 中的 Memory 的分配方式是固定的连续内存，而想要修改 Array 的大小则变得困难，这时候就需要通过 Dynamic Memory Allocation 来动态的分布内存\n8.1 Dynamic Memory Allocation #\rDynamic Memory Allocation 的核心就是在 Runtime 即时分配内存空间的过程，分配的内存量在编译时不需要预先知道 8.1.1 Different Options when array size is unknown #\r一种可以采取的方法就是直接给一个非常大的 Array size，但这不可避免的会造成浪费 一般来说，一个程序的 Main Memory 主要会被分成四个主要部分 Code #\r代码段负责储存代码 Const + Global #\r所有的程序常量和变量都会被存储在这 Heap #\r储存动态分配的内存 Stack #\r储存 function 的局部变量，如果一个函数调用另一个函数，他的局部变量会被储存于此 Stack Overflow 栈溢出 #\r当 Stack 部分的 Memory 被耗尽的情况下，没有更多空间的时候会报的错 Variable Size Array #\rArray 的大小可以被用一个 Variable 决定，这是一种灵活的分配方式，根据需要分配实际大小，以下是一种示例 #include \u0026lt;stdio.h\u0026gt; int main(void) { int size; printf(\u0026#34;Enter size of array: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;size); int arr[size]; printf(\u0026#34;Array allocated from %p to %p\u0026#34;, arr, arr+size); return 0; } 使用这种方式，即使使用了 Variable 决定 Array 的 Size，其本质上还是在 Array 上分配的，如果 Stack 的空间不足后，还是会报错 Dynamically Allocate Memory #\r通过将 Memory 放置到 heap 上，这需要 stdlib.h: malloc 库里的内容 malloc(size_t size)会分配指定字节数的内存块，并返回指向该内存块首地址的指针。如果分配失败，返回NUL 当使用malloc为数组分配内存时，需要指定分配的总字节数，通常是数组元素的数量乘以单个元素的大小 例如，要为5个 int 分配内存，可以使用表达式malloc(5 * sizeof(int)) Memory Leak #\r在 Dynamic 分配完了 Memory 后，临时放置在 Stack 中的储存 malloc 中第一个 Element 的 Pointer 也会消失，而这时候如果没有收回之前分配的 Memory，会导致 Memory Leak #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; double getAverage(int); int main(void) { int size; printf(\u0026#34;Enter size of array:\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;size); double avg = getAverage(size); printf(\u0026#34;Average is %.2lf\\n\u0026#34;, avg); return 0; } double getAverage(int size) { int* myArray = (int*)malloc(size * sizeof(int)); printf(\u0026#34;Enter grades:\u0026#34;); for (int index = 0; index \u0026lt; size; index++) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;myArray[index]); } int sum = 0; for (int index = 0; index \u0026lt; size; index++) { sum += myArray[index]; } return (double)sum / size; } 简单来说，由于 Pointer 的丢失，已经无法再次访问这个 Array，但是其还在那个地方，会导致 1. 无法再次访问，2. 空间仍然被占用 一个合理的解决方案就是在 return 之前将已有的空间收回，也就是 free free 的 Prototype 为 void free(void *pointer); free函数用于释放 malloc 分配的内存，它接受一个指向要释放内存的 Pointer，并释放该内存块，但是一旦 Memory 被释放，原有的指针变量仍然存在，但其指向的是一个不再有效的内存区域，这时候需要将 Pointer 设置为 Null #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; double getAverage(int); int main(void) { int size; printf(\u0026#34;Enter size of array:\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;size); double avg = getAverage(size); printf(\u0026#34;Average is %.2lf\\n\u0026#34;, avg); return 0; } double getAverage(int size) { int* myArray = (int*)malloc(size * sizeof(int)); printf(\u0026#34;Enter grades:\u0026#34;); for (int index = 0; index \u0026lt; size; index++) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;myArray[index]); } int sum = 0; for (int index = 0; index \u0026lt; size; index++) { sum += myArray[index]; } free(myArray); myArray = NULL; return (double)sum / size; } ","date":"Mar 7 2025","externalUrl":null,"permalink":"/docs/learning-programming-with-c/lpc8.dynamicmemoryallocation/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/7/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e前面提到过了 Array 中的 Memory 的分配方式是固定的连续内存，而想要修改 Array 的大小则变得困难，这时候就需要通过 Dynamic Memory Allocation 来动态的分布内存\u003c/p\u003e","title":"LPC 8. Dynamic Memory Allocation ","type":"docs"},{"content":"","date":"Mar 6 2025","externalUrl":null,"permalink":"/tags/cal/","section":"Tags","summary":"","title":"Cal","type":"tags"},{"content":"Calculus\n","date":"Mar 6 2025","externalUrl":null,"permalink":"/docs/calculus/","section":"Docs","summary":"\u003cp\u003eCalculus\u003c/p\u003e","title":"Calculus","type":"docs"},{"content":" Last Edit: 3/6/25\nIntegration by part #\r当 Integral 内存在两个函数的乘积的时候，可以使用 Integration by parts 已知有 Derivative\u0026rsquo;s Product Rule $$ \\left( u(x) v(x) \\right)\u0026rsquo; = u\u0026rsquo;(x) v(x) + u(x) v\u0026rsquo;(x) $$\n将两边同时积分可以得到 $$ \\int u(x) v\u0026rsquo;(x) ,dx = \\int (u(x) v(x))\u0026rsquo; ,dx - \\int v(x) u\u0026rsquo;(x) ,dx $$\n等式右边的第一项化简后可以得到 $$ \\int u(x) v\u0026rsquo;(x) ,dx = u(x) v(x) - \\int v(x) u\u0026rsquo;(x) ,dx $$\n于是就得到了 Integral By Parts 的公式 $$ \\int u ,dv = uv - \\int v ,du $$\n在得到了处理 Integral 内部有乘积时候的公式后，只需要选择乘积中的一个作为 u，另一个作为 v，并对一个求导，一个积分就可以得到 Integral By Parts 的结果了 Guidelines for Integration by Parts #\ru 和 v 的选择直接关系到了 Integral By Parts 的难度 u求导后应该比u简单 dv积分后应该比v简单 通常使用 LIATE 法则（Logarithmic, Inverse trig, Algebraic, Trigonometric, Exponential） 优先选择 LIATE 顺序靠前的函数作为 u，然后把剩下的部分作为 dv\nex. Integral By Parts #\r考虑积分 $\\int xe^{2x}dx$\n在这里由于 e 的特殊性质，应该求 x 的 Derivative，求 dv 的 Integral，求出 $x\u0026rsquo;=1,\\int e^{2x}dx=\\frac{1}{2}e^{2x}$，可以得到 $$ \\underbrace{x \\frac{1}{2} e^{2x}}{uv} - \\int \\underbrace{\\frac{1}{2} e^{2x}}{v} \\underbrace{dx}_{du} $$\n再求得 $vdu$ 项的积分有 $$ \\int xe^{2x}dx=\\int \\underbrace{x}{u} \\underbrace{e^{2x} ,dx}{dv} = \\underbrace{x \\frac{1}{2} e^{2x}}{uv} - \\int \\underbrace{\\frac{1}{2} e^{2x}}{v} \\underbrace{dx}_{du} = \\frac{1}{2} x e^{2x} - \\frac{1}{4} e^{2x} + C $$\nex. Getting the original Integral #\r求 $\\int x^2 sinx dx$\n令 $x^2$ 为 u, sinx 为 dv $$ \\int x^2 \\sin x ,dx = -x^2 \\cos x + \\int 2x \\cos x ,dx= -x^2 \\cos x + x^2 \\cos x + \\int x^2 \\sin x ,dx $$\n化简后发现得到了 $$ \\int x^2 \\sin x ,dx=\\int x^2 \\sin x ,dx $$\nTabular Method #\r当一个 Integral 中两个函数相乘的时候，如果其中一个能在有限次数的求导内得到0，便可以使用 Tabular Method 左边必须是 Alternate Sign，从 + 开始，对 u 反复求导，对 dv 反复积分，最终将 u 乘以 dv，然后将所有项包含正负号加在一块就是答案 Trigonometric Substitute #\r三角恒等式可以将 Integral 中的根号表达式通过如 $1 - \\sin^2\\theta = \\cos^2\\theta$ 的简单形式，从而让积分变得更容易计算，特别是对于以下三种形式 $$ \\sqrt{a^2 - x^2} → 令~ x=asinθ \\ \\sqrt{a^2 + x^2}→ 令 x=atanθ \\ \\sqrt{x^2 - a^2} → 令x=asecθ $$\n\\sqrt{a^2 - x^2} 的积分 #\r对于积分 $\\int \\frac{dx}{\\sqrt{a^2 - x^2}}$ 因为 $x=asin⁡θ,dx=acos⁡θ$ 有三角恒等式 $1 - \\sin^2\\theta = \\cos^2\\theta$ 可以得到 $\\sqrt{a^2 - x^2} = a \\cos\\theta$ 这里的 a 是为了化简根号中的被减数的\nex. #\r有 Integral $\\int \\frac{dx}{\\sqrt{4 - x^2}}$\n观察发现 Constant Term 是被减数，可以使用的三角恒等式为 $1 - \\sin^2\\theta = \\cos^2\\theta$，令 $x=2sin⁡θ,dx=2cos⁡θ$ 将 x 带入之后可以得到 $$ \\sqrt{4-4\\sin^2\\theta}\\Rightarrow \\sqrt{4(1-\\sin^2\\theta)}=2\\cos\\theta $$\n带入后可以得到 $$ \\int \\frac{2\\cos\\theta , d\\theta}{2\\cos\\theta} = \\int d\\theta = \\theta + C $$\n已知 $\\theta = \\arcsin\\frac{x}{2}$ $$ \\int \\frac{dx}{\\sqrt{4 - x^2}} = \\arcsin\\frac{x}{2} + C $$\n\\sqrt{a^2 + x^2} #\r对于形如 $\\int \\frac{dx}{\\sqrt{a^2 + x^2}}$ $$ x=atan⁡θ,dx=asec⁡^2θ dθ $$\n观察发现可以使用三角恒等式 $1 + \\tan^2\\theta = \\sec^2\\theta$，和上面一样可以得到 $$ \\sqrt{a^2 + x^2} = a \\sec\\theta $$\nex. #\r$$ \\int \\frac{dx}{\\sqrt{9 + x^2}} $$\n观察发现 Constant Term 为 9，并且根号内为加法，可以使用 $1 + \\tan^2\\theta = \\sec^2\\theta$，替换 $x=3tan⁡θ,dx=3sec⁡2θ dθ$ $$ \\sqrt{9 + x^2} = 3\\sec\\theta \\int \\frac{3\\sec^2\\theta , d\\theta}{3\\sec\\theta} = \\int \\sec\\theta , d\\theta= \\ln | \\sec\\theta + \\tan\\theta | + C $$\n最后可以得到 $$ \\int \\frac{dx}{\\sqrt{9 + x^2}} = \\ln \\left| \\frac{\\sqrt{9 + x^2}}{3} + \\frac{x}{3} \\right| + C $$\n\\sqrt{x^2 - a^2} 的积分 #\r对于形如 $\\int \\frac{dx}{\\sqrt{x^2 - a^2}}$，和前面的都一样，有 $$ x = a \\sec\\theta, \\quad dx = a \\sec\\theta \\tan\\theta , d\\theta $$\n使用三角恒等式 $$ \\sec^2\\theta - 1 = \\tan^2\\theta \\Rightarrow \\sqrt{x^2 - a^2} = a \\tan\\theta $$\nex. #\r解 $\\int \\frac{dx}{\\sqrt{x^2 - 16}}$\n观察得到 Constant 是减数，而根式内是减号，观察可以使用 $\\sec^2\\theta - 1 = \\tan^2\\theta$，令 $x = 4\\sec\\theta, \\quad dx = 4\\sec\\theta \\tan\\theta , d\\theta$ $$ \\int \\frac{4\\sec\\theta \\tan\\theta , d\\theta}{4\\tan\\theta} = \\int \\sec\\theta , d\\theta\\ln | \\sec\\theta + \\tan\\theta | + C $$\nSummary #\r根式形式 代换方式 结果表达式 $\\sqrt{a^2 - x^2}$ $x = a\\sin\\theta$ $\\sqrt{a^2 - x^2} = a\\cos\\theta$ $\\sqrt{a^2 + x^2}$ $x = a\\tan\\theta$ $\\sqrt{a^2 + x^2} = a\\sec\\theta$ $\\sqrt{x^2 - a^2}$ $x = a\\sec\\theta$ $\\sqrt{x^2 - a^2} = a\\tan\\theta$ Partial Fraction #\r对于一个分式 $$ \\int\\frac{1}{x^2-5x+6}dx $$\n无法对其直接做积分，于是可以通过 Partial Fraction 化简 Partial Fraction #\r对于一个分式，如果分母可以因式分解成不同的一次因式，如下形式 $$ \\frac{P(x)}{(x-a)(x-b)} $$\n那么它就可以化简为 Partial Fraction $$ \\frac{P(x)}{(x-a)(x-b)} = \\frac{A}{x-a} + \\frac{B}{x-b} $$\n接下来就需要更具步骤依次求解 A 和 B 首先将等式两边分别通分，可以得到 $$ P(x)=A(x-b)+B(x-a) $$\n现在的阶段，a 和 b 是 Constant，设 x = b 就可以解出 B，令 x = a 就可以解出 A ex. #\r因式分解 $\\frac{3x + 5}{(x-1)(x+2)}$\n$$ \\frac{3x + 5}{(x-1)(x+2)} = \\frac{A}{x-1} + \\frac{B}{x+2} $$\n通分得到 $$ 3x+5=A(x+2)+B(x-1) $$\n令 $x=-2$，有 $-1=-3B \\Rightarrow B = \\frac{1}{3}$ ，同理解出 $A=\\frac{8}{3}$ ex. Quadratic Factors #\r现在有 $\\frac{2x^3 - 4x - 8}{(x^2 - x)(x^2 + 4)} , dx$\n化简分母 $(x^2 - x)(x^2 + 4) = x(x - 1)(x^2 + 4)$ 当分母中出现二次不可约因子（即不能因式分解为两个一次因子），对应的分子必须是一次多项式，即 Cx + D 通过 Partial Fraction 可以得到 $$ \\frac{2x^3 - 4x - 8}{x(x - 1)(x^2 + 4)} = \\frac{A}{x} + \\frac{B}{x - 1} + \\frac{Cx + D}{x^2 + 4} $$\n通分后可以得到 $$ 2x^3 - 4x - 8 = A(x - 1)(x^2 + 4) + Bx(x^2 + 4) + (Cx + D)(x)(x - 1) $$\n用普通方式计算 A 和 B $x=0\\Rightarrow A=2, x=1 \\Rightarrow B =-2$ 现在将 A，B 和两个任意的 $x\\neq 0,1$ 带入原式后就可以得到一个二元一次方程组，之后就可以解出 C 和 D 了 Improper Integrals #\r在 Integral 被定义的时候，限制了他的 a 和 b 需要是一个有限的值，而有的时候上下界不可避免的会出现 Infinite 的情况，这就需要 Improper Integral 简单来说 Improper Integral 就是给 Integral 前面添加一个 Limit，在这之外就没有其他的变化 $$ \\int_{a}^{\\infty} f(x) , dx = \\lim_{b \\to \\infty} \\int_{a}^{b} f(x) , dx $$\nex. #\r计算积分 $\\int_{1}^{\\infty} \\frac{dx}{x}dx$\n通过 $\\lim_{b\\rightarrow \\infty}$ 替换上界，有 $$ \\int_{1}^{\\infty} \\frac{dx}{x} = \\lim_{b \\to \\infty} \\int_{1}^{b} \\frac{dx}{x}= \\lim_{b \\to \\infty} \\left[ \\ln x \\right]{1}^{b} = \\lim{b \\to \\infty} (\\ln b - 0) = \\infty $$\n","date":"Mar 6 2025","externalUrl":null,"permalink":"/docs/calculus/calculus8.methodsofintegration/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/6/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eIntegration by part \r\n    \u003cdiv id=\"integration-by-part\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#integration-by-part\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e当 Integral 内存在两个函数的乘积的时候，可以使用 Integration by parts\u003c/li\u003e\n\u003cli\u003e已知有 Derivative\u0026rsquo;s Product Rule\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e$$\n\\left( u(x) v(x) \\right)\u0026rsquo; = u\u0026rsquo;(x) v(x) + u(x) v\u0026rsquo;(x)\n$$\u003c/p\u003e","title":"Calculus 8. Methods of Integration","type":"docs"},{"content":"\rEF9.ResistiveCircuits #\rLast Edit: 3/3/25\nOhm’s Law #\rOhm’s Law是以德国物理学家 Georg Simon Ohm 的名字命名的，他确立了 Voltage 和 Current 之间的关系，其发现了 Resistor 两端的 Voltage 和通过的 Current 成正比 Symbol for a Resistor #\rMathematical Relationship #\rOhm\u0026rsquo;s Law 指出 $$ v(t) = Ri(t), \\text{ where } R \\geq 0 $$\n其中 Ohms 的符号为 \\(\\Omega,1\\Omega=1V/A\\) Graphical representation of V vs. I #\r不同用电器有着不同的 Voltage-Current Relationship 一个线性电阻器 一个 Light Bulb 的则是非线性的关系 Conductance 电导 #\rConductance 由符号 G 表示，其是 Resistor 的倒数 它的单位是 Siemens，有 \\(1S=1A/V\\) Power Relationships #\rPower 的最基础的定义为 W = VI，也就是 $$ p(t) = v(t) i(t) $$\n当把 \\(V=Ri\\) 带入，有 $$ p(t) = Ri^2(t) = \\frac{v^2(t)}{R} $$\n带入 Conductance \\(i(t) = Gv(t)\\) 可以得到 $$ p(t) = \\frac{i^2(t)}{G} = Gv^2(t) $$\nConductor\u0026rsquo;s Influence in Circuit #\r对于一个位于 Circuit 中的 Resistor 来说，其可以通过变换对 Circuit 整体造成不同的影响 如上图所示，当 Resistor 减小到零的时候，电源两端直接连线，形成 Short Circuit 而到了 C 中，Resistor 增大到无限大时，形成 Open Circuit Kirchhoff\u0026rsquo;s Laws #\rKirchhoff\u0026rsquo;s Laws 具体表现为 Kirchhoff\u0026rsquo;s Current Law 和 Kirchhoff\u0026rsquo;s Voltage Law KCL Current Law #\r对于一个 Circuit 中的 Node 来说，其 Algebraic Sum of the Current leaving or entering a node is zero，说明从节点流出或流入的电流 之代数和为零 想要解决 Circuit 中每一个 Node 的 Current 的办法就是通过解线性方程组，而并不是每一个节点的 Equation 都在 System 中是 Linearly Independent 的，这说明仅需要选择线性独立的方程来进行分析 Kirchhoff’s Voltage Law #\rKVL 指出，在任何闭合回路中，电压的代数和必须为零 Voltage Division #\r在 Series, Parallel Circuit 中，需要进一步通过 Current 和 Voltage 在不同情况下的性质在写出 Linear Equation 后进一步求解 当 Circuit 中存在一个 Series 的时候，可以得到d $$ -v(t) + v_{R1} + v_{R2} = 0\\Rightarrow v(t) = v_{R1} + v_{R2} $$\n根据 Ohm\u0026rsquo;s Law 可以知道，\\(v_{R1} = R_1i(t),v_{R2} = R_2i(t)\\)，有 \\(v(t)=R_1i(t)+R_2i(t)\\)，可以解出 \\(i(t) = \\frac{v(t)}{R_1 + R_2}\\) 带回 \\(v_{R_1}=R_1 i(t)\\) 后可以得到 $$ = R_1 \\left[ \\frac{v(t)}{R_1 + R_2} \\right] = \\frac{R_1}{R_1 + R_2} v(t) $$\nMultiple-Source/Resistor Networks #\r有的时候的 Circuit 会非常复杂，比如存在多个 Voltage Sources 的情况，这时候就需要通过 Simplified Equivalent Circuit 来分析 Circuit 上图中，a 存在了多个 Voltage Sources 和 Resistors，沿着 Closed Loop 列出所有 KVL 方程 \\(+vR1+v2(t)−v3(t)+vR2+v4(t)+v5(t)−v1(t)=0\\)，将所有非 Resistor 的 Voltage 移动到等式右边，有 \\(vR1+vR2=v1(t)−v2(t)+v3(t)−v4(t)−v5(t)\\) 根据 KVL ，就可以创建一个 \\(R_S=R_1+R_2+R_3+R_4+R_5\\) 的等效电路 于是就把整个 Circuit 化简为了 b 中的等效电路 ex. Find Voltage in a fragment #\r有以下图 a，求 bd 段的等效电路\n在同时存在 Resistor 和 Battery 的情况下，要先求得他们的 Current （串联分压不分流） 根据 KVL，有 $$ 10kI + 20kI + 12 + 30kI - 6 = 0\\Rightarrow60kI = -6 \\Rightarrow I = -0.1 , \\text{mA} $$\nbd 段的 Voltage 自然可以通过 \\(10kI + V_{bd} + 30kI - 6 = 0\\) 得到，代入 \\(I = -0.1 , \\text{mA}\\) 后得到 \\(V_{bd}=10V\\) ex2. #\r求出 \\(V_S\\) 段的 Voltage\n已知 Parallel Circuit 分流不分压，有 \\(I_L=458.3/220=2.083~kA\\) 后面又进入了一个 Series Circuit，有 \\(V_{line}=20\\cdot 2. 083=41.66 ~kV\\) 根据 KVL，可以得到 \\(V_S=V_{line}+V_{load}=500 ~kV\\) Single-Node-Pair Circuits #\r串联分压，并联分流的原理也可以通过 KVL 进一步验证 对于上面的电路，有 $$ i(t) = \\frac{v(t)}{R_1} + \\frac{v(t)}{R_2} = \\left( \\frac{1}{R_1} + \\frac{1}{R_2} \\right) v(t) = \\frac{v(t)}{R_p} $$\n能总结出公式为 $$ i_1(t) = \\frac{v(t)}{R_1}\\Rightarrow i_1(t) = \\frac{R_2}{R_1 + R_2} i(t) $$\n可以用于计算 Parallel Circuit 中的 Current Multiple-Source/Resistor Networks #\r对于具有 n 个 Parallel Resistor 的 Circuit，根据 KVL 可以得出 $$ i_0(t) = i_1(t) + i_2(t) + \\ldots + i_N(t) = \\left( \\frac{1}{R_1} + \\frac{1}{R_2} + \\ldots + \\frac{1}{R_N} \\right) v(t) $$\n其中每一个 Parallel Circuit 上的 Resistor 可以通过 $$ i_j(t) = \\frac{v(t)}{R_j} \\quad \\quad i_j(t) = \\frac{R_p}{R_j} i_o(t) $$\n得出答案 ","date":"Mar 3 2025","externalUrl":null,"permalink":"/docs/electrical-fundamentals/ef9.resistivecircuits/","section":"Docs","summary":"\u003ch2 class=\"relative group\"\u003eEF9.ResistiveCircuits \r\n    \u003cdiv id=\"ef9resistivecircuits\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ef9resistivecircuits\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003eLast Edit: 3/3/25\u003c/p\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eOhm’s Law \r\n    \u003cdiv id=\"ohms-law\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ohms-law\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eOhm’s Law是以德国物理学家 Georg Simon Ohm 的名字命名的，他确立了 Voltage 和 Current 之间的关系，其发现了 Resistor 两端的 Voltage 和通过的 Current 成正比\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eSymbol for a Resistor \r\n    \u003cdiv id=\"symbol-for-a-resistor\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#symbol-for-a-resistor\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/electrical-fundamentals/ef9.resistivecircuits/EF9.ResistiveCircuits_hu8924352349811077473.png 330w,\r\n        /docs/electrical-fundamentals/ef9.resistivecircuits/EF9.ResistiveCircuits_hu14817147965503634486.png 660w,\r\n        /docs/electrical-fundamentals/ef9.resistivecircuits/EF9.ResistiveCircuits_hu14812148851474538778.png 1024w,\r\n        /docs/electrical-fundamentals/ef9.resistivecircuits/EF9.ResistiveCircuits_hu7439742641865735479.png 2x\"\r\n        src=\"/docs/electrical-fundamentals/ef9.resistivecircuits/EF9.ResistiveCircuits_hu14817147965503634486.png\"\r\n        alt=\"EF9.ResistiveCircuits.png\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 9. Resistive Circuits","type":"docs"},{"content":" Last Edit: 2/22/25\n很多情况下，需要连续处理多个值，而分别给他们赋值则显得特别麻烦，于是就需要一种更加高效的数据结构\n7.1 Why and how to use arrays ? #\r假设现在需要统计全班 400 个人的成绩，不可能创建 400 个 Varibale 将成绩和名称一一赋值，更高效的做法是创建一个 Array 通过 int grades[7] 就可以 Declare 一个 Array 想要挨个指定 Array 内 Element 的值，则需要挨个指定 grades[0] = 100; grades[1] = 95; grades[2] = 67; grades[3] = 99; grades[4] = 72; grades[5] = 101; grades[6] = 200; 在 C 语言中，访问 Array 的第一个值，需要用 0 作为 Index 如果不想要一一赋值，可以直接 Initialize Array，直接 `int grades[7] = {100,95,67,99,72,101,200} 就可以完成定义并赋值 对于 Array 来说，他的 Size 在整个程序中都是固定的，定义他的大小的方式有很多种 #define SIZE 7 int main(void) { int arr[SIZE]; // 等价于 int arr[7]; int x = SIZE; // 等价于 int x = 7; return 0; } 使用 Macro #define 作为宏定义，他的作用是给 7 取了个 Alias 别名 叫做 SIZE，这样在运行的时候，所有 SIZE 都会被替换成 7 int main(void) { const int Size = 7; int arr[Size]; // 在某些编译器中可能不合法 int x = Size; return 0; } 或者常规的使用 const 来定义 ex. Find Avg of an array #\r整体思路就是累加 Array 的每一个元素，后将和处以元素个数 #include \u0026lt;stdio.h\u0026gt; #define SIZE 7 int main(void){ int grades[SIZE] = {100, 95, 67, 99, 72, 101, 200}; int sum = 0; double avg = 0; for (int index = 0; index \u0026lt; SIZE; index++){ sum = sum + grades[index]; } avg = (double) sum / SIZE; printf(\u0026#34;Average is %.2lf\u0026#34;, avg); return 0; } 对于上面的常规遍历操作，会出现以下常见问题 Array Index Range Error #\r想要遍历整个 Array，正确的 index 应该是 0 到 SIZE - 1，也就是说 Array 的最后一个元素是 SIZE - 1，若遍历为 index \u0026lt;= SIZE 则会出现越界错误 同样的，Array 的 start point 也是 index = 0，要从 0 开始不然无法访问到第一个元素 还有就是要将 sum 定义成 double 类型以确保除法不会出现精度问题 7.1.1 ex. Reverse the Elements in an Array #\r这里有很多种方法，书中采取了 Swap 的办法，即把 Low 和 High 配对然后 Swap #include \u0026lt;stdio.h\u0026gt; #define SIZE 6 int main(void){ int arr[SIZE] = {2, 5, 7, 8, 9, 12}; for (int index = 0; index \u0026lt; SIZE; index++){ printf(\u0026#34;%d, \u0026#34;, arr[index]); } printf(\u0026#34;\\n\u0026#34;); for(int low = 0, high = SIZE - 1; low \u0026lt; high; low++, high--){ int temp = arr[low]; arr[low] = arr[high]; arr[high] = temp; } for (int index = 0; index \u0026lt; SIZE; index++){ printf(\u0026#34;%d, \u0026#34;, arr[index]); } printf(\u0026#34;\\n\u0026#34;); return 0; } 7.1.2 Summary of Important Features of Arrays #\r以下总结了一些重要的 Array 的注意事项 第一个元素从 Index = 0 开始 当 Declaring Array 的时候，不是一定需要将 SIZE 给到 [] 中，因为 Compiler 编译器会自动计算 Array 中的元素个数 当 SIZE 大小大于实际元素的时候，如 int array [5] = {1,2} 的情况下，实际上它相当于 int array [5] = {1,2,0,0,0} 的效果，不会报错 同样的，当 SIZE 小于实际元素的时候，如 int array [5] = {1,2,3,4,5,6} 的情况下，程序会提示 warning: excess elements in array initializer 当访问的 index 超出 Array 有的 Elements 个数的时候，会得到 Segmentation Fault 7.2 What are arrays, and how are they stored ? #\r当使用 Array 的时候，所有元素会被 Contiguously Stored in the main memory 假设有 int x[3] = {1,7,3}，首先这是一个 int Array，而一个 int 在 Memory 中会占用 4 Bytes，所以从 Array 的第一个 Element 开始，每一个 Element 都会间隔 4 个 Bytes 既然 Elements 之间是 Contiguously 的，那么可以发现，Array 自身的名字本质上就是一个指向 Array 中第一个元素的 Pointer，即 x == \u0026amp;x[0] 既然 Array 的本质就是 Pointer，那么就有 x+1 等价于 \u0026amp;x[1]，总结就是 x[i] == *(x + i) == *( \u0026amp;x[i] ) Array 的第 i 个元素等价于 x+i 的解引用等价于 Array 的 index 为 i 的元素的 Address 的解引用 7.2.1 Pointer Arithmetic #\r明白了 Array Identifier 是一个指向第一个 Element 的 Pointer 后，Pointer Arithmetic 在理解 Array 中的 Elements 是如何连 Contiguously Stored 在 Memory 中有很重要的作用 简单来说，Pointer 和正常的 Variable 不一样，它有着自己的加减乘除方法\n假设有一个 int x[] = {1,7,3}，现在有如下代码 #include \u0026lt;stdio.h\u0026gt; int main(void) { const int size = 3; int x[size] = {1, 7, 3}; // 定义数组 x int *q = \u0026amp;x[2]; // 指针 q 指向 x[2] int dist = q - x; // 计算指针之间的偏移量 printf(\u0026#34;Dist is %d\\n\u0026#34;, dist); // 输出偏移量 return 0; } 注意这里的 dist 是两个 Pointer 之间的差而不再是普通的值运算，他的值为 $$Dist =\\frac{80-72}{4}$$ 这是因为 Pointer 之间的加减运算以 Data Type 作为单位，而不是 Bytes，或者说 Pointer 之间计算的差值为 Number of Elements 而不是 Address 的 Bytes Difference 这里由于一个 int 为 4 Bytes，所以需要处以 4 作为单位长度 7.3 How do we pass an Array to a function ? #\r在 C 语言中，将 Array 传递给 Function 实际上是传递 Array 第一个 Element 的 Pointer 给到 Function 中，这意味着，Array 本身并不会被复制，因为 Function 接收到的是 Pointer 指向的 Address，Function 内部对 Array 的修改会影响到原 Array，因为他们用的是同一块 Memory #include \u0026lt;stdio.h\u0026gt; double f(int []); // 声明函数，接受一个整数数组 int main(void){ int x[3] = {1, 7, 3}; // 定义一个数组 double result = f(x); // 传递数组 x 给函数 f return 0; } double f(int list[]){ // 这里 list[] 实际上是指针 // statements; } 7.3.1 Size of array in a function is unknown #\r前面提到了，Array 作为一个参数被传入的时候，本质上是传入了指向 First Element 的 Address 的 Pointer，这导致了 Function 并不知道 Array 的实际大小 这就使得想要让 Function 知道 Array 的 Size，必须将 Size 也作为参数传入 #include \u0026lt;stdio.h\u0026gt; int sumData(int[], const int); // 函数声明 int main(void){ int x[3] = {1, 7, 3}; // 定义数组 int result = sumData(x, 3); // 传递数组和大小 printf(\u0026#34;Sum of elements in the array: %d.\\n\u0026#34;, result); return 0; } int sumData(int list[], const int size) { int sum = 0; for (int index = 0; index \u0026lt; size; index++) { sum = sum + list[index]; // 累加数组元素 } return sum; } 可以发现在 int sumData(int[], const int); 部分，指定了 Size 作为参数的传入 7.3.2 Can I use the pointer syntax too ? #\r因为 Array Identifiers 本质上是 Pointer，所以在 Function 内部，*(list + index) 也和 list[index] 等效 #include \u0026lt;stdio.h\u0026gt; int sumData(int*, int); // 使用指针表示数组参数 int main(void) { int x[3] = {1, 7, 3}; int result = sumData(x, 3); // 传递数组 x printf(\u0026#34;Sum of elements in the array: %d.\\n\u0026#34;, result); return 0; } int sumData(int* list, int size) { int sum = 0; for (int index = 0; index \u0026lt; size; index++) { sum = sum + *(list + index); // 使用指针偏移代替数组索引 } return sum; } 可以看到 sumData(int*, int); 直接声明了接受 Pointer，而在 Function 内部则通过偏移量来遍历 Array 这也说明了 int list[] 和 int* list 的等效，无论用这两个的其中哪一个，他们都指向的是 x[0] 所对应的 Address 7.3.3 Are we passing the array by value or by pointers ? #\r下面的例子在其强调了对 Array 的操作都是基于 Address 的特殊性 #include \u0026lt;stdio.h\u0026gt; void swap(int[], int, int); // 交换数组中两个元素 void printArray(int[], const int); // 打印数组元素 int main(void) { int x[5] = {3, 5, 8, 1, 7}; printf(\u0026#34;Before swapping: \u0026#34;); printArray(x, 5); swap(x, 0, 4); // 交换 x[0] 和 x[4] printf(\u0026#34;After swapping: \u0026#34;); printArray(x, 5); return 0; } // 交换 list[i] 和 list[j] void swap(int list[], int i, int j) { int temp = list[i]; list[i] = list[j]; list[j] = temp; } // 遍历并打印数组 void printArray(int list[], const int size) { for (int index = 0; index \u0026lt; size; index++) { printf(\u0026#34;%d \u0026#34;, list[index]); } printf(\u0026#34;\\n\u0026#34;); } 这就说明了代码中，无论是 x 还是 list，拿到的都是同一个 Array 的同一系列地址 ","date":"Feb 22 2025","externalUrl":null,"permalink":"/docs/learning-programming-with-c/lpc7.arrays/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 2/22/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e很多情况下，需要连续处理多个值，而分别给他们赋值则显得特别麻烦，于是就需要一种更加高效的数据结构\u003c/p\u003e","title":"LPC 7. Arrays","type":"docs"},{"content":" Last Edit: 2/20/25\nFaraday’s Law of Induction #\r任何封闭电路中 Induced Current 大小，等于穿过这一电路 Magnetic Flux 的变化率 已知 Magnetic Flux 的定义即为 \\(\\Phi_B=\\int B\\cdot dA\\) Experiment on change of Magnetic Flux #\r如图所示，现在有两个独立闭合电路 当开关 S 闭合后，右侧电路会生成一个 Magnetic Field，此时左侧度数瞬间有读数后消失，这表明了 Change in Magnetic Flux caused the Induced Charge in the left loop EMF Electromotive Force #\rEMF 实际上被叫做 Electromotive Force，即电动势，虽然名字中有 Force，但其实际上是 Potenial Difference，单位是 Volt 在 Faraday\u0026rsquo;s Law 中，emf 由 Induced Charge 引起 EMF 来自来源于早期的电学研究，当时科学家认为电池、电机等装置“推动”电荷，所以称之为“电动势”，尽管它的单位和电压一样（伏特, V），但两者有一些区别\nFaraday\u0026rsquo;s Law 给出 EMF 的数学表达为 $$\\mathcal{E} = -\\frac{d\\Phi_B}{dt}$$ \\(\\mathcal{E}\\) 是 EMF \\(\\Phi_B\\) 是 Magnetic Flux t 是时间 负号（来自Lenz\u0026rsquo;s Law）表示感应电流方向总是抵抗磁通量的变化 也就是说当磁通量随时间变化时，就会在回路中产生 EMF，推动电荷流动，从而形成Induced Charge Coil #\r当存在多匝线圈的时候，Total EMF 为 $$\\mathcal{E} =−N\\frac{dΦB}{dt}​​$$ Ways of changing Magnetic Flux #\r已知 \\(ΦB​=BAcosθ\\)，可以知道想要改变 Magentic Flux，可以改变 Magnitude of Magnetic Flux，Area of Coil \u0026amp; Angle Between A \u0026amp; B Lenz\u0026rsquo;s Law #\rAfter Faraday propsed his law of induction, Heinrich Friedrich Lenz devised a rule for determinging the direction of an induced current in a loop 楞次定律描述了感应电流的方向，它的核心思想是 Induced Current 会产生一个 Magnetic Field 来抵抗 Magnetic Flux 的变化 换句话说，线圈中的 Induced Current 会尽可能 Resisit Magnetic Flux 的增加或减少 *如果磁通量增加，感应电流会产生一个相反方向的磁场来抵抗增加 如果磁通量减少，感应电流会产生一个相同方向的磁场来补偿减少\n当 Magnet 靠近 Coil 时，Magnetic Flux 增加，Coil 会产生一个向北的 Magentic Field 以抵抗 Change in Magnetic Flux，通过 Right Hand Rule 就可以确定这一 Magnetic Field 是由 CCW 方向的 Induced Current 形成的 Induction and Energy Transfers #\r现在有以下场景，一个闭合的导体电路在一个 Uniform Magnetic Field 中被拉出 这一运动的结果是，Magnetic Flux 减少 根据 Faraday\u0026rsquo;s Law，回路中产生 Induced Current 根据 Lenz\u0026rsquo;s Law，Induced Current 方向会抵抗磁通量的减少，形成 CW 前面没有提到的是，这一个过程必然会产生一个 Force，即拉动线圈的过程中，EMF 会产生一个和拉动方向相反的 Force，而这一个 Force 于 Velocity 平行，有 \\(P=Fv\\)，这一做功将最终转换成 Induced Current 中的 Electric Energy，即能量守恒 Induced EMF #\r已知 \\(\\mathcal{E} = -\\frac{d\\Phi_B}{dt}\\)，由于上面的回路在 Magnetic Field 中被拉出，Magnetic Flux 的变化为 $$\\mathcal{E}=BLv$$ Induced Current #\r根据 Ohm\u0026rsquo;s Law， $$i=\\frac{\\mathcal{E}}{R}=\\frac{BLv}{R}$$ Opposing Force #\r根据洛伦兹力作用，有 $$F=iLB=\\frac{B^2L^2v}{R}$$ Rate of Work #\r与上方同理，外力做功为 $$P=Fv=\\frac{B^2L^2v^2}{R}$$ Thermal Energy Dissipation #\rCurrent 在 Resistor 中流动的时候，一部分 Energy 会损耗为 Thermal Energy，有 $$P=i^2R=(\\frac{BLv}{R})^2R=\\frac{B^2L^2v^2}{R}$$ ex. Comparison of EMF #\r现在有四个 Wire Loop，依次要穿过 Magnetic Field，要求比较 EMF 大小，已知 Faraday\u0026rsquo;s Law \\(\\mathcal{E} =BLv​​\\)，只有垂直于运动方向的边长才决定 Induced EMF 大小，有 (a)\\(\\mathcal{E} = B L v\\) (b)\\(\\mathcal{E} = B L v\\) (c)\\(\\mathcal{E} = B (2L) v\\) (d)\\(\\mathcal{E} = B (2L) v\\) Eddy Currents #\rEddy 涡流是闭合导体在变化的磁场中产生的环形感应电流，类似于水中的漩涡 假设我们用 Conductor Board 代替之前的闭合导体回路 由于磁通量变化，根据 Faraday\u0026rsquo;s Law，导体中会产生 Induced Current 但由于导体是连续的金属板，电流不会沿着单一路径流动，而是形成 Eddy Current 这些感应电流与磁场相互作用，产生反作用力，阻碍导体的运动 Inductors and Inductance #\rCapacitor 用于产生所需的 Electric Field，而 Inductor 用于产生所需的 Magnetic Field Solenoid 是最基本的电感器，当电流 i 通过其线圈时，产生磁通量 ΦB​ Inductor L 通过磁通量 \\(\\Phi_B\\) 定义为： $$L = \\frac{N \\Phi_B}{i}$$ N 是线圈的匝数 \\(\\Phi_B\\) 是磁通量 i 是电流 Inductor 的单位是亨利（Henry, H） 1 亨利的定义： \\(1 H = 1 T \\cdot m^2 / A\\) 如果1 安培电流变化 1 秒，导致1 伏特感应电动势（EMF），则电感值为 1 亨利 对于 Solenoid，其单位长度的电感为： $$\\frac{L}{l} = \\mu_0 n^2 A$$ \\(\\mu_0\\) 是真空磁导率（\\(4\\pi \\times 10^{-7} H/m\\)） n 是每单位长度的匝数（匝数密度） A 是螺线管的横截面积 Property of Inductance #\r电感 L 仅取决于电感器的几何结构（类似于电容器的电容取决于板间距离和面积） 线圈匝数的平方关系 若匝数增加 n 倍，则： 磁通量 \\(\\Phi_B\\) 增加 n 倍（因为磁场 B 增加） 电感 L 增加 \\(n^2\\) 倍，因为磁通量和线圈匝数同时增加 Self-Induction #\r就像是一个具有 Mass 的物体存在惯性，抵抗瞬间产生的加速度一样，当 Current 在快速变化的时候，Inductor 会通过 Induced EMF 进行反抗 也就是说当 Current 变化的时候，Inductor 根据公式 \\(\\mathcal{E} =−L\\frac{di}{dt}​​\\) 产生一个 Induced Current Opposing the change 来 “缓冲” 这一变化 Energy Stored in a Magnetic Field #\rInductor 在 Current 流过时会储存能量，该能量由磁场存储，并由以下公式计算 $$U_B​=\\frac{1}{2}Li^2$$ \\(U_B\\)​ 是存储的 Magnetic Energy（单位： J） L 是 Inductor（单位： H） i 是线圈中的 Current（单位： A） 电容器存储电场能量（\\(\\frac{1}{2} C V^2\\)），电感器存储磁场能量（\\(\\frac{1}{2} L i^2\\)）\n","date":"Feb 20 2025","externalUrl":null,"permalink":"/docs/electrical-fundamentals/ef8.inductioninductance/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 2/20/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eFaraday’s Law of Induction \r\n    \u003cdiv id=\"faradays-law-of-induction\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#faradays-law-of-induction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e任何封闭电路中 Induced Current 大小，等于穿过这一电路 Magnetic Flux 的变化率\u003c/li\u003e\n\u003cli\u003e已知 Magnetic Flux 的定义即为 \\(\\Phi_B=\\int B\\cdot dA\\)\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eExperiment on change of Magnetic Flux \r\n    \u003cdiv id=\"experiment-on-change-of-magnetic-flux\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#experiment-on-change-of-magnetic-flux\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e如图所示，现在有两个独立闭合电路\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/electrical-fundamentals/ef8.inductioninductance/EF8.Induction\u0026amp;Inductance-1_hu7387844013605343016.png 330w,\r\n        /docs/electrical-fundamentals/ef8.inductioninductance/EF8.Induction\u0026amp;Inductance-1_hu15348448422353166210.png 660w,\r\n        /docs/electrical-fundamentals/ef8.inductioninductance/EF8.Induction\u0026amp;Inductance-1_hu15379995169890920571.png 1024w,\r\n        /docs/electrical-fundamentals/ef8.inductioninductance/EF8.Induction\u0026amp;Inductance-1_hu1971224904868116517.png 2x\"\r\n        src=\"/docs/electrical-fundamentals/ef8.inductioninductance/EF8.Induction\u0026amp;Inductance-1_hu15348448422353166210.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 8. Induction \u0026 Inductance","type":"docs"},{"content":" Last Edit: 2/20/25\n上一章中提到的所有有关于 Function 的内容都是关于一个函数的输入以及输出的，本章将讨论如何在不同函数间访问 Variables\n6.1 Why Pointers ? #\r前面提到的所有有关 Function 的操作的返回值 return 都是唯一的，这是一个需要解决的问题 6.1.1 Communicate using return #\rbool isPerfectSquare(int x) { if ((int)sqrt(x) != sqrt(x)) { return false; } else { return true; } } 以上是一段代码中的其中一个 Function，其存在了两个函数的输出，这使得 Function 可以提供多种不同的输出 但是这也成为了一个问题，就是当存在多个判断值 if 的时候，可能会导致错误，为了避免这个问题，可以通过将 return 的触发条件简化，如 bool isPerfectSquare(int x) { return ((int)sqrt(x) == sqrt(x)); } 确保了函数存在且只存在一个 return ，其具体的值将由具体Bool Value决定 Calling by Value #\r在一个参数进入Function的时候，实际上传入的是其副本而不是变量本身，这代表了函数中对于变量进行的任何操作实际上不会改变外部定义的Variable本身 #include \u0026lt;stdio.h\u0026gt; void simple(int); int main(void) { int p = 12; simple(p); printf(\u0026#34;The value of p is %d.\\n\u0026#34;, p); return 0; } void simple(int p) { p = p / 2; } -\u0026gt; The value of p is 12. 想要更改就需要首先从函数里 return ，其次再把值传给p，具体代码如下 #include \u0026lt;stdio.h\u0026gt; int simple(int); int main(void) { int p = 12; p = simple(p); //传入数值 printf(\u0026#34;The value of p is %d.\\n\u0026#34;, p); return 0; } int simple(int p) { p = p / 2; return p; //函数主动返回数值 } 6.1.2. Limitation of return #\r前面提到了 return 采取的本质是 Call by Value 按值传递的机制，具体来说，在调用函数的时候参数会接收变量的副本，这使得函数内部进行的更改不会影响外部 #include \u0026lt;stdio.h\u0026gt; void swap(int, int); int main(void) { int a = 9, b = 13; printf(\u0026#34;Before swapping\\nValue of a: %d\\nValue of b: %d\\n\u0026#34;, a, b); swap(a, b); printf(\u0026#34;After swapping\\nValue of a: %d\\nValue of b: %d\\n\u0026#34;, a, b); return 0; } void swap(int x, int y) { int temp = x; x = y; y = temp; } 6.2 What are Pointers ? #\rPointers 指针是存储变量地址的变量\n现在有以下代码 #include \u0026lt;stdio.h\u0026gt; int main(void) { int x = 7; // x 是一个 int 变量 int *p; // p 是一个指向 int 的指针变量 return 0; } 可以说Declear p的过程就是为一个 int 变量预留了内存空间 前面提到过了 declaring a variable without initializing it 使得其变成一个 Garbage Value 这边 Declar 的一个 Piont 就是专门用来指向 Memory 的，但目前还没有指向具体目标 #include \u0026lt;stdio.h\u0026gt; int main(void) { int x = 7; // 声明一个整型变量 x 并初始化为 7 int *p; // 声明一个整型指针 p p = \u0026amp;x; // 将 x 的地址赋给指针 p int y; // 声明一个整型变量 y y = *p; // 将指针 p 指向的地址（x 的地址）中的值赋给 y return 0; // 函数返回 0 } 在上面的代码基础上，令 p 指向了 x的地址，之后再把 x的值赋给了 y 需要注意的是赋值之后 x 的值的改变将不再影响到 y\n#include \u0026lt;stdio.h\u0026gt; int main(void) { int x = 7; int *p; p = \u0026amp;x; int y; y = *p; printf(\u0026#34;Address of x: %p\\n Value of x: %d\\n\u0026#34;, \u0026amp;x, x); printf(\u0026#34;Address of p: %p\\n Value of p: %p\\n\u0026#34;, \u0026amp;p, p); printf(\u0026#34;Address of y: %p\\n Value of y: %d\\n\u0026#34;, \u0026amp;y, y); printf(\u0026#34;Value stored in address %p is %d\\n\u0026#34;, p , *p); return 0; } 通过这段代码就可以看出 x，p 和 y 之间的关系 Address of x: 0x30e2af178\rValue of x: 7\rAddress of p: 0x30e2af170\rValue of p: 0x30e2af178\rAddress of y: 0x30e2af16c\rValue of y: 7\rValue stored in address 0x30e2af178 is 7 x 作为一个很正常的 Variable，地址是 0x30e2af178 ，值是 7，而 p 作为Pointer，地址是一个新的内存，而值应该是 x 的地址 0x30e2af178 ，而 y 也是一个独立的 Variable 6.3 Use Pointers to Communicate #\r既然解决了前面提到的 Call by Value 的问题，就能通过 Points 解决如 loop，function 内部 Variable 的问题了 #include \u0026lt;stdio.h\u0026gt; void swap(int*, int*); int main(void) { int a = 9, b = 13; printf(\u0026#34;Before swapping\\nValue of a: %d\\nValue of b: %d\\n\u0026#34;, a, b); swap(\u0026amp;a, \u0026amp;b); printf(\u0026#34;After swapping\\nValue of a: %d\\nValue of b: %d\\n\u0026#34;, a, b); return 0; } void swap(int* x, int* y) { int temp = *x; *x = *y; *y = temp; } 当 Variable 本身已经是一个 Pointer 的时候，*x 则变成了解析值，也就是该内存下储存的值，上面的例子中，swap 中的 int temp = *x; 则是令 temp 等于 Pointer x 的值也就是 9 *x = *y;，已知 x 是 \u0026amp;a，也就是变量 a 的地址，而 *x则就是变量 a 的 Value，对于 y 同理，那么这一行就代表了 a = b，将 b 的值赋值给 a，有 6.3.1 Size of pointer Variable #\r前面提到了以前的机器采用 32 bits 表示内存，而现今的采用 64 bits， #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(void) { printf(\u0026#34;Size of pointer (int*) is %d.\\n\u0026#34;, sizeof(int*)); printf(\u0026#34;Size of pointer (double*) is %d.\\n\u0026#34;, sizeof(double*)); printf(\u0026#34;Size of pointer (bool*) is %d.\\n\u0026#34;, sizeof(bool*)); printf(\u0026#34;Size of pointer (char*) is %d.\\n\u0026#34;, sizeof(char*)); return 0; } 使用 sizeof 就可以知道一个变量的 Size，即在这里是 8 bytes (64 bits) 6.3.2 Can a pointer hold address of another pointer ? #\r一个 Pointer 确实可以指向另一个 Pointer 的地址，因为他们本质上都是 Address 一个 Int 的 Pointer 为 int* 而他的 Pointer 则是 int**，即每一次加一个 * 变量 存储的地址 存储的值 i 45 10（整数值） pi 46 45（即 i 的地址） ppi 47 46（即 pi 的地址） 6.3.3. Can a function return a pointer? #\r可以，以下 function 就是一个接收 Pointer，在函数内部使用 * 访问 Pointer 值，在比较大小后返回较大的值的 Pointer 的一个函数 #include \u0026lt;stdio.h\u0026gt; double* largestValLoc(double*, double*); double* largestValLoc(double* a, double* b) { double* temp; if (*a \u0026gt; *b) { temp = a; // temp is double* and a is double*, so temp = a is permissible } else { temp = b; } return temp; // temp is double*, and return type is double* } int main(void) { double x = 2.6, y = 7.3; double* p = largestValLoc(\u0026amp;x, \u0026amp;y); // pass address of x to a, and address of y to b // p is (double*) and largestValLoc returns (double*) printf(\u0026#34;Address of x: %p having value %.1lf.\\n\u0026#34;, \u0026amp;x, x); printf(\u0026#34;Address of y: %p having value %.1lf.\\n\u0026#34;, \u0026amp;y, y); printf(\u0026#34;Address of larger variable: %p.\\n\u0026#34;, p); return 0; } 6.3.4. Initialization Vs. Declaration of a pointer variable #\rDeclaration 和 Initialization 也存在着区别 Declaration 声明 #\rDeclaration 告诉了编译器 Variable 的 Type，并为其分配了 Memory，在这时 Variable 仅被创造而未被赋值 （存储了不确定的“垃圾值”） int x; // 仅声明 x，x 里面的值是不确定的（垃圾值） int *p; // 仅声明指针 p，但 p 没有指向任何有效地址（垃圾指针） 上方代码只做了 Variable 的 Declaration 而未赋值，在运行时会报错 #include \u0026lt;stdio.h\u0026gt; int main() { int* p; // 仅声明指针 p，但未初始化 *p = 5; // 试图通过 p 访问地址并赋值 return 0; } -\u0026gt; warning: variable \u0026#39;p\u0026#39; is uninitialized when used here [-Wuninitialized] *p = 5; ^ Initialization 初始化 #\r在 Declare Variable 的同时赋予其一个值 int x = 5; // 声明并初始化 x，x 现在存储 5 int *p = \u0026amp;x; // 声明并初始化指针 p，使其指向 x 这里给 x 赋值了 5，给 Pointer 赋值了 x 的 Address Null #\r在 C 语言中，Null 是一个特殊的值，当用作值时为 0，而代表地址的时候表示 “不指向任何有效地址”，他的主要作用时防止未初始化的指针指向随机地址导致程序崩溃 int *p; // ❌ 未初始化的指针 *p = 5; // 可能会崩溃（指向垃圾地址） 上述代码中，由于 pointer 未被 Initialize，则会产生 Segmentation Fault 问题，修正的办法则是通过 Null int *p = NULL; // ✅ 初始化为 NULL if (p != NULL) { *p = 5; // 只有当 p 指向有效地址时才执行 } 这就提供了一种安全的检查指针是否有效的办法 ex. #\r#include \u0026lt;stdio.h\u0026gt; int *confuse(int *x, int *y) { (*y)++; y = x; *y = 10; return (y); } int main(void) { int a = 6, b = 7; int *f = \u0026amp;b; f = confuse(\u0026amp;a, \u0026amp;b); (*f)++; printf(\u0026#34;a = %d and b = %d\\n\u0026#34;, a, b); return 0; } 步骤 变量 a 变量 b 指针 f 初始化 6 7 \u0026amp;b (*y)++ (b++) 6 8 \u0026amp;b y = x（y 指向 a） 6 8 \u0026amp;b *y = 10（修改 a） 10 8 \u0026amp;b return y;（返回 \u0026amp;a，即 f = \u0026amp;a） 10 8 \u0026amp;a (*f)++（a++） 11 8 \u0026amp;a 所以最后的结果为 a = 11, b = 8 6.4. Rules defining scope of variables #\rScope 代表了在编译器中，Variable 应该出现在哪些位置才能被正确的使用 6.4.1. Variables can only be used after they are declared #\r必须要先 Declare Varibale 后才能赋值 int main() { i = 0; int i; return 0; } 这就会报错 compile-time error Local Variables #\r在 Function 内部声明的变量称为 Local Variables，它的 Scope 从被 Declare 开始到 Function 结束时结束 6.4.2. Use a variable declared in a compound statement #\r在 C 语言中，Variable Scope 受 {} 所限制，即其只能在它被 Declare 的 Compound Statement 内部可见，在 {} 外部的调用会导致 Undeclared Identifier #include \u0026lt;stdio.h\u0026gt; int main() { int i = 0; // 变量 i 在 main() 作用域内有效 { // 复合语句（新的作用域） int x = 5; printf(\u0026#34;Inside compound statement: x = %d.\\n\u0026#34;, x); // ✅ 正确，x 在作用域内 } // ❌ 错误：x 作用域结束，无法访问 printf(\u0026#34;Outside compound statement: x = %d.\\n\u0026#34;, x); return 0; } 对于上面的这种情况，解决方案就是分离 Declaration 和 Initialization #include \u0026lt;stdio.h\u0026gt; int main() { int i = 0; int x; // 声明 x 在整个 main() 内有效 { x = 5; printf(\u0026#34;Inside compound statement: x = %d.\\n\u0026#34;, x); } printf(\u0026#34;Outside compound statement: x = %d.\\n\u0026#34;, x); // ✅ 正确 return 0; } 通过在 Compound Statement 外部的声明使得其 Scope 变化至整个 main() 中 6.4.3. External identifiers/global variables #\r在 C 语言中，Global Varibale 在整个程序中都是可见的 #include \u0026lt;stdio.h\u0026gt; int i = 0; // ✅ 全局变量 i，所有函数都可以访问 void func(); // 函数声明 int main(void) { printf(\u0026#34;In main: Global variable i = %d.\\n\u0026#34;, i); // 输出 i = 0 func(); // 调用 func() printf(\u0026#34;In main after calling func: Global variable i = %d.\\n\u0026#34;, i); // 输出 i = 5 return 0; } void func() { printf(\u0026#34;In func: Global variable i = %d.\\n\u0026#34;, i); // 输出 i = 0 i = 5; // ✅ 修改全局变量 i } 在 C 语言中，External Identifier 通常指的是 在函数外部声明的变量、函数或其他可被多个文件访问的实体，其主要特性是 Scope 覆盖整个程序 6.4.4. Overlapping scope #\r不同 Scope 下可以 Declare 具有相同名称的同名变量，由于这一个 Scope 的 Overlap，可能会导致变量的 Shadowing #include \u0026lt;stdio.h\u0026gt; int main(void) { int i = 1; // ✅ 作用域：整个 main() 函数 printf(\u0026#34;Outer i = %d.\\n\u0026#34;, i); // 输出 1 { int i = 2; // ✅ 作用域：仅限于这个 `{}` 块 printf(\u0026#34;Inner i = %d.\\n\u0026#34;, i); // 输出 2 } printf(\u0026#34;Outer i = %d.\\n\u0026#34;, i); // 输出 1 return 0; } 可以发现，Variable 是否会被修改取决于是否出现了多个 Declarations，对于 6.4.3 中的代码来说，全局只有一个 Declaration，即 int i = 0 ，而在 6.4.4 中存在两个 Declarations，int i = 1，int i = 2，这就导致了 Cpmpound Statement 内部的修改不会影响到外部\n6.5. Goldbach conjecture #\r写一个程序来检查给定偶数是否符合 Goldbach Conjecture 哥德巴赫猜想 6.5.1 Problem Statement #\r他的猜想如下，所有大于 2 的偶数都可以表示为两个质数的和 6.5.2 Divide Problem into sub-problems #\r获取用户输入 —— 读取用户输入的偶数 验证输入是否合法 —— 确保输入是大于 2 的偶数 验证哥德巴赫猜想 —— 查找是否存在两个质数相加等于该数 输出结果 —— 打印该数是否符合哥德巴赫猜想 6.5.2.1. Take input from the user #\r首先要确保 Input 大于 2，有 void getUserInput(int *number) { // Get user input from the keyboard // and validates it is even and greater than 2 do { printf(\u0026#34;Enter a number to test the Goldbach conjecture: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, number); } while (*number \u0026lt;= 2 || *number % 2 != 0); } 优化代码如下 #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; void getUserInput(int*); int main(void) { int num; getUserInput(\u0026amp;num); return 0; } void getUserInput(int *number) { // 获取用户输入，并验证其是否为大于 2 的偶数 bool firstEntry = true; // 标记是否是第一次输入 do { if (firstEntry) { printf(\u0026#34;Enter a number to test the Goldbach conjecture: \u0026#34;); firstEntry = false; } else { printf(\u0026#34;Your input was invalid, please enter another even number \u0026gt; 2: \u0026#34;); } scanf(\u0026#34;%d\u0026#34;, number); } while (*number \u0026lt;= 2 || *number % 2 != 0); } 6.5.2.2. Test the Goldbach #\r现在要验证猜想，给定一个偶数，遍历小于它的一半的质数，依次将他们从偶数上减去，判断差是否为质数，后重复过程 几个需要用到的函数有 bool isPrime(int); ，void nextPrimeNumber(int*); bool testGoldbach(int N) { // 测试哥德巴赫猜想 // 如果验证成功返回 true，否则返回 false int x = 2, y; bool rejected = false; bool verified = false; while (!rejected \u0026amp;\u0026amp; !verified) { y = N - x; if (isPrime(y)) { verified = true; // 找到了 x + y = N 的质数对 } else if (y \u0026lt; x) { rejected = true; // 当 x \u0026gt; y 时，仍未找到符合条件的 x, y } else { nextPrimeNumber(\u0026amp;x); // 递增 x 到下一个质数 } } return verified; // 如果找到了两个质数，则返回 true，否则返回 false } 6.5.2.3. Get the Next Prime Number #\r获取下一个质数的函数需要自己定义，逻辑就是在当前值上 + 1，并判断是否是 Prime Number，若是则返回，不是则循环 void nextPrimeNumber(int *px) { // We will look for the numbers after *pFrist one by one // until we find the next prime number int value = *px + 1; while (!isPrime(value)) { value += 1; } *px = value; } 6.5.2.4. Find If a Number Is Prime or Not #\r判断 Prime Number 的函数也需要实现，有 bool isPrime(int num) { // check if num is prime, by checking the remainder of num / all numbers from // 2 to num - 1 bool prime = true; if (num \u0026lt; 2) { prime = false; } else { for (int denom = 2; denom \u0026lt;= num - 1 \u0026amp;\u0026amp; prime; denom++) { if (num % denom == 0) { prime = false; } } } return prime; } 逻辑就是遍历比它小的所有大于 2 的数，挨个除过去看余数是否为 0 ，若皆不为 0 ，则是 Prime Number 6.5.2.5. Print If the Conjecture Is Verified #\r还需要一个输出函数 完全不需要这个\nvoid printConjResult(int number){ //Call a function to verify the conjecture and prints the result bool verified = testGoldbach(number); if(verified){ printf(\u0026#34;Goldbach conjecture is verified.\\n\u0026#34;); } else{ printf(\u0026#34;Goldbach conjecture not verified.\\n\u0026#34;); } } 6.5.3. Integrate all pieces/functions #\r完成了所有函数的实现后，整合所有函数实现完整流程 int main(void){ int number; getUserInput(\u0026amp;number); printConjResult(number); return 0; } -\u0026gt; Enter a number to test the Goldbach conjecture: **9** Your input was invalid, please enter another number \u0026gt; 2: **8** Goldbach conjecture is verified. ","date":"Feb 20 2025","externalUrl":null,"permalink":"/docs/learning-programming-with-c/lpc6.pointers/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 2/20/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e上一章中提到的所有有关于 Function 的内容都是关于一个函数的输入以及输出的，本章将讨论如何在不同函数间访问 Variables\u003c/p\u003e","title":"LPC 6. Pointers","type":"docs"},{"content":"","date":"Feb 13 2025","externalUrl":null,"permalink":"/tags/dyn/","section":"Tags","summary":"","title":"DYN","type":"tags"},{"content":" Last Edit: 2/13/25\nNormal and Tangential Coordinates (n-t) – Circular Motion #\r当已知了物体运动的轨迹的时候，可以更加简便的通过Normal法线，和Tangential切线坐标来描述粒子的运动 t -axis：切线方向，与粒子所在位置的曲线切线方向一致，并且方向为粒子运动的正方向 n -axis：法线方向，垂直于 t 轴，正方向指向曲线的曲率中心 eₙ 和 eₜ：分别是法线和切线方向的单位向量 Radius of curvature 曲率半径 #\rRadius of Curvature 曲率半径是描述曲线在某点处弯曲程度的量度，具体来说，它是通过该点的曲线能够最佳拟合的圆的半径来定义的 $$\\rho = \\frac{(1 + y\u0026rsquo;^2)^{3/2}}{|y\u0026rsquo;\u0026rsquo;|}$$ Distance in n-t System #\r在一个 Circular Motion 中，物体移动的距离由 Radius of curvature 和滑过角度的积分得出，因为 Radius of Curvature 描述的就是在一点的曲线的完整圆的半径，半径乘以距离就得到了 Arc Length，具体来说有 $$ds=\\rho d \\beta$$ Velocity in n-t System #\r在 n-t 系统中，Velocity 的方向永远指向 Path of motion 的 tangent 方向，有 $$\\vec{v} = v \\vec{e}_t$$ 同理在上面描述了 n-t System 中的 Distance，Velocity 也可以通过对其求导得到，有 $$v = \\dot{s} = \\frac{ds}{dt} = \\frac{\\rho d\\beta}{dt} = \\rho \\dot{\\beta} \\Rightarrow \\vec{v} = v \\vec{e}_t = \\rho \\dot{\\beta} \\vec{e}_t$$ 这一个公式同时又可以推导出 Angle 关于 time 的导数，有 $$\\frac{d\\theta}{dt} = \\dot{\\theta} = \\frac{v}{\\rho}$$ Acceleration in n-t System #\r再次对 Velocity 求导就可以得到 $$\\vec{a} = \\frac{d\\vec{v}}{dt} = \\frac{d \\left( v \\hat{e}_t \\right)}{dt} = \\dot{v} \\hat{e}_t + v \\frac{d\\hat{e}_t}{dt}$$ 其中，因为 Velocity 方向的导数由 Angle 的变化量决定，因为其本身 Magnitude 并不会发生改变，一直都是一，并且方向是圆心方向，所以有 $d\\hat{e}_t = d\\theta \\hat{e}_n$，带入得到 $$\\vec{a} = \\dot{v} \\hat{e}_t + v \\frac{d\\theta}{dt} \\hat{e}_n = \\dot{v} \\hat{e}_t + \\frac{v^2}{\\rho} \\hat{e}_n$$ 而 a 的 Magnitude 就可以通过勾股定律得到 Tangential Acceleration #\r总结上面的所有公式，可以得到 $$a_t = \\frac{dV}{dt}$$ Normal Acceleration #\r同理对于 Normal 方向上的，有 $$a_n = V \\dot{\\theta}=\\rho \\dot{\\theta}^2 = \\frac{V^2}{\\rho} $$ R-Theta Coordinate #\r当我们从一个固定点观察一个 Target 的时候，通过 Polar Coordinate 来描述这个运动过程会更加简单\nPosition in R-Theta System #\r想要描述一个物体在 Coordinate 中的位置，可以通过 $$\\vec r=r\\hat e_r$$ Velocity in R-Theta System #\r对 Position 求导就能求得他的 Velocity 有 $$\\vec{v} = \\frac{d\\vec{r}}{dt} = \\frac{d(r \\hat{e}_r)}{dt} = \\dot{r} \\hat{e}_r + r \\dot{\\hat{e}}_r=\\dot{r} \\hat{e}_r + r \\dot{\\hat{e}}_r= \\dot{r} \\hat{e}r + r \\dot{\\theta} \\hat{e}\\theta$$ ex. Finding the velocity #\rA carousel is turning at the speed of 8 rpm. A child initially at 4m from the center walks toward the center at 2m/s. Find $\\vec v$ $$\\vec{V} = \\dot{r} \\hat{e}r + r \\dot{\\theta} \\hat{e}\\theta = -2 \\hat{e}r + (14)(0.84) \\hat{e}\\theta \\quad \\text{m/s}$$\nAcceleration in R-Theta System #\r再次对于 velocity 求导得到 $$ \\vec{a} = \\frac{d\\vec{v}}{dt} = \\frac{d}{dt} (\\dot{r} \\hat{e}r + r \\dot{\\theta} \\hat{e}\\theta) = \\ddot{r} \\hat{e}r + \\dot{r} \\dot{\\hat{e}}r + \\dot{r} \\dot{\\theta} \\hat{e}\\theta + r \\ddot{\\theta} \\hat{e}\\theta + r \\dot{\\theta} \\dot{\\hat{e}}_\\theta = \\hat{e}r (\\ddot{r} - r \\dot{\\theta}^2) + \\hat{e}\\theta (\\ddot{\\theta} + 2 \\dot{r} \\dot{\\theta})$$ $$\\Rightarrow a = \\hat{e}r (\\ddot{r} - r \\dot{\\theta}^2) + \\hat{e}\\theta (r\\ddot{\\theta} + 2 \\dot{r} \\dot{\\theta})$$ ex. Finding the Acceleration #\rExtracted Problem Statement:\nA shuttle is launched vertically and tracked by a radar station. At the instant when $\\theta = 60^\\circ$, $r = 9 km$, $\\ddot{r} = 21 \\text{ m/s}^2$, and $\\dot{\\theta} = 0.02 \\text{ s}^{-1}$, determine the acceleration vector $\\vec{a}$\n计算航天器的加速度 $\\mathbf{a}$，给定数据如下：\n$theta = 60^\\circ$ $r = 9000 m$ $\\dot{r}$ （需要计算） $\\ddot{r} = 21 m/s²$ $\\dot{\\theta} = 0.02 rad/s$ $\\ddot{\\theta}$（需要计算） Special Case: Circular Motion #\r对于 Polar Coordinate 中的 Circular Motion，由于 $\\dot r=\\ddot r=0$很多公式都会被化简 N-T Coordinate #\r在 Circular Motion 中有 $$v= ve_t$$ 其本身就由 Tangential Direction 上的 Velocity 决定，不受影响 R-Theta Coordinate #\r对于一个 Polar Coordinate 中的 Circular Motion，有 $$v=\\dot{r} \\hat{e}r + r \\dot{\\theta} \\hat{e}\\theta$$ 带入 $\\dot r=\\ddot r=0$，得到 $$v=r \\dot{\\theta} \\hat{e}_\\theta$$ Clockwise \u0026amp; Counter Clockwise #\r对于不同的运动方向，可以建立两个坐标系的关系 对于两个坐标系，其中一个特点就是 N-T Coordinate 中，Normal Force 是指向圆心的，而对于 R-Theta 来说，Radius 是从圆心指向物体 Postion 的，这直接导致了两个 Coordinate 下，有 $\\vec a_n=-\\vec a_r$ 再者就是对于 R-Theta 中的 Angle 来说，Angle 的变化的永远以 Counter Clockwise 为正，但是 N-T 中不同转向的 Tangential Force 的正负不同，所以当 CW 时，有 $\\vec a_t=-\\vec a_\\theta$，在 CCW 中则是 $\\vec a_t=\\vec a_\\theta$ ","date":"Feb 13 2025","externalUrl":null,"permalink":"/docs/dynamics/dyn4.coordinate/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 2/13/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eNormal and Tangential Coordinates (n-t) – Circular Motion \r\n    \u003cdiv id=\"normal-and-tangential-coordinates-n-t--circular-motion\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#normal-and-tangential-coordinates-n-t--circular-motion\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e当已知了物体运动的轨迹的时候，可以更加简便的通过Normal法线，和Tangential切线坐标来描述粒子的运动\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/dynamics/dyn4.coordinate/DYN4.NormalandTangentialCoordinates_hu14839944584691460007.png 330w,\r\n        /docs/dynamics/dyn4.coordinate/DYN4.NormalandTangentialCoordinates_hu7448766895545966441.png 660w,\r\n        /docs/dynamics/dyn4.coordinate/DYN4.NormalandTangentialCoordinates_hu1501304354376045305.png 1024w,\r\n        /docs/dynamics/dyn4.coordinate/DYN4.NormalandTangentialCoordinates_hu1575434364101877089.png 2x\"\r\n        src=\"/docs/dynamics/dyn4.coordinate/DYN4.NormalandTangentialCoordinates_hu7448766895545966441.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"DYN 4. Coordinate","type":"docs"},{"content":"","date":"Feb 13 2025","externalUrl":null,"permalink":"/docs/dynamics/","section":"Docs","summary":"","title":"Dynamics","type":"docs"},{"content":" Last Edit: 2/8/25\nMagnetic Field #\r与 Electric Field 一般，Magnetic Field 也是由 Magnetic Charge 产生的 虽然理论上存在 Individual Magnetic Charges (AKA Magnetic Monopoles) 但是尚未被证实 Creation of Magnetic Fields #\r通常来说磁场通过两种方式形成，一个是 Electrically Charged Particles 比如导线中的电流形成的 Magnetic Field 另一种则是通过 Elementary Particles 基本粒子，如 Electron 等形成的 Intrinsic Magnetic Field 固有磁场 Magnetic Field Strength #\r当 Charged Particle 在 Magnetic Field 中移动的时候，它受到的力为 $$\\vec F_B=q(\\vec v\\times\\vec B)$$ 其中 \\(\\vec v\\) 为 Velocity Vector Magnetic Field Strength 的力的方向则是 Cross Product 方向，即通过 Right Hard Rule 给出 具体来说 Magnitude 为 $$F_B=|q|v_B\\sin\\phi$$ 其中 \\(\\phi\\) 为 Velocity 和 Magnetic Field 之间的夹角 Magnetic Field Strength 的单位为 Tesla，有 $$1 , \\text{tesla} = 1 , \\text{T} = \\frac{1 , \\text{newton}}{(\\text{coulomb})(\\text{meter/second})}$$ Direction of Magnetic Field #\r磁场线从磁体的 North Pole 指向 South Pole，和 Charged Particle 一般，同性相斥异性相吸 ex. Magnetic Force on a moving charged particle #\rA uniform magnetic field \\(\\vec{B}\\), with a magnitude of \\(1.2 , \\text{mT}\\), is directed vertically upward throughout the volume of a laboratory chamber. A proton with kinetic energy \\(5.3 , \\text{MeV}\\) enters the chamber, moving horizontally from south to north. What magnetic deflecting force acts on the proton as it enters the chamber? The proton mass is \\(1.67 \\times 10^{-27} , \\text{kg}\\). (Neglect Earth\u0026rsquo;s magnetic field.)\n先通过 Energy 求得 Proton 的 Velocity 有 $$v = \\sqrt{\\frac{2K}{m}} = \\sqrt{\\frac{(2)(5.3 , \\text{MeV})(1.60 \\times 10^{-13} , \\text{J/MeV})}{1.67 \\times 10^{-27} , \\text{kg}}} = 3.2 \\times 10^7 , \\text{m/s}$$ 再将速度带入 Magnetic Field Strength，有 $$F_B = |q| v B \\sin \\phi\n= (1.60 \\times 10^{-19} , \\text{C})(3.2 \\times 10^7 , \\text{m/s})\n\\times (1.2 \\times 10^{-3} , \\text{T})(\\sin 90^\\circ)\n= 6.1 \\times 10^{-15} , \\text{N}. , (\\text{Answer})$$ Magnetic Force due to straight current wire #\r对于一条有 Current 的 Wire，当它位于一个 Uniform 的 Magnetic Field 中时，其会收到一个 Magnetic Field Strength \\(\\vec F_b\\) 具体来说，Magnetic Field Force 的方向将由 Current 和 Magnetic Field 的方向决定 Magnetic Field Create by Straight Wire #\r当一个 Current 从一根直的 Wire 中通过的时候，其周围会形成环形磁场 \\(\\vec B\\) Magnetic Field 的方向可以通过 Right Hand Rule 判断 Biot - Savart Law #\r非直线导线中一个长度元素 \\(ds\\) 在距离 r 处的点 P 产生的磁场微分为 $$dB = \\frac{\\mu_0}{4 \\pi} \\cdot \\frac{i , ds , \\sin \\theta}{r^2} $$ 其中的 \\(\\mu_0\\) 为真空磁导率，有 \\(μ0​=4π×10^{−7}T⋅m/A=1.26\\times 10^{-6}T\\cdot m/A\\) 可以得到完整的 Law of Biot and Savart 有 $$dB = \\frac{\\mu_0}{4 \\pi} \\cdot \\frac{i , d\\vec s \\ \\times \\hat r}{r^2} $$ Law of Biot and Savart in Straight current-carrying Wire #\r由 Biot and Savart 公式可以得出一个 Long Straight Wire R 远的距离的 Magnetic Field为 $$B=\\frac{\\mu_oi}{2\\pi R}$$ Law of Biot and Savart in circular wire #\r一个圆弧的导线的圆心处的 Magnetic Field Strength 有 $$B = \\frac{\\mu_0 i \\Phi}{4 \\pi R}$$ Force Between Two Parallel Currents #\r已知一根带有 Current i 的 Straight Wire 的 Magnetic Field 有 $$\\vec F_b=i\\vec L\\times \\vec B$$ 两根平行导线之间的力是由于其中一根导线产生的磁场作用在另一根导线上的结果 导线 a 产生的磁场 \\(B_a\\) 在 b 位置为 \\(B_a = \\frac{\\mu_0 i_a}{2 \\pi d}\\)，即 b 收到的 Magnetic Field Strength 为 $$F_{ba} = i_b L B_a \\sin 90^\\circ = i_b L \\cdot \\frac{\\mu_0 i_a}{2 \\pi d} \\Rightarrow F_{ba} = \\frac{\\mu_0 L i_a i_b}{2 \\pi d}$$ Ampere\u0026rsquo;s Law #\rAmpere\u0026rsquo;s Law，通过一个假想的称为安培环（Ampereian Loop）的假想闭合路径来分析电流周围的磁场 Ampereian Loop 安培环 #\rAmpereian Loop 是一个假想的闭合路径，用于计算路径所包围的 Current 对该路径上每一点处磁场的贡献 对于 Ampereian Loop 内部的 Current，有 $$\\oint \\vec{B} \\cdot d\\vec{s} = \\mu_0 i_{enc} \\quad (\\text{Ampere\u0026rsquo;s law})$$ Direction of Magnetic Field #\r通过右手来判断，四指弯曲指向 Integration 方向，大拇指方向则为 Current 方向 Inside \u0026amp; Outside of the Wire #\r在 Long Straight 内外部的 Magnetic Field 是不同的 在外部时，可以通过 Biot - Savart Law 得到 Magnetic Field 为 $$B=\\frac{\\mu_oi}{2\\pi R}$$ ","date":"Feb 8 2025","externalUrl":null,"permalink":"/docs/electrical-fundamentals/ef7.magneticfields/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 2/8/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eMagnetic Field \r\n    \u003cdiv id=\"magnetic-field\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#magnetic-field\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e与 Electric Field 一般，Magnetic Field 也是由 Magnetic Charge 产生的\u003c/li\u003e\n\u003cli\u003e虽然理论上存在 Individual Magnetic Charges (AKA Magnetic Monopoles) 但是尚未被证实\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eCreation of Magnetic Fields \r\n    \u003cdiv id=\"creation-of-magnetic-fields\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#creation-of-magnetic-fields\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e通常来说磁场通过两种方式形成，一个是 Electrically Charged Particles 比如导线中的电流形成的 Magnetic Field\u003c/li\u003e\n\u003cli\u003e另一种则是通过 Elementary Particles 基本粒子，如 Electron 等形成的 Intrinsic Magnetic Field 固有磁场\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eMagnetic Field Strength \r\n    \u003cdiv id=\"magnetic-field-strength\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#magnetic-field-strength\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e当 Charged Particle 在 Magnetic Field 中移动的时候，它受到的力为\n$$\\vec F_B=q(\\vec v\\times\\vec B)$$\u003c/li\u003e\n\u003cli\u003e其中 \\(\\vec v\\) 为 Velocity Vector\u003c/li\u003e\n\u003cli\u003eMagnetic Field Strength 的力的方向则是 Cross Product 方向，即通过 Right Hard Rule 给出\u003c/li\u003e\n\u003cli\u003e具体来说 Magnitude 为\n$$F_B=|q|v_B\\sin\\phi$$\u003c/li\u003e\n\u003cli\u003e其中 \\(\\phi\\) 为 Velocity 和 Magnetic Field 之间的夹角\u003c/li\u003e\n\u003cli\u003eMagnetic Field Strength 的单位为 Tesla，有\n$$1 , \\text{tesla} = 1 , \\text{T} = \\frac{1 , \\text{newton}}{(\\text{coulomb})(\\text{meter/second})}$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eDirection of Magnetic Field \r\n    \u003cdiv id=\"direction-of-magnetic-field\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#direction-of-magnetic-field\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e磁场线从磁体的 North Pole 指向 South Pole，和 Charged Particle 一般，同性相斥异性相吸\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eex. Magnetic Force on a moving charged particle \r\n    \u003cdiv id=\"ex-magnetic-force-on-a-moving-charged-particle\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex-magnetic-force-on-a-moving-charged-particle\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cp\u003eA uniform magnetic field \\(\\vec{B}\\), with a magnitude of \\(1.2 , \\text{mT}\\), is directed vertically upward throughout the volume of a laboratory chamber. A proton with kinetic energy \\(5.3 , \\text{MeV}\\) enters the chamber, moving horizontally from south to north. What magnetic deflecting force acts on the proton as it enters the chamber? The proton mass is \\(1.67 \\times 10^{-27} , \\text{kg}\\). (Neglect Earth\u0026rsquo;s magnetic field.)\u003c/p\u003e","title":"EF 7. Magnetic Fields","type":"docs"},{"content":" Last Edit: 2/7/25\nElectric Current #\r对于一个铜环，内部每一处都处于同一个 Potential 下，即 In Electrostatic Equilibrium 处于静电平衡，并且内部 Electric Field 均为零 通过添加一个 Battery，可以形成一个 Potential Difference，产生一个 Electric Field，之后推动 Charge 移动，导致了 Current 电流的产生\nDirection of electric Current #\r电流的方向被定义为是 Positive 指向 Negative 的，但实际上在电路中移动的是 Electron，由于 Electron 在电路中的移动才产生了 Position Charge 的“移动”，但根据定义，电流方向仍然按照正电荷运动方向定义 约定建立之初，人们尚未了解到电子的存在，导致错误的定义沿用至今\nCurrent #\r对于一个在 Conductor 中的电流，有 $$i=\\frac{dq}{dt}$$ 代表了单位时间内穿过导体截面的电荷量 Kirchhoff\u0026rsquo;s Current Law KCL #\r基尔霍夫电流定律指出，在电路的任意 Junction 处，流入该节点的 Totoal Current 等于流出的 Total Current Current Density #\r电流密度是描述电荷流动分布的重要量，带有方向信息 $$i=\\int\\vec J\\cdot d\\vec A$$ 其中 dA 是垂直于导体表面元素的面积矢量 若电流 i 在截面上均匀分布且平行于 \\(\\vec A\\)，积分就可以化简为 $$i=JA\\Rightarrow J=\\frac{i}{A}$$ Drift Speed #\r在不同 Electirc Force 下，Charge Carriers (Assumed Positive) 会获得一个 Drift Speed \\(\\vec v_d\\)，其方向于 Electric Field 方向一致 并且 Current Density 与 Drift Speed 有 $$\\vec J=(ne)\\vec V_d$$ 其中 n 是单位面积（通常为 \\(1m^3\\) 中 Charge Carrier 的数量） e 则是单个 Charge Carrier 的电荷量 Resistance and Resistivity #\r一个 Conductor 的 Resistance R 被定义为 $$R=\\frac{V}{i}$$ V 是 Conductor 两端的 Potential Difference Resitance 的SI Unit 为 欧姆 \\(\\Omega\\) Resistance 在电路中起到了 Reduce Current Flow，Adjust Signal Levels，Divide Votages 等作用 Resistor Color Code #\r电阻的颜色编码标识了他的电阻值和公差，具体来 前两位代表了电阻值的有效数字，第三位代表了倍率，第四位为公差 例如，红-红-橙-金： 红色（2）、红色（2）、橙色（\\(\\times 1000\\)）、金色（公差 \\(\\pm 5%\\)） 电阻值为 \\(22 \\times 1000 = 22k\\Omega\\)，误差为 \\(\\pm 5%\\) Resitivity 电阻率 #\r与 Capacitance 一样，Resitivity 也是材料的固有属性，用于描述材料对于电流的阻碍能力 $$\\rho=\\frac{1}{\\sigma}=\\frac{E}{J}$$ E 为电场强度，J 为电流密度，Resitivity 的单位是 \\(\\Omega\\cdot m\\) 同样也有 \\(\\vec E=\\rho \\vec J\\)，说明了材料的电阻率越高，相同电流密度下的电场强度就越高 Resistance 电阻 #\rResitivity 描述的是 Material 对 Current 流动的阻碍属性，与其形状和大小无关，而 Resistance 描述的特点物体对电流流动的阻碍，单位是 \\(\\Omega\\)，计算一个 Conductor Resisitance 的方式是 $$R=\\rho\\frac LA$$ A 为 Cross-Sectional Area Temperature \u0026amp; Resisitance #\r大多数材料的 Resistance 会根据温度而变化，由公式 $$\\rho - \\rho_0 = \\rho_0 \\alpha (T - T_0)$$ Ohm\u0026rsquo;s Law #\rOhm\u0026rsquo;s Law 表明，通过一个器件的 Current 总是与施加在器件上的 Potential Difference 成正比 当一个 Conductor 的 Resistance 不依赖于施加的 Potential Difference 的大小和极性时，则其遵守 Ohm\u0026rsquo;s Law 当一个 Material 的 Resitivity 不依赖于施加的 Electric Field 的大小和方向时，其遵守欧姆定律 Ohm\u0026rsquo;s Law 也就是说当它们的 Resistance 和 Resitivity 是固有属性的时候，他们就遵守 Ohm\u0026rsquo;s Law\nPower #\rPower 是能量转换的速率，其最基本的计算公式为 \\(P=iV\\)，单位为瓦特 利用 Ohm\u0026rsquo;s Law，可以改写成 $$P=i^2R=\\frac{V^2}{R}$$ ","date":"Feb 7 2025","externalUrl":null,"permalink":"/docs/electrical-fundamentals/ef6.currentresistance/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 2/7/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eElectric Current \r\n    \u003cdiv id=\"electric-current\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#electric-current\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e对于一个铜环，内部每一处都处于同一个 Potential 下，即 In Electrostatic Equilibrium 处于静电平衡，并且内部 Electric Field 均为零\n\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/electrical-fundamentals/ef6.currentresistance/EF6.Current\u0026amp;Resistance_hu12897430973313359960.png 330w,\r\n        /docs/electrical-fundamentals/ef6.currentresistance/EF6.Current\u0026amp;Resistance_hu13147796366552973561.png 660w,\r\n        /docs/electrical-fundamentals/ef6.currentresistance/EF6.Current\u0026amp;Resistance_hu4088479549258487442.png 1024w,\r\n        /docs/electrical-fundamentals/ef6.currentresistance/EF6.Current\u0026amp;Resistance_hu7321396153845132530.png 2x\"\r\n        src=\"/docs/electrical-fundamentals/ef6.currentresistance/EF6.Current\u0026amp;Resistance_hu13147796366552973561.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 6. Current \u0026 Resistance","type":"docs"},{"content":" Last Edit: 2/6/25\nCapacitor 电容器是一种储存 Electrical Energy 的装置，由两个相互隔离的导体（即极板）组成，分别带有 +q 和 -q 的电荷\n5.1 Capacitance 电容 #\rCapacitance 电容代表了导体储存 Charge 的能力，表示一个电容器在一定的电压下能储存多少电荷，其基本定义是 $$q=CV$$ 其中 \\(V\\) 是两个 Plate 极板之间的 Potential Difference Charging a Capacitor #\r要使 Capacitor 充电，需要利用到电池两侧初始存在的 Potential Difference 由于电池两侧存在 Potential Difference，于是就形成了一个 Electirc Field，电场会对电荷产生一个 Force \\(F=qE\\) ，这使得电荷在电场中受力，正电荷从负极电极到了正极（正电荷是不会移动的，只有负电荷会，这里的“移动”是假设”，负电核到了正极 举一个例子就是假设一开始电池具有 10 V 的电压，充电完成后正极板上有 +10V，负极则有 0V，此时由于两个电极板之间是绝缘的，电荷会积累到电极板表面并形成 Electric Field，从正极指向负极，此时电路中的电极板电压等于电池电压，电荷不在移动，电极板完成整个充电的过程 类比一个水流抽水的过程，电池就是水泵推动水在管道中移动\nProperty of Capacitance #\r与电阻一样，电容是一个电容器的特性，其即使公式为 \\(q=CV\\) ，但实际上其并不依赖于储存的电荷量 q 真正影响电容的因素为形状，尺寸，相对位置以及介质 也就是说 q = CV 这个公式真正定义的是 q 和 V 之间的系数关系\n5.2 Calculating The Capacitance #\r不同类型的电容器，其电容值的计算方式不同，具体取决于几何结构和极板之间的介质\nParallel-Plate Capacitor 平行板电容器 #\r当有两个面积为 A 的平行导体板相距为 d 的时候，其电容有 $$C=\\frac{\\varepsilon_0 A}{d}$$\n可以看出面积增大、电极板距离减小时，电容增大\nCylindrical Capacitor 圆柱形电容器（ #\r两个同轴圆柱导体，内外圆柱的半径分别为 a 和 b，长度为 L $$C = 2 \\pi \\varepsilon_0 \\frac{L}{\\ln(b/a)}$$ 电容与圆柱长度 L 成正比，内外圆柱半径比值决定了电容大小。 Spherical Capacitor 球形电容器 #\r两个同心球形导体，内外球半径分别为 a 和 b $$C = 4 \\pi \\varepsilon_0 \\frac{ab}{b - a}$$ Isolated Spherical Capacitor 孤立球形电容器 #\r仅有一个孤立的球体，半径为 R $$C = 4 \\pi \\varepsilon_0 R$$ 孤立球体的电容只与球体半径有关 ex. Change in Capacitance when change in radius #\rA drop of mercury is an isolated sphere with radius R= 3.83. What is the capacitance of a drop that results from three drops of mercury combined, each with the same radius R\n三个球的总体积为： $$V_{\\text{total}} = 3 \\times \\frac{4}{3} \\pi R^3 = 4 \\pi R^3$$ 此时可以求出新半径 \\(R\u0026rsquo; = \\sqrt[3]{3} R = 1.442 , R\\) 将 R=3.83R = 3.83 代入： $$R\u0026rsquo; = 1.442 \\times 3.83 \\approx 5.524$$ 已知孤立球体的电容公式为： $$C = 4 \\pi \\varepsilon_0 R$$ 带入半径之后得到 $$C≈6.14×10−10 FC \\approx 6.14 \\times 10^{-10} , \\text{F}$$ 5.3 Capacitors in parallel and in series #\r电路中的电容器也将遵循并联和串联的特性 5.3.1 Capacitors in Parallel #\r对于一个电路，其中三个 Capacitors 并联放置，有 $$\\ q_1 = C_1 V, \\ q_2 = C_2 V, \\mbox{ and } \\ q_3 = C_3 V$$ 根据串联分压，并联分流的特性，说明并联的时候每个电容器 V 相等，有 $$q = q_1 + q_2 + q_3 = (C_1 + C_2 + C_3) V$$ $$C_{eq} = \\frac{q}{V} = C_1 + C_2 + C_3$$ 也就是说电容器并联时，总电容 \\(C_{\\text{eq}}\\)​ 增大 5.3.2 Capacitors in Series #\r到了串联的时候，每个电容器电流相同，也就是 q 一致，有 $$V_1 = \\frac{q}{C_1}, \\quad V_2 = \\frac{q}{C_2}, \\text{ and } \\quad V_3 = \\frac{q}{C_3}$$ $$V = V_1 + V_2 + V_3 = q \\left( \\frac{1}{C_1} + \\frac{1}{C_2} + \\frac{1}{C_3} \\right)$$ $$C_{eq} = \\frac{q}{V} = \\frac{1}{\\frac{1}{C_1} + \\frac{1}{C_2} + \\frac{1}{C_3}}$$ $$\\frac{1}{C_{eq}} = \\frac{1}{C_1} + \\frac{1}{C_2} + \\frac{1}{C_3}$$ ex. Capacitors in both Parallel and Series #\rFind charge on C1\n首先计算 C1 和 C2 两个 Parallel Capacitor 的总电容，有并联电路 $$C=C_1+C_2=17.3$$ 之后这个 17.3 再和 4.5 串联，有 $$\\frac1C=\\frac{1}{17.3}+\\frac{1}{4.5}\\Rightarrow C=3.57$$ 5.4 Energy Stored in an Electric Field #\r当外部装置（如电池）对电容器充电时，做的功以势能 U 的形式储存，有 $$U=\\frac{q^2}{2C}$$\n当带入 \\(q =cv\\) 的时候，得到另一种形式 $$U=\\frac 12CV^2$$ 做的功主要是由 Electric Field Strength \\(F=qE\\) 提供，具体来说是将负电荷从一个极板移动到另外一个极板所做的功，完整推导如下 当少量电荷 dq 从一个极板到达另一个的时候，两个极板之间形成一个初始电场 E，导致极板之间产生 Potential Difference \\(V=\\frac qC\\) 想要在移动电荷，则需要 Electric Field Strength，F 做功，有 \\(W=Fd\\)，其中 F就是电场力，那么就有 \\(dW= Fdl\\)，用了 l 替换 d，同时因为 \\(F=qE\\)，有 \\(dW=qE\\cdot dl\\) 现在知道电势差 V 与电场的关系为 $$V=-\\int^b_a\\vec E\\cdot dl$$ 积分在均匀电场和点电荷电场等对称电场中简化，有 \\(V_{AB} = - \\int_A^B \\vec{E} \\cdot d\\vec{l} = - E \\int_A^B \\cos \\theta , dl\\)，\\(V_{AB} = - \\int_A^B \\frac{kq}{r^2} , dr = kq \\left( \\frac{1}{r_A} - \\frac{1}{r_B} \\right)\\) 等\n从上面的 V 中可以推导出 \\(dV=-E \\cdot dl\\)，带回做功的公式中有 \\(dW=q\\cdot dv\\)，观察此时的公式，它描述的是一个电荷在经过路径上不同的 V 的时候产生的功，也就是一个电荷在不同电势的路径下的功 而我们像描述的是一个充电，也就是电荷累加到极板上的一个过程，此时的瞬时电势 V 将会是一个 Constant，但是电容器极板上的 Charge 则会随时间增加，即每增加一个微小的电荷 dq，电场力都要做一个微小功为 \\(dW=V\\cdot dq\\) 两边积分得到 $$W=U=\\int^Q_0 V\\cdot dq=\\int^Q_0\\frac{q}{C}\\cdot dq=\\frac{q^2}{2C}$$ 为什么 W = U 我也不知道\nDistance between plates and Capacitance #\r已知\\(U = \\frac{q^2}{2C}\\) ，将 \\(C = \\frac{\\varepsilon_0 A}{d}\\) 带入，有 \\(U = \\frac{q^2}{2 \\frac{\\varepsilon_0 A}{d}}\\)，整理得到 $$U = \\frac{dq^2}{2 \\varepsilon_0 A}$$ Energy Density #\r能量密度由总能量除以体积得到，有 $$u = \\frac{U}{Ad} = \\frac{CV^2}{2Ad}$$ 带入 \\(C = \\frac{\\varepsilon_0 A}{d}\\) 得到 $$u = \\frac{1}{2} \\varepsilon_0 \\left( \\frac{V}{d} \\right)^2= \\frac{1}{2} \\varepsilon_0 E^2$$ Dielectric #\r介电材料是绝缘的材料，其填充在电容器板之间提高电容 Michael Faraday 于1837年发现了此规律，并且定义加入介电材料后的电容值将会增加一个比例因子 \\(\\kappa\\) ，其中真空中的介电常数默认为 1 Breakdown Potential #\r在电容器中加入了介电材料后，这个材料会存在一个 Maximum Potential （Breakdown Potentioal），当电压超过这个值，Dielectirc 会被 Break Down 击穿并变为导体 Material Dielectric Constant ( \\kappa ) Dielectric Strength (kV/mm) Air (1 atm) 1.00054 3 Polystyrene 2.6 24 Paper 3.5 16 Transformer oil 4.5 Pyrex 4.7 14 Ruby mica 5.4 Porcelain 6.5 Silicon 12 Germanium 16 Ethanol 25 Water (20°C) 80.4 Water (25°C) 78.5 Titania ceramic 130 Strontium titanate 310 8 For a vacuum, ( \\(\\kappa = 1\\) ).*\nCapacitor with a Dielectric #\r当加入了 Dielectric 后，电容公式改变为 $$C = \\kappa \\frac{\\varepsilon_0 A}{d}$$ 同时可以定义一个 \\(l=\\frac{A}{d}\\)，公式就变为 \\(C = \\kappa \\varepsilon_0 \\ell\\) 电压 V 保持恒定（并联电容器）**： $$q = CV = \\kappa \\varepsilon_0 \\ell V$$ 电荷 q 保持恒定（串联电容器） $$V = \\frac{q}{C} = \\frac{q}{\\kappa \\varepsilon_0 \\ell}$$ Super Capacitor #\r对比了超级电容器（Supercapacitor）与锂离子电池（Lithium-ion battery）的性能和特性：\n功能 超级电容器 锂离子电池（通用） 充电时间 1 – 10 秒 10 – 60 分钟 循环寿命 100 万次或 30,000 小时 500 次及以上 单元电压 2.3 至 2.75 伏 3.6 至 3.7 伏 比能量 (Wh/kg) 5（典型值） 100 – 200 比功率 (W/kg) 高达 10,000 1000 – 3000 每 Wh 成本 约 20 美元 0.50 – 1.00 美元（大系统） 超级电容器充电快、循环寿命长、比功率高，但能量密度低，成本较高 锂离子电池有较高的能量密度和较低的成本，但充电时间长，循环寿命较短 ex. Energy change when insert an Dielectirc #\r平行板电容器的电容为 \\(C = 13.5 , \\text{pF}\\)，通过电池充电到电压 \\(V = 12.5 , \\text{V}\\) 断开电池后，插入介电常数 \\(\\kappa = 6.50\\) 的瓷板。 问题：\na) 插入前的电容器电势能是多少？\nb) 插入后的电容器电势能是多少？ 插入前的电势能 \\(U_i\\) 为 \\(U_i = \\frac{1}{2} C V^2\\) $$U_i = \\frac{1}{2} \\times 13.5 \\times 10^{-12} , \\text{F} \\times (12.5 , \\text{V})^2 = 1.055 \\times 10^{-9} , \\text{J} \\approx 1100 , \\text{pJ}$$ 插入后的电势能 \\(U_f\\) $$U_f = \\frac{q^2}{2 \\kappa C} = \\frac{U_i}{\\kappa}$$ 插入介电材料后，能量减少，损失的能量为： $$W = U_i - U_f = 1055 , \\text{pJ} - 162 , \\text{pJ} = 893 , \\text{pJ}$$ 插入介电材料后，电势能因介电常数 \\(\\kappa\\) 的影响减少。 损失的能量可被视为在插入过程中施加的机械功。 ","date":"Feb 6 2025","externalUrl":null,"permalink":"/docs/electrical-fundamentals/ef5.capacitance/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 2/6/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eCapacitor 电容器是一种储存 Electrical Energy 的装置，由两个相互隔离的导体（即极板）组成，分别带有 +q 和 -q 的电荷\u003c/p\u003e","title":"EF 5. Capacitance","type":"docs"},{"content":"","date":"Jan 28 2025","externalUrl":null,"permalink":"/tags/computer-science/","section":"Tags","summary":"","title":"Computer Science","type":"tags"},{"content":"","date":"Jan 28 2025","externalUrl":null,"permalink":"/series/d2l/","section":"Series","summary":"","title":"D2L","type":"series"},{"content":"","date":"Jan 28 2025","externalUrl":null,"permalink":"/tags/d2l/","section":"Tags","summary":"","title":"D2L","type":"tags"},{"content":"","date":"Jan 28 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l6.convolutionneuronnetwork/","section":"Docs","summary":"","title":"D2L 6. ConvolutionNeuronNetwork","type":"docs"},{"content":" Last Edit: 1/29/25\n由于卷积神经网络的设计就是为了处理图像，所以这里直接以图像为例\n6.2.1 Cross-Correlation Calculation #\r严格来说卷积层表达的运算实际上是 Cross-correlation 互相关运算，而不是卷积运算 暂时忽略图像的第三个维度信息，构造输入，卷积核和输出 在二维互相关运算中，卷积窗口从输入张量的左上角开始，从左到右、从上到下滑动 当输入中的卷积窗口移动到一个新位置的时候，窗口内的元素将和卷积核中按位置相乘并计算和得到一个标量值，如下 $0 \\times 0 + 1 \\times 1 + 3 \\times 2 + 4 \\times 3 = 19$ $1 \\times 0 + 2 \\times 1 + 4 \\times 2 + 5 \\times 3 = 25$ $3 \\times 0 + 4 \\times 1 + 6 \\times 2 + 7 \\times 3 = 37$ $4 \\times 0 + 5 \\times 1 + 7 \\times 2 + 8 \\times 3 = 43$ 由于卷积核的长宽是大于一的，导致了输出的大小等于输入大小减去核大小加一 $$(n_h - k_h + 1) \\times (n_w - k_w + 1)$$ 想让输入输出大小一致，可以在四周填充0保证输入的大小\nimport torch from torch import nn from d2l import torch as d2l def corr2d(X, K): #@save \u0026#34;\u0026#34;\u0026#34;计算二维互相关运算\u0026#34;\u0026#34;\u0026#34; h, w = K.shape Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)) for i in range(Y.shape[0]): for j in range(Y.shape[1]): Y[i, j] = (X[i:i + h, j:j + w] * K).sum() return Y X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]) K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) corr2d(X, K) 现在有 Kernel $k=h\\times w$，则每一个Input x上的点 $i,j$ 的输出都将是其 i:i+h, j:j+w 范围内的输入与k进行元素乘法后的和 X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]) K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) corr2d(X, K) -\u0026gt; tensor([[19., 25.], [37., 43.]]) 6.2.2 Convolution Layer 卷积层 #\rclass Conv2D(nn.Module): def __init__(self, kernel_size): super().__init__() self.weight = nn.Parameter(torch.rand(kernel_size)) self.bias = nn.Parameter(torch.zeros(1)) def forward(self, x): return corr2d(x, self.weight) + self.bias nn.Parameter 是 PyTorch 中的一个类，它被用来将一个张量转换为一个模块的参数 当使用 nn.Parameter 包装一个张量时，这意味着你希望这个张量能够在模型的训练过程中被优化器优化（即进行梯度更新） 6.2.3 Edge detection #\r卷积层，或者说互相关层的主要作用就是提取相邻像素的特殊信息，如颜色边缘 现在构造一个黑白色 6x8 图像 X = torch.ones((6, 8)) X[:, 2:6] = 0 X -\u0026gt; tensor([[1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.]]) 现在用一个 Kernel 为 K = torch.tensor([[1.0, -1.0]]) 可以发现这个核的作用是：如果水平相邻的两元素相同，则输出为零，否则输出为非零，具体来说，从1，也就是白色到0黑色的时候，有 $Y[i,j]=1+0*(-0.1)=1$，相反则是 -1，于是整体输出就为 tensor([[ 0., 1., 0., 0., 0., -1., 0.],\r[ 0., 1., 0., 0., 0., -1., 0.],\r[ 0., 1., 0., 0., 0., -1., 0.],\r[ 0., 1., 0., 0., 0., -1., 0.],\r[ 0., 1., 0., 0., 0., -1., 0.],\r[ 0., 1., 0., 0., 0., -1., 0.]]) 现在如果将上面的图片做Transpose，可以发现检测到的垂直边缘消失了，也就是说其只能检测一个自由度上的特征 6.2.4. 学习卷积核 #\r到了更加复杂的 Convolution Layer 的时候不可能手动设计滤波器，需要主动学习这一个Kernel Core，在忽略 Bias 的前提下有 # 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核 conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False) # 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度）， # 其中批量大小和通道数都为1 X = X.reshape((1, 1, 6, 8)) Y = Y.reshape((1, 1, 6, 7)) lr = 3e-2 # 学习率 for i in range(10): Y_hat = conv2d(X) l = (Y_hat - Y) ** 2 conv2d.zero_grad() l.sum().backward() # 迭代卷积核 conv2d.weight.data[:] -= lr * conv2d.weight.grad if (i + 1) % 2 == 0: print(f\u0026#39;epoch {i+1}, loss {l.sum():.3f}\u0026#39;) -\u0026gt; epoch 2, loss 6.422 epoch 4, loss 1.225 epoch 6, loss 0.266 epoch 8, loss 0.070 epoch 10, loss 0.022 此时输出得到的 Tensor 有 tensor([[ 1.0010, -0.9739]]) 6.2.5. Cross-Correlation and Convolution #\r卷积和互相关运算在前面提到过，他们的差别就在 Kernel 是否翻转，但由于DL的历史遗留问题，我们统称 Convolution Feature Map and Receptive Field 特征层和感受野 #\r对于一个 Convolution Layer 的output，其可以被称为 Feature Map，每过一层卷积层都会得到一个新的特征图，他们可以代表图像的特点信息如边缘，颜色，形状等 而 Receptive Field 感受野是指输入中影响单个输出的区域大小的区域，其在单层卷积层时就是 Kernel 大小，而到二零多层堆叠时，感受野就会累加 ","date":"Jan 28 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l6.convolutionneuronnetwork/d2l6.2imageconvolution/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/29/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e由于卷积神经网络的设计就是为了处理图像，所以这里直接以图像为例\u003c/p\u003e","title":"D2L 6.2 Image Convolution","type":"docs"},{"content":" Last Edit: 1/28/25\n5.1 Functions #\rFunction是用来执行特定任务的可重复调用恶的代码块，通过Modular Programming将复杂问题分解\nvoid printStars(int numOfStars) { for (int star = 1; star \u0026lt;= numOfStars; star++) { printf(\u0026#34;%c\u0026#34;, \u0026#39;*\u0026#39;); } printf(\u0026#34;\\n\u0026#34;); // to start a new line } 这个函数包含了一下的属性 返回类型：void（不返回任何值） 函数名称：printStars 输入参数类型：int 输入参数的变量名：numOfStars 函数体：包含用于打印一行星号的指令 5.1.1 Void #\rvoid 用于表示无类型或无值，void 指的是函数的返回类型，表示这个函数在执行完毕后不会返回任何值 5.1.2 Function Prototype #\r在C语言中，Function Prototype 是用来在函数实际定义前声明函数接口的代码，其包含了改函数的调用参数类型和数量，但不包含具体的执行内容 void printPattern(int numOfRows); void printStars(int numOfStars); 这行就是两个Function的Prototype，表明了两个函数均需要整数作为输入 5.1.3 Order of execution #\r在C语言中，存在编译和执行的两个步骤，从编译来说，顺序是从上到下的，这就代表了下方是可以引用上方的定义，但是如果下方需要引用的东西在上方没有出现，则会报错因为找不到目标 具体来说所有函数和参数的下方就是 main 函数，因为C语言在运行的时候是从 main 函数开始的，也就是说所有在 main 中call到的function都应该在上方被定义，但为了[##5.1.4 Another way to write functions]中将要提到的问题，Funtion Prototype被定义用来优化代码 而C语言程序的执行始终从 main 函数开始，这时函数已经完成了编译，也就是已经编译完了整个代码，所以这时的 main 是可以找到任意位置上的 function 的，而不是从源文件的最上方向下逐行执行 通过在 main 函数中调用函数，其能找到任意函数，即编译器可以知道函数的存在以及他的接口是什么 5.1.4 Another way to write functions #\r如果不写 Function Prototype 的话，就需要把所有Function的定义放置在 main 函数的前方以确保在编译 main 的时候不会因为找不到而报错 # include \u0026lt;stdio.h\u0026gt; void printStars(int numOfStars) { for (int star = 1; star \u0026lt;= numOfStars; star++) { printf(\u0026#34;%c\u0026#34;, \u0026#39;*\u0026#39;); } printf(\u0026#34;\\n\u0026#34;); // to start a newline } void printPattern(int numOfRows) { for (int row = 1; row \u0026lt;= numOfRows; row++) { printStars(row); } } int main(void) { int lines; printf(\u0026#34;Enter the number of lines in the pattern:\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;lines); prinntPattern(lies); return 0; } 但是这种写法使得代码的可读性降低了很多，这可能导致 main 函数远离文件的起始位置，使得跟踪程序流程更加困难 同时在多人开发环境中，团队成员通常需要清楚地知道可以调用哪些函数及其参数，而不必查看每个函数的实现。函数原型在头文件中提供了这样的信息，便于团队成员之间的协作 5.1.4.1 Error Case #\r如果代码如下 #include \u0026lt;stdio.h\u0026gt; void printPattern(int numOfRows) { for (int row = 1; row \u0026lt;= numOfRows; row++) { printStars(row); } } void printStars(int numOfStars) { for (int star = 1; star \u0026lt;= numOfStars; star++) { printf(\u0026#34;%c\u0026#34;, \u0026#39;*\u0026#39;); } printf(\u0026#34;\\n\u0026#34;); // to start a new line } int main(void) { int lines; printf(\u0026#34;Enter the number of lines in the pattern: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;lines); printPattern(lines); return 0; } 在上面的代码中，在，代码的printPattern function中调用了 printStars(row) ，但是这个函数的定义位于下方，如果在一个函数被调用之前，编译器没有遇到这个函数的声明或定义，它就不会知道这个函数的存在，导致编译错误 5.2. Communicate from a function #\r前面提到的 Functions 并没有任何返回值，这是因为定义 Function的时候采取的是 void 5.2.1 Return a non-void variable type #\r#include \u0026lt;stdio.h\u0026gt; int factorial(int n); int main(void) { int number = 4; int result = factorial(number); printf(\u0026#34;Factorial of %d: %d.\\n\u0026#34;, number, result); return 0; } int factorial(int n) { int fact = 1; for (int i = 1; i \u0026lt;= n; i++) { fact = fact * i; } return fact; } factorial 函数接收一个 int 参数 n，并返回 n! return fact; 语句将计算结果返回给调用者，即 main 函数 main 通过 result = factorial(number); 获取返回值并存储 printf 用于打印最终结果 5.2.2. Summary of syntax #\r#include \u0026lt;stdio.h\u0026gt; // 函数原型（声明） \u0026lt;return type\u0026gt; functionName(\u0026lt;type\u0026gt;); int main(void) { // 调用有返回值的函数 \u0026lt;type\u0026gt; variableName = functionName(\u0026lt;variable to pass\u0026gt;); // 调用无返回值的函数 functionName(\u0026lt;variable to pass\u0026gt;); return 0; } // 函数实现（定义） \u0026lt;return type\u0026gt; functionName(\u0026lt;type\u0026gt; \u0026lt;input parameter name\u0026gt;) { return \u0026lt;变量，类型与 \u0026lt;return type\u0026gt; 相同\u0026gt;; } 5.3 Variable Scope #\r在前面的Loop单元中提到过 Variable Scope 的概念，即一个变量的定义范围，在前面提到的是loop中的variable只能作用在其循环当中，想要让其作用于循环外则需要在外部声明变量\nint count; for (count = 1; count \u0026lt;= n; count++) { printf(\u0026#34;*\u0026#34;); } count = 10; // ✅ 正确，count 在整个函数内都可用 同样的，Function 中的变量也只能储存在 Function 中 #include \u0026lt;stdio.h\u0026gt; // 函数声明 double divideByTwo(double); int main(void) { double n = 4.2, result; result = divideByTwo(n); printf(\u0026#34;%lf,%lf\u0026#34;, n, result) return 0; } // 函数定义 double divideByTwo(double n) { n = n / 2; return n; } 在这个程序中同时存在两个 n 其中函数中的独立于外部主程序存在 所以这个程序的返回值将会是 4.2,2.1 5.4. Pass more values to a function #\r一个函数可以指定接收多个 Variable #include \u0026lt;stdio.h\u0026gt; int median(int, int, int); // Prototype int main(void) { // Main Function printf(\u0026#34;The median of (%d, %d, %d) is %d\\n\u0026#34;, -105, -28, -73, median(-105, -28, -73)); printf(\u0026#34;The median of (%d, %d, %d) is %d\\n\u0026#34;, 0, -101, 98, median(0, -101, 98)); printf(\u0026#34;The median of (%d, %d, %d) is %d\\n\u0026#34;, -101, -67, 0, median(-101, -67, 0)); return 0; } int median(int x, int y, int z) { // Function Body int result = 0; if ((x \u0026gt;= z \u0026amp;\u0026amp; x \u0026lt;= y) || (x \u0026gt;= y \u0026amp;\u0026amp; x \u0026lt;= z)) result = x; else if ((y \u0026gt;= x \u0026amp;\u0026amp; y \u0026lt;= z) || (y \u0026gt;= z \u0026amp;\u0026amp; y \u0026lt;= x)) result = y; else result = z; return result; } ","date":"Jan 28 2025","externalUrl":null,"permalink":"/docs/learning-programming-with-c/lpc5.functions/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/28/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e5.1 Functions \r\n    \u003cdiv id=\"51-functions\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#51-functions\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cp\u003eFunction是用来执行特定任务的可重复调用恶的代码块，通过Modular Programming将复杂问题分解\u003c/p\u003e","title":"LPC 5. Functions","type":"docs"},{"content":" Last Edit: 1/23/25\n4.1 Electric Potential #\r对于一个重力场，其Field Strength为g，而Gravity所做的功则为\\(W=mgh\\) 可以发现这一个Work Done只和高度差有关，与路径无关（也就是说即使在途中左右摇摆，重力做的功依然不变） 同理可以类比到Electric Field中，电场力做功为\\(W=Eqh\\)，并且同样的与路径无关 Electrical Potential Energy 电势能 #\rElectrical Potential Energy 是带电粒子由于其位置处于电场中而具有的能量 如果Charge在Electric Field中做了Negative的Work，其就是在Electric Field中积累了Electric Potential Energy，于是就有公式 $$U=-W$$ 其中U就是Electric Potential Energy 电势能 具体来说定义Electric Potential Energy的办法就是通过Test Charge的两个参考点，一个是无穷远处电荷之间相互作用力忽略不记的地方，到另一个参考点，Test Charge在这两个点之间做的功便为电势能 Electrical Potential 电势 #\rElectrical Potential 指的是电场中某一点单位电荷所具有的电势能 $$V=\\frac{U}{q}$$ 当Paritical从Electrical Field中的初始点移动到终点时，电势发生变化，用公式表示为 $$\\Delta V = V_f - V_i$$ 电势能的变化可以用公式计算，由于Paritcal的Charge并不发生改变，有 $$\\Delta U = -W=q \\Delta V = q(V_f - V_i)$$ 在这一过程中，总能量是守恒的，这意味着动能和势能之和保持不变 从初始点 i 移动到终点 f 时，机械能守恒关系表示为： $$U_i + K_i = U_f + K_f 或\\Delta K = -\\Delta U$$ 4.2 Equipotential Surfaces 等势面 #\rEquipotential Surfaces 指的是一个Electrical Potential 相等的区域，Partical沿着这一个Surface移动的时候不需要做功 Calculating the Potential from the Field #\r根据Electric Field Magnitude可以计算出Partical移动后的Potential Difference 由于Partical在Electric Field中需要克服电场力做功，则有 $$dW=\\vec E \\cdot d\\vec s\\Rightarrow \\int dW= V_f - V_i = -\\int_i^f \\vec{E} \\cdot d\\vec{s}$$ 4.3 Electrical Potential Due to a Charged Particle #\rCharged Particle在空间中会形成一个Electrical Field，\\(\\vec{E} = \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r^2} \\hat{r}\\)，将其代入积分 $$V = -\\int_\\infty^r \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r^2} dr= \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r}$$ A positively charged particle produces a positive electric potential. A negatively charged particle produces a negative electric potential.\nex. Rank the Electral Potential #\rAssume all dots are Protons 根据\\(V= \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r}\\)，r越小V越大，有 a) Proton 1 has more Electric Potential (v) than Proton 2, since D \u0026gt; d b) Proton 1 has more Electric Potential (v) than Proton 2, since D \u0026gt; d c) Proton 1 has more Electric Potential (v) than Proton 2, since D \u0026gt; d 4.7 Electrical Potential Energy of a system of charged Particles #\r对于空间中的两个Particle，他们之间的距离为 r ，则由他们之间的Electrical Field相互作用而具有的Energy被称为他们的Potential Energy，前面已经提到了一个Partical在空间中会形成一个Electrial Potential \\(V = \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r}\\) ，而U是Partical在电场中所具有的能量，就有 $$U = \\frac{1}{4\\pi \\epsilon_0} \\frac{q_1 q_2}{r}$$ U：两电荷之间的Electrical Potential Energy \\(q_1、q_2\\)：两个电荷的电荷量（C） \\(r\\)：两电荷之间的距离 \\(\\varepsilon_0\\)：真空介电常数（\\(8.85 \\times 10^{-12} , \\text{F/m}\\)） Sign Convention #\r已知2个Partical可能出现三种不同的系统 如果两电荷都是正电荷，它们会排斥，电势能 U\u0026gt;0 如果两电荷都是负电荷，它们同样会排斥，但电势能公式保持不变，因为两个负电荷相乘仍为正数，因此 U\u0026gt;0 如果两个电荷符号不同（例如，一个是正电荷，另一个是负电荷），它们会吸引，表示系统释放能量 ex. Potential Energy of a system of three charged particles #\r有一个等边三角形的电荷系统，包含三个带电粒子：q1=+q，q2=−4q，q3=+2q，分别间隔12cm，求这个系统的Total Potential Energy\n已知两个电荷之间的电势能为： \\(U_{ij} = \\frac{1}{4\\pi \\epsilon_0} \\frac{q_i q_j}{d}\\)，总电势能是所有电荷对之间电势能的总和： \\(U = U_{12} + U_{13} + U_{23}\\) $$U = U_{12} + U_{13} + U_{23}$$ $$U = -\\frac{4q^2}{4\\pi \\epsilon_0 d} + \\frac{2q^2}{4\\pi \\epsilon_0 d} - \\frac{8q^2}{4\\pi \\epsilon_0 d} $$ $$U = -\\frac{10q^2}{4\\pi \\epsilon_0 d}$$ 代入数据后可以得到 $$U = -\\frac{10 (150 \\times 10^{-9})^2}{4\\pi \\epsilon_0 \\times 0.12}\\Rightarrow U = -1.7 , \\text{J} = -1.7 , \\text{mJ}$$ 负电势能意味着这个带电系统更稳定，或者说如果你想把这些电荷分开到无限远，就需要额外做功才能克服它们之间的相互作用。负值越大，系统的束缚越强。\n","date":"Jan 23 2025","externalUrl":null,"permalink":"/docs/electrical-fundamentals/ef4.electricpotential/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/23/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e4.1 Electric Potential \r\n    \u003cdiv id=\"41-electric-potential\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#41-electric-potential\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于一个重力场，其Field Strength为g，而Gravity所做的功则为\\(W=mgh\\)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/electrical-fundamentals/ef4.electricpotential/EF4.ElectricPotential_hu3013009443759680203.png 330w,\r\n        /docs/electrical-fundamentals/ef4.electricpotential/EF4.ElectricPotential_hu10790805179443622640.png 660w,\r\n        /docs/electrical-fundamentals/ef4.electricpotential/EF4.ElectricPotential_hu15032556861933157744.png 1024w,\r\n        /docs/electrical-fundamentals/ef4.electricpotential/EF4.ElectricPotential_hu2476701224367274999.png 2x\"\r\n        src=\"/docs/electrical-fundamentals/ef4.electricpotential/EF4.ElectricPotential_hu10790805179443622640.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 4. Electric Potential","type":"docs"},{"content":" Last Edit: 1/22/25\nSequences #\rSequence是按照一定顺序排列的一列数。序列可以是有限的也可以是无限的，通常表示为\\(a_1, a_2, a_3, \\ldots\\)，其中\\(a_n\\)表示序列的第n项 Limit of a Sequence #\r对于一个Sequence，如果有 $$\\lim_{n\\rightarrow\\infty}a_n=L,L\\in \\mathbb R$$ 则该Sequence的Limit为L 如果存在这个L，也可以说Sequence是Converge 收敛的 如果不存在，则Sequence Diverge 发散 ex. Nature Number #\r找到Sequence \\(a_n = \\left(1 + \\frac{1}{n}\\right)^n\\)的Limit $$\\lim_{n \\to \\infty} a_n = \\lim_{n \\to \\infty} \\left(1 + \\frac{1}{n}\\right)^n = e$$ Properties of Limits of Sequences #\rLet \\(\\lim_{n \\to \\infty} a_n = L \\text{ and } \\lim_{n \\to \\infty} b_n = K\\) $$\\lim_{n \\to \\infty} (a_n \\pm b_n) = L \\pm K$$ $$\\lim_{n \\to \\infty} c a_n = cL$$ $$\\lim_{n \\to \\infty} (a_n b_n) = LK$$ $$\\lim_{n \\to \\infty} \\frac{a_n}{b_n} = \\frac{L}{K}$$ Squeeze Theorem for Sequences #\rSqueeze Theorem也可以用来解Sequence的Convergence，其通常用在 \\((-1)^n, \\sin(x)\\)等在\\(n\\rightarrow \\infty\\)时oscillate的函数中 ex. Sequence Convergence by Squeeze Theorem #\r证明Sequence \\({ c_n } = \\left{ (-1)^n \\frac{1}{n!} \\right}\\)收敛 使用两个序列\\(a_n=\\frac{1}{2^n}\\)，已知Factorial的扩散速度小于Exponential，有 $$-\\frac{1}{2^n} \\leq (-1)^n \\frac{1}{n!} \\leq \\frac{1}{2^n}, \\quad n \\geq 4$$ Monotonic Sequences #\r当一个Sequence的每一项都单调递增或单调递减时，该Sequence被称为Monotonic Sequence Bounded Sequence #\rBounded Above #\r当存在一个\\(M\\in \\mathbb R\\)使得\\(a_n\\leq M\\)时，称该Sequence Bounded Above Bounded Below #\r当存在一个\\(M\\in \\mathbb R\\)使得\\(a_n\\geq M\\)时，称该Sequence Bounded Below Bounded #\r当一个Sequence同时Bounded Above和Below的时候，其Bounded Theorem - Convergent Sequence are Bounded #\r如果一个Sequence Convergent，则其一定Bounded 同理也可以反推，如果一个Sequence Bounded并且是Monotonic 单调的Sequence的话，该Sequence Convergent 收敛 Series (Infinite Series) #\r对于Sequence来说，它的所有项相加的和便成为了Series $$S_n=\\sum_{n=1}^{\\infty} a_n = a_1 + a_2 + a_3 + \\cdots + a_n + \\cdots$$ Convergent of Series #\r对于一个Series \\(\\sum^\\infty_{n=1}a_n\\)来说，如果其Partial Sum（前n项之和）等于S，则该Series Converge，反则Diverge Telescoping Series 列项级数 #\r通过将级数的两个项组合得到一个新的通项公式求得级数的解 ex. Finding Series Convergency by Telescoping #\r求解\\(\\sum_{n=1}^{\\infty} \\frac{2}{4n^2 - 1}\\) $$a_n = \\frac{2}{4n^2 - 1} = \\frac{2}{(2n - 1)(2n + 1)} = \\frac{1}{2n - 1} - \\frac{1}{2n + 1}$$ 通过观察规律可以看出 $$S_n = \\left( \\frac{1}{1} - \\frac{1}{3} \\right) + \\left( \\frac{1}{3} - \\frac{1}{5} \\right) + \\cdots + \\left( \\frac{1}{2n-1} - \\frac{1}{2n+1} \\right) = 1 - \\frac{1}{2n+1}$$ 最终得出 $$\\sum_{n=1}^{\\infty} \\frac{2}{4n^2 - 1} = \\lim_{n \\to \\infty} S_n = \\lim_{n \\to \\infty} \\left(1 - \\frac{1}{2n+1}\\right) = 1$$ Geometric Series #\r形如\\(\\sum_{n=0}^{\\infty} ar^n\\)的Series被称为Geometric Series，其完整形式为 $$\\sum_{n=0}^{\\infty} ar^n = a + ar + ar^2 + \\cdots + ar^n + \\cdots, \\quad a \\neq 0$$ Convergenvce of Geometric Series #\r当Geometric Series的的敛散性高度取决于其公比r的取值 具体来说当\\(0\u0026lt;|r|\u0026lt;1\\) Geometric Series Converge ，当\\(|r|\\geq 1\\)，其Diverge The Value Geometric Series Converge to #\rGeometric Sereis是很特别的一个Series，于大部分Series不同，当其Converge的时候可以简单的求出Series的值为 $$\\lim_{n \\to \\infty} S_n = \\lim_{n \\to \\infty} \\left[ \\frac{a(1 - r^n)}{1 - r} \\right] = \\frac{a}{1 - r} \\lim_{n \\to \\infty} (1 - r^n) = \\frac{a}{1 - r}$$ Property of Infinite Series #\r如果\\(\\sum a_n\\)和\\(\\sum b_n\\)都是Converge的Series，并且分别收敛到A和B，则有 $$\\sum_{n=1}^{\\infty} c a_n = cA$$ $$\\sum_{n=1}^{\\infty} (a_n + b_n) = A + B$$ $$\\sum_{n=1}^{\\infty} (a_n - b_n) = A - B$$ p-Series and Harmonic Series #\r$$\\sum_{n=1}^{\\infty} \\frac{1}{n^p} = \\frac{1}{1^p} + \\frac{1}{2^p} + \\frac{1}{3^p} + \\cdots$$\nConvergence of p-Series #\r当 \\(p\u0026gt;1\\) 的时候Converge，\\(0\u0026lt;p\\leq 1\\) 的时候Diverge Harmonic Series #\r当p=1时，p-Series变成其特殊形式，即Harmonic Series Alternating Series #\r到目前为止的Series都只含有Postitive的Terms Alternating Series 交错级数指的是一正一负（一负一正）的Terms的级数 Alternating Series Remainder #\r如果一个收敛的交错级数满足以下条件： \\(a_{n+1} \\leq a_n\\)（即正项部分单调递减），\\(\\lim_{n \\to \\infty} a_n = 0\\)， 那么，当用第N项部分和\\(S_N\\)来近似整个级数的和 SS 时，有 $$|S - S_N| = |R_N| \\leq a_{N+1}$$ 换句话说，误差的绝对值小于等于被忽略的第一个正项\\(a_{N+1}\\) Absolute and Conditional Convergence #\r有的Series可能含有正负项，但他们不已一定规律出现 这时候就需要利用Absolute and Conditional Convergence 如果一个级数 \\(\\sum |a_n|\\) Convergence Absolutly（即级数的项的绝对值构成的级数收敛），则原级数 \\(\\sum a_n\\) 也一定Converge Conditionally Converge #\r对于一个Series，当\\(\\sum |a_n|\\) Diverge但是\\(\\sum a_n\\) converge的时候，其Conditionally Converge 条件收敛 Tests for Convergency #\r对于Series存在许多的判断其是否收敛的办法 The Integral Test #\r如果函数f(x)满足以下条件：f(x)在 \\(x \\geq 1\\) 上是positive，continuous，decreasing的，则： $$\\sum_{n=1}^\\infty a_n与\\int_{1}^\\infty f(x), dx$$ 的收敛性是一致的： 要么两者都收敛，要么两者都发散 Direct Comparison Test #\r假设存在两个正项级数 \\(\\sum a_n\\) 和 \\(\\sum b_n\\)，并且对所有n都满足 \\(0 \u0026lt; a_n \\leq b_n\\)，则有： 如果 \\(n\\sum b_n\\) Converge，则 \\(\\sum a_n\\) 也Converge 如果 \\(\\sum a_n\\) Diverge，则 \\(\\sum b_n\\) 也Diverge Limit Comparison Test #\r对于Direct Comparison能做的，Limit都能做到并且会更加简单 假设存在两个正项级数 \\(\\sum a_n\\) 和 \\(\\sum b_n\\)，并且满足： \\(a_n \u0026gt; 0\\) 和 \\(b_n \u0026gt; 0\\) 对所有n成立，存在极限： \\(\\lim_{n \\to \\infty} \\frac{a_n}{b_n} = L\\) 其中\\(0 \u0026lt; L \u0026lt; \\infty\\)\n如果 \\(\\sum b_n\\) Converge，则 \\(\\sum a_n\\) 也Converge 如果 \\(\\sum b_n\\) Diverge，则 \\(\\sum a_n\\) 也Diverge Throrem - nth Test #\rIf \\(\\lim_{n \\to \\infty} a_n \\neq 0\\), then \\(\\sum_{n=1}^{\\infty} a_n\\) diverges Alternating Series Test #\r对于形式为交错级数的两个级数： $$\\sum_{n=1}^\\infty (-1)^n a_n \\quad \\text{和} \\quad \\sum_{n=1}^\\infty (-1)^{n+1} a_n$$ 如果满足以下两个条件，则级数收敛： \\(\\lim_{n \\to \\infty} a_n = 0\\)，\\(a_{n+1} \\leq a_n\\) 对所有n成立（即\\({a_n}\\)是单调递减的正项数列）。 Ratio Test #\rLet \\(\\sum a_n\\) be a series with nonzero terms 当\\(\\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| \u0026lt; 1\\)，级数Converges Absolutely 当\\(\\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| \u0026gt; 1 \\text{ or } \\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| = \\infty\\)，级数Diverge 当\\(\\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| =1\\)时，Ratio Test失效 简单解释一下原理就是通过转化为Geometric Series后计算公比\nThe Root Test #\rLet \\(\\sum a_n\\) be a series with nonzero terms 当\\(\\lim_{n \\to \\infty} \\sqrt[n]{|a_n|} \u0026lt; 1\\)时，级数Converge Absolutely 当\\(\\lim_{n \\to \\infty} \\sqrt[n]{|a_n|} \u0026gt; 1 \\text{ or } \\lim_{n \\to \\infty} \\sqrt[n]{|a_n|} = \\infty\\)时，Diverge 同理\\(\\lim_{n \\to \\infty} \\sqrt[n]{|a_n|} = 1\\)时失效 Taylor Polynomials and Approximations #\r想要通过一个Polynomial来近似一个function，首先找到一点c，其在function的domain中，再给与\\(p(c)\\)和\\(f(c)\\)相同的值，就可以说这个Polynomial是以c点为中心近似function的 由于过一个点的Polynomial非常之多，所以更一步的近似就是同时令function和polynomial在点c处的slope也相似，有\\(p\u0026rsquo;(c)=f\u0026rsquo;(c)\\)满足了以上两个条件，就获得了一个简单的对于function的近似 ex. First Degree Approximation for e^x #\r\\(f(x)=e^x\\) 存在一个特殊的性质，就是其derivate等于原函数，于是有 $$f(0)=f\u0026rsquo;(0)=e^0=1$$ 现在拿出一个One degree polynomial \\(p(x)=a_0+a_1x\\)，分别对齐\\(p(0)\\)和\\(p\u0026rsquo;(0)\\) \\(p(0)=a_0+0=1\\Rightarrow a_0=1\\)，\\(p\u0026rsquo;(0)=a_1=1\\Rightarrow = a_1 =1\\) 可以得到\\(p(x)=1+x\\)，就这样逐渐的往高阶逼近，Polynomial和Function以c为中心的逼近也会越来越精确 Taylor Polynomials #\r在上面的例子中，多项式是以\\(c=0\\)为中心approximate function的，而这一个c可以根据需要进行调整，具体来说这个多项式在n阶下应该为 $$P_n(x) = a_0 + a_1(x-c) + a_2(x-c)^2 + a_3(x-c)^3 + \\cdots + a_n(x-c)^n$$ 这一个polynomial中存在三个参数，其中c为常数，x为variable，于是就要求解a的值 在前面的例子中提到了求解\\(a_0,a_1\\)的办法，具体就是令\\(p_n^{(n)}(c)=f_n^{(n)}(c)\\) 观察polynomial求到第n阶导数的样子，有 $$P_n\u0026rsquo;\u0026rsquo;\u0026rsquo;(x) = 2(3a_3) + \\cdots + n(n - 1)a_n(x - c)^{n-3}$$ $$P_n^{(n)}(x) = n(n - 1)(n - 2) \\cdots (2)(1) a_n$$ 可以发现求解\\(a_n\\)的关键就在于当P求到第n阶导数的时候\\((x-c)^n\\)这一项会只剩下系数（z）乘以\\(a_n\\)，也就是\\(za_n(x-c)^0\\)（具体系数等于多少稍后讨论），那么这时候令\\(x=c\\)，所有高次的项均会被消去只剩下\\(p_n(x)\\)原本的第n项系数，这时候有 $$p_n^{(n)}(c)=f_n^{(n)}(c)=za_n$$ 这就可以得出 $$a_n=\\frac{f_n^{(n)}(c)}{z}$$ 那么问题就来到了z等于多少上，已知到这一步时，\\(P_n(x)\\)已经被求导了n次，也就是说这一项的幂减去了n次1，而系数乘上了\\(n(n-1)(n-2)(n-3)\\ldots 1=n!\\)，总结得出 $$a_n=\\frac{f_n^{(n)}(c)}{n!}$$ 将其带入Polynomial有 $$P_n(x) = f(c) + f\u0026rsquo;(c)(x - c) + \\frac{f\u0026rsquo;\u0026rsquo;(c)}{2!}(x - c)^2 + \\cdots + \\frac{f^{(n)}(c)}{n!}(x - c)^n$$ Maclaurin Polynomial #\r麦克劳林级数是Taylor Series的特殊情况，其发生在\\(c=0\\)的时候，有 $$P_n(x) = f(0) + f\u0026rsquo;(0)x + \\frac{f\u0026rsquo;\u0026rsquo;(0)}{2!}x^2 + \\frac{f\u0026rsquo;\u0026rsquo;\u0026rsquo;(0)}{3!}x^3 + \\cdots + \\frac{f^{(n)}(0)}{n!}x^n$$ ex. Finding a 3 degrees Taylor Polynomial for sin x at pi/6 #\r以\\(\\pi/6\\)为中心找到sinx的泰勒多项式\n找Taylor Polynomial实际上只用求原函数在各阶导数下的值就行 \\(f(x) = \\sin x \\quad f\\left(\\frac{\\pi}{6}\\right) = \\sin\\left(\\frac{\\pi}{6}\\right) = \\frac{1}{2}\\) \\(f\u0026rsquo;(x) = \\cos x \\quad f\u0026rsquo;\\left(\\frac{\\pi}{6}\\right) = \\cos\\left(\\frac{\\pi}{6}\\right) = \\frac{\\sqrt{3}}{2}\\) \\(f\u0026rsquo;\u0026rsquo;(x) = -\\sin x \\quad f\u0026rsquo;\u0026rsquo;\\left(\\frac{\\pi}{6}\\right) = -\\sin\\left(\\frac{\\pi}{6}\\right) = -\\frac{1}{2}\\) \\(f\u0026rsquo;\u0026rsquo;\u0026rsquo;(x) = -\\cos x \\quad f\u0026rsquo;\u0026rsquo;\u0026rsquo;\\left(\\frac{\\pi}{6}\\right) = -\\cos\\left(\\frac{\\pi}{6}\\right) = -\\frac{\\sqrt{3}}{2}\\) $$P_3(x) = f\\left(\\frac{\\pi}{6}\\right) + f\u0026rsquo;\\left(\\frac{\\pi}{6}\\right) (x - \\frac{\\pi}{6}) + \\frac{f\u0026rsquo;\u0026rsquo;\\left(\\frac{\\pi}{6}\\right)}{2!} (x - \\frac{\\pi}{6})^2 + \\frac{f\u0026rsquo;\u0026rsquo;\u0026rsquo;\\left(\\frac{\\pi}{6}\\right)}{3!} (x - \\frac{\\pi}{6})^3 $$ $$= \\frac{1}{2} + \\frac{\\sqrt{3}}{2} \\left(x - \\frac{\\pi}{6}\\right) - \\frac{1}{2(2!)} \\left(x - \\frac{\\pi}{6}\\right)^2 - \\frac{\\sqrt{3}}{2(3!)} \\left(x - \\frac{\\pi}{6}\\right)^3$$ Remainder of a Taylor Polynomial #\r作为一个逼近，其总是存在Error，而Error与实际值之间的差值就是Remainder，有 $$\\text{Error} = |R_n(x)| = |f(x) - P_n(x)|$$ Taylor\u0026rsquo;s Theorem #\r如果一个函数n+1阶可导在一个包含了c的区间I中，则每一个I中的x都有一个\\(z\\in [x,c]\\)使得 $$f(x) = f(c) + f\u0026rsquo;(c)(x - c) + \\frac{f\u0026rsquo;\u0026rsquo;(c)}{2!}(x - c)^2 + \\cdots + \\frac{f^{(n)}(c)}{n!}(x - c)^n + R_n(x)$$ 其中 $$R_n(x) = \\frac{f^{(n+1)}(z)}{(n+1)!} (x - c)^{n+1}$$ 以上就是Taylor\u0026rsquo;s Theorem的完整定理，其可以被总结为一个更加易懂的二级结论，有 $$|R_n(x)| \\leq \\frac{|x - c|^{n+1}}{(n+1)!} \\max |f^{(n+1)}(z)|$$ 简单来说，直接找到Taylor\u0026rsquo;s Theroem中的z是十分困难的，这使得其更多像是一个存在性定理，所以实际上这个定理想表达的是这个z的存在使得Remainder能别限制在一个区间 ex. Determing Accuracy of Approximation #\r有Thrid Degree Maclaurin Polynomial \\(P_3(x) = x - \\frac{x^3}{3!}\\)，求近似\\(x=0.1\\)时的误差 $$\\sin x = x - \\frac{x^3}{3!} + R_3(x) = x - \\frac{x^3}{3!} + \\frac{f^{(4)}(z)}{4!}x^4$$\n在\\(0\u0026lt;z\u0026lt;0.1\\)的区间中，\\(\\sin(0.1)\\)有着最大的值，于是有 $$0 \u0026lt; R_3(0.1) = \\frac{\\sin z}{4!} (0.1)^4 \u0026lt; \\frac{0.0001}{4!} \\approx 0.000004 $$ ex. Approximating a Value to a Desired Accuracy #\rDetermine the degree of the Taylor polynomial expanded about c=1 that should be used to approximate \\(\\ln(1.2)\\) so that the error is less than 0.001\n既然求的是Error Value，直接用Remainder $$|R_n(1.2)| = \\left| \\frac{f^{(n+1)}(z)}{(n+1)!} (1.2 - 1)^{n+1} \\right| = \\frac{n!}{z^{n+1}(n + 1)!} (0.2)^{n+1} = \\frac{(0.2)^{n+1}}{z^{n+1}(n + 1)}$$ 要让这玩意小于0.001，由于在\\(1\u0026lt;z\u0026lt;1.2\\)的区间中 $$\\frac{(0.2)^{n+1}}{z^{n+1}(n + 1)}\u0026lt;\\frac{(0.2)^{n+1}}{n + 1}\u0026lt;0.001$$ 最终可以得到 \\(n=3\\) Power Series #\rPower Series 幂级数是一种形式为无穷多项式的Series，通常用来近似函数，其表示为 $$\\sum_{n=0}^{\\infty} c_n (x-a)^n$$ 其中，\\(c_n\\)是系数，x是变量，a是幂级数展开的中心点 Center of Power Sereis #\r中心点的选择是为了确定一个近似最精确的点，如果想要用Power Series来近似\\(e^x\\)，并且对于\\(x=1\\)这一点的函数更加关心时，就可以选择\\(a=1\\)为展开的中心点，这使得x=1周围的对于函数的逼近更加精确 Radius and Interval of Convergency #\r对于一个Power Series来说，只存在三种收敛的情况 Converges at center 只在中心收敛 Converges within a radius R 收敛于一定半径R之间 Converges absolutely for all x 收敛于任意\\(x\\in R\\) 通过计算Power Series的Ratio或者Radius Test后便可以知道Radius of Convergency ex. Finding the radius of Convergence (R=1) #\r对于Series \\(\\sum_{n=0}^{\\infty} 3(x-2)^n\\)，找到他的Radius of Convergence 利用Ratio Test得到 $$\\lim_{n \\to \\infty} \\frac{u_{n+1}}{u_n} = \\lim_{n \\to \\infty} \\frac{3(x-2)^{n+1}}{3(x-2)^n} = \\lim_{n \\to \\infty} |x-2| = |x-2|$$ 已知当这一个极限\\(\\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| \u0026lt; 1\\)的时候Series Converge，则有 $$|x-2|\u0026lt;1\\Rightarrow -1\u0026lt;x-2\u0026lt;1\\Rightarrow 1\u0026lt;x\u0026lt;3\\Rightarrow R=1$$ ex. Finding the radius of Convergence (\\(R=\\infty\\)) #\r判断Series \\(\\sum_{n=0}^{\\infty} \\frac{(-1)^n x^{2n+1}}{(2n+1)!}\\) $$\\lim_{n \\to \\infty} \\frac{u_{n+1}}{u_n} = \\lim_{n \\to \\infty} \\frac{(-1)^{n+1} x^{2n+3}}{(2n + 3)!} \\div \\frac{(-1)^n x^{2n+1}}{(2n + 1)!} = \\lim_{n \\to \\infty} \\frac{x^2}{(2n + 3)(2n + 2)}=0$$ 这个情况下，无论x取什么值都有\\(\\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| \u0026lt; 1\\)，所以R也为\\(\\infty\\) End Point Convergence #\r在判断了Convergency Radius后，还需要判断两个End Point的取值情况，这是因为在End Point位于\\(\\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| = 1\\)的点，前面提到了这个点处Ratio Test是失效的，所以需要单独计算 ex. Finding Interval of Convergence #\r判断Series \\(\\sum_{n=1}^{\\infty} \\frac{x^n}{n}\\)的Interval of Convergence （注意问题变了） $$\\lim_{n \\to \\infty} \\frac{u_{n+1}}{u_n} = \\lim_{n \\to \\infty} \\frac{x^{n+1} / (n+1)}{x^n / n} = \\lim_{n \\to \\infty} \\frac{nx}{n+1} = |x|$$ 知道了Convergence Radius\\(R=1\\)后分析两个End Point的Behavior $$whenx=1:\\sum_{n=1}^{\\infty} \\frac{1}{n} = \\frac{1}{1} + \\frac{1}{2} + \\frac{1}{3} + \\cdots$$ $$whenx=-1:\\sum_{n=1}^{\\infty} \\frac{(-1)^n}{n} = -1 + \\frac{1}{2} - \\frac{1}{3} + \\frac{1}{4} - \\cdots$$ 最终得到完整Interval of Convergence为 \\([-1,1)\\) Properties of Functions Defined by Power Series #\r如果用一个Power Series来拟合一个function，有 $$f(x) = \\sum_{n=0}^{\\infty} a_n (x - c)^n = a_0 + a_1 (x - c) + a_2 (x - c)^2 + a_3 (x - c)^3 + \\cdots$$ 这个function的Derivative的Integral同样也可以用一个Taylor Polynomial表示 $$f\u0026rsquo;(x) = \\sum_{n=1}^{\\infty} n a_n (x - c)^{n-1} = a_1 + 2a_2(x - c) + 3a_3(x - c)^2 + \\cdots$$ $$\\int f(x) , dx = C + \\sum_{n=0}^{\\infty} a_n \\frac{(x - c)^{n+1}}{n+1} = C + a_0 (x - c) + \\frac{a_1 (x - c)^2}{2} + \\frac{a_2 (x - c)^3}{3} + \\cdots$$ 其Integral和Derivative会有和原函数相同的Radius of convergency，但是由于Series本身发生了改变，导致End Point Behavior可能不同 $$$$ Representation of Functions by Power Series #\r考虑一个function \\(f(x) = \\frac{1}{1 - x}\\) 这个function长得非常像在前面所提到的Geometric Series的Partial Sum，具体来说一个Geometric Series会在\\(0\u0026lt;|r|\u0026lt;1\\)的时候有 $$\\sum_{n=0}^{\\infty} ar^n = \\frac{a}{1 - r}$$ 而对于上面的\\(f(x)\\)，当 \\(a=1,r=x\\) 的时候就有 $$\\frac{1}{1 - x} = \\sum_{n=0}^{\\infty} ar^n = \\sum_{n=0}^{\\infty} x^n = 1 + x + x^2 + x^3 + \\cdots, \\quad |x| \u0026lt; 1. $$ 当然要知道一个Power Series存在Convergence Radius，这使得这个Series仅在\\((-1,1)\\)的区间上拟合了function，如果需要研究函数在其他区间的拟合，则可以更改Power Series的c 比如当 \\(c=-1\\) 的时候就有 $$\\frac{1}{1 - x} = \\frac{1}{2 - (x + 1)} = \\frac{\\frac{1}{2}}{1 -\\frac{(x + 1)}{2}} = \\frac{a}{1 - r}$$ 于是可以得出 \\(a= \\frac{1}{2},r=\\frac{x+1}{2}\\)，带入Power Series中有 $$\\frac{1}{1 - x} = \\sum_{n=0}^{\\infty} \\left(\\frac{1}{2}\\right)\\left(\\frac{x+1}{2}\\right)^n = \\frac{1}{2} \\left[ 1 + \\frac{x+1}{2} + \\left(\\frac{x+1}{2}\\right)^2 + \\left(\\frac{x+1}{2}\\right)^3 + \\cdots \\right], \\quad |x+1| \u0026lt; 2$$ Power Series仅在Convergence Interval中拟合Function\nex. Find Geometeric Power Sereis Centerd at 0 #\r找一个拟合function \\(f(x) = \\frac{4}{x + 2}\\) 的Power Series\n将function写成 \\(\\frac{a}{1-r}\\) 的形式 $$\\frac{4}{2 + x} = \\frac{2}{1 - \\left(-\\frac{x}{2}\\right)} = \\frac{a}{1 - r}$$ 有 \\(a=2,r=\\frac{-x}{2}\\) 于是可以写出Power Series $$\\frac{4}{x + 2} = \\sum_{n=0}^{\\infty} a r^n = \\sum_{n=0}^{\\infty} 2 \\left(-\\frac{x}{2}\\right)^n = 2 \\left(1 - \\frac{x}{2} + \\frac{x^2}{4} - \\frac{x^3}{8} + \\cdots \\right)$$ Operations with Power Series #\r$$f(x) = \\sum_{n=0}^{\\infty} a_n x^n \\text{ and } g(x) = \\sum_{n=0}^{\\infty} b_n x^n$$ $$f(kx) =\\sum_{n=0}^{\\infty} a_n (kx)^n$$ $$f(x^N) =\\sum_{n=0}^{\\infty} a_n (x^N)^n$$ $$f(x) \\pm g(x) = \\sum_{n=0}^{\\infty} (a_n + b_n) x^n$$\nex. Finding Power Series by Integration #\r前面提到了Power Series的Integral和Derivative也都还是Power Series，于是当一个函数的积分或者导数可以被整理为一个Geometric Power Series时，该函数也可以用Power Series来表示 找到Power Series Representation of \\(f(x)=\\ln x\\)\n已知\\(\\int f(x)dx=\\frac1x+C\\)，有 $$\\frac{1}{x} = \\sum_{n=0}^{\\infty} (-1)^n (x - 1)^n$$ 这是一个 \\(a=1,r=-(x-1)\\) 的Power Series，对这个Power Series积分有 $$\\ln x = \\int \\frac{1}{x} , dx + C = C + \\sum_{n=0}^{\\infty} (-1)^n \\frac{(x - 1)^{n+1}}{n+1}= \\frac{(x-1)}{1} - \\frac{(x-1)^2}{2} + \\frac{(x-1)^3}{3} - \\frac{(x-1)^4}{4} + \\cdots $$ ex. 2. Finding a Power Series by Integration #\r找到 \\(g(x)=\\arctan x\\) 的Power Series\n已知\\(\\arctan(x)\\)的Derivative为\\(\\frac{1}{1+x^2}\\)，令\\(x^2\\)为r，就可以写出他的Power Series有 $$f(x^2) = \\frac{1}{1 + x^2} = \\sum_{n=0}^{\\infty} (-1)^n x^{2n}$$ 再对这玩意积分，有 $$\\arctan x = \\int \\frac{1}{1 + x^2} , dx + C = C + \\sum_{n=0}^{\\infty} (-1)^n \\frac{x^{2n+1}}{2n+1}$$ 令 \\(x=1\\) 可以知道 \\(C=0\\)，有 $$= \\sum_{n=0}^{\\infty} (-1)^n \\frac{x^{2n+1}}{2n+1} = x - \\frac{x^3}{3} + \\frac{x^5}{5} - \\frac{x^7}{7} + \\cdots$$ Taylor and Maclaurin Series #\r在前面通过了使用Geometric Series的Partial Sum找到了很多函数对于的Power Series，通过Taylor Series则可以找到那些可以被求导n次的函数的Power Series 前面提到了Taylor Polynomial拟合的function在他的Radius of Convergence中可以表示为 $$f(x) = f(c) + f\u0026rsquo;(c)(x - c) + \\frac{f\u0026rsquo;\u0026rsquo;(c)}{2!}(x - c)^2 + \\cdots + \\frac{f^{(n)}(c)}{n!}(x - c)^n + \\cdots$$ 这个Polynomial也是不同Power的和，当\\(n=\\infty\\)的时候，其也可以被当作一个Series，有 $$\\sum_{n=0}^{\\infty} \\frac{f^{(n)}(c)}{n!} (x - c)^n = f(c) + f\u0026rsquo;(c)(x - c) + \\cdots + \\frac{f^{(n)}(c)}{n!}(x - c)^n + \\cdots $$ 这时候只要Taylor Series Converge，其就完全的拟合了Function Binomial Series #\r对于形如 \\(f(x)=(1+x)^k\\) 的function，可以通过Binomial Serises逼近，因为其本身就是一个Binomial 二项式，当然可以同Series来表示他的二项式展开，经典二项式定理为 $$(1+x)^k = \\sum_{n=0}^k \\binom{k}{n} x^n$$ 但经典二项式定理存在一个前提为 \\(k\\in \\mathbb z^+\\)，当k不为整数的时候，二项式系数不会在某一项后归零，导致级数没有终止，这就导致了二项式展开变成了Seires，有 $$(1 + x)^k = 1 + kx + \\frac{k(k-1)x^2}{2!} + \\frac{k(k-1)(k-2)x^3}{3!} + \\frac{k(k-1)(k-2)(k-3)x^4}{4!} + \\cdots$$ POWER SERIES FOR ELEMENTARY FUNCTIONS #\r$$\\frac{1}{x} = 1 - (x - 1) + (x - 1)^2 - (x - 1)^3 + \\cdots, \\quad 0 \u0026lt; x \u0026lt; 2$$ $$\\frac{1}{1 + x} = 1 - x + x^2 - x^3 + x^4 - \\cdots, \\quad -1 \u0026lt; x \u0026lt; 1$$ $$\\ln x = (x - 1) - \\frac{(x - 1)^2}{2} + \\frac{(x - 1)^3}{3} - \\frac{(x - 1)^4}{4} + \\cdots, \\quad 0 \u0026lt; x \u0026lt; 2$$ $$e^x = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\frac{x^4}{4!} + \\cdots, \\quad -\\infty \u0026lt; x \u0026lt; \\infty$$ $$\\sin x = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\cdots, \\quad -\\infty \u0026lt; x \u0026lt; \\infty$$ $$\\cos x = 1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} - \\frac{x^6}{6!} + \\cdots, \\quad -\\infty \u0026lt; x \u0026lt; \\infty$$ $$\\arctan x = x - \\frac{x^3}{3} + \\frac{x^5}{5} - \\frac{x^7}{7} + \\cdots, \\quad -1 \\leq x \\leq 1$$ $$\\arctan x = x - \\frac{x^3}{3} + \\frac{x^5}{5} - \\frac{x^7}{7} + \\cdots, \\quad -1 \\leq x \\leq 1$$ $$\\arcsin x = x + \\frac{1 \\cdot 3 x^3}{2 \\cdot 4} + \\frac{1 \\cdot 3 \\cdot 5 x^5}{2 \\cdot 4 \\cdot 6} + \\cdots, \\quad -1 \\leq x \\leq 1$$ $$(1 + x)^k = 1 + kx + \\frac{k(k-1)x^2}{2!} + \\frac{k(k-1)(k-2)x^3}{3!} + \\cdots, \\quad -1 \u0026lt; x \u0026lt; 1^*$$\n","date":"Jan 22 2025","externalUrl":null,"permalink":"/docs/calculus/calculus9.series/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/22/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eSequences \r\n    \u003cdiv id=\"sequences\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#sequences\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eSequence是按照一定顺序排列的一列数。序列可以是有限的也可以是无限的，通常表示为\\(a_1, a_2, a_3, \\ldots\\)，其中\\(a_n\\)表示序列的第n项\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eLimit of a Sequence \r\n    \u003cdiv id=\"limit-of-a-sequence\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#limit-of-a-sequence\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于一个Sequence，如果有\n$$\\lim_{n\\rightarrow\\infty}a_n=L,L\\in \\mathbb R$$\u003c/li\u003e\n\u003cli\u003e则该Sequence的Limit为L\u003c/li\u003e\n\u003cli\u003e如果存在这个L，也可以说Sequence是Converge 收敛的\u003c/li\u003e\n\u003cli\u003e如果不存在，则Sequence Diverge 发散\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eex. Nature Number \r\n    \u003cdiv id=\"ex-nature-number\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex-nature-number\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e找到Sequence \\(a_n = \\left(1 + \\frac{1}{n}\\right)^n\\)的Limit\n$$\\lim_{n \\to \\infty} a_n = \\lim_{n \\to \\infty} \\left(1 + \\frac{1}{n}\\right)^n = e$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eProperties of Limits of Sequences \r\n    \u003cdiv id=\"properties-of-limits-of-sequences\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#properties-of-limits-of-sequences\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003eLet \\(\\lim_{n \\to \\infty} a_n = L \\text{ and } \\lim_{n \\to \\infty} b_n = K\\)\n$$\\lim_{n \\to \\infty} (a_n \\pm b_n) = L \\pm K$$\n$$\\lim_{n \\to \\infty} c a_n = cL$$\n$$\\lim_{n \\to \\infty} (a_n b_n) = LK$$\n$$\\lim_{n \\to \\infty} \\frac{a_n}{b_n} = \\frac{L}{K}$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eSqueeze Theorem for Sequences \r\n    \u003cdiv id=\"squeeze-theorem-for-sequences\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#squeeze-theorem-for-sequences\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003eSqueeze Theorem也可以用来解Sequence的Convergence，其通常用在 \\((-1)^n, \\sin(x)\\)等在\\(n\\rightarrow \\infty\\)时oscillate的函数中\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eex. Sequence Convergence by Squeeze Theorem \r\n    \u003cdiv id=\"ex-sequence-convergence-by-squeeze-theorem\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex-sequence-convergence-by-squeeze-theorem\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e证明Sequence \\({ c_n } = \\left{ (-1)^n \\frac{1}{n!} \\right}\\)收敛\u003c/li\u003e\n\u003cli\u003e使用两个序列\\(a_n=\\frac{1}{2^n}\\)，已知Factorial的扩散速度小于Exponential，有\n$$-\\frac{1}{2^n} \\leq (-1)^n \\frac{1}{n!} \\leq \\frac{1}{2^n}, \\quad n \\geq 4$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eMonotonic Sequences \r\n    \u003cdiv id=\"monotonic-sequences\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#monotonic-sequences\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e当一个Sequence的每一项都单调递增或单调递减时，该Sequence被称为Monotonic Sequence\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eBounded Sequence \r\n    \u003cdiv id=\"bounded-sequence\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#bounded-sequence\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eBounded Above \r\n    \u003cdiv id=\"bounded-above\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#bounded-above\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e当存在一个\\(M\\in \\mathbb R\\)使得\\(a_n\\leq M\\)时，称该Sequence Bounded Above\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eBounded Below \r\n    \u003cdiv id=\"bounded-below\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#bounded-below\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e当存在一个\\(M\\in \\mathbb R\\)使得\\(a_n\\geq M\\)时，称该Sequence Bounded Below\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eBounded \r\n    \u003cdiv id=\"bounded\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#bounded\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e当一个Sequence同时Bounded Above和Below的时候，其Bounded\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eTheorem - Convergent Sequence are Bounded \r\n    \u003cdiv id=\"theorem---convergent-sequence-are-bounded\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#theorem---convergent-sequence-are-bounded\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e如果一个Sequence Convergent，则其一定Bounded\u003c/li\u003e\n\u003cli\u003e同理也可以反推，如果一个Sequence Bounded并且是Monotonic 单调的Sequence的话，该Sequence Convergent 收敛\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eSeries (Infinite Series) \r\n    \u003cdiv id=\"series-infinite-series\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#series-infinite-series\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于Sequence来说，它的所有项相加的和便成为了Series\n$$S_n=\\sum_{n=1}^{\\infty} a_n = a_1 + a_2 + a_3 + \\cdots + a_n + \\cdots$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eConvergent of Series \r\n    \u003cdiv id=\"convergent-of-series\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#convergent-of-series\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于一个Series \\(\\sum^\\infty_{n=1}a_n\\)来说，如果其Partial Sum（前n项之和）等于S，则该Series Converge，反则Diverge\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eTelescoping Series 列项级数 \r\n    \u003cdiv id=\"telescoping-series-%E5%88%97%E9%A1%B9%E7%BA%A7%E6%95%B0\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#telescoping-series-%E5%88%97%E9%A1%B9%E7%BA%A7%E6%95%B0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e通过将级数的两个项组合得到一个新的通项公式求得级数的解\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eex. Finding Series Convergency by Telescoping \r\n    \u003cdiv id=\"ex-finding-series-convergency-by-telescoping\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex-finding-series-convergency-by-telescoping\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e求解\\(\\sum_{n=1}^{\\infty} \\frac{2}{4n^2 - 1}\\)\n$$a_n = \\frac{2}{4n^2 - 1} = \\frac{2}{(2n - 1)(2n + 1)} = \\frac{1}{2n - 1} - \\frac{1}{2n + 1}$$\u003c/li\u003e\n\u003cli\u003e通过观察规律可以看出\n$$S_n = \\left( \\frac{1}{1} - \\frac{1}{3} \\right) + \\left( \\frac{1}{3} - \\frac{1}{5} \\right) + \\cdots + \\left( \\frac{1}{2n-1} - \\frac{1}{2n+1} \\right) = 1 - \\frac{1}{2n+1}$$\u003c/li\u003e\n\u003cli\u003e最终得出\n$$\\sum_{n=1}^{\\infty} \\frac{2}{4n^2 - 1} = \\lim_{n \\to \\infty} S_n = \\lim_{n \\to \\infty} \\left(1 - \\frac{1}{2n+1}\\right) = 1$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eGeometric Series \r\n    \u003cdiv id=\"geometric-series\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#geometric-series\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e形如\\(\\sum_{n=0}^{\\infty} ar^n\\)的Series被称为Geometric Series，其完整形式为\n$$\\sum_{n=0}^{\\infty} ar^n = a + ar + ar^2 + \\cdots + ar^n + \\cdots, \\quad a \\neq 0$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eConvergenvce of Geometric Series \r\n    \u003cdiv id=\"convergenvce-of-geometric-series\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#convergenvce-of-geometric-series\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e当Geometric Series的的敛散性高度取决于其公比r的取值\u003c/li\u003e\n\u003cli\u003e具体来说当\\(0\u0026lt;|r|\u0026lt;1\\) Geometric Series Converge ，当\\(|r|\\geq 1\\)，其Diverge\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eThe Value Geometric Series Converge to \r\n    \u003cdiv id=\"the-value-geometric-series-converge-to\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#the-value-geometric-series-converge-to\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003eGeometric Sereis是很特别的一个Series，于大部分Series不同，当其Converge的时候可以简单的求出Series的值为\n$$\\lim_{n \\to \\infty} S_n = \\lim_{n \\to \\infty} \\left[ \\frac{a(1 - r^n)}{1 - r} \\right] = \\frac{a}{1 - r} \\lim_{n \\to \\infty} (1 - r^n) = \\frac{a}{1 - r}$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eProperty of Infinite Series \r\n    \u003cdiv id=\"property-of-infinite-series\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#property-of-infinite-series\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e如果\\(\\sum a_n\\)和\\(\\sum b_n\\)都是Converge的Series，并且分别收敛到A和B，则有\n$$\\sum_{n=1}^{\\infty} c a_n = cA$$\n$$\\sum_{n=1}^{\\infty} (a_n + b_n) = A + B$$\n$$\\sum_{n=1}^{\\infty} (a_n - b_n) = A - B$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003ep-Series and Harmonic Series \r\n    \u003cdiv id=\"p-series-and-harmonic-series\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#p-series-and-harmonic-series\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cp\u003e$$\\sum_{n=1}^{\\infty} \\frac{1}{n^p} = \\frac{1}{1^p} + \\frac{1}{2^p} + \\frac{1}{3^p} + \\cdots$$\u003c/p\u003e","title":"Calculus 9. Series","type":"docs"},{"content":" Last Edit: 1/20/25\n曲线运动，主要描述物体的位移速度和加速度\nPlane Curvilinear Motion 平面曲线运动 #\r已知位置r，速度v和加速度a 物体的运动轨迹是一条二维曲线，表示物体在x-y平面中的运动。 位置矢量\\(\\vec{r}(t)\\)是的是物体在时间t的时候从原点到物体当前所在位置的Vector 轨迹点P(t) 和\\(P\u0026rsquo;(t + \\Delta t)\\)是物体在时刻t的位置 当时间t改变时，物体沿着曲线移动，位置矢量\\(\\vec{r}\\)也会随时间变化 曲线运动中的速度和加速度是通过\\(\\vec{r}(t)\\)的导数来确定的 $$\\vec{r}(t) = x(t)\\hat{i} + y(t)\\hat{j}$$ $$\\vec{v}(t) = \\frac{d\\vec{r}(t)}{dt} = \\frac{dx(t)}{dt}\\hat{i} + \\frac{dy(t)}{dt}\\hat{j}$$ $$\\vec{a}(t) = \\frac{d\\vec{v}(t)}{dt} = \\frac{d^2x(t)}{dt^2}\\hat{i} + \\frac{d^2y(t)}{dt^2}\\hat{j}$$ 如果Velocity的Magnitude没有发生改变，其加速度依然存在，具体来说速度不仅与速度的大小变化相关，还与速度的方向变化相关 Instantaneous Direction 瞬时方向 #\r对于曲线运动中的物体，当\\(\\Delta t\\rightarrow 0\\)的时候，其Displacement Vector和Velocity Vector总是与物体运动轨迹的Tangent方向一致 ex. Collision Problem in Plane #\rThe motions of two particles (A and B) are described by the position vectors. Find the point at which the particles collide and their speeds just before the collision. $$\\vec{r}_A = \\left[ 3t , \\hat{i} + 9t(2 - t) , \\hat{j} \\right] , \\text{m} ,\\vec{r}_B = \\left[ 3(t^2 - 2t + 2) , \\hat{i} + 3(t - 2) , \\hat{j} \\right] , \\text{m}$$\n想要做到碰撞，令i和j分别相等就行，之后就是求解了 Rectangular Coordinate System #\r对于3D的情况，就是多了一个Freedom of motion其Position Vector以及Magnitude为 $$\\vec{r} = x\\hat{i} + y\\hat{j} + z\\hat{k},|\\vec{r}| = \\sqrt{x^2 + y^2 + z^2} $$ Velocity #\r同理只要对Position对时间t求导就是速度了 $$\\vec{v} = \\frac{d\\vec{r}}{dt} = \\frac{d}{dt} \\left( x\\hat{i} + y\\hat{j} + z\\hat{k} \\right)$$ $$\\vec{v} = \\left( \\frac{dx}{dt}\\hat{i} + x\\frac{d\\hat{i}}{dt} \\right) + \\left( \\frac{dy}{dt}\\hat{j} + y\\frac{d\\hat{j}}{dt} \\right) + \\left( \\frac{dz}{dt}\\hat{k} + z\\frac{d\\hat{k}}{dt} \\right) $$ 由于i，j，k是Unit Vector，其不受时间影响，所以可以去掉 $$vec{v} = \\frac{dx}{dt}\\hat{i} + \\frac{dy}{dt}\\hat{j} + \\frac{dz}{dt}\\hat{k} $$ Acceleration #\r同理对速度求导就有 $$\\vec{a} = \\frac{dv_x}{dt} \\hat{i}+ \\frac{dv_y}{dt} \\hat{j} + \\frac{dv_z}{dt} \\hat{k}$$ Projectile Motion #\r斜抛运动其实就是在分析物体在两个自由度上的运动 现在为了简化问题，做出以下假设，忽略空气阻力，地球自转，并令重力为常数 于是有以下两个方向的初速度为 Axis Initial Velocity Acceleration x \\(v_0 \\cos \\theta\\) \\(0\\) y \\(v_0 \\sin \\theta\\) \\(\\downarrow g, , -g \\uparrow\\) 总结便可以得出以下表格 Axis Velocity (\\(v = v_0 + at\\)) Position (\\(s = s_0 + v_0t + \\frac{1}{2}at^2\\)) No \u0026ldquo;t\u0026rdquo; (\\(v^2 = v_0^2 + 2a\\Delta s\\)) x \\(v_x = v_0 \\cos \\theta\\) \\(x = x_0 + (v_0 \\cos \\theta)t\\) \\(N/A\\) y \\(v_y = v_0 \\sin \\theta - gt\\) \\(y = y_0 + (v_0 \\sin \\theta)t - \\frac{1}{2}gt^2\\) \\(v_y^2 = (v_0 \\sin \\theta)^2 - 2g\\Delta y\\) 可以发现之所以x的第三列为\\(N/A\\)是因为x方向的加速度为零 Maximum Height #\r物体在Projectile Motion中到达最高点后的Velocity会降到0 到达这一点的时间可以通过\\(0=v_y-gt\\)得到，有 $$t=\\frac{v_y}{g}$$ 其高度则是根据\\(v^2 = v_0^2 + 2a\\Delta s\\) 解得 $$\\Delta y = \\frac{v_{y0}^2}{2g}$$ ex. Messi kicks the ball #\rex. Snowmobile #\rSnowmobile is going 15 𝑚/𝑠 at point A. Find: The horizontal distance it travels (𝑅) and the time (𝑡) in the air\n","date":"Jan 20 2025","externalUrl":null,"permalink":"/docs/dynamics/dyn3.curvilinearmotion/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/20/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e曲线运动，主要描述物体的位移速度和加速度\u003c/p\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003ePlane Curvilinear Motion 平面曲线运动 \r\n    \u003cdiv id=\"plane-curvilinear-motion-%E5%B9%B3%E9%9D%A2%E6%9B%B2%E7%BA%BF%E8%BF%90%E5%8A%A8\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#plane-curvilinear-motion-%E5%B9%B3%E9%9D%A2%E6%9B%B2%E7%BA%BF%E8%BF%90%E5%8A%A8\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e已知位置r，速度v和加速度a\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/dynamics/dyn3.curvilinearmotion/DYN3.CurvilinearMotion_hu4409606457859543426.png 330w,\r\n        /docs/dynamics/dyn3.curvilinearmotion/DYN3.CurvilinearMotion_hu96041044582256950.png 660w,\r\n        /docs/dynamics/dyn3.curvilinearmotion/DYN3.CurvilinearMotion_hu5149378687093651996.png 1024w,\r\n        /docs/dynamics/dyn3.curvilinearmotion/DYN3.CurvilinearMotion_hu8566725093979122226.png 2x\"\r\n        src=\"/docs/dynamics/dyn3.curvilinearmotion/DYN3.CurvilinearMotion_hu96041044582256950.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"DYN 3. Curvilinear Motion","type":"docs"},{"content":" Last Edit: 1/20/25\n3.1 Electric Flux 电通量 #\r从一个Flat的面积为A的平面开始，其处于一个Electric Field \\(\\vec E\\) 中，其中会有\\(E\\cos \\theta\\)个电荷穿过这个平面，而这些个穿过该平面的电荷的数量就叫做Electric Flux，电通量 $$\\Delta \\Phi = (E \\cos \\theta) \\Delta A$$\n同时，上面的形式也可以替换为Dot Product的形式，\\(\\Delta \\Phi = \\vec E \\cdot \\Delta A\\)，同样的，Total Flux就是 $$\\Phi=\\sum \\vec E\\cdot \\Delta \\vec A，or~\\Phi=\\int\\vec E\\cdot d\\vec A$$ ex. #\rConsider a cylinder of radius R in a uniform electric field with axis parallel to the field direction, what are the flux through the end caps, cylindrical surface, and the net flux?\n$$\\begin{align*} \\text{right cap: } \u0026amp;\\Phi_{\\text{right}} = \\int E \\cos 0^\\circ \\cdot dA = E \\int dA = E \\pi R^2 \\ \\text{left cap: } \u0026amp;\\Phi_{\\text{left}} = \\int E \\cos 180^\\circ \\cdot dA = -E \\int dA = -E \\pi R^2 \\ \\text{cylindrical surface: } \u0026amp;\\Phi = \\int E \\cos 90^\\circ \\cdot dA = 0 \\ \\text{net flux: } \u0026amp;\\Phi = -E \\pi R^2 + E \\pi R^2 + 0 = 0 \\end{align*} $$\n3.2 Gauss\u0026rsquo;s Law 高斯定律 #\r一个闭合表面的电通量等于该表面所包围的净电荷量除以真空介电常数\\(\\epsilon_0\\) $$\\Phi = \\frac{Q_{\\text{enc}}}{\\epsilon_0}$$ 其中\\(Q_{\\text{enc}}\\)是闭合表面内部的总电荷 需要注意的点是，Gaussian Surface是一个Closed Surface 一个Gaussian Surface外的电荷不贡献Electric Flux ex. #\rConsider a particle with charge +q is surrounded by an imaginary concentric sphere\n$$\\Phi = \\oint \\vec{E} \\cdot d\\vec{A} \\ = \\oint E dA \\ = E \\oint dA \\ = E \\cdot 4\\pi r^2 \\ = \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r^2} \\cdot 4\\pi r^2 \\ = \\frac{q}{\\epsilon_0}$$\n利用现有的点电荷电场强度推导Gaussian\u0026rsquo;s Law ex. Gauss\u0026rsquo;s Law #\rConsider two charges with opposite signs and equal magnitude (+q and –q). Determine the electric flux of the four Gaussian surfaces are shown below:\n对于S1来说，q是一个Positive Charge，所以其也是一个Postive Number 对于S2，q是一个Negative Charge，所以他也是Negative的 对于S3，其所围成的空间中并不包含Charge，所以Zero 对于S4，其Net charge为0，即Zero Gauss’ Law and Coulomb’s Law #\r将两个定律结合可以发现由于\\(\\epsilon_0 \\oint \\vec{E} \\cdot d\\vec{A} = q_{\\text{enc}}\\)，所以Electric Flux可以化简为 $$\\Phi = E \\cdot 4\\pi r^2$$ 3.3 A charged Isolated Conductor #\r在孤立导体上，所有额外的电荷都会移动到导体的表面，导体内部不会有多余电荷 这是因为导体内部的电荷会通过相互作用重新分布，直到内部电场为零，从而达到静电平衡 同理如果里面出现了一个Cavity，其也不会存在电荷 当Conductor不是一个光滑的Spherical的情况下，电荷并不会均匀的分布在表面上，而是受到曲率的影响，导致尖锐的部分会拥有更多的电荷密度 The External Electric Field #\r$$ε₀EA = σA$$\n导体外部电场强度与其表面上电荷密度成正比 对于具有对称性的Electric Field来说，Gauss\u0026rsquo; Law就可以计算其Field Strength 3.4 Applying Gauss\u0026rsquo;s Law: Cylinderical Symmetry #\r有一个长度为无线的Plastic Rod，其Charge Density为\\(\\lambda\\) 想求离Central Axis的半径为r的距离处的Electric Field Magnitude 由于Electric Field是从圆柱体中心穿过的，而有Gauss\u0026rsquo; Law \\(\\Phi = \\frac{Q_{\\text{enc}}}{\\epsilon_0}= \\oint \\vec{E} \\cdot d\\vec{A}\\) 可以得出面积等于\\(A = 2\\pi rl\\) 已知电荷密度为\\(\\lambda\\)，即总电荷数为\\(Q_{enclosed}=\\lambda \\cdot L\\)，所以有\\(2\\pi rl E=\\frac{\\lambda L}{E_0}\\)，也就是 $$E = \\frac{\\lambda}{2\\pi\\epsilon_0 r}$$ ex. Lighting strikes the tree #\r当雷电击中一棵树的时候，其可以被看作是一个导线，而半径为r内的空气都将被Ionized，计算出这个半径r，令\\(E=3\\times 10^6 N/C\\) $$r = \\frac{\\lambda}{2\\pi\\epsilon_0 E} = \\frac{1 \\times 10^{-3}\\ \\text{C/m}}{(2\\pi)(8.85 \\times 10^{-12}\\ \\text{C}^2/\\text{N}\\cdot\\text{m}^2)(3 \\times 10^6\\ \\text{N/C})}\n= 6\\ \\text{m}$$\n3.5 Applying Gauss\u0026rsquo;s Law: Planar Symmetry #\r对于一个无限大的电荷密度为\\(\\sigma\\)的Plane，有\\(\\sigma=\\frac{Q}{A}\\) 更具Guass\u0026rsquo; Law \\(\\Phi = \\frac{Q_{\\text{enc}}}{\\varepsilon_0}\\)，其中\\(Q=\\sigma A\\)，于是有 $$\\Phi=\\frac{\\sigma A_0}{\\varepsilon_0}$$ 令其中一个Cylinder为高斯面，对于Cylinder的侧面（Curved Surface）由于于电场平行没用Flux，而Flux从两个Cross-Sectional Area流过即 $$\\Phi=EA=2EA_0=\\frac{\\sigma A_0}{\\varepsilon_0}$$ $$\\Rightarrow E=\\frac{\\sigma}{2\\varepsilon_0}$$ 3.6 Applying Gauss\u0026rsquo; Law: Spherical Symmetry #\r有一个球壳，上面的Charge均匀分布，电荷总量为q，半径为R 使用两个同心的球形高斯面\\(S_1\\)和\\(S_2\\) 对于内部高斯面\\(S_1\\)来说，Electric Field为0，Electric Flux也为0 对于外部高斯面\\(S_2\\)来说，Electric Field公式由\\(E=\\frac{q}{4\\pi\\varepsilon_0r^2}\\)给出，由Shell Theorem 1证明，球壳外部的Charge可以被视为Point Charge 第二种情况则是一个带电的均匀实心球体（电荷在其中均匀分布） 令整个实心球半径为R，总电荷量为q，且在体积内均匀分布，则体积电荷密度 $$ρ = q43πR3. \\rho ;=; \\frac{q}{\\tfrac{4}{3}\\pi R^3}$$ 在球内取一半径为\\(r\u0026lt;R\\)的球面作高斯面，则该高斯面所包围的电荷量 $$Q_{\\text{enclosed}} ;=; \\rho \\times \\bigl(\\tfrac{4}{3}\\pi r^3\\bigr) = \\frac{q}{\\tfrac{4}{3}\\pi R^3};\\times;\\tfrac{4}{3}\\pi r^3 = q,\\frac{r^3}{R^3}$$ 由对称性，球面上电场大小恒为E，方向辐向向外，故 $$\\oint \\mathbf{E}\\cdot \\mathrm{d}\\mathbf{A} = E,\\cdot 4\\pi r^2$$ 高斯定律给出 $$E \\cdot 4\\pi r^2 = \\frac{Q_{\\text{enclosed}}}{\\varepsilon_0} = \\frac{q,\\tfrac{r^3}{R^3}}{\\varepsilon_0}$$ $$\\Rightarrow E(r) = \\frac{1}{4\\pi \\varepsilon_0} ,\\frac{q,\\tfrac{r^3}{R^3}}{r^2} = \\frac{1}{4\\pi \\varepsilon_0},\\frac{q}{R^3},r$$ 总的来说空心球壳： 壳外\\(r \\ge R\\)：电场如点电荷，\\(E=\\frac{1}{4\\pi\\varepsilon_0},\\frac{q}{r^2}\\) 壳内\\(r \\le R\\)：电场为 0 实心均匀带电球： 球外\\(r \\ge R\\)：同样表现为点电荷，\\(E=\\frac{1}{4\\pi\\varepsilon_0},\\frac{q}{r^2}\\) 球内\\(r \\le R\\)：\\(E=\\frac{1}{4\\pi \\varepsilon_0},\\frac{q}{R^3},r\\)，即随r线性增大 ","date":"Jan 20 2025","externalUrl":null,"permalink":"/docs/electrical-fundamentals/ef3.gausslaw/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/20/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e3.1 Electric Flux 电通量 \r\n    \u003cdiv id=\"31-electric-flux-%E7%94%B5%E9%80%9A%E9%87%8F\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#31-electric-flux-%E7%94%B5%E9%80%9A%E9%87%8F\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e从一个Flat的面积为A的平面开始，其处于一个Electric Field \\(\\vec E\\) 中，其中会有\\(E\\cos \\theta\\)个电荷穿过这个平面，而这些个穿过该平面的电荷的数量就叫做Electric Flux，电通量\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"EF3.Gauss%27Law.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 3. Gauss' Law","type":"docs"},{"content":" Last Edit: 1/20/25\nLoops帮助程序节省空间，提高编写效率并减少错误，常见的Loop存在两种，while loop和for loop\n4.1 While Loop #\rwhile (\u0026lt;condition\u0026gt;) { \u0026lt;statements\u0026gt;; } \u0026lt;other statements\u0026gt;; while loop会重复循环直到while内的condition不再成立，也就是说当\u0026lt;condition\u0026gt;为True时，程序将会不断重复执行\u0026lt;statement\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(void) { int i = 1; while (i \u0026lt;= 10) { printf(\u0026#34;%d \u0026#34;, i); i++; } return 0; } 这就是一个很简单的累加器的例子，程序依次打印1到10后跳出循环 4.1.2 Infinite Loops #\r如果永远跳不出Loop，就叫做Infinite Loops 4.2 Do-while Loop #\r与While最大的区别就在于，Do-while Loop会至少执行\u0026lt;statement\u0026gt;一次，之后根据Condition判断是否循环 do { \u0026lt;statements\u0026gt;; } while (\u0026lt;condition\u0026gt;); 可以看出，无论\u0026lt;condition\u0026gt;为True or False，都将先做一遍statement的 4.2.2 Do-While vs. while #\r#include \u0026lt;stdio.h\u0026gt; int main(void) { int num; do { printf(\u0026#34;Please enter a number between 1 and 10 (inclusive): \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;num); } while (num \u0026lt; 1 || num \u0026gt; 10); printf(\u0026#34;The number entered is %d.\\n\u0026#34;, num); return 0; } For loops #\rfor 循环的本质是为了解决重复执行一定次数的任务的问题，尤其是在已知迭代次数或需要遍历某个范围或集合的场景下\n4.3.1 Forming for loop #\rfor (\u0026lt;initialization\u0026gt;;\u0026lt;condition\u0026gt;;\u0026lt;increment\u0026gt;) { \u0026lt;statements\u0026gt;; } \u0026lt;other statements\u0026gt;; 可以看到相比于while，for更像是while的下层应用，将问题具体到了已知范围的事件下 #include \u0026lt;stdio.h\u0026gt; int main(void) { for (int i = 1; i \u0026lt;= 10; i++) { printf(\u0026#34;%d \u0026#34;, i); } return 0; } 对比上方的while，他们干了相同的事件不过用了更加简介的API 4.3.2 Scope of the loop variable #\r对于For loop来说一般都会存在一个变量充当累加器的作用，其Scope 作用域将在Loop结束后不再可用 #include \u0026lt;stdio.h\u0026gt; int main(void) { for (int i = 1; i \u0026lt;= 10; i++) { // declare \u0026amp; initialize the loop variable inside the loop printf(\u0026#34;%d \u0026#34;, i); } printf(\u0026#34;\\nWe exited the loop with i = %d \\n\u0026#34;, i); return 0; } 上述代码展示了Loop内部的i和外部的i的访问，由于printf(\u0026quot;\\nWe exited the loop with i = %d \\n\u0026quot;, i);调用的是out of scope的，所以将会报错 其解决方案就是在执行循环前先定义Variable，也就是在外面加一句int i = 0; 4.3.3 Variations in for loop #\r实际上，for loop存在许多变体使得他可以省略一些参数 #include \u0026lt;stdio.h\u0026gt; int main(void) { for (int i = 1, j = 7; i \u0026lt;= 10; printf(\u0026#34;7 * %d = %d\\n\u0026#34;, i, j), i += 1, j += 7); return 0; } 这本质和以下代码是一样的 #include \u0026lt;stdio.h\u0026gt; int main(void) { for (int i = 1, j = 7; i \u0026lt;= 10;) printf(\u0026#34;7 * %d = %d\\n\u0026#34;, i, j); i += 1; j += 7; return 0; } 变体使得代码在可能略微减少大小的情况下使得整体可读性，是一种非常不健康的写法 4.4 Nested Loop #\rLoop中套Loop，复杂度变成多项式复杂度\n4.4.1 Print 2D pattern #\r如果想要打印出以下图案 * ** *** **** ***** 可以通过设计外层loop构建层，内层loop确定单层打印个数的方式完成 #include \u0026lt;stdio.h\u0026gt; int main(void) { for (int line = 1; line \u0026lt;= 5; line += 1) { // 外层循环控制行数 for (int star = 1; star \u0026lt;= line; star += 1) { // 内层循环控制每行星号的数量 printf(\u0026#34;*\u0026#34;); } printf(\u0026#34;\\n\u0026#34;); // 每行结束后换行 } return 0; } 4.4.2 Tweak a little #\r现在要打印这个 *\r**\r***\r****\r***** 前的部分为空格 #include \u0026lt;stdio.h\u0026gt; int main(void) { int n = 0; printf(\u0026#34;Enter the number of rows:\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); for (int row = 1; row \u0026lt;= n; row += 1) { for (int col = 1; col \u0026lt;= n; col += 1) { if (col \u0026lt;= n - row) { printf(\u0026#34; \u0026#34;); } else { printf(\u0026#34;*\u0026#34;); } } printf(\u0026#34;\\n\u0026#34;); } return 0; } 4.5 Debugging for loops #\r本节将会给出一个loop的错误，需要发现该错误并修正，想要打印一个 Enter the number of rows: **5**\r*\r***\r*****\r*******\r********* #include \u0026lt;stdio.h\u0026gt; int main(void) { int n = 0; printf(\u0026#34;Enter the number of rows: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); for (int row = 1; row \u0026lt;= n; row += 1) { for (int col = 1; col \u0026lt; n; col += 1) { if (col \u0026lt;= n - row) { printf(\u0026#34; \u0026#34;); } else if (col \u0026gt;= n - row || col \u0026lt;= n - 1 + row) { printf(\u0026#34;*\u0026#34;); } } printf(\u0026#34;\\n\u0026#34;); } return 0; } ","date":"Jan 20 2025","externalUrl":null,"permalink":"/docs/learning-programming-with-c/lpc4.repetition/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/20/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLoops帮助程序节省空间，提高编写效率并减少错误，常见的Loop存在两种，while loop和for loop\u003c/p\u003e","title":"LPC 4. Repetition","type":"docs"},{"content":" Last Edit: 1/19/25\n简介 #\rHugo是一个基于Go语言的Github开源项目，其支持Markdown语法并可以托管到Github Pages上 环境准备 #\rGit https://git-scm.com/ Go语言的安装 https://go.dev/doc/install Scoop下载 https://scoop.sh 创建项目 #\r在配置完了环境后，在终端通过Scoop安装Hugo文件 scoop install hugo-extended 之后在准备好的项目路径下通过hugo指令直接创建项目文件 hugo new site {{这里填你的文件名}} 之后提示Congratulation后，cd进入文件下下尝试启动hugo hugo server 如果输出为 - Web Server is available at http://localhost:1313/ (bind address 127.0.0.1)\r- Press Ctrl+C to stop 则说明项目已被成功部署，打开链接可以看到以下界面 显示Page Not Found是正确的\n之后建议Ctrl + C退出后台 安装主题 #\rHugo项目可以通过安装他人准备好的Theme主题来达到轻松的美化效果 Hugo主页上列出了很多个主题，可以任意选择一个喜欢的 这里将以Blowfish作为示范，以下是其Github仓库链接\nhttps://github.com/nunocoracao/blowfish/?tab=readme-ov-file\n更具教程，使用git submodule安装主题\n需要注意的是先要git init，之后在hugo文件夹下安装\ngit submodule add -b main https://github.com/nunocoracao/blowfish.git themes/blowfish 等待主题安装完毕后，打开hugo文件夹下的hugo.toml文件，添加以下代码 - theme = \u0026#39;blowfish\u0026#39; 保存后再次运行hugo便可以预览到该主题已经被成功安装 主题配置 #\r建议在添加Markdown文档之前对主题做出如下更改 打开\\themes\\blowfish\\config`，并将params.toml更改至如下 [homepage] layout = \u0026#34;background\u0026#34; # valid options: page, profile, hero, card, background, custom #homepageImage = \u0026#34;IMAGE.jpg\u0026#34; # used in: hero, and card showRecent = true 这将打开主页上的最佳文档，可以直接在homepage上浏览到最近添加的文档 创建文章 #\r打开Content文件夹，在里面新建文件夹 创建_index.md并写入以下代码 --- title: \u0026#34;Docs\u0026#34; description: \u0026#34;\u0026#34; cascade: showDate: true showAuthor: false invertPagination: true --- 关于具体代码的含义，请查看 Documentation · Blowfish文档 之后保存文件并且在该文件夹下再次新建文件夹 建议采取一个文件夹一个文章方式，如该文件夹为其他页面的父页面，则命名为_index.md，如没有子文档，则文档存放markdown命名为index.md\n之后添加index.md文件，并写入任意Markdown文章，具体语法可以查看 Markdown Guide 预览 #\r在想要预览的时候，于终端输入 hugo server 打开http://localhost:1313/便可以看到创建出来的文档 上传至Github pages #\r打开github创建新仓库，创建一个名为{{id}}.github.io的仓库 来到hugo文件夹下 hugo cd .\\public\\ hugo是令hugo创建准备好的上传的页面，其会被存到public文件夹下，之后cd进入 git init -b main git remote add origin {{仓库链接}} 链接远程git仓库（git设置部分请自行准备） git add .\rgit commit -m \u0026#34;init\u0026#34;\rgit push -u origin main 添加文件后push至github等其完成部署之后就能在{{id}}.github.io访问到了 ","date":"Jan 19 2025","externalUrl":null,"permalink":"/docs/projects/buildapersonalwebsitebyhugo/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/19/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e简介 \r\n    \u003cdiv id=\"%E7%AE%80%E4%BB%8B\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%AE%80%E4%BB%8B\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/projects/buildapersonalwebsitebyhugo/BuildapersonalwebsitebyHugo-3_hu7946849046172097452.png 330w,\r\n        /docs/projects/buildapersonalwebsitebyhugo/BuildapersonalwebsitebyHugo-3_hu5581787319040588473.png 660w,\r\n        /docs/projects/buildapersonalwebsitebyhugo/BuildapersonalwebsitebyHugo-3_hu10522245190111443328.png 1024w,\r\n        /docs/projects/buildapersonalwebsitebyhugo/BuildapersonalwebsitebyHugo-3_hu13328635153818595949.png 2x\"\r\n        src=\"/docs/projects/buildapersonalwebsitebyhugo/BuildapersonalwebsitebyHugo-3_hu5581787319040588473.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"Build a personal website by Hugo","type":"docs"},{"content":"","date":"Jan 19 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l5.deeplearningcomputation/","section":"Docs","summary":"","title":"D2L 5. Deep Learning Computation","type":"docs"},{"content":" Last Edit: 1/19/25\n在整体网络中，存在一些不同的层，他们都是专门用来处理不同事件的，这也令自定义层变得有必要\n5.4.1 Layer without parameter #\rimport torch import torch.nn.functional as F from torch import nn class CenteredLayer(nn.Module): def __init__(self): super().__init__() def forward(self, X): return X - X.mean() 将比之前的层，这个forward过程中仅包含了一个减去平均值的操作，这相当于在模型中以一个层的方式包装了一个函数 5.4.2 Layer with parameter #\rclass MyLinear(nn.Module): def __init__(self, in_units, units): super().__init__() self.weight = nn.Parameter(torch.randn(in_units, units)) self.bias = nn.Parameter(torch.randn(units,)) def forward(self, X): linear = torch.matmul(X, self.weight.data) + self.bias.data return F.relu(linear) 本质上就是重构了一下pytorch的nn.Linear模块 self.weight = nn.Parameter(torch.randn(in_units, units)) self.bias = nn.Parameter(torch.randn(units,)) 权重矩阵W决定了输入X如何被映射到输出空间。 每个输入特征（列）需要与输出特征（列）有连接。 因此，权重矩阵需要有： 行数：输入特征的数量（in_units） 列数：输出特征的数量（units） 转换到pytorch中就相当于 import torch import torch.nn as nn import torch.nn.functional as F class MyLinearWithBuiltin(nn.Module): def __init__(self, in_units, units): super().__init__() self.linear = nn.Linear(in_units, units) # 内置线性层 def forward(self, X): linear = self.linear(X) # 使用内置线性层 return F.relu(linear) # ReLU 激活函数 ","date":"Jan 19 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.4customlayer/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/19/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e在整体网络中，存在一些不同的层，他们都是专门用来处理不同事件的，这也令自定义层变得有必要\u003c/p\u003e","title":"D2L 5.4 Custom Layer","type":"docs"},{"content":" Last Edit: 1/19/25\n2.1 Rectilinear Motion 直线运动 #\rVelocity \u0026amp; Speed #\rVelocity，瞬时速度，\\(\\vec v=\\frac{d\\vec s}{dt}\\) Average Velocity，一个区间内的平均速度\\(\\vec{v}_{avg}=\\frac{\\Delta \\vec x}{\\Delta t}\\) Speed，Scalar，\\(|\\vec v|\\) Acceleration 加速度 #\r$$a=\\frac{d\\vec v}{dt}=\\frac{d^2\\vec x}{dt^2}$$\nAcceleration is a function of time a(t) #\r当Acceleration是时间t的函数的时候（也就是说加速度在随着事件t变化而变化时），这种情况下，例如一个汽车加速或减速，有s和v等于 $$a(t) = \\frac{dv}{dt} \\implies \\int_{t_0}^{t} a(t) , dt = \\int_{v_0}^{v} dv = v - v_0 \\implies v = v_0 + \\int_{t_0}^{t} a(t) , dt$$ $$v(t) = \\frac{ds}{dt} \\implies \\int_{t_0}^{t} v , dt = \\int_{s_0}^{s} ds = s - s_0 \\implies s = s_0 + \\int_{t_0}^{t} \\left[ v_0 + \\int_{t_0}^{t} a(t) , dt \\right] dt$$ 对于上面的公式，当加速度a是一个Constant的时候 $$v=v_0+\\int_{t_0}^{t} a , dt=v_0+a\\int_{t_0}^{t} , dt=v_0+a(t-t_0)$$ 同理s也就有 $$s=s_0+\\int_{t_0}^{t} \\left[ v_0+a(t-t_0) \\right] dt=s_0+\\frac{1}{2}at^2-at_0t+v_0t$$ Acceleration is a function of position a(s) #\r在这种情况下，加速度取决于位置，这常见于诸如重力势能场中物体的运动 同理Acceleration是速度对于时间的导数，有 $$a(s)=\\frac{dv}{dt}\\Rightarrow dt=\\frac{dv}{a(s)}$$ 又因为Veloctiy是Speed对于时间的导数，有 $$v=\\frac{ds}{dt}\\Rightarrow dt=\\frac{ds}{v}$$ 建立等式便可得到 $$\\frac{dv}{a(s)}=\\frac{ds}{v}\\Rightarrow \\int a(s)ds=\\int vdv=\\frac{1}{2}(v^2-{v_0}^2)$$ 同理当a是Constant的时候有 $$\\frac{1}{2}(v^2-{v_0}^2)=a\\int^s_{s_0}ds=a\\Delta S\\Rightarrow v^2={v_0}^2+2a\\Delta S$$ 在加速度是位置的函数的时候没有对于s的公式\nex. Speed of asteroid falling #\rFind the impact speed of an asteroid falling to earth from a height of 109m (from the center of earth), when 𝑣𝑜 =-50 m/s. Consider m(earth)=6e24 kg, and G=6.67e-11Nm²/kg², and r(earth)=6.4e6 m\n已知u，S0，Sf，求Vf，已知加速度是Position s的函数\\(a=\\frac{Gm_e}{r^2}\\) $$v^2={v_0}^2-2\\int\\frac{Gm_e}{s^2}ds={v_0}^2+2Gm_e(\\frac{1}{s}-\\frac{1}{s_0})$$ Acceleration is a function of velocity a(v) #\r加速度为速度v的函数，一般来说有速度越快加速度越小 $$a(v)=\\frac{dv}{dt}\\Rightarrow dt=\\frac{dv}{a(v)}\\Rightarrow \\int^t_{t_0}dt=\\int^v_{v_0}\\frac{dv}{a(v)}=t-t_0$$ ex. Projectile Motion #\rA projectile travels through fluid with an initial velocity of 60 m/s. The acceleration is 𝑎 = −0.4 v3𝑚/𝑠². Find v after 4 s\n可以发现a是v的函数，有\\(a(v)=-0.4v^3\\) $$a(v)=\\frac{dv}{dt}\\Rightarrow \\int^t_{t_0} dt=\\int\\frac{dv}{-0.4v^3}=\\frac{-1}{0.4}\\int v^{-3}dv$$ 分别求出积分后得到 $$t-t_0=\\frac{-1}{0.4}\\frac{-1}{2}=(\\frac{1}{v^2}-\\frac{1}{{v_0}^2})\\Rightarrow v=0.559m/s$$ Summary #\r加速度 a(t)a(t) 是时间的函数 $$∫dv=∫a(t) dt\\int dv = \\int a(t) , dt$$ 加速度 a(s)a(s) 是位移的函数 $$∫v dv=∫a ds\\int v , dv = \\int a , ds$$ 加速度 a(v)a(v) 是速度的函数 $$∫dva(v)=∫dt\\int \\frac{dv}{a(v)} = \\int dt$$ 当a是常数的时候 $$V = V_0 + at$$ $$S = S_0 + V_0 t + \\frac{1}{2} a t^2$$ $$V^2 = V_0^2 + 2a \\Delta s$$ ","date":"Jan 19 2025","externalUrl":null,"permalink":"/docs/dynamics/dyn2.rectilinearmotion/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/19/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e2.1 Rectilinear Motion 直线运动 \r\n    \u003cdiv id=\"21-rectilinear-motion-%E7%9B%B4%E7%BA%BF%E8%BF%90%E5%8A%A8\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#21-rectilinear-motion-%E7%9B%B4%E7%BA%BF%E8%BF%90%E5%8A%A8\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/dynamics/dyn2.rectilinearmotion/DYN2.RectilinearMotion_hu4983377577876070246.png 330w,\r\n        /docs/dynamics/dyn2.rectilinearmotion/DYN2.RectilinearMotion_hu11782187809402169278.png 660w,\r\n        /docs/dynamics/dyn2.rectilinearmotion/DYN2.RectilinearMotion_hu7394882687713836707.png 1024w,\r\n        /docs/dynamics/dyn2.rectilinearmotion/DYN2.RectilinearMotion_hu1418611603489186125.png 2x\"\r\n        src=\"/docs/dynamics/dyn2.rectilinearmotion/DYN2.RectilinearMotion_hu11782187809402169278.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"DYN 2. Rectilinear Motion","type":"docs"},{"content":"","date":"Jan 19 2025","externalUrl":null,"permalink":"/tags/ma/","section":"Tags","summary":"","title":"MA","type":"tags"},{"content":"","date":"Jan 19 2025","externalUrl":null,"permalink":"/tags/pr/","section":"Tags","summary":"","title":"PR","type":"tags"},{"content":"Projects\n","date":"Jan 19 2025","externalUrl":null,"permalink":"/docs/projects/","section":"Docs","summary":"\u003cp\u003eProjects\u003c/p\u003e","title":"Projects","type":"docs"},{"content":" Last Edit: 1/18/25\nDeferred Initialization是指模型的某些参数在模型创建时并不会立即被初始化，而是会在第一次接收到输入数据时，根据输入数据的实际形状动态地完成初始化 需要知道的是延后初始化的核心目标 就是为了解决 输入维度未知 的问题，而模型内部层之间的维度通常是事先定义好的\n5.3.1 Create Network 实例化网络 #\rclass MyNet(nn.Module): def __init__(self): super().__init__() self.layers = nn.Sequential( nn.Linear(0, 0), nn.ReLU(), nn.Linear(0, 0) ) 先定义模型框架，将两个Linear Layer留空，这样就可以在之后更改 def forward(self, x): if isinstance(self.layers[0], nn.Linear) and self.layers[0].in_features == 0: self.layers[0] = nn.Linear(x.size(1), 256) # 动态初始化第一层 if isinstance(self.layers[2], nn.Linear) and self.layers[2].in_features == 0: self.layers[2] = nn.Linear(256, 10) # 动态初始化第二层 return self.layers(x) 定义前向传播的过程，并在过程中加入初始化的部分，由于不知道具体的输入维度，将self.layers[0] = nn.Linear(x.size(1), 256)这一层的input Feature设置为输入的维度，也就是x.size(1)，而层与层之间的维度都是可以自行调整的，这里就可以设置这一层的output维度为256 分别检查定义模型时的层和运行后的，有 Before input:\rLayer 0 weights: None\rLayer 2 weights: None\rAfter input:\rLayer 0 weights: torch.Size([256, 20])\rLayer 2 weights: torch.Size([10, 256]) ","date":"Jan 18 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.3deferredinitialization/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/18/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eDeferred Initialization是指模型的某些参数在模型创建时并不会立即被初始化，而是会在第一次接收到输入数据时，根据输入数据的实际形状动态地完成初始化\n需要知道的是延后初始化的\u003cstrong\u003e核心目标\u003c/strong\u003e 就是为了解决 \u003cstrong\u003e输入维度未知\u003c/strong\u003e 的问题，而模型内部层之间的维度通常是事先定义好的\u003c/p\u003e","title":"D2L 5.3 Deferred Initialization","type":"docs"},{"content":" Last Edit: 1/17/25\n在训练的过程中，目标是找到使得Cost Function最小化的Parameters，而有些时候需要提取其中一层的参数检查或者移动到其他环境下，这就需要访问参数\n5.2.1 Access parameters 访问参数 #\r现在先用一个简单的MLP import torch from torch import nn net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1)) X = torch.rand(size=(2, 4)) net(X) 当采用pytorch的Sequential定义模型的时候，可以通过Index访问层 print(net[2].state_dict()) -\u0026gt; OrderedDict([(\u0026#39;weight\u0026#39;, tensor([[-0.0861, 0.1627, 0.2363, 0.2068, 0.0122, -0.1120, -0.3021, -0.2810]])), (\u0026#39;bias\u0026#39;, tensor([0.0187]))]) 查看Output，其包含了\u0026rsquo;weight\u0026rsquo; 和 \u0026lsquo;bias\u0026rsquo; 两个参数 需要知道的是每一层的参数的名称都对应唯一的值，如访问所有模型参数时 print(net.state_dict()) -\u0026gt; OrderedDict([(\u0026#39;0.weight\u0026#39;, tensor([[ 0.2787, 0.1086, 0.2637, 0.1725], [ 0.0952, 0.4238, 0.0774, -0.1717], [-0.2244, 0.0670, -0.4168, 0.1995], [ 0.1364, -0.1932, 0.0650, 0.3378], [-0.1094, 0.2522, -0.2162, -0.2466], [ 0.1079, 0.0859, -0.4721, -0.1010], [-0.2436, 0.2096, -0.3895, 0.4636], [ 0.2348, 0.1281, -0.1079, 0.4432]])), (\u0026#39;0.bias\u0026#39;, tensor([-0.0356, 0.3268, 0.3199, -0.4558, -0.2564, -0.3566, -0.1493, 0.0168])), (\u0026#39;2.weight\u0026#39;, tensor([[-0.0861, 0.1627, 0.2363, 0.2068, 0.0122, -0.1120, -0.3021, -0.2810]])), (\u0026#39;2.bias\u0026#39;, tensor([0.0187]))]) 5.2.1.1 Target Parameter 目标参数 #\r既然能访问层下参数，当然也能访问到具体参数 print(type(net[2].bias)) print(net[2].bias) print(net[2].bias.data) -\u0026gt; \u0026lt;class \u0026#39;torch.nn.parameter.Parameter\u0026#39;\u0026gt; Parameter containing: tensor([0.0187], requires_grad=True) tensor([0.0187]) 单个参数是一个复合对象，即不止包含值 5.2.1.3 Collect Parameter from blocks #\rdef block1(): return nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 4), nn.ReLU()) def block2(): net = nn.Sequential() for i in range(4): # 在这里嵌套 net.add_module(f\u0026#39;block {i}\u0026#39;, block1()) return net rgnet = nn.Sequential(block2(), nn.Linear(4, 1)) rgnet(X) 这里构建了一个挺复杂的网络，具体来说block2定义了一个大块，其中input要经过4个block1之后通过一个Linear Layer，完整结构如下 -\u0026gt; rgnet: Sequential( (0): block2: Sequential( (block 0): block1 (block 1): block1 (block 2): block1 (block 3): block1 ) (1): Linear(4, 1) ) 就像多层的List一样，需要通过维度依次访问，最外层为一个Block 2和一个Linear，而Block2 内部依然是一个“二维列表”，通过rgnet[0][1][0].bias.data就可以访问到(block 1): block1的Linear层的bias的值 5.2.2 Parameter Initialization 参数初始化 #\r前面讨论过了一个系统的初始化的重要性，可以简单的通过框架做默认初始化也可以自定义 5.2.2.1 Built-in initialization 内置初始化 #\rdef init_normal(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, mean=0, std=0.01) nn.init.zeros_(m.bias) net.apply(init_normal) net[0].weight.data[0], net[0].bias.data[0] 上面的nn.init.normal_和nn.init.zeros_分别对应了Gaussian Distribution和零值 nn.init.constant_(m.weight,1)则可以将weight全设置为固定值1 5.2.2.2 Custom Initialization 自定义初始化 #\r5.2.3 Combined Parameter 参数绑定 #\r通过在定义模型之间定义层，后将层作为元素直接放入模型中，这样就可以做到模型中的两个层不止在数值上是相等的，其调用的Memory都是同一个（即改一个则全变） 当参数绑定时，梯度会发生什么情况？ 答案是由于模型参数包含梯度，因此在反向传播期间第二个隐藏层 （即第三个神经网络层）和第三个隐藏层（即第五个神经网络层）的梯度会加在一起。 -\u0026gt; 将补充原理\n","date":"Jan 17 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.2parametermanagement/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/17/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e在训练的过程中，目标是找到使得Cost Function最小化的Parameters，而有些时候需要提取其中一层的参数检查或者移动到其他环境下，这就需要访问参数\u003c/p\u003e","title":"D2L 5.2 Parameter Management","type":"docs"},{"content":" Last Edit: 1/13/25\nPolynomial Interpolation #\r如果想要找一个Polynomial，其穿过两个Point，很简单的做法就是建立$P(x)=ax+b$的多项式 但是如果问题变成了三个点甚至更多，问题的复杂度就会上升很多，于是需要考虑另一种做法 对于点$(-1,-1),(1,3),(2,-2)$我们需要找到一个Polynomial穿过这三个点，可以先写出三个Quadratic Polynomial $$L_1(x) := \\begin{cases} 1, \u0026amp; \\text{if } x = -1 \\ 0, \u0026amp; \\text{if } x = 1 \\ 0, \u0026amp; \\text{if } x = 2, \\end{cases} L_2(x) := \\begin{cases} 0, \u0026amp; \\text{if } x = -1 \\ 1, \u0026amp; \\text{if } x = 1 \\ 0, \u0026amp; \\text{if } x = 2, \\end{cases}\nL_3(x) := \\begin{cases} 0, \u0026amp; \\text{if } x = -1 \\ 0, \u0026amp; \\text{if } x = 1 \\ 1, \u0026amp; \\text{if } x = 2. \\end{cases} $$\n之后再令$P_2(x)=−1L_1(x) + 3L_2(x) − 2L_3(x)$ 分别查看三个点的值可以发现 $$P_2(-1) = -1L_1(-1) + 3L_2(-1) - 2L_3(-1) \\ = -1(1) + 3(0) - 2(0) \\ = -1$$ $$P_2(1) = -1L_1(1) + 3L_2(1) - 2L_3(1) \\ = -1(0) + 3(1) - 2(0) \\ = 3$$ $$ P_2(2) = -1L_1(2) + 3L_2(2) - 2L_3(2) \\ = -1(0) + 3(0) - 2(1) \\ = -2$$ 可以发现这样构建的Polynomial是符合要求的，那么问题就变成了如何构建这三个Quadratic Polynomial 已知$L_1(x)$有两个Roots，分别为$x=1$和$x=2$，并且因为$L_1(-1)=1$所以有 $$L_1(-1)=C(-1-1)(-1-2)=1\\Rightarrow C=\\frac{1}{(-1-1)(-1-2)}$$ 同理对于$L_2$和$L_3$来说有 $$P_2(x) = -1 \\frac{(x - 1)(x - 2)}{(-1 - 1)(-1 - 2)} + 3 \\frac{(x + 1)(x - 2)}{(1 + 1)(1 - 2)} - 2 \\frac{(x + 1)(x - 1)}{(2 + 1)(2 - 1)} $$ 这就是Lagrange Interpolation 拉格朗日插值法 ex. #\r将Lagrange Interpolation推广到四个点上，有 $$L_1(x) := \\begin{cases} 1, \u0026amp; \\text{if } x = x_1 \\ 0, \u0026amp; \\text{if } x = x_2 \\ 0, \u0026amp; \\text{if } x = x_3 \\ 0, \u0026amp; \\text{if } x = x_4, \\end{cases} L_2(x) := \\begin{cases} 0, \u0026amp; \\text{if } x = x_1 \\ 1, \u0026amp; \\text{if } x = x_2 \\ 0, \u0026amp; \\text{if } x = x_3 \\ 0, \u0026amp; \\text{if } x = x_4, \\end{cases}\nL_3(x) := \\begin{cases} 0, \u0026amp; \\text{if } x = x_1 \\ 0, \u0026amp; \\text{if } x = x_2 \\ 1, \u0026amp; \\text{if } x = x_3 \\ 0, \u0026amp; \\text{if } x = x_4, \\end{cases}\nL_4(x) := \\begin{cases} 0, \u0026amp; \\text{if } x = x_1 \\ 0, \u0026amp; \\text{if } x = x_2 \\ 0, \u0026amp; \\text{if } x = x_3 \\ 1, \u0026amp; \\text{if } x = x_4. \\end{cases}$$\n其最终的Polynomial将会长这样 $$P_3(x) = y_1 \\frac{(x-x_2)(x-x_3)(x-x_4)}{(x_1-x_2)(x_1-x_3)(x_1-x_4)} + y_2 \\frac{(x-x_1)(x-x_3)(x-x_4)}{(x_2-x_1)(x_2-x_3)(x_2-x_4)} + y_3 \\frac{(x-x_1)(x-x_2)(x-x_4)}{(x_3-x_1)(x_3-x_2)(x_3-x_4)} + y_4 \\frac{(x-x_1)(x-x_2)(x-x_3)}{(x_4-x_1)(x_4-x_2)(x_4-x_3)}$$ ","date":"Jan 13 2025","externalUrl":null,"permalink":"/docs/calculus/calculusa1.polynomialinterpolation/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/13/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003ePolynomial Interpolation \r\n    \u003cdiv id=\"polynomial-interpolation\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#polynomial-interpolation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e如果想要找一个Polynomial，其穿过两个Point，很简单的做法就是建立$P(x)=ax+b$的多项式\u003c/li\u003e\n\u003cli\u003e但是如果问题变成了三个点甚至更多，问题的复杂度就会上升很多，于是需要考虑另一种做法\u003c/li\u003e\n\u003cli\u003e对于点$(-1,-1),(1,3),(2,-2)$我们需要找到一个Polynomial穿过这三个点，可以先写出三个Quadratic Polynomial\n$$L_1(x) := \\begin{cases}\n1, \u0026amp; \\text{if } x = -1 \\\n0, \u0026amp; \\text{if } x = 1 \\\n0, \u0026amp; \\text{if } x = 2,\n\\end{cases}\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eL_2(x) := \\begin{cases}\n0, \u0026amp; \\text{if } x = -1 \\\n1, \u0026amp; \\text{if } x = 1 \\\n0, \u0026amp; \\text{if } x = 2,\n\\end{cases}\u003c/p\u003e","title":"Calculus A1. Polynomial Interpolation","type":"docs"},{"content":" Last Edit: 1/13/25\nIn this chapter, we will discuss how to make decisions in C. We will discuss the if, else and else if statements\n3.1 If-Statement #\r开发一个提示用户输入年龄的程序。如果未满工作的法定年龄，程序会打印“您还没有资格工作”，否则会显示“您有资格工作” if和else的语法在C中如下 if (condition) { // code to execute if condition is true } else { // code to execute if condition is false } 3.1.1 What can this condition be #\rCondition是一个Bool variable，其可以用True表示，也可以用Numerical Value。在C中，任意非零的值都（通常用1）代表了True，而False则是0 Relational Expression #\r关系运算符通常使用以下的符号 ==：Equal to !=：Not Equal to \u0026lt;：Less than \u0026gt;：Greater than \u0026lt;=：Leq \u0026gt;=：Geq 有了这些就可以完整编写一个判断年龄的程序了 #include \u0026lt;stdio.h\u0026gt; int main(void) { int age = 0; printf(\u0026#34;Enter your age: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;age); if (age \u0026lt; 14) { // Condition checking if age is less than 14 printf(\u0026#34;You are not yet eligible to work in Ontario.\u0026#34;); } else { printf(\u0026#34;You are eligible to work in Ontario.\u0026#34;); } return 0; } 3.1.2. What can we do with relational operators? #\r通过Relational Operators，可以实现 比较值的大小：(7.2\u0026gt;5.1) 比较char的大小：'a'\u0026gt;'b'，这里比较的是他们的ASCII 比较char和int：比如(0 == '0')，char的0有ASCII = 48，所以0 != \u0026lsquo;0\u0026rsquo; int x = 0; if (x = 1) { printf(\u0026#34;True\u0026#34;); } 这是一个判断，他最终会输出True，这是因为即使第一行赋值int x = 0;，第二行重新令x = 1，使得判断变成了if (1)，而1就是True 3.2 Multiple Conditions #\r想要同时判断两个Condition的成立，可以通过\u0026amp;\u0026amp;的判断符，这些完整的叫做Logical Operators 3.2.1 Logical/Boolean Operators #\rA B A \u0026amp;\u0026amp; B A || B false false false false false true false true true false false true true true true true 完整的Logical Opeators的判断结果如上，但是记住过程比背下表格更加简单 \u0026amp;\u0026amp;，and，当A和B同为true则为True，其他均为False ||，or，当A和B其中一个为True则整体为True 还有第三个Logial Operators为!，其的作用就是Reverse Bool Value #include \u0026lt;stdio.h\u0026gt; int main(void) { char letter = \u0026#39; \u0026#39;; printf(\u0026#34;Enter a letter: \u0026#34;); scanf(\u0026#34;%c\u0026#34;, \u0026amp;letter); if (letter == \u0026#39;A\u0026#39; || letter == \u0026#39;a\u0026#39;) { printf(\u0026#34;You entered an upper case or lower case A.\u0026#34;); } else { printf(\u0026#34;You did not enter an upper case or lower case A.\u0026#34;); } return 0; } 上面的程序，当输入为A或者a的时候，都会进入if，因为用的是||，or判断符 3.2.1.1 Lazy Evaluation #\r假设执行了x % y \u0026lt; 10的判断，一个问题可能出现在当y=0的时候，所以这就需要在整除之前做一步y!=0的判断 一种做法就是nested-if，嵌套if，这是一个非常lj的做法，虽然可读性高，但占用的时间和空间都是庞大的 if (条件1) { // 条件1满足时执行的代码 if (条件2) { // 条件1和条件2同时满足时执行的代码 } } 另外一种做法就是通过Lazy Evaluation，其实就是使用\u0026amp;\u0026amp; if (y != 0 \u0026amp;\u0026amp; x % y \u0026lt; 10) { // do something } Lazy evaluation将多个判断结合为一个的办法，详细来说他会从左到右的顺序判断 || 这个运算符先评估左侧的表达式（LHS，Left-Hand Side）。 如果LHS为true，那么整个条件表达式结果为true，程序将不再继续评估右侧的表达式（RHS，Right-Hand Side）。 如果LHS为false，程序需要继续评估RHS来决定整个表达式的结果。 \u0026amp;\u0026amp; 这个运算符也先评估LHS。 如果LHS为false，那么整个条件表达式结果为false，程序将不再继续评估RHS。 如果LHS为true，程序需要继续评估RHS来决定整个表达式的结果。 这种评估方式是一种效率优化手段，可以减少不必要的计算 3.2.1.2 De Morgan\u0026rsquo;s Law #\r当一个Lazy Evaluation（注意仅是两个及以上的判断同时发生的情况下）判断的最外侧为一个Not，也就是!的时候，整体的判断将会看上去十分复杂，这可以通过De Morgan\u0026rsquo;s Law化简 具体来说!(A \u0026amp;\u0026amp; B) is equivalent to !A || !B，!(A || B) is equivalent to !A \u0026amp;\u0026amp; !B 同时Relational Expression也可以变换，\u0026gt; 变成了\u0026lt;=，\u0026gt;= 变成 \u0026lt;，== 变成 != 3.3 Nested-if Statement #\r当想要做特别多的判断的时候，可以采取Nested-if Statement，也就是嵌套If 3.3.2 Dangling Else Problem #\r在C语言中，if语句可以不带大括号{}来执行单条语句 if (condition) statement; else statement; 这种写法没有问题，因为每个if和else清晰地对应一条语句。但是，如果没有使用大括号对嵌套的if语句进行清晰的界定，就会产生 Dangling Else 问题 if (condition1) if (condition2) statement; else statement; 在这种情况下，不明确的是这个else应该属于哪个if。按照C语言的规则，else总是匹配最近的未匹配的if，所以在没有大括号明确界定的情况下，上面的else属于if (condition2) 所以没事就加个{} ","date":"Jan 13 2025","externalUrl":null,"permalink":"/docs/learning-programming-with-c/lpc3.decisionmakingstatements/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/13/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e In this chapter, we will discuss how to make decisions in C. We will discuss the \u003ccode\u003eif\u003c/code\u003e, \u003ccode\u003eelse\u003c/code\u003e and \u003ccode\u003eelse if\u003c/code\u003e statements\u003c/p\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e3.1 If-Statement \r\n    \u003cdiv id=\"31-if-statement\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#31-if-statement\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e开发一个提示用户输入年龄的程序。如果未满工作的法定年龄，程序会打印“您还没有资格工作”，否则会显示“您有资格工作”\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eif\u003c/code\u003e和\u003ccode\u003eelse\u003c/code\u003e的语法在C中如下\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003econdition\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// code to execute if condition is true\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e \u003cspan class=\"k\"\u003eelse\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// code to execute if condition is false\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\r\n\r\n\u003ch2 class=\"relative group\"\u003e3.1.1 What can this condition be \r\n    \u003cdiv id=\"311-what-can-this-condition-be\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#311-what-can-this-condition-be\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eCondition是一个Bool variable，其可以用\u003ccode\u003eTrue\u003c/code\u003e表示，也可以用Numerical Value。在C中，任意非零的值都（通常用1）代表了\u003ccode\u003eTrue\u003c/code\u003e，而\u003ccode\u003eFalse\u003c/code\u003e则是0\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eRelational Expression \r\n    \u003cdiv id=\"relational-expression\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#relational-expression\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e关系运算符通常使用以下的符号\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e==\u003c/code\u003e：Equal to\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e!=\u003c/code\u003e：Not Equal to\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e\u0026lt;\u003c/code\u003e：Less than\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e\u0026gt;\u003c/code\u003e：Greater than\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e\u0026lt;=\u003c/code\u003e：Leq\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e\u0026gt;=\u003c/code\u003e：Geq\u003c/li\u003e\n\u003cli\u003e有了这些就可以完整编写一个判断年龄的程序了\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;stdio.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eage\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;Enter your age: \u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nf\"\u003escanf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;%d\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e14\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e  \u003cspan class=\"c1\"\u003e// Condition \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003echecking\u003c/span\u003e \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eage\u003c/span\u003e \u003cspan class=\"n\"\u003eis\u003c/span\u003e \u003cspan class=\"n\"\u003eless\u003c/span\u003e \u003cspan class=\"n\"\u003ethan\u003c/span\u003e \u003cspan class=\"mi\"\u003e14\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;You are not yet \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eeligible\u003c/span\u003e \u003cspan class=\"n\"\u003eto\u003c/span\u003e \u003cspan class=\"n\"\u003ework\u003c/span\u003e \u003cspan class=\"n\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eOntario\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e}\u003c/span\u003e \u003cspan class=\"k\"\u003eelse\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;You are eligible to \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ework\u003c/span\u003e \u003cspan class=\"n\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eOntario\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\r\n\r\n\u003ch2 class=\"relative group\"\u003e3.1.2. What can we do with relational operators? \r\n    \u003cdiv id=\"312what-can-we-do-with-relational-operators\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#312what-can-we-do-with-relational-operators\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e通过Relational Operators，可以实现\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003e比较值的大小：\u003ccode\u003e(7.2\u0026gt;5.1)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e比较\u003ccode\u003echar\u003c/code\u003e的大小：\u003ccode\u003e'a'\u0026gt;'b'\u003c/code\u003e，这里比较的是他们的ASCII\u003c/li\u003e\n\u003cli\u003e比较\u003ccode\u003echar\u003c/code\u003e和\u003ccode\u003eint\u003c/code\u003e：比如\u003ccode\u003e(0 == '0')\u003c/code\u003e，char的0有ASCII = 48，所以0 != \u0026lsquo;0\u0026rsquo;\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;True\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e这是一个判断，他最终会输出True，这是因为即使第一行赋值\u003ccode\u003eint x = 0;\u003c/code\u003e，第二行重新令\u003ccode\u003ex = 1\u003c/code\u003e，使得判断变成了\u003ccode\u003eif (1)\u003c/code\u003e，而1就是True\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e3.2 Multiple Conditions \r\n    \u003cdiv id=\"32-multiple-conditions\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#32-multiple-conditions\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e想要同时判断两个Condition的成立，可以通过\u003ccode\u003e\u0026amp;\u0026amp;\u003c/code\u003e的判断符，这些完整的叫做Logical Operators\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e3.2.1 Logical/Boolean Operators \r\n    \u003cdiv id=\"321-logicalboolean-operators\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#321-logicalboolean-operators\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003eA\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eB\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eA \u0026amp;\u0026amp; B\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eA || B\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cul\u003e\n\u003cli\u003e完整的Logical Opeators的判断结果如上，但是记住过程比背下表格更加简单\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e\u0026amp;\u0026amp;\u003c/code\u003e，and，当A和B同为true则为True，其他均为False\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e||\u003c/code\u003e，or，当A和B其中一个为True则整体为True\u003c/li\u003e\n\u003cli\u003e还有第三个Logial Operators为\u003ccode\u003e!\u003c/code\u003e，其的作用就是Reverse Bool Value\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;stdio.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"kt\"\u003echar\u003c/span\u003e \u003cspan class=\"n\"\u003eletter\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"sc\"\u003e\u0026#39; \u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;Enter a letter: \u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nf\"\u003escanf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;%c\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eletter\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eletter\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"sc\"\u003e\u0026#39;A\u0026#39;\u003c/span\u003e \u003cspan class=\"o\"\u003e||\u003c/span\u003e \u003cspan class=\"n\"\u003eletter\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"sc\"\u003e\u0026#39;a\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;You entered an upper case or lower \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003ecase\u003c/span\u003e \u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e}\u003c/span\u003e \u003cspan class=\"k\"\u003eelse\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;You did not enter an upper case or \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003elower\u003c/span\u003e \u003cspan class=\"k\"\u003ecase\u003c/span\u003e \u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e上面的程序，当输入为A或者a的时候，都会进入if，因为用的是\u003ccode\u003e||\u003c/code\u003e，or判断符\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003e3.2.1.1 Lazy Evaluation \r\n    \u003cdiv id=\"3211-lazy-evaluation\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#3211-lazy-evaluation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e假设执行了\u003ccode\u003ex % y \u0026lt; 10\u003c/code\u003e的判断，一个问题可能出现在当y=0的时候，所以这就需要在整除之前做一步\u003ccode\u003ey!=0\u003c/code\u003e的判断\u003c/li\u003e\n\u003cli\u003e一种做法就是nested-if，嵌套if，这是一个非常lj的做法，虽然可读性高，但占用的时间和空间都是庞大的\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"err\"\u003e条件\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 条件1满足时执行的代码\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"err\"\u003e条件\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"c1\"\u003e// 条件1和条件2同时满足时执行的代码\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e另外一种做法就是通过Lazy Evaluation，其实就是使用\u003ccode\u003e\u0026amp;\u0026amp;\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e!=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e%\u003c/span\u003e \u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// do something\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003eLazy evaluation将多个判断结合为一个的办法，详细来说他会从左到右的顺序判断\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e||\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e这个运算符先评估左侧的表达式（LHS，Left-Hand Side）。\u003c/li\u003e\n\u003cli\u003e如果LHS为\u003ccode\u003etrue\u003c/code\u003e，那么整个条件表达式结果为\u003ccode\u003etrue\u003c/code\u003e，程序将不再继续评估右侧的表达式（RHS，Right-Hand Side）。\u003c/li\u003e\n\u003cli\u003e如果LHS为\u003ccode\u003efalse\u003c/code\u003e，程序需要继续评估RHS来决定整个表达式的结果。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e\u0026amp;\u0026amp;\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e这个运算符也先评估LHS。\u003c/li\u003e\n\u003cli\u003e如果LHS为\u003ccode\u003efalse\u003c/code\u003e，那么整个条件表达式结果为\u003ccode\u003efalse\u003c/code\u003e，程序将不再继续评估RHS。\u003c/li\u003e\n\u003cli\u003e如果LHS为\u003ccode\u003etrue\u003c/code\u003e，程序需要继续评估RHS来决定整个表达式的结果。\u003c/li\u003e\n\u003cli\u003e这种评估方式是一种效率优化手段，可以减少不必要的计算\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003e3.2.1.2 De Morgan\u0026rsquo;s Law \r\n    \u003cdiv id=\"3212-de-morgans-law\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#3212-de-morgans-law\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e当一个\u003cstrong\u003eLazy Evaluation\u003c/strong\u003e（注意仅是两个及以上的判断同时发生的情况下）判断的最外侧为一个Not，也就是\u003ccode\u003e!\u003c/code\u003e的时候，整体的判断将会看上去十分复杂，这可以通过De Morgan\u0026rsquo;s Law化简\u003c/li\u003e\n\u003cli\u003e具体来说\u003ccode\u003e!(A \u0026amp;\u0026amp; B)\u003c/code\u003e is equivalent to \u003ccode\u003e!A || !B\u003c/code\u003e，\u003ccode\u003e!(A || B)\u003c/code\u003e is equivalent to \u003ccode\u003e!A \u0026amp;\u0026amp; !B\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e同时Relational Expression也可以变换，\u0026gt; 变成了\u0026lt;=，\u0026gt;= 变成 \u0026lt;，== 变成 !=\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/learning-programming-with-c/lpc3.decisionmakingstatements/LPC3.DecisionMakingStatements_hu14771444122089271576.png 330w,\r\n        /docs/learning-programming-with-c/lpc3.decisionmakingstatements/LPC3.DecisionMakingStatements_hu3266321974582059814.png 660w,\r\n        /docs/learning-programming-with-c/lpc3.decisionmakingstatements/LPC3.DecisionMakingStatements_hu9341054436462208839.png 1024w,\r\n        /docs/learning-programming-with-c/lpc3.decisionmakingstatements/LPC3.DecisionMakingStatements_hu13158954285452890454.png 2x\"\r\n        src=\"/docs/learning-programming-with-c/lpc3.decisionmakingstatements/LPC3.DecisionMakingStatements_hu3266321974582059814.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"LPC 3. Decision Making Statements","type":"docs"},{"content":" Last Edit: 1/12/25\n1.1 Basic Concepts #\rConcepts Definition Space The geometric region occupied by bodies Time A measure of the succession of events and is considered an absolute quantity in Newtonian mechanics Mass The quantitative measure of the inertia or resistance to change in motion of a body Force The vector action of one body on another Particle A body of negligible dimensions (e.g., mass, size) Rigid Body A body whose changes in shape are negligible Vector and Scalar Their distinction should be perfectly clear 1.2 Newton\u0026rsquo;s Laws #\rLaw I. A particle remains at rest or continues to move with uniform velocity (in a straight line with a constant speed) if there is no unbalanced force acting on it. Law II. The acceleration of a particle is proportional to the resultant force acting on it and is in the direction of this force. Law III. The forces of action and reaction between interacting bodies are equal in magnitude, opposite in direction, and collinear. 1.3 Units #\rDimension SI Unit U.S. Unit Conversion Factor Mass {M} Kg Slug 1 slug = 14.5939 kg Length {L} m ft 1 ft = 0.3048 m Time {T} s s 1 s = 1 s Force {F} N lbf 1 lbf = 4.44822 N (*g = 32.2 ft/s²) 1.4 Gravitation #\rNewton’s Law of Gravitational Attraction #\r$$F = \\frac{G m_1 m_2}{r^2}$$\n\\(G = 66.73 \\times 10^{-12} , \\mathrm{m^3 / kg , s^2}\\) \\(r = \\text{distance between mass centers}\\) Apparent Weight #\r$$W=mg$$\n","date":"Jan 12 2025","externalUrl":null,"permalink":"/docs/dynamics/dyn1.intoductiontodynamics/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/12/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e1.1 Basic Concepts \r\n    \u003cdiv id=\"11-basic-concepts\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#11-basic-concepts\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003eConcepts\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eDefinition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eSpace\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eThe geometric region occupied by bodies\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eTime\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eA measure of the succession of events and is considered an absolute quantity in Newtonian mechanics\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eMass\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eThe quantitative measure of the inertia or resistance to change in motion of a body\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eForce\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eThe vector action of one body on another\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eParticle\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eA body of negligible dimensions (e.g., mass, size)\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eRigid Body\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eA body whose changes in shape are negligible\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eVector and Scalar\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eTheir distinction should be perfectly clear\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e1.2 Newton\u0026rsquo;s Laws \r\n    \u003cdiv id=\"12-newtons-laws\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#12-newtons-laws\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eLaw I. A particle remains at rest or continues to move with uniform velocity (in a straight line with a constant speed) if there is no unbalanced force acting on it.\u003c/li\u003e\n\u003cli\u003eLaw II. The acceleration of a particle is proportional to the resultant force acting on it and is in the direction of this force.\u003c/li\u003e\n\u003cli\u003eLaw III.  The forces of action and reaction between interacting bodies are equal in magnitude, opposite in direction, and collinear.\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e1.3 Units \r\n    \u003cdiv id=\"13-units\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#13-units\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003eDimension\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eSI Unit\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eU.S. Unit\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eConversion Factor\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eMass {M}\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eKg\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eSlug\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e1 slug = 14.5939 kg\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eLength {L}\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003em\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eft\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e1 ft = 0.3048 m\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eTime {T}\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003es\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003es\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e1 s = 1 s\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eForce {F}\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eN\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003elbf\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e1 lbf = 4.44822 N (*g = 32.2 ft/s²)\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e1.4 Gravitation \r\n    \u003cdiv id=\"14-gravitation\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#14-gravitation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eNewton’s Law of Gravitational Attraction \r\n    \u003cdiv id=\"newtons-law-of-gravitational-attraction\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#newtons-law-of-gravitational-attraction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cp\u003e$$F = \\frac{G m_1 m_2}{r^2}$$\u003c/p\u003e","title":"DYN 1. Intoduction to Dynamics","type":"docs"},{"content":" Last Edit: 1/9/25\n1. Imaginary and complex numbers #\rReal Number 实数，包含了Reation \u0026amp; Irrational Number一直以来拥有一个Fundamental Property就是 Square of any real number is always nonnegative 换句话来说，方程\\(x^2=-1\\)在实数域是无解的，但这并不代表这个方程无解 要分析这一问题，首先就需要定义\\(\\sqrt{-1}\\) Definition of Imaginary Number #\rAn imaginary number is a number of the form bi, where b is real and $$i=\\sqrt{-1}$$ 定义指出Complex Number是形式为\\(bi\\)的数，其中b为Real Number 有了这定义，我们便可以为任意Real Number找到对应的Square Root，具体来说 $$(bi)^2=b^2\\cdot i^2=b^2\\cdot -1=-b^2$$ 例如\\((3i)^2=-9,\\sqrt{-9}=3i\\) ex. #\rSolve the equation \\(x^2 +2x+2 = 0\\). Using the quadratic formula $$z_1 = \\frac{-2 + \\sqrt{4 - 8}}{2} = -1 + i \\quad \\text{and} \\quad z_2 = \\frac{-2 - \\sqrt{4 - 8}}{2} = -1 - i. $$\nDefinition of Complex Number #\rA complex number is a number of the form \\(z = a+bi\\), where a and b are real numbers 其中a和b分别被称为z的Real \u0026amp; Imaginary Parts $$a=Re(z)和b=Im(z)$$ If \\(Re(z) = 0\\), then z is an imaginary number and if \\(Im(z) = 0\\), then z is a real number 可以发现对于上面的例子\\(z_1\\)和\\(z_2\\)，\\(Re(z_1)=Re(z_2),Im(z_1)=-Im(z_2)\\)，这并不是一个巧合，而是可以引出另一个Complex Number的特性，Complex Conjugate Definition of Complex Conjugate #\rThe complex conjugate of \\(a+bi\\) is the number \\(a-bi\\). We use a bar over the number to denote the conjugate $$\\overline{a + bi} = a - bi$$ 对于二次方程\\(x^2 + \\beta x + \\gamma = 0\\) 中的\\(\\beta^2 - 4\\alpha\\gamma \u0026lt; 0\\) 时，该方程没有实数解，但可以有复数解。这种情况下，解是共轭复数对。解可以通过标准的二次公式来计算： $$a = \\frac{-\\beta}{2\\alpha},b = \\frac{\\sqrt{|\\beta^2 - 4\\alpha\\gamma|}}{2\\alpha}$$ 其中\\(a + bi\\) 和 \\(a - bi\\) 分别是这个二次方程的两个解。 z = a 是一个实数，则它的复数共轭是它自身，即\\(\\overline{z} = z\\)，这表明实数是它们自己的共轭。此外，任何复数z的共轭的共轭是z本身，即\\(\\overline{\\overline{z}} = z\\) 2. Complex Arithmetic 复数运算 #\rComplex numbers和Real Number一样也可以坐加减乘除运算，并且commutativity, associativity and distributivity等特性依然存在 Addition and Sibtraction #\r要给两个Complex Numbers做加减，分别加减他们的Real and Imaginary Components $$(a+bi)+(c+di)=(a+b)+(b+d)i$$ Propisition 2.1 Complex Number\u0026rsquo;s Conjugate #\r对于任何复数z，\n\\(z + \\overline{z} = 2 \\cdot \\text{Re}(z)\\) \\(z - \\overline{z} = 2 \\cdot \\text{Im}(z) \\cdot i\\) Proof #\r假设\\(z = a + bi\\)，其中a是实部，b是虚部，那么：\n\\(z + \\overline{z} = (a + bi) + (a - bi) = 2a = 2 \\text{Re}(z)\\)。这说明复数和其共轭的和是两倍实部 \\(z - \\overline{z} = (a + bi) - (a - bi) = 2bi = 2 \\text{Im}(z) \\cdot i\\)。这说明复数和其共轭的差是两倍虚部的虚数单位 2.2 Multiplication #\r$$(a +bi) (c+di) = ac+adi +cbi +bdi^2 = (ac-bd)+(ad+bc)i$$\n2.3 Division #\rComplex Number的除法可以视为乘以其逆元。复数\\(z = a + bi\\)的逆元\\(z^{-1}\\)满足\\(z \\cdot z^{-1} = 1\\)。 给定非零复数\\(a + bi\\)，求解使得\\((a + bi)(x + yi) = 1\\)的复数\\(x + yi\\)，整理后得到： \\(ax - by = 1\\) \\(bx + ay = 0\\) 这两个方程可以通过以下步骤解决： 将方程 (2) 乘以a，方程 (3) 乘以b，然后将两个结果相加，消去y得到\\((a^2 + b^2)x = a\\)，从而解得\\(x = \\frac{a}{a^2 + b^2}\\) 类似地，将方程 (2) 乘以−b，方程 (3) 乘以a，然后将两个结果相加，消去x得到\\((a^2 + b^2)y = -b\\)，从而解得\\(y = \\frac{-b}{a^2 + b^2}\\) 这样，复数\\(a + bi\\)的乘法逆元\\(x + yi\\)可以表示为： $$x = \\frac{a}{a^2 + b^2},y = \\frac{-b}{a^2 + b^2}$$ Proposition 2.2 Complex Number\u0026rsquo;s Division #\r所以当Complex Number \\(a+bi\\neq 0\\)，then $$(a + bi)^{-1} = \\frac{a}{a^2 + b^2} - \\frac{b}{a^2 + b^2}i$$ 这样就可以做除法的运算了，便有 $$\\frac{c + di}{a + bi} = (c + di) \\cdot (a + bi)^{-1} = (c + di) \\cdot \\left(\\frac{a}{a^2 + b^2} - \\frac{b}{a^2 + b^2}i\\right) = \\frac{ac + bd}{a^2 + b^2} + \\frac{ad - bc}{a^2 + b^2}i$$ Proposition 2.3 Complex Number\u0026rsquo;s Conjugate\u0026rsquo;s Property #\r对于Complex Numbers z 和 w， $$\\overline{z+w}=\\overline{z}+\\overline{w},\\overline{z\\cdot w}=\\overline{z}\\cdot \\overline{w},if~w\\neq ~\\overline{(\\frac{z}{w})}=\\frac{\\overline{z}}{\\overline{w}}$$ Proof #\r$$\\begin{aligned} \\overline{(a + bi) + (c + di)} \u0026amp;= \\overline{(a + c) + (b + d)i} \\ \u0026amp;= (a + c) - (b + d)i \\ \u0026amp;= (a - bi) + (c - di) \\ \u0026amp;= \\overline{(a + bi)} + \\overline{(c + di)} \\end{aligned}$$ $$\\begin{aligned} \\overline{(a + bi),(c + di)} \u0026amp;= \\overline{(ac - bd) + (ad + bc),i} \\ \u0026amp;= (ac - bd) - (ad + bc),i \\ \u0026amp;= (a - bi),(c - di) \\ \u0026amp;= \\overline{(a + bi)} ,\\cdot, \\overline{(c + di)} \\end{aligned}$$\n3. The Geometry of Complex Numbers #\r对于Complex Number来说，其可以通过Complex Plane来表示，其中两个轴分别是Real Axis和Imaginary Axis 每一个复数可以被视为起始于原点的向量，而复数的加法可以通过向量加法在几何上表示出来 3.2 The modulus of a Complex Number #\r对于Real Number来说，其Magnitude可以通过Absolute Value\\(|a|\\)来得到，这同理也可以运用到Complex Number上 Definition of modulus of Complex Number #\rThe modulus, or absolute value, of a complex number \\(z= a+ bi\\), is denoted by \\(|z|\\) and defined to be the distance in the complex plane between the point z and the point 0 Proposition 3.1 Complex Number\u0026rsquo;s Conjugate \u0026amp; Modulus #\rFor any Complex Number z $$|z|^2=z\\cdot \\overline z$$ Proof #\r假设有Complex Number z，根据Complex Number的Modulus可以得到\\(|z|^2=a^2+b^2\\) $$z\\cdot \\overline z=(a+bi)(a-bi)=a^2-abi+abi-b^2i^2=a^2+b^2=|z|^2$$ 于是当\\(z\\neq 0\\)的情况下， $$z^{-1}=\\frac{\\overline z}{|z|^2}$$ 这与上面Proposition 2.2 Complex Number\u0026rsquo;s Division的内容相似 Proposition 3.2 Commutative Property #\r\\(|z\\cdot w|=|z|\\cdot |w|\\) $$|z \\cdot w|^2 = (z \\cdot w) \\cdot (\\overline{z \\cdot w}) = z \\cdot w \\cdot \\overline{z} \\cdot \\overline{w} = |z|^2 \\cdot |w|^2$$ 两边同时取Square Root可以得到 $$|z \\cdot w| = \\sqrt{|z \\cdot w|^2} = \\sqrt{|z|^2 \\cdot |w|^2} = \\sqrt{|z|} \\cdot \\sqrt{|w|} = |z| \\cdot |w| $$ Proposition 3.3 Inverse #\rIf \\(z\\neq 0,then~|z^{-1}|=(|z|)^{-1}\\) 3.3 The Argument of a Complex Number 复数的辐角 #\r如果说Modulus决定了一个Complex Number的Magnitude，他的Angle则是被Argument决定 The argument (or phase) of \\(z= a+ bi(z\\neq 0)\\)is ‘the’ angle, \\(φ\\) between the positive real axis and the line segment connecting z to 0 The argument of z is denoted by arg(z) 通常情况下，复数的辐角是多值的，因为角度可以通过加上\\(2\\pi\\)的整数倍来得到相同的方向 求的Complex Number的Argument的办法就是通过\\(\\arctan\\)函数 在不同Quadrant下的Complex Number所得到的Argument则需要有所调整，具体来说 第一象限\\(a \u0026gt; 0, b \u0026gt; 0\\)，直接使用\\(\\arctan(b/a)\\)，无需调整。 第二象限\\(a\u0026lt;0,b\u0026gt;0\\)，\\(arctan(b/a)\\) 计算的是一个负值，但实际的Argument应是\\(\\pi\\)加上这个负值。所以，辐角是\\(\\pi + \\text{arctan}(b/a)\\) 第三象限\\(a\u0026lt;0,b\u0026lt;0\\)，此时\\(\\text{arctan}(b/a)\\)产生正值，但由于在第三象限，所需的辐角是这个值减去\\(\\pi\\)，即\\(\\arctan(b/a) - \\pi\\) 第四象限\\(a\u0026gt;0,b\u0026lt;0\\)，在此象限，\\(\\arctan(b/a)\\) 本身就是正确的辐角值，因为它会给出负的角度值。 特殊情况a = 0 时，辐角取决于b的符号： 如果\\(b\u0026gt;0\\)，辐角是\\(\\frac{\\pi}{2}\\)， 如果\\(b\u0026lt;0\\)，辐角是\\(\\frac{3\\pi}{2}\\) 3.4 The polar-coordinate representation of complex numbers. #\r在分别求得了Complex Number的Modulus和Argument后，便可以求出Complex Number的Polar Coordinate 其于正常的Polar Coordinate一样，\\(Re(z)=r\\cos\\theta,Im(z)=r\\sin \\theta,z=r(\\cos \\theta+i\\sin \\theta)\\) Proposition 3.5 Argument\u0026rsquo;s Associative Law #\r\\(arg(z_1z_2)=arg(z_1)+arg(z_2)\\) 有\\(z_1 = r \\bigl(\\cos \\theta + i \\sin \\theta\\bigr), \\quad z_2 = \\rho \\bigl(\\cos \\phi + i \\sin \\phi\\bigr)\\) $$z_1 z_2 = \\bigl(r(\\cos \\theta + i \\sin \\theta)\\bigr) \\cdot \\bigl(\\rho(\\cos \\phi + i \\sin \\phi)\\bigr) =r\\rho ,\\Bigl((\\cos \\theta + i \\sin \\theta),(\\cos \\phi + i \\sin \\phi)\\Bigr)$$ 其中\\((\\cos \\theta + i \\sin \\theta),(\\cos \\phi + i \\sin \\phi)= (\\cos \\theta)(\\cos \\phi) + (\\cos \\theta)(i \\sin \\phi) + (i \\sin \\theta)(\\cos \\phi) + (i \\sin \\theta)(i \\sin \\phi)\\) 当把各项一一对应起来后，就会发现 $$\\cos(\\theta + \\phi) + i,\\sin(\\theta + \\phi)$$ 所以 $$z_1 z_2 = r\\rho ,\\bigl(\\cos(\\theta + \\phi) + i \\sin(\\theta + \\phi)\\bigr)$$ 由此得出\\(\\arg(z_1 z_2) = \\arg(z_1) + \\arg(z_2)\\) 同理Argument的取值范围应为\\((-\\pi,\\pi]\\)，所以 当\\(\\text{arg}(z_1) + \\text{arg}(z_2) \u0026gt; \\pi\\)， 为了将结果拉回到\\((-\\pi, \\pi]\\)的范围内，需要从这个和中减去\\(2\\pi\\) 当\\(\\text{arg}(z_1) + \\text{arg}(z_2) \u0026lt; -\\pi\\) 为了将结果拉回到\\((-\\pi, \\pi]\\)的范围内，需要在这个和中加上\\(2\\pi\\) Proposition 3.6 #\r如果\\(z \\neq 0\\)，且w是任意复数，那么将w乘以z： 会将w的模（大小）按\\(|z|\\)进行伸缩（即缩小或放大） 会将w的辐角（方向角）按\\(\\text{arg}(z)\\)旋转 这说明复数乘法对复数的几何意义是模的缩放和角度的旋转 3.5 Exponential Notation Euler\u0026rsquo;s formula 欧拉公式 #\r对于实数\\(\\theta\\)，复数可以表示为：\\(\\cos\\theta + i\\sin\\theta = e^{i\\theta}\\) 这表明复数的极坐标表示（幅角和模）可以用指数形式表示 Proof #\r对于Euler\u0026rsquo;s Formula的推导从Taylor expansion开始 已知指数函数 exe^x 在实数域中的泰勒展开式为： $$e^x = \\sum_{n=0}^\\infty \\frac{x^n}{n!} = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots$$ 将\\(x\\)替换为\\(i\\theta\\)可以得到 $$e^{i\\theta} = \\sum_{n=0}^\\infty \\frac{(i\\theta)^n}{n!}$$ 已知Imaginary Number i在Even次Exponent下均为\\(-1\\)，可以得到 $$e^{i\\theta} = \\sum_{n=0}^\\infty \\frac{(i\\theta)^n}{n!} = \\sum_{n=0}^\\infty \\frac{(-1)^n\\theta^{2n}}{(2n)!} + i \\sum_{n=0}^\\infty \\frac{(-1)^n\\theta^{2n+1}}{(2n+1)!}$$ 这两个Series分别对应余弦和正弦的泰勒展开式，于是便有 $$e^{i\\theta} = \\cos\\theta + i\\sin\\theta$$ Proposition 3.7 #\rIf \\(z= r \u0026gt; 0\\) and \\(\\theta= arg(z)\\), then $$z=r\\cdot e^{\\theta i}$$ 本质上就是\\(z=r(\\cos\\theta +i\\sin\\theta)\\)，因为有Eulers\u0026rsquo; Formula Proposition 3.8 #\rFor any number and any integer k $$e^{(\\theta+2k\\pi)i}=e^{\\theta i}$$ Proof #\r从Euler\u0026rsquo;s Formula入手，已知\\(e^{(\\theta+2k\\pi )i}=e^{\\theta i}\\cdot e^{2k\\pi i}\\) 令\\(2k\\pi = \\theta\\)，有 $$e^{(\\theta+2k\\pi )i}=e^{\\theta}\\cdot(\\cos 2\\pi+i\\sin 2\\pi)=e^{\\theta}$$ 4. Roots of polynomials #\r4.1 The fundamental theorem of algebra #\r如果P(z)是一个次数为n \u0026gt; 0的多项式，其形式为： $$P(z) = c_n z^n + c_{n-1} z^{n-1} + \\cdots + c_1 z + c_0$$ 其中\\(c_n\\)为Complex Numbers 那么，The fundamental theorem of algebra 表明 \\(P(z) = 0\\) has a Solution in the Complex 一个例子便是对于实数系数多项式\\(P(x) = x^2 + 1\\)，其has no real solutions，但在Complex Number中有两个解\\(i和-i\\) Propisition 4.1 #\r对于任意次数\\(n \\geq 1\\)的复系数多项式\\(P(z)\\)，可以表示为： $$P(z) = c_n \\cdot (z - \\zeta_1)(z - \\zeta_2) \\cdots (z - \\zeta_n)$$ 与Real Number roots一样，并不是所有的根\\(\\zeta_1, \\dots, \\zeta_n\\)都是不同的，某些根可能会重复，称为Reapeated Root 一个例子便是\\(Q(z) = z^4 - 2z^3 + 2z^2 - 2z + 1\\)，其因式分解为： $$Q(z) = (z - 1)(z - 1)(z - i)(z + i)$$ Proposition 4.2 #\r如果 P(z)P(z) 是一个次数\\(n \\geq 1\\)且具有复系数的多项式，那么：\nP(z) 至少有一个根（The fundamental theorem of algebra） P(z) 最多有n个根（Included Repeated Roots) 4.2 Polynomials with real coefficients #\r4.1介绍了Coefficients为Complex Numbers的情况，由于Real Number是Complex Number的Subset，所以当Coeffcients为Real Number的时候，其也有Root 但即使是Real Number的Coefficient，其也不保证Root为Real Number Proposition 4.3 #\r如果\\(P(z) = a_n z^n + a_{n-1} z^{n-1} + \\cdots + a_1 z + a_0\\)是一个Real Number Coefficients Polynomial，并且\\(\\zeta\\)是P(z)的一个根，那么其Complex Conjugate\\(\\overline{\\zeta}\\)也是P(z)的一个根 Proof #\r假设\\(\\zeta\\)是P(z)的一个根，即： $$a_n \\zeta^n + a_{n-1} \\zeta^{n-1} + \\cdots + a_1 \\zeta + a_0 = 0$$ 对等式两边取共轭： $$\\overline{a_n \\zeta^n + a_{n-1} \\zeta^{n-1} + \\cdots + a_1 \\zeta + a_0} = 0$$ 利用共轭的性质 $$\\overline{a_k \\zeta^k} = \\overline{a_k} \\cdot \\overline{\\zeta^k} = a_k \\cdot (\\overline{\\zeta})^k$$ 因为\\(a_k\\)是实数，因此等式变为 $$a_n (\\overline{\\zeta})^n + a_{n-1} (\\overline{\\zeta})^{n-1} + \\cdots + a_1 \\overline{\\zeta} + a_0 = 0$$ 这说明\\(\\overline{\\zeta}\\)也是P(z)的一个根 Proposition 4.4 #\r如果多项式的系数是Real Number，那么其Complex Root必然成共轭对出现 Proposition 4.5 #\r对于一个Real Number Coefficient Polynomial： $$P(z) = a_n z^n + a_{n-1} z^{n-1} + \\cdots + a_1 z + a_0$$ 其可以表示为以下因式分解形式： $$P(z) = a_n (z - \\xi_1)(z - \\xi_2)\\cdots(z - \\xi_m) Q_1(z) Q_2(z) \\cdots Q_k(z)$$ 其中\\(\\xi_1, \\dots, \\xi_m\\)：是所有的Real Roots \\(Q_j(z) = z^2 - 2\\text{Re}(\\zeta_j)z + |\\zeta_j|^2\\)：是与复数根和其共轭对应的实系数二次多项式 4.3 Square roots and quadratic equations #\r想要求解General Quadratic Equation，需要先算出Complex Number的Square Roots Propposition 4.6 #\r如果\\(u \\neq 0\\)，那么复数方程\\(z^2 = u\\)的解是： $$\\zeta_1 = \\sqrt{|u|} e^{i\\theta/2}, \\quad \\zeta_2 = -\\zeta_1$$ Proof #\r已知任何非零复数u都可以表示为\\(u = |u| e^{i\\theta}\\) 于是可以得出其中的一个Root为\\(\\zeta_1 = \\sqrt{|u|} e^{i\\theta/2}\\) 另一个解则是\\(\\zeta_2 = -\\zeta_1\\) Proposition 4.7 #\r对于二次方程： $$az^2 + bz + c = 0$$ 其解的公式为： $$z_1 = \\frac{-b + \\sqrt{b^2 - 4ac}}{2a}, \\quad z_2 = \\frac{-b - \\sqrt{b^2 - 4ac}}{2a}$$ 其中：a, b, c 是复数（且\\(a \\neq 0\\)），公式中的平方根\\(\\sqrt{b^2 - 4ac}\\) 按复数的平方根规则计算。 Example 4.3 #\r$$z^2 + (1 - 2i)z - 2i = 0$$\n这里\\(a = 1，b = 1 - 2i，c = -2i\\) $$\\zeta_1 = \\frac{-(1 - 2i) + \\sqrt{(1 - 2i)^2 - 4(1)(-2i)}}{2}, \\quad \\zeta_2 = \\frac{-(1 - 2i) - \\sqrt{(1 - 2i)^2 - 4(1)(-2i)}}{2}$$ $$b^2 - 4ac = (1 - 2i)^2 - 4(-2i) = 1 - 4i + 4 - 8i = -3 - 4i + 8i = -3 + 4i$$ 根据公式\\(\\sqrt{|b^2 - 4ac|} e^{i\\theta/2}\\)计算其复数平方根\\(\\sqrt{-3 + 4i} = 1 - 2i\\) $$\\zeta_1 = \\frac{-b + \\sqrt{-3 + 4i}}{2} = \\frac{-(1 - 2i) + (1 - 2i)}{2} = 2i$$$$\\zeta_2 = \\frac{-b - \\sqrt{-3 + 4i}}{2} = \\frac{-(1 - 2i) - (1 - 2i)}{2} = -1$$ 4.4 The nth roots of a complex number #\r对于一个正实数\\(\\alpha \u0026gt; 0\\)和正整数n，\\(\\alpha\\)的n次根\\(\\beta\\)定义为： $$\\beta^n = \\alpha \\quad \\text{或} \\quad \\beta = \\alpha^{1/n}$$ 这是解决方程\\(z^n - \\alpha = 0\\)的一个特定解，通常选择正实数解作为主n次根 若\\(u \\neq 0\\)是一个复数，且n是正整数，那么方程\\(z^n = u\\)总共有n个不同的复数解，这些解可以记为\\(\\zeta_1, \\zeta_2, \\dots, \\zeta_n\\) $$z^n - u = (z - \\zeta_1)(z - \\zeta_2)\\cdots(z - \\zeta_n)$$ Proposition 4.8 #\r对于复数\\(u \\neq 0\\)，如果\\(\\theta = \\text{arg}(u)\\)，n是一个正整数，那么方程\\(z^n = u\\)的解为： $$\\zeta_k = \\sqrt[n]{|u|} e^{i\\left(\\frac{\\theta + 2k\\pi}{n}\\right)}, \\quad k = 0, 1, 2, \\dots, n-1$$ 其中总共有n个不同的解，这些解在复平面上均匀分布，构成一个以原点为中心、半径为\\(\\sqrt[n]{|u|}\\)的正n边形。 Proof #\r对于任意k来说，有 $$\\zeta_k = \\sqrt[n]{|u|} e^{i\\left(\\frac{\\theta + 2k\\pi}{n}\\right)}$$ 计算\\(\\zeta_k^n\\) $$\\zeta_k^n = \\left(\\sqrt[n]{|u|}\\right)^n \\cdot \\left(e^{i\\left(\\frac{\\theta + 2k\\pi}{n}\\right)}\\right)^n$$ $$\\left(\\sqrt[n]{|u|}\\right)^n = |u|，\\left(e^{i\\left(\\frac{\\theta + 2k\\pi}{n}\\right)}\\right)^n = e^{i\\left(\\theta + 2k\\pi\\right)} = e^{i\\theta}$$ 所以 $$\\zeta_k^n = |u| e^{i\\theta} = u$$ 这表明每个\\(\\zeta_k\\)都是\\(z^n = u\\)的解 在这之后还需要验证解是不同的\\(\\zeta_k \\neq \\zeta_j\\)，假设\\(\\zeta_k = \\zeta_j\\)，那么\\(\\frac{\\zeta_k}{\\zeta_j} = 1\\) $$\\frac{\\zeta_k}{\\zeta_j} = \\frac{\\sqrt[n]{|u|} e^{i\\left(\\frac{\\theta + 2k\\pi}{n}\\right)}}{\\sqrt[n]{|u|} e^{i\\left(\\frac{\\theta + $2j\\pi}{n}\\right)}} = e^{i\\left(\\frac{2(k-j)\\pi}{n}\\right)}$$ 若\\(\\frac{\\zeta_k}{\\zeta_j} = 1\\)，则必须有： $$\\frac{2(k-j)\\pi}{n} = 2m\\pi \\quad (m \\in \\mathbb{Z})$$ 这意味着： $$\\frac{k-j}{n} = m \\quad \\Rightarrow \\quad k-j = mn$$ 由于\\(0 \\leq k, j \u0026lt; n\\)，因此\\(|k-j| \u0026lt; n\\)，所以只有m = 0，即k = j。 这表明当\\(k \\neq j\\)时，\\(\\zeta_k \\neq \\zeta_j\\) ","date":"Jan 9 2025","externalUrl":null,"permalink":"/docs/calculus/calculus11.complexnumber/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/9/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e1.  Imaginary and complex numbers \r\n    \u003cdiv id=\"1--imaginary-and-complex-numbers\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#1--imaginary-and-complex-numbers\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eReal Number 实数，包含了Reation \u0026amp; Irrational Number一直以来拥有一个Fundamental Property就是 Square of any real number is always nonnegative\u003c/li\u003e\n\u003cli\u003e换句话来说，方程\\(x^2=-1\\)在实数域是无解的，但这并不代表这个方程无解\u003c/li\u003e\n\u003cli\u003e要分析这一问题，首先就需要定义\\(\\sqrt{-1}\\)\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eDefinition of Imaginary Number \r\n    \u003cdiv id=\"definition-of-imaginary-number\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#definition-of-imaginary-number\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003eAn imaginary number is a number of the form bi, where b is real and\n$$i=\\sqrt{-1}$$\u003c/li\u003e\n\u003cli\u003e定义指出Complex Number是形式为\\(bi\\)的数，其中b为Real Number\u003c/li\u003e\n\u003cli\u003e有了这定义，我们便可以为任意Real Number找到对应的Square Root，具体来说\n$$(bi)^2=b^2\\cdot i^2=b^2\\cdot -1=-b^2$$\u003c/li\u003e\n\u003cli\u003e例如\\((3i)^2=-9,\\sqrt{-9}=3i\\)\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eex. \r\n    \u003cdiv id=\"ex\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cp\u003eSolve the equation \\(x^2 +2x+2 = 0\\). Using the quadratic formula\n$$z_1 = \\frac{-2 + \\sqrt{4 - 8}}{2} = -1 + i \\quad \\text{and} \\quad z_2 = \\frac{-2 - \\sqrt{4 - 8}}{2} = -1 - i.\n$$\u003c/p\u003e","title":"CAL 11. Complex Number","type":"docs"},{"content":"","date":"Jan 9 2025","externalUrl":null,"permalink":"/tags/calulus/","section":"Tags","summary":"","title":"Calulus","type":"tags"},{"content":" Last Edit: 1/9/25\n2.1 Double data type for real numbers #\r在程序中用分数代表数字 2.1.1 Convert Inches to Centimeters #\r// Description: This program convert inches to centimeters #include \u0026lt;stdio.h\u0026gt; int main(void){ // Declare variables const double InchesToCm = 2.54; double inputInches, outputCm; // Prompt user for input printf(\u0026#34;Enter the number of inches to convert to cm: \u0026#34;); scanf(\u0026#34;%lf\u0026#34;, \u0026amp;inputInches); // Convert inches to centimeters outputCm = inputInches * InchesToCm; // Display output in 2 decimal places printf(\u0026#34;The number of centimeters is %.2lf\\n\u0026#34;, outputCm); return 0; } const是一个关键字，指示变量是常量。不能在整个代码中更改该变量 int main(void){ const double InchesToCm = 2.54; InchesToCm = 2.51; } 这样操作将会报错，因为InchesToCm是一个不可以更改的Constant\ndouble 是一种数据类型，指示变量是小数 What would happen if a number with decimal is stored in an int? 当赋值一个小数给int的时候，小数部分将被 Truncated 截断，只保留整数部分\n%lf 这是一个格式说明符，指示输入是小数 .2 表示该值应以 2 位小数打印 2.1.2 Summary #\rint：整数数据类型，Format Specifier是%d double：小数数据类型，Format Specifier是%lf 2.2 Data types and representation #\r不同的数据类型在Memory中的储存方式都不同 2.2.1 Integers #\rint使用32位存储，其中31位用于表示整数本身，一位为Sign Bit Sign bit为0是说明整数是正数，为1说明是负数 由于有整数可以有31位，其在正数的范围为0到$2^{31}-1$，在负数的范围为$-2^{31}$到-1 Other Integers Representation #\rshort：16位整数 unsigned int：使用32位，没有符号位，表示范围是0到$2^{32} - 1$ long：通常使用64位（8个字节） long long：也是使用64位（8个字节） 2.2.2. Floating point or real numbers #\rfloat的储存方法类似于科学计数法，其写成$m\\times 10^e$的形式 其中m是尾数，是一个介于1到10的数字，e是指数，表示数字的大小 Two float Representation #\rfloat使用32位，即4bytes double使用64位，即8bytes，由于精度是float的两倍，也叫Double data type双精度 2.2.3. Characters #\r要表示一个字符（如字母、符号或数字），可以使用 char 数据类型。常见的字符包括 A, B, 1, 9, @, # 等 #include \u0026lt;stdio.h\u0026gt; int main(void){ char firstInitial = \u0026#39;S\u0026#39;; printf(\u0026#34;My first initial is %c.\\n\u0026#34;, firstInitial); return 0; } The format specifier for char is %c char 类型使用8bits（1bytes）来存储每个字符 其可以于ASCII编码对应范围是0到$2^7-1$ ASCII 标准使用7位来表示字符，第8位是多余的，因此它被设置为0以兼容字节存储结构。这是因为ASCII最初设计时，只有7位用于字符表示，8位的字节结构是为了适应现代计算机的存储需求 2.2.4. Boolean #\r布尔类型用于表示逻辑值，即 true 或 false。在C语言中，true 被表示为 1，而 false 被表示为 0 尽管布尔类型只需要1个bit来表示其值，但由于内存的组织结构，每个内存单元（cell）通常存储1byte，因此布尔类型在内存中实际占用1byte #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(void){ bool isRaining = true; printf(\u0026#34;Is it raining? %d\\n\u0026#34;, isRaining); return 0; } Boolean没有专门针对的格式说明符，采用%d来打印值 使用布尔类型时，需要包含 \u0026lt;stdbool.h\u0026gt; 库。没有这个库，编译器无法识别 bool 类型 ex. #\r假设n是正整数 bool isPositive = n \u0026gt; 0; \u0026gt; True bool isPositive = n; \u0026gt; True or False,any non-zero number is considered as `true` bool isPositive = n \u0026gt; 0 != 0; \u0026gt; True bool isPositive = n \u0026lt;= 0 != 1; \u0026gt; n\u0026lt;=0 is 0, 0 != 1 -\u0026gt; 1 or True 2.2.5. Declaring Vs. Initializing Variables #\rDeclaring Variables是告诉编译器使用某个变量。在C语言中，声明一个变量的语法是int var; 这样，编译器知道了一个类型为 int 的变量，名为 var。此时，编译器为变量保留了内存空间，但此变量尚未被赋值 变量声明后如果没有赋值，它就是Uninitialized Variables 未初始化变量，这意味着变量没有存储任何有效的值，只是占据了一块内存 如果你声明了一个变量 var，但没有给它赋值，那么它的值可能是一个随机值，例如 174739296（这只是一个示例值，实际结果因每次运行而异）。每次运行时，这个值可能会不同 #include \u0026lt;stdio.h\u0026gt; int main(void) { int var; printf(\u0026#34;Value of uninitialized variable \\\u0026#34;var\\\u0026#34;: %d\\n\u0026#34;, var); int var2 = 0; printf(\u0026#34;Value of initialized variable \\\u0026#34;var\\\u0026#34;: %d\\n\u0026#34;, var2); return 0; } 编译器会发出警告，指出未初始化的变量 var 在使用时可能会导致不确定的行为。警告信息类似于：variable ‘var’ is uninitialized when used here [-Wuninitialized] 为了避免这种警告，最佳做法是声明变量并初始化它，例如：int var = 0; 2.2.6. Taking in input from the user using scanf #\rMutiple Numbers in mutiple variables #\r#include \u0026lt;stdio.h\u0026gt; int main(void) { int num1 = 0, num2 = 0; double dnum1 = 0, dnum2 = 0; printf(\u0026#34;Enter a number: \u0026#34;); scanf(\u0026#34;%d %lf %d %lf\u0026#34;, \u0026amp;num1, \u0026amp;dnum1, \u0026amp;num2, \u0026amp;dnum2); printf(\u0026#34;Numbers entered: %d %lf %d %lf\\n\u0026#34;, num1, dnum1, num2, dnum2); return 0; } \u0026gt; 1 1.2 3 3.4 \u0026gt; Enter a number: 1 1.2 3 3.4 Numbers entered: 1 1.200000 3 3.400000 可以使用 一个 scanf 来接收多个输入，并将它们分别存储在多个变量中。输入的各个数值通过分隔符（如空格、回车或制表符）分隔 Numbers and Characters #\r#include \u0026lt;stdio.h\u0026gt; int main(void) { char idChar; int idNum; printf(\u0026#34;Enter your ID: \u0026#34;); scanf(\u0026#34;%c %d\u0026#34;, \u0026amp;idChar, \u0026amp;idNum); printf(\u0026#34;ID entered: %c%d\\n\u0026#34;, idChar, idNum); return 0; } \u0026gt; S1321234 \u0026gt; Enter your ID: S1321234 ID entered: S1321234 你可以在同一行中使用 scanf 接收字符和数字。比如，用户输入一个以字符开头，后面跟随数字的ID。 使用 %c 来接收字符，接着用 %d 来接收数字。scanf 会自动区分字符和数字，不需要在字符和数字之间添加分隔符 Take in characters and ignoring leading spaces #\r#include \u0026lt;stdio.h\u0026gt; int main(void) { char c1, c2, c3, c4, c5, c6, c7; printf(\u0026#34;Enter license plate letters and numbers: \u0026#34;); scanf(\u0026#34;%c %c %c %c %c %c %c\u0026#34;, \u0026amp;c1, \u0026amp;c2, \u0026amp;c3, \u0026amp;c4, \u0026amp;c5, \u0026amp;c6, \u0026amp;c7); printf(\u0026#34;Licence plate entered: %c%c%c%c-%c%c%c\\n\u0026#34;, c1, c2, c3, c4, c5, c6,c7); return 0; } 在这段代码中，为了忽略输入字符之间的空格，使用了 scanf 函数中的 %c 格式说明符之间加入空格的方法。这样，scanf 在读取每个字符时会自动跳过空格 Common mistake: Spaces after format specifiers #\r#include \u0026lt;stdio.h\u0026gt; int main(void) { double dnum1 = 0; printf(\u0026#34;Enter a number: \u0026#34;); scanf(\u0026#34; %lf \u0026#34;, \u0026amp;dnum1); printf(\u0026#34;Number entered: %.2lf\\n\u0026#34;, dnum1); return 0; } scanf 使用了一个格式说明符 %lf 后跟一个空格。这种情况下，程序会在接收到一个数字输入后继续等待，直到遇到非空格的输入。这是因为 scanf 的行为是读取输入直到满足格式要求，而空格在格式说明符之后会导致它等待下一个非空白字符 2.3 Operations #\r通过已知的四种data types，int, double, char, bool来进行运算 2.3.1 Basic Arithmetic Operations #\r基础的算术运算还是通过 + - * / % 实现的 其中运算优先级根据括号，幂，乘，除，取模，加减的顺序，如果没有优先级，则从左到右的顺序运算 int x = 10 / 5 * 2; 先10/5=2再*2=4 2.3.2. The more accurate data type is contagious #\rint x = 10 * 5 / 3; 在数学中，这个的答案很明显是$16\\frac{2}{3}$，但是10，5和3都是int，所以他们运算的值也必须是一个int，也就是16在这个例子中 int x = 50 / 3.0; 在这个例子中，由于3.0是一个double，他们的结果将会是一个double，但是由于是储存在int中的，所以16后面的小数部分将被抛弃只剩下16 2.3.3. What happens when we divide by 0? #\r在程序中除以0可能导致奇怪的结果，如果是double运算的话也有可能是inf 2.3.4. Modulo operator #\r取得Remainder 余数的运算符 如 10%3=1，10%4=2 3 % 0 的结果是什么？ 会表现出和3/0类似的行为\n2.3.5. Assignment operators #\r赋值运算符，也就是 = ，其优先级小于所有Operations，确保了所有运算结束后才会赋值 赋值运算与其他运算不同，是从右往左结合的，如 x = y =z 先将z的值赋值给y，再将y的值给x Complex Assignment Operations #\r形如 +=, -=, *=, /=, %= 的为复合赋值运算符 x += 3 等价于 x = x + 3 ，剩下的同理 2.3.6. Increment and decrement operators #\r想表达一个值+1有很多种方法，包含了i += 1;, i++; and i++; 这第三个就是Increment Operator，其可以放在Variable前后，放在前面，如 ++i 代表了先将变量加一再更新值，而 i++ 则是先更新值再加一 ，等价于 j = i; i = i + 1; 2.3.7. Type casting #\r想要强制将一个数据类型转换为另一个也有很多做法 double x = 3 / 2; // x 的值是 1.0 因为 3 和 2 都是整数（int），所以 3 / 2 会执行整数除法，结果是 1，然后被存储为 1.0 如果希望 x 的结果是 1.5，需要将操作数之一转换为浮点数 double x = 3.0 / 2; // 或者 double x = (double) 3 / 2; // x 的值是 1.5 (double) 将整数 3 转换为浮点数 3.0，然后执行浮点除法 假设需要将 2.9 转换为整数 double x = 3 / (int) 2.9; // x 的值是 1.0 (int) 2.9 将 2.9 转换为整数 2，然后执行整数除法 3 / 2，结果是 1 2.3.8. sizeof() operator #\rsizeof 用来计算某种数据类型或变量在内存中占用的字节数 sizeof(int)：返回 int 类型的大小（通常为 4 字节） sizeof(double)：返回 double 类型的大小（通常为 8 字节） sizeof(char)：返回 char 类型的大小（通常为 1 字节） 2.4. Math library #\r运算符不只限于 +-*/，还包含了如 $\\sqrt{x}$ 等复杂运算，他们可以通过math librbary实现 #include \u0026lt;math.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(void) { double a = 0, b = 0, c = 0; printf(\u0026#34;Enter the lengths of the sides: \u0026#34;); scanf(\u0026#34;%lf %lf\u0026#34;, \u0026amp;a, \u0026amp;b); c = sqrt(a * a + b * b); printf(\u0026#34;The length of the hypotenuse is %.2lf\\n\u0026#34;, c); return 0; } 2.4.2. You can still use integer values #\r前面没提到的是，sqrt要求的输入实际上是 double 但是其实输入 int 也可以，系统会自动将其转换成 double 想要输出变成 int 也可以通过前面提到的 type casting 2.5. Random numbers #\r2.5.1. Generating a random number #\r需要先导入一个新的库叫做 stdlib.h，然后就可以用 int rand(); 生成随机数了，由于类型是一个 int 这使得生成的范围将再 $[0,2^{31}-1]$ 内取值 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(void) { printf(\u0026#34;Random number 1: %d\\n\u0026#34;, rand()); printf(\u0026#34;Random number 2: %d\\n\u0026#34;, rand()); printf(\u0026#34;Random number 3: %d\\n\u0026#34;, rand()); return 0; } 上述代码很简单，输出就是三个随机数，但是问题是当再一次运行这个程序的时候，会输出三个一样的随机值，这是因为C语言生成的是 Pseudo-random Numebrs 伪随机数，是通过某种算法得出的值，这就导致如果使用的是相同的随机种子时，每次运行程序都将得到一样的随机数 通过调用 srand(unsigned int seed) 可以设置伪随机数的种子，而这个种子会生成一个随机数的Sequence，调用了几次rand就会用到序列中的第几个数 这就导致了如果一个代码中重复的初始化了两次随机种子，随机数就会重置，下一次调用将从Sequence的第一个重新开始 2.5.2. Are we generating random numbers? #\r如果想得到一个真正的随机数，可以采用时间当作种子，调用 time.h 库便可以获取当前时间 Time overflow Problem #\r使用 time(NULL) 可以返回自 1970年1月1日（Unix 纪元）以来的秒数 但是time这个东西本身是一个 int ，这使得他的上限为 $2^{31}-1$， 也就是2038年1月19日03:14:07（UTC）后，这个值将会溢出，所以许多现代系统通过将int改为double解决了这个问题，使溢出的时间来到了2920亿年后 Nested rand #\r如果用 srand(rand()) 替代 srand(time(NULL))，是否会让种子变得随机？\n如果调用 srand(rand())，rand() 的结果依赖于之前的种子。 如果没有明确设置种子，rand() 使用默认种子（通常是 1）。 这意味着每次运行程序时，rand() 的第一个结果是固定的，例如可能是 16807。 因此，srand(rand()) 实际上等效于设置一个固定的种子（例如 16807） 2.5.3. Random numbers within a range #\r默认情况下，rand() 生成的伪随机数范围是从 0 到 RAND_MAX，其中 RAND_MAX 是一个常量 如果需要生成一个更小范围内的随机数（例如 0 和 1 之间的随机数），可以结合取模运算符 % 使用 不像其他语言可以更改这个上线，C语言采取的是取模的办法生成指定范围内的随机数 如果要生成 0 到 5 的随机数，有 int random_number = rand() % 6; // 结果范围是 [0, 5] 这是因为观察取模操作，他的输出将会是 0 % 5 = 0 1 % 5 = 1 2 % 5 = 2 3 % 5 = 3 4 % 5 = 4 5 % 5 = 0 (循环重复) 那么如果范围是1到6，则是 int random_number = (rand() % 6) + 1; // 结果范围是 [1, 6] 总结得出，要生成一个范围在 [MIN, MAX]（包括上下限）的随机数，可以使用公式 int random_number = rand() % (MAX - MIN + 1) + MIN; ","date":"Jan 9 2025","externalUrl":null,"permalink":"/docs/learning-programming-with-c/lpc2.dataoperations/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/9/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e2.1 Double data type for real numbers \r\n    \u003cdiv id=\"21-double-data-type-for-real-numbers\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#21-double-data-type-for-real-numbers\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e在程序中用分数代表数字\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e2.1.1 Convert Inches to Centimeters \r\n    \u003cdiv id=\"211-convert-inches-to-centimeters\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#211-convert-inches-to-centimeters\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// Description: This program convert inches to centimeters\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;stdio.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e\u003cspan class=\"p\"\u003e){\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// Declare variables\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"kt\"\u003edouble\u003c/span\u003e \u003cspan class=\"n\"\u003eInchesToCm\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e2.54\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"kt\"\u003edouble\u003c/span\u003e \u003cspan class=\"n\"\u003einputInches\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eoutputCm\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// Prompt user for input\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;Enter the number of inches to convert to cm: \u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nf\"\u003escanf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;%lf\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003einputInches\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// Convert inches to centimeters\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"n\"\u003eoutputCm\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einputInches\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eInchesToCm\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// Display output in 2 decimal places\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;The number of centimeters is %.2lf\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eoutputCm\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003ccode\u003econst\u003c/code\u003e是一个关键字，指示变量是常量。不能在整个代码中更改该变量\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e\u003cspan class=\"p\"\u003e){\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"kt\"\u003edouble\u003c/span\u003e \u003cspan class=\"n\"\u003eInchesToCm\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e2.54\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003eInchesToCm\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e2.51\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cblockquote\u003e\n\u003cp\u003e这样操作将会报错，因为\u003ccode\u003eInchesToCm\u003c/code\u003e是一个不可以更改的Constant\u003c/p\u003e","title":"LPC 2. Data \u0026 Operations","type":"docs"},{"content":"","date":"Jan 8 2025","externalUrl":null,"permalink":"/tags/calculus/","section":"Tags","summary":"","title":"Calculus","type":"tags"},{"content":" Last Edit: 1/8/25\n10.1 Parametric Equations #\rIf x and y are continuous functions of t on an interval I, then the equations are called parametric equations and t is called the parameter $$x=x(t) andy=y(t)$$ Eliminating the Parameter 化简 #\r通过关系式直接得到x和y之间的函数 ex. #\r$$x(t) = t^2 - 3, \\quad y(t) = 2t + 1, \\quad -2 \\leq t \\leq 3.$$\n从第二个Equation中提出\\(t = \\frac{y - 1}{2}\\)后带入 $$x = \\left(\\frac{y - 1}{2}\\right)^2 - 3 \\ = \\frac{y^2 - 2y + 1}{4} - 3 \\ = \\frac{y^2 - 2y - 11}{4}$$ Use Trigonometrey to Eliminate Parameter #\r通过一些等式建立x和y之间的关系 例如\\(\\cos^2x+\\sin^2 x=1\\) ex. #\r有\\(x = 3 \\cos \\theta \\quad \\text{and} \\quad y = 4 \\sin \\theta, \\quad 0 \\leq \\theta \\leq 2\\pi\\) 通过\\(cos \\theta=\\frac{x}{3},sin\\theta=\\frac{y}{4}\\)替换原式，便有\\((\\frac{x}{3})^2+(\\frac{y}{4})^2=1\\) 10.2 Calculus of Parametric Curves #\rDerivatives of Parametric Equations #\rIf a smooth curve C is given by the equations $$x = f(t) \\quad \\text{and} \\quad y = g(t)$$ then the slope of C at (x, y) is $$\\frac{dy}{dx} = \\frac{\\frac{dy}{dt}}{\\frac{dx}{dt}}, \\quad \\frac{dx}{dt} \\neq 0 $$ Arc Length of a Parametric Curve #\r普通的Arc Length公式为\\(\\int^b_a\\sqrt{1+[f\u0026rsquo;(x)]^2}dx\\) 将Parametric Curve的Derivative带入，得到 $$\\int^b_a\\sqrt{1+(\\frac{dy/dt}{dx/dt})^2}dx=\\int^b_a\\sqrt{\\frac{(dx/dt)^2+(dy/dt)^2}{(dx/dt)^2}}\\frac{dx}{dt}dt$$ 也就是 $$=\\int^b_a\\sqrt{(\\frac{dx}{dt})^2+(\\frac{dy}{dt})^2}dt=\\int^b_a\\sqrt{[f\u0026rsquo;(x)]^2+[g\u0026rsquo;(t)]^2}dt$$ 10.3 Polar Coordinates 极坐标\nPolar Coordinates，一个新的坐标系，通过Radius和于Polar Axis的Directed Angle来表示点在坐标系中的位置 Converting Points between Coordinate Systems #\r想要把Cartesian Coordinates转换为Polar Coordinates，只需要找到\\(r=\\sqrt{x^2+y^2}\\) 和 \\(\\tan^{-1}\\frac{y}{x}\\)便可 而Polar 到 Cartesian的转换则是通过公式\\(x=r\\cos\\theta , y=r\\sin\\theta\\)得到 10.4 Area and Arc Length in Polar Coordinates #\rSlope of Polar Curve #\r对于Polar Coodinates来说，其Derivative可以通过一个简单的Chain Rule得到 $$\\frac{dy}{dx} = \\frac{\\frac{dy}{d\\theta}}{\\frac{dx}{d\\theta}} = \\frac{f(\\theta) \\cos \\theta + f\u0026rsquo;(\\theta) \\sin \\theta}{-f(\\theta) \\sin \\theta + f\u0026rsquo;(\\theta) \\cos \\theta}$$ Areas of Regions Bounded by Polar Curves #\r在之前都是采用多边形来近似面积，而在Polar Region中，采用了扇形的来近似 $$A = \\lim_{n \\to \\infty} \\frac{1}{2} \\sum_{i=1}^{n} [f(\\theta_i)]^2 \\Delta \\theta = \\frac{1}{2} \\int_{\\alpha}^{\\beta} [f(\\theta)]^2 d\\theta$$\n","date":"Jan 8 2025","externalUrl":null,"permalink":"/docs/calculus/calculus10.parametricequationsandpolarcoordinates/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/8/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e10.1 Parametric Equations \r\n    \u003cdiv id=\"101-parametric-equations\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#101-parametric-equations\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eIf x and y are continuous functions of t on an interval I, then the equations are called parametric equations and t is called the parameter\n$$x=x(t) andy=y(t)$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eEliminating the Parameter 化简 \r\n    \u003cdiv id=\"eliminating-the-parameter-%E5%8C%96%E7%AE%80\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#eliminating-the-parameter-%E5%8C%96%E7%AE%80\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e通过关系式直接得到x和y之间的函数\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eex. \r\n    \u003cdiv id=\"ex\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cp\u003e$$x(t) = t^2 - 3, \\quad y(t) = 2t + 1, \\quad -2 \\leq t \\leq 3.$$\u003c/p\u003e","title":"Calculus 10. Parametric Equations and Polar Coordinates","type":"docs"},{"content":" Last Edit: 1/8/25\n1.2 Binary representation in memory #\rBinary to Decimal Number 二进制转十进制 #\rBinary到Decimal Number的转换通过位数和值相乘得到 Decimal Number to Binary 十进制转二进制 #\rDecimal Number通过除法的余数得到二进制 Number of Bits to represent x #\r需要n个二进制位数来表达一个\\(2^n\\)的Decimal Number 要表示 256 个数字，我们需要 8 位。要表示 512 个数字，我们需要 9 位。要表示 1024 个数字，我们需要 10 位 Memory organized way 内存管理方式 #\rMemory通过Cells的方式管理，每一个Cell储存了一个byte 字节 而每一个Cell包换他的Address 地址，这使得Mmory Byte 内存字节是Byte-Addressable的 当采用32个Bits来表达Cell的Address的时候，我们可以储存\\(2^{32}\\)个Bytes 字节 A byte is a group of 8 bits. A kilobyte (KB) is 1024 bytes. A megabyte (MB) is 1024 kilobytes. A gigabyte (GB) is 1024 megabytes. A terabyte (TB) is 1024 gigabytes. \\(2^{32}\\) Bytes也就是4个Gigabytes 现代计算机是64-bits的，也就是说它们的Memory Length可以达到\\(2^{64}\\)位 Hexadecimal \u0026amp; Binary 十六进制和二进制 #\r已知Hexadecimal和Binary的对应表为 0 = 0000, 1 = 0001, 2 = 0010, 3 = 0011, 4 = 0100, 5 = 0101, 6 = 0110, 7 = 0111, 8 = 1000, 9 = 1001, A = 1010, B = 1011, C = 1100, D = 1101, E = 1110, F = 1111 一个Hexadecimal \\(c_1c_2\\)的本质为\\(16^1c_1+16^0c_2\\) 举例来说一个Hexadecimal \\(3A\\)的Decimal Number就是\\(316^1+A16^0=316+101=58\\) 更简单的Hexadecimal直接转换到Binary Number的办法就是拼接 3 转换为 0011 A 转换为 1010 将它们拼接：3A = 0011 + 1010 = 00111010 1.4 Write Simple C Programs 编写简单的 C 程序 #\r// This program prints the message \u0026#34;Hello World!\u0026#34; on the screen. ##include \u0026lt;stdio.h\u0026gt; int main(void){ printf(\u0026#34;Hello World!\\n\u0026#34;); return 0; } #include \u0026lt;stdio.h\u0026gt;允许访问与输入（如键盘）和输出（如监视器）设备接口的功能。这些函数包括 和 。printf``scanf main 是 C 程序的入口点。所有 C 程序都需要 main 函数 在执行程序时调用。它返回一个整数值。该值表示程序执行成功。任何其他值都表示程序失败 printf 是将字符串打印到屏幕的函数 \\ is called an escape character 转义字符 ，\\n is a special character that indicates a new line Input 输入 #\r##include \u0026lt;stdio.h\u0026gt; int main(void){ int numPizzas, numSlices; printf(\u0026#34;How many pizzas do you have?\\n\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;numPizzas); numSlices = numPizzas * 8; printf(\u0026#34;You have %d slices in %d pizza.\\n\u0026#34;, numSlices, numPizzas); return 0; } int numPizzas, numSlices;声明两个类型的变量int is a data type that represents integers scanf(\u0026quot;%d\u0026quot;, \u0026amp;numPizzas);将获取用户输入并将其分配给 variable \u0026amp; Address-of Operator（取地址符） 是为了将变量的地址传递给 scanf pass-by-value 按值传递 #\r在 C 语言中，函数的参数传递默认是按值传递（pass-by-value）。这意味着：\n当你调用一个函数时，传递的实际上是变量值的副本，而不是变量本身。 因此，如果不通过地址传递，函数无法直接修改原始变量的值。 Escape Sequences 转义序列 #\r转义字符是由反斜杠 \\ 开头的一组特殊字符，用于表示一些特殊含义。 \\n 表示换行。 \\t 表示制表符。 \\\\ 表示反斜杠本身。 \\\u0026quot; 表示双引号。 ","date":"Jan 8 2025","externalUrl":null,"permalink":"/docs/learning-programming-with-c/lpc1.introtoprogrammingcomputers/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/8/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e1.2 Binary representation in memory \r\n    \u003cdiv id=\"12-binary-representation-in-memory\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#12-binary-representation-in-memory\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eBinary to Decimal Number 二进制转十进制 \r\n    \u003cdiv id=\"binary-to-decimal-number-%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%BD%AC%E5%8D%81%E8%BF%9B%E5%88%B6\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#binary-to-decimal-number-%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%BD%AC%E5%8D%81%E8%BF%9B%E5%88%B6\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003eBinary到Decimal Number的转换通过位数和值相乘得到\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/learning-programming-with-c/lpc1.introtoprogrammingcomputers/LPC1.IntrotoProgrammingComputers_hu4440032987239514809.png 330w,\r\n        /docs/learning-programming-with-c/lpc1.introtoprogrammingcomputers/LPC1.IntrotoProgrammingComputers_hu15081779412421026257.png 660w,\r\n        /docs/learning-programming-with-c/lpc1.introtoprogrammingcomputers/LPC1.IntrotoProgrammingComputers_hu17787250618502931940.png 1024w,\r\n        /docs/learning-programming-with-c/lpc1.introtoprogrammingcomputers/LPC1.IntrotoProgrammingComputers_hu12766134372818378964.png 2x\"\r\n        src=\"/docs/learning-programming-with-c/lpc1.introtoprogrammingcomputers/LPC1.IntrotoProgrammingComputers_hu15081779412421026257.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"LPC 1. Intro to Programming Computers","type":"docs"},{"content":" Last Edit: 12/21/24\nLayer 层 #\r对于一个Layer来说，其接受一组输入（通常是矢量化的），通过调整参数后生成相应的输出 对于一个Softmax回归，其模型本身就是一个Layer Block 块 #\r在神经网络中，Block是一种通用的抽象概念，用来描述网络中的组件，可以是一个简单的单层，也可以是由多层组成的模块，甚至是整个模型本身 块的主要目的是对神经网络的结构进行分层抽象，方便构建和复用复杂的网络 MLP #\r一个MLP就可以组建成一个简单的Block，通过如下方式 import torch from torch import nn from torch.nn import functional as F net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10)) X = torch.rand(2, 20) net(X) 5.1.1 Custom block 自定义块 #\r其具体的实现方式是通过一个Python中的Class定义的 class MLP(nn.Module): # 用模型参数声明层。这里，我们声明两个全连接的层 def __init__(self): super().__init__() # 调用nn.Module的构造函数减少重新定义的代码 self.hidden = nn.Linear(20, 256) # 隐藏层 self.out = nn.Linear(256, 10) # 输出层 # 定义前向传播流程 def forward(self, X): #hidden -\u0026gt; relu -\u0026gt; out return self.out(F.relu(self.hidden(X))) 5.1.2 Sequence Block 顺序块 #\r简单定义一个Sequential类，实现 按顺序执行Block 一个前向传播函数 class MySequential(nn.Module): def __init__(self, *args): super().__init__() for idx, module in enumerate(args): self._modules[str(idx)] = module def forward(self, X): for block in self._modules.values(): X = block(X) return X for idx, module in enumerate(args) : 遍历所有传入的模块，并为每个模块分配一个从 0 开始的索引 比如传入了三个模块 MySequential( nn.Linear(10, 20), nn.ReLU(), nn.Linear(20, 10)) 那么 enumerate(args) 会依次返回 (0, nn.Linear(10, 20)), (1, nn.ReLU()), (2, nn.Linear(20, 10)) self._modules[str(idx)] = module self._modules 是 PyTorch 提供的一个内置容器（OrderedDict），用来存储子模块。 self._modules[str(idx)] = module 的作用是： X 先传入 _modules[\u0026quot;0\u0026quot;]（即 nn.Linear(10, 20)）中进行计算。 输出传入 _modules[\u0026quot;1\u0026quot;]（即 nn.ReLU()）中激活。 最后传入 _modules[\u0026quot;2\u0026quot;]（即 nn.Linear(20, 5)），得到最终结果。 str(idx)： Dict的Key要求使用可哈希值，所以需要转换为str 5.1.3 Control Flow in forward propagation #\r在网络中，可以加入一些不被更新的参数，即Constant Parameter，这一个参数不会在优化过程中被更新 class FixedHiddenMLP(nn.Module): def __init__(self): super().__init__() self.rand_weight = torch.rand((20, 20), requires_grad=False) self.linear = nn.Linear(20, 20) def forward(self, X): X = self.linear(X) X = F.relu(torch.mm(X, self.rand_weight) + 1) X = self.linear(X) while X.abs().sum() \u0026gt; 1: X /= 2 return X.sum() self.rand_weight = torch.rand((20, 20), requires_grad=False) requires_grad=False 指定该张量不会参与梯度计算，因此它是一个固定的权重，在训练过程中不会被优化。 它可以被视为一个网络中的“常量” ","date":"Dec 21 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.1layerblock/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 12/21/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eLayer 层 \r\n    \u003cdiv id=\"layer-%E5%B1%82\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#layer-%E5%B1%82\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于一个Layer来说，其接受一组输入（通常是矢量化的），通过调整参数后生成相应的输出\u003c/li\u003e\n\u003cli\u003e对于一个Softmax回归，其模型本身就是一个Layer\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eBlock 块 \r\n    \u003cdiv id=\"block-%E5%9D%97\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#block-%E5%9D%97\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e在神经网络中，Block是一种通用的抽象概念，用来描述网络中的组件，可以是一个简单的单层，也可以是由多层组成的模块，甚至是整个模型本身\u003c/li\u003e\n\u003cli\u003e块的主要目的是对神经网络的结构进行分层抽象，方便构建和复用复杂的网络\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.1layerblock/D2L5.1Layer\u0026amp;Block_hu399865873791596830.png 330w,\r\n        /docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.1layerblock/D2L5.1Layer\u0026amp;Block_hu13772976285383848655.png 660w,\r\n        /docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.1layerblock/D2L5.1Layer\u0026amp;Block_hu17735818070818276903.png 1024w,\r\n        /docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.1layerblock/D2L5.1Layer\u0026amp;Block_hu13633986511892309580.png 2x\"\r\n        src=\"/docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.1layerblock/D2L5.1Layer\u0026amp;Block_hu13772976285383848655.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"D2 5.1 Layer \u0026 Block","type":"docs"},{"content":" Last Edit: 12/20/24\n“如果微妙的边界条件很重要，我们很可能是在研究数学而非工程”\nPerceptron 感知机 #\r一种单层神经网络模型，用于Binary Classification $$o = \\sigma\\left(\\langle w, x \\rangle + b\\right)~~~~ \\sigma(x) = \\begin{cases} 1 \u0026amp; \\text{if } x \u0026gt; 0 \\ -1 \u0026amp; \\text{otherwise} \\end{cases}$$ Binary Classification 二分类问题 #\r两个可能的值的问题，例如「正类」（1）和「负类」（0） Training 训练 #\rinitialize w = 0 and b = 0\rrepeat\rfor each (xi, yi) in the training data:\rif yi * (⟨w, xi⟩ + b) ≤ 0 then\rw ← w + yi * xi\rb ← b + yi\rend if\rend for\runtil all points are classified correctly initialize w = 0 and b = 0：初始化weight和bias if yi * (⟨w, xi⟩ + b) ≤ 0：如果分类与预测不符 在Perceptron中并没有明确的Optimize Method，但可以隐式定义一个仅与分类错误的点有关的数据的损失，也就是上面小于零情况下的 $$L(w, b) = -\\sum_{x_i \\in M} y_i (w \\cdot x_i + b)$$ 由于\\(y_i (w \\cdot x_i + b)\\)本身是负的，取负之后，这部分损失就变成了正 这意味着误分类样本对损失的贡献是增加的，因为我们希望最小化正的损失值 而对于weight和bias分别的Gradient为 $$\\nabla_w L(w, b) = -\\sum_{x_i \\in M} y_i x_i$$ $$\\nabla_b L(w, b) = -\\sum_{x_i \\in M} y_i$$ 对应了伪代码中的w ← w + yi * xi 与 b ← b + yi 完整代码如下 import numpy as np w = np.zeros(2) b = 0.0 n_epoch = 11 X = np.array([ [0.5, 1.5], [1.0, 1.0], [1.5, 0.5], [2.0, 1.0], [2.5, 1.5], [3.0, 3.0], [3.5, 3.5], [4.0, 4.5], [4.5, 5.0], [5.0, 5.5]]) y = np.array([-1, -1, -1, -1, -1, 1, 1, 1, 1, 1]) for epoch in range(n_epochs): for i in range(len(X)): if y[i] * (np.dot(w, X[i]) + b) \u0026lt;= 0: w += y[i] * X[i] b += y[i] else: continue def predict(X, w, b): return np.sign(np.dot(X, w) + b) predictions = predict(X, w, b) print(\u0026#34;Predictions:\u0026#34;, predictions) print(\u0026#34;Actual labels:\u0026#34;, y) \u0026gt; Predictions: [-1. -1. -1. -1. -1. 1. 1. 1. 1. 1.] \u0026gt; Actual labels: [-1 -1 -1 -1 -1 1 1 1 1 1] XOR Problem #\rXOR（异或）逻辑门是一个二输入逻辑门，其输出只在两个输入不同时为1（即当输入是(0,1)或(1,0)时）。其逻辑如下：\n0 XOR 0 = 0\n0 XOR 1 = 1\n1 XOR 0 = 1\n1 XOR 1 = 0\n线性模型，如感知机，是基于线性方程的，它试图找到一个权重向量和偏差，以便通过一个超平面来分割数据点。\n对于 XOR 问题，无论如何调整线性模型的参数，都无法得到一个能够将这四个点分开的单一直线\n为了解决XOR问题，我们可以使用非线性模型。最常见的方法是使用神经网络，尤其是多层感知机（MLP）。通过添加一个或多个隐藏层，神经网络能够学习非线性函数\n单调假设与线性模型的局限性 #\r单调假设：在一个线性模型中，特征与输出之间的关系是单调的 线性模型的局限：虽然线性模型简单且易于理解，但很多现实世界的关系是非线性的 Hidden Layer 隐藏层 #\r我们可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制 对于线性网络来说，每一层都是线性的Affine transformation 仿射变换 $$H = XW^{(1)} + b^{(1)}, O = HW^{(2)} + b^{(2)}$$\n这样即使构造了多层的模型，其实际上还是只等于一个Affine Transformation $$O = (XW^{(1)} + b^{(1)})W^{(2)} + b^{(2)} = XW^{(1)}W^{(2)} + b^{(1)}W^{(2)} + b^{(2)} = XW + b$$\n而为了发挥多层框架的潜力，就需要在Affine Transformation后应用一个Non-Linear的Activation Function激活Output\n一般来说在Activation之后便不能将其退化为Linear Model $$H = \\sigma(XW^{(1)} + b^{(1)}), O = HW^{(2)} + b^{(2)}$$\n为了构建更通用的多层感知机， 我们可以继续堆叠这样的隐藏层， 一层叠一层，从而产生更有表达能力的模型\nActivation Function 激活函数 #\rActivation function 通过计算加权和并加上偏置来确定神经元是否应该被激活， 它们将输入信号转换为输出的可微运算。 大多数激活函数都是非线性的 通过加入了更“DEEP”的层数，MLP理论可以拟合任意连续函数 Weierstrass Approximation Theorem #\r在知道了Weierstrass Approximation Theorem后，也就是证明该 $$B_n(x) = \\sum_{i=0}^n f\\left(\\frac{i}{n}\\right) \\binom{n}{i} x^i (1-x)^{n-i}$$ Bernstein Polynomial，\\(B_n(f, x)\\)在区间\\([0, 1]\\)上以任意精度逼近\\(f(x)\\) 通过说明MLP如何通过从Activation Function构造Polynomial，最终证明MLP如何实现函数的理论任意精度逼近 Activation Function that has Tyler Series #\rWeierstrass Approximation Theorem指出，任意定义在闭区间 \\([a, b]\\)上的连续函数\\(f\\)都可以被多项式函数以任意精度逼近。即，对于任意\\(\\varepsilon \u0026gt; 0\\)，存在一个多项式\\(P(x)\\)，使得 $$|f(x) - P(x)| \u0026lt; \\varepsilon \\quad \\forall x \\in [a, b]$$ 为了证明单隐层神经网络能够逼近任意多项式，我们考虑如下多项式： $$P(x) = \\sum_{k=0}^n a_k x^k$$ 其中\\(a_k\\)是多项式系数，n是多项式的次数。 目标是要构造一个单隐层神经网络\\(F(x) = \\sum_{j=1}^m \\alpha_j \\sigma(w_j x + b_j)\\)，使得\\(F(x)\\)能够逼近\\(P(x)\\)以任意精度 选择合适的非线性激活函数是关键。假设\\(\\sigma\\)在某个区间内具有泰勒展开： $$\\sigma(z) = \\sum_{k=0}^\\infty c_k z^k$$ 其中\\(c_k\\)是泰勒级数的系数。典型的激活函数如 sigmoid、tanh 等都满足在某个区间内可展开为幂级数 $$\\sigma(x) = \\frac{1}{2} + \\frac{x}{4} - \\frac{x^3}{48} + \\frac{x^5}{480} + \\cdots$$ $$\\tanh(x) = x - \\frac{x^3}{3} + \\frac{2x^5}{15} - \\frac{17x^7}{315} + \\cdots$$ 由于\\(P(x)\\)是多项式，我们需要构造网络的输出\\(F(x)\\)来逼近\\(P(x)\\)具体步骤如下： 对于每个高阶项\\(x^k\\)，利用激活函数的非线性性质，通过组合多个隐藏单元来逼近。具体来说，可以通过调整\\(w_j\\)和\\(b_j\\)，使得多个\\(\\sigma(w_j x + b_j)\\)的组合能够近似\\(x^k\\) 一个二次多项式的例子便是 $$F(x) = \\underbrace{\\sigma(b_1) \\cdot \\alpha_1}_{\\text{常数项}} + \\underbrace{\\sigma(w_2x + b_2) \\cdot \\alpha_2}_{\\text{线性项}} + \\underbrace{\\sigma(w_{3,1}x + b_{3,1}) \\cdot \\alpha_{3,1} + \\sigma(w_{3,2}x + b_{3,2}) \\cdot \\alpha_{3,2}}_{\\text{二次项}}$$\r由于多项式是各阶项的线性组合，单隐层网络通过线性组合隐藏层的输出即可实现对多项式的逼近 $$F(x) = \\sum_{j=1}^m \\alpha_j \\sigma(w_j x + b_j) \\approx \\sum_{k=0}^n a_k x^k = P(x)$$ 上述证明假设激活函数\\(\\sigma\\)能够通过适当组合逼近多项式项。某些激活函数（如ReLU）虽然非多项式，但由于其分段线性性质，也具备强大的逼近能力。 Activation Function that doesn\u0026rsquo;t have Tyler Series #\r首先要说明的就是上面所提到的那句话，\u0026ldquo;如果微妙的边界条件很重要，我们很可能是在研究数学而非工程.\u0026rdquo; ReLU函数定义为： $$\\sigma(z) = \\max(0, z)$$ $$\\sigma(z) = \\begin{cases} 0, \u0026amp; z \\leq 0 \\ z, \u0026amp; z \u0026gt; 0 \\end{cases}$$ 分段线性函数能够在不同的区间内表现出不同的线性特征 这种特性允许神经网络通过组合多个ReLU单元，在输入空间中划分出多个线性区域，每个区域内的网络输出都是一个线性函数 通过增加隐藏单元数，可以在输入空间中创建更多的线性区间，从而逼近复杂的非线性函数 $$F(x) = \\sum_{j=1}^m \\alpha_j \\sigma(w_j x + b_j) = \\sum_{j=1}^m \\alpha_j \\max(0, w_j x + b_j)$$ 每个隐藏单元\\(\\sigma(w_j x + b_j)\\)在\\(w_j x + b_j = 0\\)处产生一个“折点”，即输入\\(x = -\\frac{b_j}{w_j}\\)处 通过调整不同单元的权重\\(w_j\\)和偏置\\(b_j\\)，可以在输入空间中创建多个折点，将输入空间划分为多个线性区间。 5分钟理解激活函数让神经网络能拟合任何函数 - 知乎\n","date":"Dec 20 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.1multilayerperceptron/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 12/20/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e“如果微妙的边界条件很重要，我们很可能是在研究数学而非工程”\u003c/p\u003e","title":"D2L 4.1 Multilayer Perceptron","type":"docs"},{"content":" Last Edit: 12/20/24\n使用纯MLP参加https://www.kaggle.com/competitions/titanic的Competition\n# This Python 3 environment comes with many helpful analytics libraries installed # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python # For example, here\u0026#39;s several helpful packages to load import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) # Input data files are available in the read-only \u0026#34;../input/\u0026#34; directory # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory import os for dirname, _, filenames in os.walk(\u0026#39;/kaggle/input/d/heptapod/titanic/train_and_test2.csv\u0026#39;): for filename in filenames: print(os.path.join(dirname, filename)) # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \u0026#34;Save \u0026amp; Run All\u0026#34; # You can also write temporary files to /kaggle/temp/, but they won\u0026#39;t be saved outside of the current session train_path = \u0026#39;/kaggle/input/titanic/train.csv\u0026#39; test_path = \u0026#39;/kaggle/input/titanic/test.csv\u0026#39; train_data = pd.read_csv(train_path) test_data = pd.read_csv(test_path) data = pd.concat([train_data, test_data], sort=False).reset_index(drop=True) display(data) # 填补Age的缺失值 data[\u0026#39;Age\u0026#39;].fillna(data[\u0026#39;Age\u0026#39;].median(), inplace=True) # 填补Fare的缺失值 data[\u0026#39;Fare\u0026#39;].fillna(data[\u0026#39;Fare\u0026#39;].median(), inplace=True) display(data[\u0026#39;Fare\u0026#39;]) data = data[[\u0026#39;Survived\u0026#39;,\u0026#39;Pclass\u0026#39;,\u0026#39;Sex\u0026#39;,\u0026#39;Age\u0026#39;,\u0026#39;SibSp\u0026#39;,\u0026#39;Parch\u0026#39;,\u0026#39;Fare\u0026#39;]] data[\u0026#39;Sex\u0026#39;] = data[\u0026#39;Sex\u0026#39;].map({\u0026#39;male\u0026#39;: 0, \u0026#39;female\u0026#39;: 1}) print(data) train_data = data.iloc[:891].copy() test_data = data.iloc[891:].copy() X_train = train_data.drop(\u0026#39;Survived\u0026#39;, axis=1) y_train = train_data[\u0026#39;Survived\u0026#39;].astype(int) X_test = test_data.drop(\u0026#39;Survived\u0026#39;, axis=1).copy() print(X_test) from sklearn.neural_network import MLPClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score, classification_report # 将训练集分为训练子集和验证子集 X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42) # 初始化MLPClassifier mlp = MLPClassifier(hidden_layer_sizes=(100,), # 一个隐藏层，100个神经元 activation=\u0026#39;relu\u0026#39;, # 激活函数为ReLU solver=\u0026#39;adam\u0026#39;, # 优化器为Adam max_iter=1000, # 最大迭代次数 random_state=42) # 训练模型 mlp.fit(X_tr, y_tr) # 在验证集上进行预测 y_pred = mlp.predict(X_val) # 计算准确率 accuracy = accuracy_score(y_val, y_pred) print(f\u0026#34;\\n验证集准确率：{accuracy:.4f}\u0026#34;) # 查看分类报告 print(\u0026#34;\\n分类报告：\u0026#34;) print(classification_report(y_val, y_pred)) y_test = mlp.predict(X_test) result = mlp.predict(X_test) X_test[\u0026#39;Survived\u0026#39;] = result passenger_ids = np.arange(891, 1309) X_test[\u0026#39;Passengerid\u0026#39;] = passenger_ids X_test = X_test[\u0026#39;Survived\u0026#39;] print(X_test) X_test.to_csv(\u0026#39;submission.csv\u0026#39;, index=False) print(\u0026#34;提交文件 \u0026#39;submission.csv\u0026#39; 已生成。\u0026#34;) ","date":"Dec 20 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.2exampleofmlp/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 12/20/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e使用纯MLP参加https://www.kaggle.com/competitions/titanic的Competition\u003c/p\u003e","title":"D2L 4.2 Example of MLP","type":"docs"},{"content":" Last Edit: 12/19/24\nWeierstrass Approximation Theorem #\r每一个定义在闭区间\\([a,b]\\)上的实值连续函数都可以被多项式序列在整个区间上一致逼近。 换句话说，给定任意的连续函数\\(f: [a, b] \\to \\mathbb{R}\\)和任意小的正数\\(\\epsilon\\)，都存在一个多项式\\(P(x)\\)，使得对所有\\(x \\in [a, b]\\)都有\\(|f(x) - P(x)| \u0026lt; \\epsilon\\) Bernstein\u0026rsquo;s Proof 1912 #\r采用离散的Convolution $$f(x)\\approx\\sum^n_{i=0}f(x_i)w(x_i)$$ 其满足\\(\\sum_i(x_i)=1\\)，离\\(x\\)越近的地方\\(w(x_i)\\)越大 Binomial Distribution 二项分布 #\r一种离散概率分布，用于模型在固定次数的独立试验中每次试验成功的次数 其质量概率函数为 $$P(X=k) = \\binom{n}{k} p^k (1-p)^{n-k}$$ p：单次独立事件的成功概率 k：实验中事件成功的次数 n：实验的总事件的数量 Interpretation #\r这样理解，先不管\\(\\binom{n}{k}\\)，假设一个成功率为\\(60%\\)的事件，其总共实验次数为5次，也就是\\(p=0.6,n=5\\) 现在当\\(k=5\\)的时候，Binomial Distribution表示的概率为\\(0.6^5\\)，也就是说对于一个概率为0.6的事件，其独立测试五次后都成功的概率为\\(0.6^5\\)，这就是最简单的概率 当\\(k=3\\)时，概率质量函数为 $$\\binom{5}{3} 0.6^3 (1-0.6)^{5-3}$$ 也就是说，5次实验，每一个5次实验中3次成功的概率为\\(0.6^3 (1-0.6)^{5-3}\\) 而在5次实验中这些成功的和失败的实验都可能出现在不同的位置，而这些中的成功的事件的位置可以是 $$123,124,125,134,135,145,234,235,245,345$$ 这10种情况，也就是出现5次中3次的会有10中情况，所以乘以10 Bernstein Polynomial 伯恩斯坦多项式 #\r$$B_n(x) = \\sum_{i=0}^n f\\left(\\frac{i}{n}\\right) \\binom{n}{i} x^i (1-x)^{n-i}$$\n用加权平均的方式（基于二项分布）生成新的多项式\\(B_n(x)\\)，作为\\(f(x)\\)的近似，实际上就是一个离散的Convolution Similarity to Convolution #\r$$(f * g)(x) = \\sum_{k} f(k) g(x-k)$$\n可以发现两者的区别就在于Bernstein Poly的Weight是基于Binomial Distribution的 并且采样点不再是连续的输入而是离散且固定的值 Expectation #\r$$B_n(x) = \\mathbb{E}\\left[f\\left(\\frac{X}{n}\\right)\\right]$$\n最终可以得到Bernstein Polynomial的期望值在\\(n\\rightarrow \\infty\\)的情况下是就是\\(f(x)\\) 也就是说可以通过一致收敛性，说明\\(B_n(f, x)\\)在区间\\([0, 1]\\)上以任意精度逼近\\(f(x)\\) ","date":"Dec 19 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter4multilayerperceptron/weierstrassapproximation/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 12/19/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eWeierstrass Approximation Theorem \r\n    \u003cdiv id=\"weierstrass-approximation-theorem\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#weierstrass-approximation-theorem\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e每一个定义在闭区间\\([a,b]\\)上的实值连续函数都可以被多项式序列在整个区间上一致逼近。\u003c/li\u003e\n\u003cli\u003e换句话说，给定任意的连续函数\\(f: [a, b] \\to \\mathbb{R}\\)和任意小的正数\\(\\epsilon\\)，都存在一个多项式\\(P(x)\\)，使得对所有\\(x \\in [a, b]\\)都有\\(|f(x) - P(x)| \u0026lt; \\epsilon\\)\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eBernstein\u0026rsquo;s Proof 1912 \r\n    \u003cdiv id=\"bernsteins-proof-1912\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#bernsteins-proof-1912\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e采用离散的Convolution\n$$f(x)\\approx\\sum^n_{i=0}f(x_i)w(x_i)$$\u003c/li\u003e\n\u003cli\u003e其满足\\(\\sum_i(x_i)=1\\)，离\\(x\\)越近的地方\\(w(x_i)\\)越大\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eBinomial Distribution 二项分布 \r\n    \u003cdiv id=\"binomial-distribution-%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#binomial-distribution-%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e一种离散概率分布，用于模型在固定次数的独立试验中每次试验成功的次数\u003c/li\u003e\n\u003cli\u003e其质量概率函数为\n$$P(X=k) = \\binom{n}{k} p^k (1-p)^{n-k}$$\u003c/li\u003e\n\u003cli\u003ep：单次独立事件的成功概率\u003c/li\u003e\n\u003cli\u003ek：实验中事件成功的次数\u003c/li\u003e\n\u003cli\u003en：实验的总事件的数量\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eInterpretation \r\n    \u003cdiv id=\"interpretation\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#interpretation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e这样理解，先不管\\(\\binom{n}{k}\\)，假设一个成功率为\\(60%\\)的事件，其总共实验次数为5次，也就是\\(p=0.6,n=5\\)\u003c/li\u003e\n\u003cli\u003e现在当\\(k=5\\)的时候，Binomial Distribution表示的概率为\\(0.6^5\\)，也就是说对于一个概率为0.6的事件，其独立测试五次后都成功的概率为\\(0.6^5\\)，这就是最简单的概率\u003c/li\u003e\n\u003cli\u003e当\\(k=3\\)时，概率质量函数为\n$$\\binom{5}{3} 0.6^3 (1-0.6)^{5-3}$$\u003c/li\u003e\n\u003cli\u003e也就是说，5次实验，每一个5次实验中3次成功的概率为\\(0.6^3 (1-0.6)^{5-3}\\)\u003c/li\u003e\n\u003cli\u003e而在5次实验中这些成功的和失败的实验都可能出现在不同的位置，而这些中的成功的事件的位置可以是\n$$123,124,125,134,135,145,234,235,245,345$$\u003c/li\u003e\n\u003cli\u003e这10种情况，也就是出现5次中3次的会有10中情况，所以乘以10\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eBernstein Polynomial 伯恩斯坦多项式 \r\n    \u003cdiv id=\"bernstein-polynomial-%E4%BC%AF%E6%81%A9%E6%96%AF%E5%9D%A6%E5%A4%9A%E9%A1%B9%E5%BC%8F\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#bernstein-polynomial-%E4%BC%AF%E6%81%A9%E6%96%AF%E5%9D%A6%E5%A4%9A%E9%A1%B9%E5%BC%8F\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003e$$B_n(x) = \\sum_{i=0}^n f\\left(\\frac{i}{n}\\right) \\binom{n}{i} x^i (1-x)^{n-i}$$\u003c/p\u003e","title":"D2L Weierstrass Approximation Theorem","type":"docs"},{"content":" Last Edit: 12/15/24\nReal Number 实数 #\rRational Number 有理数 #\r整数，有限位小数，无限循环小数，分数 只要是能被表达为 $$\\frac{p}{q},p,q\\in \\mathbb z,q\\neq 0$$ 的数都叫做Rational Number 也就是说可以被任意两个Nature Number通过加减乘除所得到的数都被称为Rational Number（做除法的时候分母不能为零） Irrational Number 无理数 #\rPythagoras Theorem 毕达哥拉斯定理 #\r在一个直角三角形中，直角边对面的斜边（最长边）的平方等于两个直角边的平方和 Contradiction #\r在当时并没有Irrational Number的定义，但是表示一个两个直角边长度为一的直角三角形的斜边的时候却出现了问题，即\\(1^2+1^2=x^2\\)，无法通过一个Rational Number，也就是两个Nature Number的任意四则运算求出这个x Proof that sqrt 2 isn\u0026rsquo;t Rational Number #\rProof By Contradiction 假设\\(\\sqrt 2\\)是一个Rational Number，则有\\(2=(\\frac{p}{q})^2\\)，其中p和q是互素的 即\\(p^2=2q^2\\)，已知\\(2q^2\\)为一个Even Number，则等号另一边的\\(p\\)也必为一个Even Number（Odd Number的平方为Odd Number） 既然p是一个Even Number，则他可以被2整除，即\\(p^2\\)可以被4整除，同理可以得到\\(2|q^2\\) 那既然p和q都是偶数，很明显他们不可能互素，Contradict，故假设不成立 于是证明了Irrational Number的存在 Define Real Number #\r首先要知道的是，根号的本质是一个服务幂而创造出的代数运算，其能表达出的Irrational Number的个数几乎可以忽略不计 所以定义实数的第一步就是构造出所有Irrational Number，第二步则是定义全序列关系，第三步为定义代数运算，第四步研究拓扑结构（稠密性） Dedekind Cut #\r设数集的一个划分\\({\\alpha,\\beta }\\)，其中\n\\(\\alpha,\\beta\\neq \\emptyset\\)，即两个划分必须为有元素\n向下封闭：\\(\\forall x,y\\in k, x\u0026lt;y,y\\in \\alpha \\Rightarrow x\\in \\alpha\\)\n\\(\\alpha\\)中无最大元素：\\(\\forall x\\in \\alpha,\\exists y\\in \\alpha~ st.~y\u0026gt;x\\)\n满足以上条件的Cut则称为k上的一个Dedekind Cut，记做\\(\\alpha|\\beta\\) ，其中\\(\\alpha,\\beta\\)分别称为Dedekind Cut的Lower Set和Upper Set\n每一个Dedekind Cut都确定了一个Real Number，其为一个存在无限过程的集合，具体来说有对于一个Set，其无最大元素的定义便是一个无限的过程，所以即使Dedekind Cut的Lower Set是一个集合，其实际上表示的是一个Real Number\n再次对于上面的\\(x^2=2\\)做分析，假设其正根为\\(x_0\\)，令 $$\\alpha = {a \\in \\mathbb{Q} : a \u0026lt; x_0}~~~~~ \\beta = {a \\in \\mathbb{Q} : a \u0026gt; x_0}$$ ![[MA2.RealNumber.png]]\n则集合\\(\\alpha\\)便就是一个表达\\(\\sqrt2\\)的方法\nReal Number Set Definition #\r有理数集\\(\\mathbb Q\\)上的所有Dedekind Cut的Lower Set的Set称为Set of Real Numbers，记做\\(\\mathbb R\\) 其中的每一个Dedekind Cut的Lower Set表示一个Real Number Sequence Relationship #\r定义了Real Number后，需要将他们排列，具体来说需要将由Dedekind Cut所确定的Lower Sets做排列，有 $$\\alpha_1\\leq\\alpha_2=\\alpha1\\subseteq\\alpha _2$$ 但是左边是一个全序集，而右边是偏序集 证明右边是全序集可以通过向下封闭的性质，即 $$\\forall \\alpha_1\\leq \\alpha_2~\\exists\\forall x\\in\\alpha_1\\Rightarrow x \\in\\alpha_2$$ 则可以证明出Real Number Set\\(\\mathbb R\\)是一个全序集 Summation #\r通过两个Dedekind Cut相加定义出一个新的Dedekind Cut $$\\alpha+\\beta={a+b,a\\in\\alpha,b\\in\\beta}$$ 现在需要证明这个定义Well-defined Proof #\r只需证明\\(\\alpha + \\beta\\)是一个 Dedekind Cut的Lower Set，也就是证明其1.向下封闭，2.没有最大元素 (i) 显然\\(\\alpha + \\beta \\neq \\emptyset\\)。任取\\(c \\in (\\alpha + \\beta)\\)，令\\(c = a + b\\)，其中\\(a \\in \\alpha, b \\in \\beta\\)。若\\(c\u0026rsquo; \u0026lt; c\\)，则存在\\(d \u0026gt; 0\\)满足\\(c\u0026rsquo; = c - d = (a + b) - d = (a - d) + b\\)，由于\\(a - d \u0026lt; a\\)，故\\(a - d \\in \\alpha\\)。这表明\\(c\u0026rsquo; \\in (\\alpha + \\beta)\\)，于是可知\\(\\alpha + \\beta\\)向下封闭 (ii) 由于\\(\\alpha\\)和\\(\\beta\\)中都没有最大元素，因此一定存在\\(a\u0026rsquo; \\in \\alpha, b\u0026rsquo; \\in \\beta\\)满足\\(a\u0026rsquo; \u0026gt; a, b\u0026rsquo; \u0026gt; b\\)，于是\\((a\u0026rsquo; + b\u0026rsquo;) \\in (\\alpha + \\beta)\\)且\\(a\u0026rsquo; + b\u0026rsquo; \u0026gt; a + b\\)，于是可知\\(\\alpha + \\beta\\)中也没有最大元素。 综上可述\\(\\alpha+\\beta\\in \\mathbb R\\) Law of Operation #\r加法结合律 #\r对任意的\\(\\alpha, \\beta, \\gamma \\in \\mathbb{R}\\)，有\\((\\alpha + \\beta) + \\gamma = \\alpha + (\\beta + \\gamma)\\) 加法交换律 #\r对任意的\\(\\alpha, \\beta \\in \\mathbb{R}\\)，有\\(\\alpha + \\beta = \\beta + \\alpha\\) 加法零元 #\r对于任意的\\(\\alpha \\in \\mathbb{R}\\)，存在一个零元\\(0^\\)使得\\(\\alpha + 0^ = 0^* + \\alpha = \\alpha\\) 加法负元 #\r对于任意的\\(\\alpha \\in \\mathbb{R}\\)，存在一个负元\\(\\beta\\)使得\\(\\alpha + \\beta = \\beta + \\alpha = 0^*\\) Completeness of Real Number Field 实数域的完备性 #\rDense 稠密 #\r设S是一个集合，X是一个包含S的更大的空间。我们说S在X中稠密，如果对于X中任意的点x，在x的任意小的邻域中，总能找到至少一个属于S的点 $$\\forall x \\in X, \\forall \\epsilon \u0026gt; 0, \\exists s \\in S \\ \\text{st.} \\ |s - x| \u0026lt; \\epsilon$$\nReal Number Field\u0026rsquo;s Density 实数域的稠密性 #\r对于任意𝛼,𝛽∈R,若𝛼\u0026lt; 𝛽,则一定存在𝛾∈R满足\\(\\alpha \u0026lt; \\gamma \u0026lt;\\beta\\) Proof #\r令𝛾=(𝛼+𝛽)/2.由于𝛼 \u0026lt; 𝛽,故 $$2𝛼 \u0026lt; 𝛼+𝛽 \u0026lt;2𝛽 ⇐⇒ 𝛼\u0026lt; \\frac{𝛼+𝛽} {2} \u0026lt;𝛽 ⇐⇒ 𝛼\u0026lt;𝛾\u0026lt;\\beta$$ Dedekind Theorem In Rational Number Field 有理数的戴德金分割 #\r有理数域\\(\\mathbb Q\\)上的Dedekind Cut可能会出现Upper Set中无最小元素的情况.这说明有理数域存在空隙\nex. sqrt{2} 在 Q中的分割 #\r考虑实数\\(\\sqrt{2}\\)（它是无理数，不属于\\(\\mathbb{Q}\\)），我们定义：\n\\(A = { q \\in \\mathbb{Q} \\mid q^2 \u0026lt; 2 }\\) （所有小于\\(\\sqrt{2}\\) 的有理数） \\(B = { q \\in \\mathbb{Q} \\mid q^2 \u0026gt; 2 }\\) （所有大于\\(\\sqrt{2}\\) 的有理数） 可以验证：\n\\(A \\cup B = \\mathbb{Q}\\)且\\(A \\cap B = \\emptyset\\) \\(a \u0026lt; b\\) 对于任意\\(a \\in A, b \\in B\\) 但是Upper Set B中不存在最小元素，因为对于任意\\(b \\in B\\)，都可以找到一个更小的\\(b\u0026rsquo; \\in B\\)\n这说明在\\(\\mathbb{Q}\\)中，\\(\\sqrt{2}\\)这样的点无法被有理数表示，导致了“空隙”的存在。\nDedekind Theorem in Real Number Field 实数的戴德金分割 #\r对于实数域R上的任一Dedekind Cut \\(𝐴| 𝐵\\), Upper Set 𝐵中都有最小元素 Proof #\r简单来说，给定实数域上的一个Dedekind Cut(A|B)。\n若A有最大元，则这个最大元即属于B，因此B有最小元。 若A无最大元，则A中可找出一列有理数向上递增逼近分割点。若该分割点存在于A中，则逼近过程能产生一个最大元与分割矛盾；若分割点不在A中，就会落在B中，从而成为B的最小元。 总而言之，无论A是否有最大元，B中总能找到一个最小元\nThe limit principle 界 #\rDedekind Cut 𝐴 | 𝐵 中, Lower Set 𝐴的任一元素都小于𝐵中任一元素，从直观上看, 𝐴是有‘‘上界的”,而𝐵是有‘‘下界的”.\nBounded 有界的 #\r设非空集合𝐸⊆R.若存在𝑀\u0026gt;0使得|𝑥|\u0026lt;𝑀 (∀𝑥∈𝐸),则称𝐸是有界的(bounded) Supremum 上确界 #\r集合E的一个数M被称为其上确界（supremum），如果满足以下两个条件\nM是E的上界 Upper bound： $$\\forall x \\in E, \\quad x \\leq M$$ M是所有上界中的最小值，也就是上确界 Supremum： 对于任意\\(\\varepsilon \u0026gt; 0\\)，都存在\\(x_\\varepsilon \\in E\\)，使得\\(M - \\varepsilon \u0026lt; x_\\varepsilon \\leq M\\) Infimum 下确界 #\r集合E的一个数m被称为其下确界（infimum），如果满足以下两个条件：\nm是E的下界（lower bound）： $$\\forall x \\in E, \\quad m \\leq x$$ m是所有下界中的最大值： 对于任意\\(\\varepsilon \u0026gt; 0\\)，都存在\\(x_\\varepsilon \\in E\\)，使得\\(m\\leq x_\\varepsilon \u0026lt; m + \\varepsilon\\) Existence of Supremum \u0026amp; Infimum 上，下确界的存在性 #\r对于一个实数集的子集\\(E\\subseteq\\mathbb R\\)，其根据Real Number的 Completeness一定存在确界 ex. Supremum \u0026amp; Infimum #\r$$E ={ \\frac{1}{n} : n \\in \\mathbb{N}^* }$$\n对于E来说，\\(supE=1,infE=0\\) Least-upper-bound property, LUB 最小上界性 #\r定义：如果一个非空的实数集合S在实数集中有上界，那么S必定在实数集中有最小的上界（简称为确界）\nDedekind Theorem和确界原理是等价的 Heine-Borel Theorem #\r有限闭区间的任一开覆盖都存在一个有限子覆盖 Open Cover 开覆盖 #\r设Set \\(E\\subseteq \\mathbb R\\)和一族开区间\\({I_\\lambda:\\lambda\\in \\Lambda }\\)，\\(\\Lambda\\)是一个指标集，若 $$E \\subseteq \\bigcup_{\\lambda \\in \\Lambda} I_\\lambda.$$ 则\\({I_\\lambda:\\lambda\\in \\Lambda }\\)是E的一个Open Cover，也就是一个开区间的集合的并集能够覆盖满整个集合E，记作\\(C_E\\) 若E有一个Open Cover \\(C_E\u0026rsquo;\\subseteq C_E\\)，则称\\(C_E\u0026rsquo;\\)为\\(C_E\\)的Subcover 子覆盖 过这个Cover里只有有限个Open Set，则称他为Finite Subcover 有限子覆盖 Set\u0026rsquo;s Cardinality 集合的基数 #\rCardinality 基数 #\r对于一个Finite Set A来说，他的基数是一个可以数出来的数字，即可以在\\(\\mathbb Z\\)中找到一个数表示他的Cardinality，计作cardA或是\\(|A|\\) 我们约定\\(card \\emptyset =0\\) 同时也可以发现两个Card相同的Set之间一定存在一个Bijective 对于一个Infinite Set，即使无法直接数出他的Card，但可以通过Bijective的角度刻画 Equivalency of Set 集合的对等 #\r设集合A，B若存在一个A到B的双射 , 则称A与B对等 (equivalent), 记作A ∼ B Finite Set 有限集 #\r设集合A. 若A= ∅ , 或存在\\(n∈ N^∗\\), 使得集合 \\({ 1 , 2 , · · · , n}\\) ∼ A , 则称集合A为有限集 (finite set) Finite Set的任一Subset仍是一个Finite Set Equivalency of Integer Set and Nature Number Set 整数集和自然数集的对等 #\r考虑以下问题，自然数集和整数集的Cardinality是否相等？ 从直觉上看\\(\\mathbb N \\subset \\mathbb Z\\)，看似自然数的总数比整数少，但并非如此 前面说明了，如果两个Set之间可以建立一个Bijective的关系，则说明两个Set是Equivalent的，现在把Integer Set的所有元素排成一列 $$0,1,-1,2,-2,3,-3,\\cdots$$ 通过以下函数建立\\(f:\\mathbb N\\rightarrow \\mathbb Z\\) $$f(n) = \\begin{cases} -\\frac{n}{2}, \u0026amp; \\text{n is Even} \\ \\frac{n+1}{2}, \u0026amp; \\text{n is Odd} \\end{cases}$$ 可以发现 $$n = 1 \\to 0,n = 2 \\to -n,n = 3 \\to 1,n = 4 \\to -2,n = 5 \\to 2,n = 6 \\to -3 $$ 于是可知\\(\\mathbb N\\) ~ \\(\\mathbb Z\\) Countable Set 可数集 #\r设Infinite Set A，若\\(A\\) ~ \\(\\mathbb N\\)，集存在一个A到N的Bijective Relationship，则称A为Countable 可数的，这样的Set也被称为Countable Set Countable Set的Cardinality称为Countable Cardinality 可数基数，记做\\(\\aleph_0\\) Aleph 阿列夫\nRational Number Set is a Countable Set #\r同理只要将Rational Number通过\\(\\frac{p}{q}\\)那样排成一排然后和\\(\\mathbb N\\)建立Bijective Relationship就行 $$ \\left[ \\begin{array}{cccc} \\frac{1}{1} \u0026amp; \\frac{1}{2} \u0026amp; \\frac{1}{3} \u0026amp; \\cdots \\ \\frac{2}{1} \u0026amp; \\frac{2}{2} \u0026amp; \\frac{2}{3} \u0026amp; \\cdots \\ \\frac{3}{1} \u0026amp; \\frac{3}{2} \u0026amp; \\frac{3}{3} \u0026amp; \\cdots \\ \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \\end{array} \\right] $$ 具体排列方式不限，但可以知道Rational Number Set的Cardinality也同为\\(\\aleph_0\\) Uncountable Set 不可数集 #\r下面给出一个不可数集的例子，其实既然知道了有理数集是Infinite Countable Set，那Uncountable Set很明显就是Irrational Number或者的Subset了 ex. Interval \\([0,1)\\) is Uncountable Set #\r假设区间\\([0,1)\\)中的所有实数是可数的，那么我们可以将这些实数按序列排列如下： $$x_1, x_2, x_3, \\ldots$$\n每一个Real Number \\(x_i\\)都可以表示为小数形式 $$\\begin{align} x_1 = 0.a_{11}a_{12}a_{13}a_{14} \\cdots \\ x_2 = 0.a_{21}a_{22}a_{23}a_{24} \\cdots \\ x_3 = 0.a_{31}a_{32}a_{33}a_{34} \\cdots \\ \\vdots \\end{align} $$ 假设前三个实数 $$ \\begin{array}{c|cccc} \u0026amp; \\text{第1位} \u0026amp; \\text{第2位} \u0026amp; \\text{第3位} \u0026amp; \\text{第4位} \\ \\hline x_1 \u0026amp; 3 \u0026amp; 1 \u0026amp; 4 \u0026amp; 1 \\ x_2 \u0026amp; 5 \u0026amp; 9 \u0026amp; 2 \u0026amp; 6 \\ x_3 \u0026amp; 5 \u0026amp; 3 \u0026amp; 5 \u0026amp; 8 \\ \\end{array} $$ 康托尔的对角线论证法要求我们构造一个新的实数y，其小数部分的每一位都与列表中第i个数\\(x_i\\)的第i位不同，通过这样的构造，y与列表中的每个数\\(x_i\\)至少在第i位上不同，也就是说前面的假设：我们可以将实数按序列排列成一个序列不成立，因为永远存在一个y不在列表中 这证明了\\([0,1)\\)的实数集合是不可数的 这种证明方法也叫做Cantor的Diagonal Process Real Number Set is Uncountable 实数集是不可数集 #\r通过一个Bijective Relationship $$f(x)=-cot(\\pi x)$$ 其Domain为\\((0,1)\\)，Range为\\(\\mathbb R\\)，即f为\\((0,1)和\\mathbb R\\)的一个Bijective Relationship 因此\\((0,1)\\) ~ \\(\\mathbb R\\) 已知\\((0,1)\\)是一个Uncountable Set，即证\\(\\mathbb R\\)也是Uncountable的 Continuum 连续统 #\r和Real Number Set等势的Set称为continuum 连续统 Continuum的Cardinality为\\(\\aleph_1\\) Continuum hypothesis 连续统假设 #\r1874 年 Cantor 提出猜想 : 不存在基数介于\\(ℵ_0\\)和\\(ℵ_1\\)的集合 . 这就是著名的连续统假设 ","date":"Dec 15 2024","externalUrl":null,"permalink":"/docs/mathematicalanalysis/ma2.realnumber/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 12/15/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eReal Number 实数 \r\n    \u003cdiv id=\"real-number-%E5%AE%9E%E6%95%B0\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#real-number-%E5%AE%9E%E6%95%B0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eRational Number 有理数 \r\n    \u003cdiv id=\"rational-number-%E6%9C%89%E7%90%86%E6%95%B0\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#rational-number-%E6%9C%89%E7%90%86%E6%95%B0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e整数，有限位小数，无限循环小数，分数\u003c/li\u003e\n\u003cli\u003e只要是能被表达为\n$$\\frac{p}{q},p,q\\in \\mathbb z,q\\neq 0$$\u003c/li\u003e\n\u003cli\u003e的数都叫做Rational Number\u003c/li\u003e\n\u003cli\u003e也就是说可以被任意两个Nature Number通过加减乘除所得到的数都被称为Rational Number（做除法的时候分母不能为零）\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eIrrational Number 无理数 \r\n    \u003cdiv id=\"irrational-number-%E6%97%A0%E7%90%86%E6%95%B0\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#irrational-number-%E6%97%A0%E7%90%86%E6%95%B0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\r\n\r\n\u003ch4 class=\"relative group\"\u003ePythagoras Theorem 毕达哥拉斯定理 \r\n    \u003cdiv id=\"pythagoras-theorem-%E6%AF%95%E8%BE%BE%E5%93%A5%E6%8B%89%E6%96%AF%E5%AE%9A%E7%90%86\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#pythagoras-theorem-%E6%AF%95%E8%BE%BE%E5%93%A5%E6%8B%89%E6%96%AF%E5%AE%9A%E7%90%86\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e在一个直角三角形中，直角边对面的斜边（最长边）的平方等于两个直角边的平方和\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eContradiction \r\n    \u003cdiv id=\"contradiction\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#contradiction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e在当时并没有Irrational Number的定义，但是表示一个两个直角边长度为一的直角三角形的斜边的时候却出现了问题，即\\(1^2+1^2=x^2\\)，无法通过一个Rational Number，也就是两个Nature Number的任意四则运算求出这个x\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eProof that sqrt 2 isn\u0026rsquo;t Rational Number \r\n    \u003cdiv id=\"proof-that-sqrt-2-isnt-rational-number\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#proof-that-sqrt-2-isnt-rational-number\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003eProof By Contradiction\u003c/li\u003e\n\u003cli\u003e假设\\(\\sqrt 2\\)是一个Rational Number，则有\\(2=(\\frac{p}{q})^2\\)，其中p和q是互素的\u003c/li\u003e\n\u003cli\u003e即\\(p^2=2q^2\\)，已知\\(2q^2\\)为一个Even Number，则等号另一边的\\(p\\)也必为一个Even Number（Odd Number的平方为Odd Number）\u003c/li\u003e\n\u003cli\u003e既然p是一个Even Number，则他可以被2整除，即\\(p^2\\)可以被4整除，同理可以得到\\(2|q^2\\)\u003c/li\u003e\n\u003cli\u003e那既然p和q都是偶数，很明显他们不可能互素，Contradict，故假设不成立\u003c/li\u003e\n\u003cli\u003e于是证明了Irrational Number的存在\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eDefine Real Number \r\n    \u003cdiv id=\"define-real-number\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#define-real-number\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e首先要知道的是，根号的本质是一个服务幂而创造出的代数运算，其能表达出的Irrational Number的个数几乎可以忽略不计\u003c/li\u003e\n\u003cli\u003e所以定义实数的第一步就是构造出所有Irrational Number，第二步则是定义全序列关系，第三步为定义代数运算，第四步研究拓扑结构（稠密性）\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eDedekind Cut \r\n    \u003cdiv id=\"dedekind-cut\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#dedekind-cut\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e设数集的一个划分\\({\\alpha,\\beta }\\)，其中\u003c/p\u003e","title":"MA 2. RealNumber","type":"docs"},{"content":"","date":"Nov 25 2024","externalUrl":null,"permalink":"/tags/chemistry/","section":"Tags","summary":"","title":"Chemistry","type":"tags"},{"content":"","date":"Nov 25 2024","externalUrl":null,"permalink":"/series/ecms/","section":"Series","summary":"","title":"ECMS","type":"series"},{"content":"","date":"Nov 25 2024","externalUrl":null,"permalink":"/tags/ecms/","section":"Tags","summary":"","title":"ECMS","type":"tags"},{"content":" Last Edit: 11/25/24\nThe finger of time #\r在上一章中讨论了Solide Crystalline Nacl的形成，我们知道它在室温和压力下是稳定的 同理当我们看到手机从人手上掉下来并不会感到惊讶 通过The Second Law Of Thermodynamics，我们可以意识到时间的流逝 The Second Law of Thermodynamics 热力学第二定律 #\rThe entropy of the Universe increases during any spontaneous process Spontaneous 自发的 #\rSpontaneous, here, means that the process proceeds on its own, without the need for an input of energy 代表了该过程自行进行，不需要能量输入 例如在空气中点燃一张纸，他将会燃烧，我面对如此现象并不会感到惊讶 Entropy 熵 #\r前面反复的介绍的Second Law的重要性，而Entropy的存在将定义如何使用它 熵是一个衡量系统混乱程度的物理量，系统的熵越高，系统的无序程度就越高 $$\\Delta S = \\frac{q_{REV}}{T}$$ S is the entropy 熵 \\(q_{rev}\\)​ is the heat transferred 传递的热量 T is the thermodynamic temperature 热力学温度，单位为Kelvin The Thermodynamic Alphabet 热力学字母表 #\rReversibility 可逆性 #\r对于rev的下标，这代表了Heat is transferred reversibly 但实际上Reversibility仅存在于Concept中，因为真实的物理过程总会有一些不可逆的因素，如摩擦，热损失等 System Surroundings and the Universe #\r周围的一切都被叫做Surroundings 而System和Surrounding一起构成了Universe 带回到The Second law of thermodynamic中，有 $$\\Delta S_{universe} = \\Delta S_{system} + \\Delta S_{surroundings} \u0026gt; 0$$ 所以唯一的判断Spontaneous的要求即为当Entropy change for universe must be positive The First Law of Thermodynamics 热力学第一定律 #\r在一个孤立系统中，能量既不能被创造也不能被消灭，能量只能从一种形式转换为另一种形式，或者从一个物体传递到另一个物体 $$ΔU=q+w$$ Internal Energy 内能 #\rInternal Energy是一个System的总能量，包括所有可能的能量形式，如动能、势能、化学能等 在听到内能的时候，可能会联想到Fuel, battery or a Quantity of Nuclear Fuel，但他们都不是完全的 对于一个System其中存在着无数种能影响内能的能量形式，这也使得研究System的Internal Energy的Absolute Value变得难以测定以至于不具有实际意义 所以所研究的Internal Energy更多的是一种Change of Energy 而Change，是建立在所谓的控制变量法 Potential Energy - Water Bottle #\r考虑上面的水平，要计算它的Internal Energy，我们会本能的选择一个Obvious Reference Surface从而计算瓶子相对于该平面的Potential Energy 同时，我们不需要考虑其动能或者是燃烧瓶子所释放的能量 这强调了在特定问题中选择关注特定类型能量的重要性 Similarly, in thermodynamics we\u0026rsquo;ll need to define a logical reference point to measure changes in energy Logical Reference Point - The Standard State #\r在热力学和化学中，需要一个清晰、一致的基准来测量能量变化。比如，当讨论燃烧汽油（主要成分为辛烷）所需的能量时，我们需要一个基准状态作为起点 这段话在讨论热力学和化学中如何选择一个参考点，称为“Standard State”，来测量和比较化学反应和能量变化 标准状态是在特定条件下（通常是25°C和105帕斯卡压力），一种纯元素的最稳定形式 State Functions and Path Functions 状态和路径函数 #\r再次考虑前面水瓶的例子 $$Water Bottle_{on table} → Water Bottle_{on high shelf}$$ State Function 状态函数 #\rIt does not depend on how we got to the final state, all that matters is what that state is 它不取决于我们如何达到最终状态，重要的是那个状态是什么 另一个例子为Temperature，你不需要查阅过去的温度来计算现在的，只需要测量当前温度便可以， 这就是一种State Function 庆幸的是Internal Energy只能是一种State Function，这意味着内能的变化仅取决于系统的初始状态和最终状态。无论系统是通过何种过程从初始状态转变到最终状态，内能的变化总量是固定的 Path Function 路径函数 #\r如果问题变成了，把水瓶从桌子上移到高架子上有多困难 做的工作取决 how you got there - it depends on the path Closed Versus Isolated Systems 封闭系统与孤立系统 #\r我们可以研究Boundaries开放且物质穿过它们的系统，但这不是我们现在需要考虑的 我们需要考虑systems where matter is not allowed to pass the boundaries的系统 Isolated System 隔离式系统 #\rNo heat is exchanged with the surroundings $$ΔU=q+w,q=w=0\\RightarrowΔU=0$$ Closed system 封闭系统 #\rHeat may pass the boundaries $$ΔU=q+w$$ - q is the heat transferring into the system w is the work done on the system Sign convention在这里很重要，heat in and work on are positive Enthalpy 焓 #\r焓（Enthalpy），符号为H，是热力学中的一个重要概念，用于描述系统在一定压力下的总热含量 焓是一个状态函数，它与系统的内能、压力和体积关系密切。焓的定义是 $$H=U+PV$$ 其中U是内能，P是压力，V是体积 Enthalpy in Solid 固体中的焓 #\r在固态物理过程中，物质的体积变化通常非常小，因此PV工作相对于内能U的变化可以忽略不计 所以在在固态物理领域，人们可能会将“Enthalpy”或“Enthalpy Change”与“Energy”或“Energy Change”这些术语互换使用 The Gibbs Energy 吉布斯自由能 #\r$$G=H−TS$$\nG：吉布斯能量 H：焓（系统的总能量，包括内能和体积功） T：温度（开尔文，K） S：熵（系统的无序程度） 这个定义说明吉布斯自由能考虑了系统的能量状态（Enthalpy）和无序度（Entropy） Spontaneity for a system 系统的自发性 #\r如果\\(\\Delta G \u0026lt; 0\\)：过程是自发的（有利于发生）。 如果\\(\\Delta G = 0\\)：系统达到平衡。 如果\\(\\Delta G \u0026gt; 0\\)：过程是非自发的（需要外界能量输入） 自发过程的基本条件是整个宇宙的熵（包括系统和环境的熵）总和需要增加，这是在前面的The Second Law of Thermodynamics中定义的 $$\\Delta S_{\\text{system}} + \\Delta S_{\\text{surroundings}} \u0026gt; 0$$ 在恒温下，周围环境的熵变是进入周围环境的热量除以温度 $$\\Delta S_{\\text{Surroundings}} = \\frac{q_{\\text{Surroundings}}}{T}$$ 离开系统的任何热量都与周围环境吸收的热量相同，或者相反，因此有 $$\\Delta S_{\\text{Surrounding}} = \\frac{-q_{\\text{System}}}{T}$$ 于是就可以推出Spontaneous的同时由Entropy和Enthalpy定义的公式变为 $$\\Delta H_{\\text{system}}-T \\Delta S_{\\text{system}} \u0026lt; 0$$ Phase Transformations #\r图中为对不同阶段的水加热后的变化 固态（冰）升温：在冰的温度低于 0°C 时，输入热量会使冰的温度上升。 熔化（0°C 平台）：温度停止上升，因为输入的热量用于冰的相变（熔化），这个热量叫做熔化焓（enthalpy of fusion）。 液态（水）升温：冰完全融化后，输入热量使液态水的温度上升，此时温度上升速率（曲线的斜率）与冰时不同。 汽化（100°C 平台）：在 100°C 时，热量再次用于相变（汽化），这一阶段输入的热量叫做汽化焓（enthalpy of vaporization）。 气态（蒸汽）升温：水完全汽化后，输入热量让蒸汽升温 在图中的斜率定义为 $$\\text{Slope} = \\frac{\\Delta T}{q} , \\left[ = \\frac{K}{\\frac{J}{\\text{mol}}} \\right] $$ $$q = \\frac{1}{\\text{Slope}} \\Delta T$$ \\(\\frac{1}{\\text{Slope}}\\)其还有一个名字叫做Molar Heat Capacity \\(C_P\\)，也就是Specific Heat Capacity比热容 Molar Hear Capacity 摩尔热容 #\r$$q = \\frac{1}{\\text{Slope}} \\Delta T = n C_P \\Delta T$$\nq：热量 n：物质的摩尔数 \\(C_P\\)​：摩尔热容 \\(\\Delta T\\)：温度变化 Specific Heat Capacity 比热容 #\r$$q=mcΔT$$\nm：物质质量 c：比热容 ","date":"Nov 25 2024","externalUrl":null,"permalink":"/docs/engineering-chemistry--materials-science/ecms8.thermodynamics/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/25/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eThe finger of time \r\n    \u003cdiv id=\"the-finger-of-time\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#the-finger-of-time\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e在上一章中讨论了Solide Crystalline Nacl的形成，我们知道它在室温和压力下是稳定的\u003c/li\u003e\n\u003cli\u003e同理当我们看到手机从人手上掉下来并不会感到惊讶\u003c/li\u003e\n\u003cli\u003e通过The Second Law Of Thermodynamics，我们可以意识到时间的流逝\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eThe Second Law of Thermodynamics 热力学第二定律 \r\n    \u003cdiv id=\"the-second-law-of-thermodynamics-%E7%83%AD%E5%8A%9B%E5%AD%A6%E7%AC%AC%E4%BA%8C%E5%AE%9A%E5%BE%8B\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#the-second-law-of-thermodynamics-%E7%83%AD%E5%8A%9B%E5%AD%A6%E7%AC%AC%E4%BA%8C%E5%AE%9A%E5%BE%8B\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eThe entropy of the Universe increases during any spontaneous process\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eSpontaneous 自发的 \r\n    \u003cdiv id=\"spontaneous-%E8%87%AA%E5%8F%91%E7%9A%84\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#spontaneous-%E8%87%AA%E5%8F%91%E7%9A%84\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eSpontaneous\u003c/em\u003e, here, means that the process proceeds on its own, without the need for an input of energy 代表了该过程自行进行，不需要能量输入\u003c/li\u003e\n\u003cli\u003e例如在空气中点燃一张纸，他将会燃烧，我面对如此现象并不会感到惊讶\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eEntropy 熵 \r\n    \u003cdiv id=\"entropy-%E7%86%B5\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#entropy-%E7%86%B5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e前面反复的介绍的Second Law的重要性，而Entropy的存在将定义如何使用它\u003c/li\u003e\n\u003cli\u003e熵是一个衡量系统混乱程度的物理量，系统的熵越高，系统的无序程度就越高\n$$\\Delta S = \\frac{q_{REV}}{T}$$\u003c/li\u003e\n\u003cli\u003eS is the entropy 熵\u003c/li\u003e\n\u003cli\u003e\\(q_{rev}\\)​ is the heat transferred 传递的热量\u003c/li\u003e\n\u003cli\u003eT is the \u003cem\u003ethermodynamic\u003c/em\u003e temperature 热力学温度，单位为Kelvin\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eThe Thermodynamic Alphabet 热力学字母表 \r\n    \u003cdiv id=\"the-thermodynamic-alphabet-%E7%83%AD%E5%8A%9B%E5%AD%A6%E5%AD%97%E6%AF%8D%E8%A1%A8\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#the-thermodynamic-alphabet-%E7%83%AD%E5%8A%9B%E5%AD%A6%E5%AD%97%E6%AF%8D%E8%A1%A8\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS8.Thermodynamics/ECMS8.Thermodynamics.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"ECMS 8. Thermodynamics","type":"docs"},{"content":"","date":"Nov 25 2024","externalUrl":null,"permalink":"/tags/la/","section":"Tags","summary":"","title":"LA","type":"tags"},{"content":" Last Edit: 11/25/24\nEigenvectors and Eigenvalues #\r考虑Linear Transformation为一种Function，输入x而输出\\(Ax\\) Eigenvector即对于指定的Vector x，其Ax平行于x，有 $$Ax=\\lambda x$$ 其中x为A的Eigenvector，\\(\\lambda\\)为A的Eigenvalue 特征向量的定义要求\\(x \\neq 0\\) Zero Eigenvalue #\r如果0为Matrix的Eigenvalue，则有 $$Ax=0x=0$$ Eigenvalue 0所对应的Vector Span出了Matrix的Null Space 如果矩阵A为不可逆矩阵，则0是其特征值之一 ex. Projection Matrix #\r对于Projection Matrix P，其Column Space中的任意Vector都会是一个Eigenvector ![[LA8.DiagonalizationandEigenvalues.png]]\n因为当其投影到Subspace的时候并没有改变 因此x为Eigenvector，并且Eigenvalue为1 同时对于Orthogonal于Subspace的Vector，有\\(Px=0\\)，则这个x也是Eigenvector，其Eigenvalue为0 ex. Permutation Matrix #\r$$A = \\begin{bmatrix} 0 \u0026 1 \\\\ 1 \u0026 0 \\end{bmatrix}$$\r对于置换矩阵存在Eigenvector \\(x=[1,1]^T\\)，Eigenvalue为1 另一个Eigenvalue为\\(x=[-1,1]^T\\)，对应Eigenvalue为-1，\\(Ax=-x\\) Trace 迹 #\r\\(n\\times n\\) 的Matrix存在n个Eigenvalue 并且它们的和，即为Trace，等于矩阵对角线上的元素之和 对于二阶矩阵，在已知一个特征值的条件下， 可以据此得到另一个特征值 Solve Ax = lambdax #\r对于\\(Ax=\\lambda x\\)存在两个未知数，下面讨论求解的办法 Rewrite等式为\\((A-\\lambda I)x=0\\) 如果系数矩阵\\(A - \\lambda I\\)是非奇异矩阵（行列式不为零），那么方程组只有Trivial Solution \\(x=0\\) 而如果系数矩阵\\(A - \\lambda I\\)是奇异矩阵（行列式为零），那么方程组可能有非零解\\(x \\neq 0\\) 于是可以推出\\(det(A-\\lambda I)=0\\) 在这个没有x的“特征方程”中，可以解得n个特征值，但是有可能方程有Repeated Root，则会得到重复的Eigenvalue 得到特征值之后，用消元法解\\(A-\\lambda I\\)，这一矩阵零空间中的向量为矩阵 A的特征向量 ex. #\r对于Matirx $$A= \\begin{bmatrix}3 \u0026 1 \\\\1 \u0026 3\\end{bmatrix}$$\r$$\\det (A-\\lambda I) = \\begin{vmatrix} 3-\\lambda \u0026 1 \\\\ 1 \u0026 3-\\lambda \\end{vmatrix} = (3-\\lambda)^2 - 1 = \\lambda^2 - 6\\lambda + 8$$\r在一元二次方程中，6为Trace，8为Determinant 于是可以总结对于二阶矩阵的Eigenvalue为该方程的解 $$\\lambda^2 - \\text{trace}(A) \\lambda + \\det A = 0$$\r对于上面的Matrix则有Eigenvalue = 4 \u0026amp; 2 $$A-4I = \\begin{bmatrix} -1 \u0026 1 \\\\ 1 \u0026 -1 \\end{bmatrix}, \\quad (A-4I)x_1 = 0, \\quad x_1 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$$\r$$A-2I = \\begin{bmatrix} 1 \u0026 1 \\\\ 1 \u0026 1 \\end{bmatrix}, \\quad (A-2I)x_2 = 0, \\quad x_2 = \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}$$\r与前面的例子\\(A=\\begin{bmatrix} 0 \u0026amp; 1 \\ 1 \u0026amp; 0 \\end{bmatrix}\\)的特征值和特征向量相对比，可知两者为一组平移矩阵 在对角元素上分别加3，改变了特征值但是没有改变特征向量 $$Ax = \\lambda x, \\quad \\text{则有} (A+3I)x = \\lambda x + 3x = (\\lambda + 3)x$$\r所以当两个Matrix有相同的Eigenvectors的时候，他们是可以“相加”的 当然其中一个为Identity Matrix的情况除外 Trace Equal to Eigenvalue Summation 矩阵的迹等于特征值之和 #\r将\\(det(A-\\lambda I)=0\\)展开会得到\\(\\lambda\\)的n 阶多项式，多项式的解就是矩阵 A 的特征值 根据多项式根与系数的关系，解之和即特征值之和等于\\(\\lambda^{n-1}\\)的系数 而行列式展开式中只有对角线的积这一项包含的\\(\\lambda^{n-1}\\)（其它项最高是n-2次方），而其系数为矩阵A对角线元素之和即矩阵A的Trace，因此特征值之和与矩阵的迹相等 Symmetry Matrix\u0026rsquo;s Eigenvector Orthogonal 对称矩阵的特征向量正交 #\r\\(\\lambda_1,\\lambda_2\\)是对称矩阵的两个不同的特征值，对应的特征向量分别为x1和x2。 $$\\text{则有 } A\\mathbf{x}_1 = \\lambda_1 \\mathbf{x}_1, \\text{ 左乘 } \\mathbf{x}_2^\\top \\text{ 得 } \\mathbf{x}_2^\\top A\\mathbf{x}_1 = \\lambda_1 \\mathbf{x}_2^\\top \\mathbf{x}_1$$\r$$\\mathbf{x}_2^\\top A\\mathbf{x}_1 = (\\mathbf{A}^\\top \\mathbf{x}_2)^\\top \\mathbf{x}_1 = \\lambda_2 \\mathbf{x}_2^\\top \\mathbf{x}_1。\\\\\r\\text{因此有 } (\\lambda_1 - \\lambda_2) \\mathbf{x}_2^\\top \\mathbf{x}_1 = 0$$\r而两特征值不等，所以两特征向量正交 Complex eigenvalues 复数特征值 #\r$$Q = \\begin{bmatrix} 0 \u0026 -1 \\\\ 1 \u0026 0 \\end{bmatrix} = \\begin{bmatrix} \\cos 90^\\circ \u0026 -\\sin 90^\\circ \\\\ \\sin 90^\\circ \u0026 \\cos 90^\\circ \\end{bmatrix}$$\rQ是一个是一个90度Rotation Matrix 从矩阵的Trace和Determinant的值可以得到\\(\\lambda_1+\\lambda_2=0,\\lambda_1\\lambda_2=1\\) 仅观察Matrix可以发现他的Eigenvector只能是Zero Vector，因为其他Vector乘以Rotation Matrix，其方向将会改变而，不可逆平行于原向量，通过原来的计算可得 $$\\det (Q - \\lambda I) = \\begin{vmatrix} -\\lambda \u0026 -1 \\\\ 1 \u0026 -\\lambda \\end{vmatrix} = \\lambda^2 + 1 = 0$$\r可以解得\\(\\lambda_1=i,\\lambda_2=-i\\) 如果一个矩阵具有复数特征值a+bi则，它的共轭复数a-bi也是矩阵的特征值 实数特征值让特征向量伸缩而虚数让其旋转 Antisymmetric matrices 反对称矩阵 #\r即满足\\(A^T=-A\\)的矩阵 对称矩阵永远具有实数的特征值，而，具有纯虚数的特征值 Triangular matrices and repeated eigenvalues 三角阵和重特征值 #\r对于一个Uppertriangular Matrix $$A = \\begin{bmatrix}3 \u0026 1 \\\\0 \u0026 3\\end{bmatrix}$$\r$$\\det (A - \\lambda I) = \\begin{vmatrix} 3-\\lambda \u0026 1 \\\\ 0 \u0026 3-\\lambda \\end{vmatrix} = (3-\\lambda)(3-\\lambda) = 0\r$$\r即\\(\\lambda_1=\\lambda_2=3\\) $$(A-\\lambda I)x = \\begin{bmatrix} 0 \u0026 1 \\\\ 0 \u0026 0 \\end{bmatrix}x = 0, \\quad \\text{得到} \\quad x_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$$\r其并没有没有线性无关的x2，说明A是一个退化矩阵，对应相同的特征值，而特征向量短缺 Diagonalization 对角化 #\r如果矩阵A具有n个线性无关的特征向量，将它们作为列向量可以组成一个可逆方阵S，并且有 $$AS = A \\begin{bmatrix} \\mathbf{x}_1 \u0026 \\mathbf{x}_2 \u0026 \\cdots \u0026 \\mathbf{x}_n \\end{bmatrix} = \\begin{bmatrix} \\lambda_1 \\mathbf{x}_1 \u0026 \\lambda_2 \\mathbf{x}_2 \u0026 \\cdots \u0026 \\lambda_n \\mathbf{x}_n \\end{bmatrix} = S \\begin{bmatrix} \\lambda_1 \u0026 0 \u0026 \\cdots \u0026 0 \\\\ 0 \u0026 \\lambda_2 \u0026 \\cdots \u0026 0 \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ 0 \u0026 0 \u0026 \\cdots \u0026 \\lambda_n \\end{bmatrix} = S D$$\r根据上式可写出\\(AS=SD\\Rightarrow S^{-1}AS=D\\)，这就叫Diagonalization 同理也有\\(A=SDS^{-1}\\) Power of A 矩阵的幂 #\r特征值给矩阵的幂计算提供了方法。 $$\\text{如果 } A\\mathbf{x} = \\lambda \\mathbf{x}, \\text{ 则有 } A^2\\mathbf{x} = \\lambda A\\mathbf{x} = \\lambda^2 \\mathbf{x}。$$\r这说明了Matrix \\(A\\)与\\(A^2\\)拥有相同的Eigenvector $$A^2 = S D S^{-1} S D S^{-1} = S D^2 S^{-1}$$\r同理可以推广到k-th power的情况，有\\(A^k = S D^k S^{-1}\\) 这说明\\(A^k\\)有着和A一样的特征向量，而特征值为\\(\\lambda^k\\) 如果矩阵A具有n个线性无关的特征向量，并且特征值均满足\\(|\\lambda_i|\u0026lt;1\\)，则k→∞时，Ak→0 Repeated eigenvalues 重特征值 #\r如果矩阵A没有重特征值，则其一定具有n个线性无关的特征向量 如果矩阵A有重特征值，它有可能具有n个线性无关的特征向量，也可能没有 Identity Matrix #\r比如单位阵的特征值为重特征值1，但是其具有n个线性无关的特征向量 UpperTriangular Matrix #\r参考上面的例子 对于一个Uppertriangular Matrix $$A = \\begin{bmatrix}3 \u0026 1 \\\\0 \u0026 3\\end{bmatrix}$$\r$$\\det (A - \\lambda I) = \\begin{vmatrix} 3-\\lambda \u0026 1 \\\\ 0 \u0026 3-\\lambda \\end{vmatrix} = (3-\\lambda)(3-\\lambda) = 0$$\r即\\(\\lambda_1=\\lambda_2=3\\) $$(A-\\lambda I)x = \\begin{bmatrix} 0 \u0026 1 \\\\ 0 \u0026 0 \\end{bmatrix}x = 0, \\quad \\text{得到} \\quad x_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$$\r其存在Repeated Eigenvalue所以可能没有n个Linearly Independent的Eigenvector Difference equations 差分方程 #\r差分方程描述了离散变量之间的递推关系 简单来说，差分方程是用来研究一系列离散点上的函数值之间的关系 从给定的一个向量\\(u_0\\)出发，我们可以通过对前一项乘以矩阵A得到下一项的方式，得到一个向量序列：\\(u_{k+1}=Au_k\\) 这里的\\(u_k+1=Au_k\\)可以是一个一阶差分方程，而\\(u_k=A^ku_0\\)就是方程的解 其可以写出Eigenvector的Linear Combination $$\\mathbf{u}_0 = c_1 \\mathbf{x}_1 + c_2 \\mathbf{x}_2 + \\cdots + c_n \\mathbf{x}_n = S\\mathbf{c}$$\r$$A\\mathbf{u}_0 = c_1 \\lambda_1 \\mathbf{x}_1 + c_2 \\lambda_2 \\mathbf{x}_2 + \\cdots + c_n \\lambda_n \\mathbf{x}_n$$\r$$\\mathbf{u}_k = A^k \\mathbf{u}_0 = c_1 \\lambda_1^k \\mathbf{x}_1 + c_2 \\lambda_2^k \\mathbf{x}_2 + \\cdots + c_n \\lambda_n^k \\mathbf{x}_n = D^k S\\mathbf{c}$$\rFibonacci sequence 斐波那契数列 #\r斐波那契数列为0,1,1,2,3,4,8,13……其通项公式为\\(F_{k+2}=F_{k+1}+F_k\\) 令 $$\\mathbf{u}_k = \\begin{bmatrix} F_{k+2} \\\\ F_{k+1} \\end{bmatrix}$$\r$$F_{k+2} = F_{k+1} + F_k, \\quad F_{k+1} = F_{k+1} \\\\ \\text{写成矩阵形式为 } \\mathbf{u}_{k+1} = \\begin{bmatrix} 1 \u0026 1 \\\\ 1 \u0026 0 \\end{bmatrix} \\mathbf{u}_k$$\r所以现在A就是\\(\\begin{bmatrix} 1 \u0026amp; 1 \\ 1 \u0026amp; 0 \\end{bmatrix}\\)，求解其Eigenvalues有 $$\\det(A - \\lambda I) = \\begin{vmatrix} 1-\\lambda \u0026 1 \\\\ 1 \u0026 -\\lambda \\end{vmatrix} = \\lambda^2 - \\lambda - 1 = 0$$\r\\(\\text{解得 } \\lambda_1 = \\frac{1 + \\sqrt{5}}{2}, \\quad \\lambda_2 = \\frac{1 - \\sqrt{5}}{2}\\)，且\\(\\mathbf{u}_k = A^k \\mathbf{u}_0 = c_1 \\lambda_1^k \\mathbf{x}_1 + c_2 \\lambda_2^k \\mathbf{x}_2\\) 由于\\(\\lambda_1\\)大于零，\\(\\lambda_2\\)小于零，则在k趋于无线的时候，\\(\\lambda_2^k\\)趋于零 从特征值可以求得对应的特征向量\\(\\mathbf{x}_1 = \\begin{bmatrix} \\lambda_1 \\ 1 \\end{bmatrix} \\text{ 的和 } \\mathbf{x}_2 = \\begin{bmatrix} \\lambda_2 \\ 1 \\end{bmatrix}\\) 在因为是二阶方程，而且矩阵\\(A - \\lambda I\\)是奇异矩阵，所以只要符合其中一个方程即可，立刻可以看出\\(\\begin{bmatrix} \\lambda_1 \\ 1 \\end{bmatrix}\\)是解\n$$\\text{从 } \\mathbf{u}_0 = \\begin{bmatrix} F_1 \\\\ F_0 \\end{bmatrix} = c_1 \\mathbf{x}_1 + c_2 \\mathbf{x}_2, \\text{ 可以求得 } c_1 = -c_2 = \\frac{1}{\\sqrt{5}}$$$$\r\\begin{bmatrix} F_{100} \\\\ F_{99} \\end{bmatrix} = A^{99} \\begin{bmatrix} F_1 \\\\ F_0 \\end{bmatrix} = \\begin{bmatrix} \\lambda_1 \u0026 \\lambda_2 \\\\ 1 \u0026 1 \\end{bmatrix} \\begin{bmatrix} \\lambda_1^{99} \u0026 0 \\\\ 0 \u0026 \\lambda_2^{99} \\end{bmatrix} \\begin{bmatrix} c_1 \\\\ c_2 \\end{bmatrix} =\r\\begin{bmatrix} c_1 \\lambda_1^{100} + c_2 \\lambda_2^{100} \\\\ c_1 \\lambda_1^{99} + c_2 \\lambda_2^{99} \\end{bmatrix}. \\\\\r\\text{可知 } F_{100} \\approx c_1 \\lambda_1^{100}.\r$$\r","date":"Nov 25 2024","externalUrl":null,"permalink":"/docs/linearalgebra/la8.diagonalizationandeigenvalues/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/25/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eEigenvectors and Eigenvalues \r\n    \u003cdiv id=\"eigenvectors-and-eigenvalues\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#eigenvectors-and-eigenvalues\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e考虑Linear Transformation为一种Function，输入x而输出\\(Ax\\)\u003c/li\u003e\n\u003cli\u003eEigenvector即对于指定的Vector x，其Ax平行于x，有\n$$Ax=\\lambda x$$\u003c/li\u003e\n\u003cli\u003e其中x为A的Eigenvector，\\(\\lambda\\)为A的Eigenvalue\u003c/li\u003e\n\u003cli\u003e特征向量的定义要求\\(x \\neq 0\\)\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eZero Eigenvalue \r\n    \u003cdiv id=\"zero-eigenvalue\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#zero-eigenvalue\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e如果0为Matrix的Eigenvalue，则有\n$$Ax=0x=0$$\u003c/li\u003e\n\u003cli\u003eEigenvalue 0所对应的Vector Span出了Matrix的Null Space\u003c/li\u003e\n\u003cli\u003e如果矩阵A为不可逆矩阵，则0是其特征值之一\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eex. Projection Matrix \r\n    \u003cdiv id=\"ex-projection-matrix\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex-projection-matrix\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于Projection Matrix P，其Column Space中的任意Vector都会是一个Eigenvector\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e![[LA8.DiagonalizationandEigenvalues.png]]\u003c/p\u003e","title":"LA 8. Diagonalization and Eigenvalues","type":"docs"},{"content":"","date":"Nov 25 2024","externalUrl":null,"permalink":"/docs/linearalgebra/","section":"Docs","summary":"","title":"Linear Algebra","type":"docs"},{"content":" Last Edit 11/21/2024\n正交向量Orthogonal vectors #\r正交就是垂直（perpendicular）的另一种说法 两向量正交的判据之一是其点 积\\(x^Ty=y^Tx\\)=0 当两个向量的夹角为90度时，按照勾股定理（毕达哥拉斯定理 Pythagorean theorem）x，y满足 $$\\|\\mathbf{x}\\|^2 + \\|\\mathbf{y}\\|^2 = \\|\\mathbf{x} + \\mathbf{y}\\|^2 ,||\\mathbf{x}\\|^2 = \\mathbf{x}^T \\mathbf{x}$$\r零向量与所有向量都正交 Orthogonal Subspaces 正交子空间 #\r图中绘制空间成90度角，这是表示这两个空间正交 子空间S与子空间T正交，则S中的任意一个向量都和T中的任意向量正交 Nullspace is perpendicular to row space 零空间与行空间正交 #\r矩阵A的行空间和它的零空间正交。若x在零空间内，则有Ax=0 $$\\begin{bmatrix}\r\\text{row}_1 \\\\\r\\text{row}_2 \\\\\r\\vdots \\\\\r\\text{row}_m\r\\end{bmatrix} \\times \\mathbf{x} = \\begin{bmatrix}\r\\text{row}_1 \\cdot \\mathbf{x} \\\\\r\\text{row}_2 \\cdot \\mathbf{x} \\\\\r\\vdots \\\\\r\\text{row}_m \\cdot \\mathbf{x}\r\\end{bmatrix} = \\begin{bmatrix}\r0 \\\\\r0 \\\\\r\\vdots \\\\\r0\r\\end{bmatrix}\r$$\rx与矩阵A的行向量点积都等于0，则它和矩阵A行向量的线性组合进行点积也为0，所以x与A的行空间正交 同理可以证明列空间与左零空间正交 Orthogonal complements 正交补 #\r行空间和零空间不仅仅是正交，并且其维数之和等于n，我们称行空间和零空间为\\(R^n\\)空间内的正交补 Orthogonal complements Orthonormal #\r如果矩阵的列向量是互相垂直的单位向量，则它们一定是线性无关的 我们将这种向量称之为标准正交（orthonormal） $$例如\\begin{bmatrix}\r1 \\\\\r0 \\\\\r0 \\end{bmatrix}\r,\r\\begin{bmatrix}\r0 \\\\\r1\\\\\r0 \\end{bmatrix},\r\\begin{bmatrix}\r0 \\\\\r0 \\\\\r1 \\end{bmatrix}\r还有\r\\begin{bmatrix}\r\\cos \\theta \\\\\r\\sin \\theta\r\\end{bmatrix}\r,\r\\begin{bmatrix}\r\\cos \\theta \\\\\r\\sin \\theta\r\\end{bmatrix}$$\r## Orthonormal Vectors 标准正交向量\r$$q_i^T q_j = \\begin{cases} 0 \u0026 \\text{若 } i \\neq j \\\\\r1 \u0026 \\text{若 } i = j \\end{cases}$$\r指的是单位长度为1的（Unit Vector） ATA #\r下面讨论如何求解一个无解方程组Ax=b的解 它是一个\\(n\\times n\\)方阵，并且是对称阵\\((A^TA)^T=(A^TA)\\) 本章的核心内容就是当Ax=b无解的时候，求解\\(A^TAx\\)=\\(A^Tb\\)得到最优解 $$例：A = \\begin{bmatrix} 1 \u0026 1 \\\\ 1 \u0026 2 \\\\ 1 \u0026 5 \\end{bmatrix}, \\quad \\text{则} \\ A^T A = \\begin{bmatrix} 1 \u0026 1 \u0026 1 \\\\ 1 \u0026 2 \u0026 5 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 1 \\\\ 1 \u0026 2 \\\\ 1 \u0026 5 \\end{bmatrix} = \\begin{bmatrix} 3 \u0026 8 \\\\ 8 \u0026 30 \\end{bmatrix} \\text{是可逆的矩阵。}\r$$\r但是矩阵\\(A^TA\\)并不总是可逆 $$例：A = \\begin{bmatrix} 1 \u0026 3 \\\\ 1 \u0026 3 \\\\ 1 \u0026 3 \\end{bmatrix}, \\quad \\text{则} \\ A^T A = \\begin{bmatrix} 1 \u0026 1 \u0026 1 \\\\ 3 \u0026 3 \u0026 3 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 3 \\\\ 1 \u0026 3 \\\\ 1 \u0026 3 \\end{bmatrix} = \\begin{bmatrix} 3 \u0026 9 \\\\ 9 \u0026 27 \\end{bmatrix} \\text{是不可逆矩阵。}\r$$\rProjections in 2D 2D中的投影 #\r投影的几何解释便是：在向量a的方向上寻找与向量b距离最近的一 点 这个距离最近的点p就位于穿过b点并与向量a正交的直线 与向量a所在直线的交点上 则p就是b在a上的投影 如果我们将向量p视为b 的一种近似，则长度e=b-p就是这一近似的误差 于是便有方程\\(a^T(b-xa)=0\\) 因为向量a和b是列向量，在计算它们的点积（即内积）时，通常需要将其中一个向量转置成行向量，这样才能进行矩阵乘法并得到标量\n解得 $$\\begin{equation}\rx = \\frac{\\mathbf{a}^T \\mathbf{b}}{\\mathbf{a}^T \\mathbf{a}}, \\quad p = a x = \\mathbf{a} \\frac{\\mathbf{a}^T \\mathbf{b}}{\\mathbf{a}^T \\mathbf{a}}.\r\\end{equation}\r$$\r如果方程的自变量发生改变，p的改变量 如果b变为原来的2倍，则p也变为原来的2倍 而如果a变为原来的2倍， p不发生变化 （从几何角度考虑也很合理） Projection Matrix in 2D #\r$$proj_p=Pb$$\r其中P为投影矩阵 $$\\begin{equation}\rp = a x = a \\frac{\\mathbf{a}^T \\mathbf{b}}{\\mathbf{a}^T \\mathbf{a}}. \\quad \\text{则有} \\quad P = \\frac{\\mathbf{a} \\mathbf{a}^T}{\\mathbf{a}^T \\mathbf{a}}.\r\\end{equation}\r$$\r其分子\\(aa^T\\)是一个矩阵，而分母\\(a^Ta\\)是一个数 观察这个矩阵可知，矩阵P的列空间就是向量a所在的直线 矩阵的秩是1 (直线) Property of projection 投影的性质 #\rSymmetry 对称性 #\r对P做一次转置，其还是P 则P是对称矩阵 Apply Twice #\r如果做两次投影则有P2b=Pb，这是因为 第二次投影还在原来的位置。 因此矩阵P有如下性质：\\(P^T=P,P^2=P\\) Closest vector 最短向量 #\r方程Ax=b有可能无解 当出现比Unknown更多的Equations的时候，只能求解最优解 Ax一定在矩阵A的列空间之内，但是b不一定， p是b在Colunm Space上的Projection，所以其是最优解 将问题转化为求解\\(A\\hat x=p\\) Closest Vector Theorem #\rSuppose V is a subspace of Rn and \\(\\vec x ∈ R^n\\). The closest vector in V to \\(\\vec x\\) is given by \\(ProjV (\\vec x )\\) In other words, \\(|\\text{Proj}_V(\\vec{x}) - \\vec{x}| \\leq |\\vec{v} - \\vec{x}|~\\text{for any } \\vec{v} \\in V\\) 投影的方向到向量上最短的点就是其在改方向上的投影到向量的距离\nProof #\r$$\\|\\vec{v} - \\vec{x}\\|^2 = \\|\\vec{v} + \\text{Proj}_V(\\vec{x}) - \\text{Proj}_V(\\vec{x}) - \\vec{x}\\|^2 \\\\\r= \\|\\vec{v} - \\text{Proj}_V(\\vec{x}) + \\text{Proj}_V(\\vec{x}) - \\vec{x}\\|^2$$\r$$\\|\\vec{v} - \\vec{x}\\|^2 = \\|\\vec{v} - \\vec{x}^\\parallel + \\vec{x}^\\parallel - \\vec{x}\\|^2 \\\\\r= \\|\\vec{v} - \\vec{x}^\\parallel - \\vec{x}^\\perp\\|^2$$\r$$\\|\\vec{v} - \\vec{x}\\|^2 = \\|\\vec{v} - \\vec{x}^\\parallel\\|^2 + \\|-\\vec{x}^\\perp\\|^2 \\\\\r= \\|\\vec{v} - \\vec{x}^\\parallel\\|^2 + \\|\\vec{x}^\\perp\\|^2$$\r可以发现\\(|\\vec{v} - \\vec{x}|^2\\)最小的值出现在\\(\\vec{v} = \\vec{x}^\\parallel\\)的时候 Orthogonal projection 正交投影 #\r注意Orthogonal Projection和Orthogonal Linear Transformation是完全不同的东西 之所以叫Orthogonal Projection指的是这个Projection就是最一般的情况，就是一般所理解的正交于一个Subspace的投影\n在上面的\\(P = A (A^T A)^{-1} A^T\\)中，之所以不拆成\\(P=AA^{-1}(A^T)^{-1}A^T=I\\)，是因为A并不是Square Matrix，即不存在Inverse 当A为Square Matrix的时候，即m=n，Input dim = Output dim，这个Projection也就变成了Identity Matrix，即将自身Project Into自己的空间 但是即使是Projecct到自己的Space，其中仍会包含Linear Transformation Orthogonal Projection Formula 正交投影公式 #\r正交投影公式是通过公式计算一个正交的投影向量在目标子空间的投影，和Orthogonal Linear Transformation无关\n对于一组Orthogonal的Basis，将Vector投影到改Space的公式为 $$\\text{Proj}_V(\\vec{x}) = \\vec{u}_1 (\\vec{u}_1 \\cdot \\vec{x}) + \\vec{u}_2 (\\vec{u}_2 \\cdot \\vec{x})$$\r举例来说，对于一组Orthonormal Vector $$u = {\\begin{bmatrix}\\frac{1}{\\sqrt{2}} \\0 \\\\frac{1}{\\sqrt{2}}\\end{bmatrix},\\begin{bmatrix}-\\frac{1}{\\sqrt{2}} \\0 \\\\frac{1}{\\sqrt{2}}\\end{bmatrix}$$ \\([2,2,2]^T\\)的Projection为 $$\\begin{align*}\r\u0026= \\begin{bmatrix}\r\\frac{1}{\\sqrt{2}} \\\\\r0 \\\\\r\\frac{1}{\\sqrt{2}}\r\\end{bmatrix}\r\\left( \\begin{bmatrix}\r\\frac{1}{\\sqrt{2}} \\\\\r0 \\\\\r\\frac{1}{\\sqrt{2}}\r\\end{bmatrix} \\cdot\r\\begin{bmatrix}\r\\sqrt{2} \\\\\r0 \\\\\r\\sqrt{2}\r\\end{bmatrix} \\right)\r+\r\\begin{bmatrix}\r-\\frac{1}{\\sqrt{2}} \\\\\r0 \\\\\r\\frac{1}{\\sqrt{2}}\r\\end{bmatrix}\r\\left( \\begin{bmatrix}\r-\\frac{1}{\\sqrt{2}} \\\\\r0 \\\\\r\\frac{1}{\\sqrt{2}}\r\\end{bmatrix} \\cdot\r\\begin{bmatrix}\r\\sqrt{2} \\\\\r0 \\\\\r\\sqrt{2}\r\\end{bmatrix} \\right) \\\\\r\u0026= 2 \\begin{bmatrix}\r\\frac{1}{\\sqrt{2}} \\\\\r0 \\\\\r\\frac{1}{\\sqrt{2}}\r\\end{bmatrix}\r=\r\\begin{bmatrix}\r\\sqrt{2} \\\\\r0 \\\\\r\\sqrt{2}\r\\end{bmatrix}\r\\end{align*}$$\rProjection Matrix 正交投影矩阵 #\r正交投影矩阵，将向量正交投影到Subspace上的一个矩阵，A可以是任意矩阵，不是非得是Orthogonal Matrix，其和正交投影公式干的是一样的事，不过用了不同的表达方式\n在\\(R^3\\)空间内，如何将向量b投影到它距离平面最近的一点p？ 如果a1和a2构成了平面的一组基，则平面就是矩阵\\(A=[a1,a2]\\)的列空间 \\(e=b-p\\)是垂直于平面的 已知p在平面内，于是有\\(p=\\hat x_1a_1+\\hat x_2a_2=A\\hat x\\) 而\\(e=b-p=b- A\\hat x\\)正交于平面，因此e与\\(a_1\\),\\(a_2\\)均正交 因此可以得到：\\(a_1^T(b-A\\hat x )=0\\)并且\\(a_2^T(b-A\\hat x )=0\\) 因为a1和a2分别为矩阵A的列向量，即\\(a1^T\\)和\\(a2^T\\)为矩阵\\(A^T\\)的行向量 \\(A^T(b-A\\hat x)=0\\) 由于\\(b-A\\hat x\\)在于矩阵AT的零空间\\(N(A^T)\\)里，从上一讲讨论子空间的正交性可知，向量e与矩阵A的列空间正交，这也正是方程的意义 $$\\begin{align}\r\\hat{x} \u0026= (A^T A)^{-1} A^T b \\\\\rp \u0026= A \\hat{x} = A (A^T A)^{-1} A^T b \\\\\rP \u0026= A (A^T A)^{-1} A^T=\\frac{AA^T}{A^TA}\r\\end{align}$$\r注意区别大小写P\n对于上面的等式在dim = 1中则是\\(\\frac{\\mathbf{a} \\mathbf{a}^T}{\\mathbf{a}^T \\mathbf{a}}\\) 投影矩阵\\(P=A(A^TA)^{-1}A^T\\)，当它作用于向量b，相当于把b投影到矩阵A的列空间 Case when b is in column Space A #\r当b已经在A的列空间之中，有\\(Ax=b\\) $$\\begin{align*}\r\\mathbf{Pb} \u0026= \\mathbf{A}(\\mathbf{A}^\\top \\mathbf{A})^{-1} \\mathbf{A}^\\top \\mathbf{b} \\\\\r\u0026= \\mathbf{A}(\\mathbf{A}^\\top \\mathbf{A})^{-1} \\mathbf{A}^\\top \\mathbf{Ax} \\\\\r\u0026= \\mathbf{A}((\\mathbf{A}^\\top \\mathbf{A})^{-1} \\mathbf{A}^\\top \\mathbf{A}) \\mathbf{x} \\\\\r\u0026= \\mathbf{Ax} = \\mathbf{b}\r\\end{align*}$$\rCase when b orthorgal to column Space A #\r如果向量b与A的列空间正交，即向量b在矩阵A的左零空间N(A)中 在Left Null Space的意义在于\\(A^Tb=0\\)，所以\\(Pb=0\\) $$\\mathbf{Pb} = \\mathbf{A}(\\mathbf{A}^\\top \\mathbf{A})^{-1} \\mathbf{A}^\\top \\mathbf{b} = \\mathbf{A}(\\mathbf{A}^\\top \\mathbf{A})^{-1} (\\mathbf{A}^\\top \\mathbf{b}) = \\mathbf{A}(\\mathbf{A}^\\top \\mathbf{A})^{-1} 0 = 0$$\rI−P 的效果: I - P 则是从向量x中移除其在A的列空间上的分量，留下的部分即为x在A的列空间的正交补上的分量 这表明I - P将向量x投影到A的列空间的正交补空间上 Orthogonal Projection Matrix in Orthogonal Basis 矩阵为正交矩阵的正交投影矩阵 #\r正交矩阵的正交投影矩阵的正确读法是，当正交投影矩阵的矩阵为正交矩阵的情况下的正交投影，即改投影矩阵的A为Q的情况下，改投影将不体现“投影”的作用，而是在原空间中做Orthogonal Linear Transformation\nOrthogonal Projection Matrix必须是Square Matrix $$\\mathbf{P} = \\mathbf{Q} (\\mathbf{Q}^\\top \\mathbf{Q})^{-1} \\mathbf{Q}^\\top$$\r- 因为\\\\(Q^TQ=I\\Rightarrow P=QQ^T\\\\)\r如果Q为Square Matrix，则是一个投影到自身空间的Matrix，即\\(P=I\\)，因为Q的列向量张成了整个空间，投影过程不会对向量有任何改变 就上面的例子来说，其Projection在用了Matrix后可以得到 Orthogonal Matrix 正交矩阵 #\r注意这里定义的不再是投影了，而是前面提到的矩阵为正交矩阵的正交投影矩阵，是一个东西\nOrthogonal Matrix 正交矩阵 #\rConsider an n × n matrix A The matrix A is orthogonal if and only if \\(A^TA = I\\) or, equivalently, if \\(A^{−1} = A^T\\) Orthogonal Matrix的Column Vector需要Norm = 1 $$\\mathbf{Q} = \\begin{bmatrix} 0 \u0026 0 \u0026 1 \\\\ 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \\end{bmatrix}, \\quad\r\\text{则有 } \\mathbf{Q}^\\top = \\begin{bmatrix} 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\\\ 1 \u0026 0 \u0026 0 \\end{bmatrix}\r$$\r再比如\\(\\begin{bmatrix} 1 \u0026amp; 1 \\ 1 \u0026amp; -1 \\end{bmatrix} \\text{ 并不是正交矩阵}.\\) 因为其Norm为2，\\(\\mathbf{Q} = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \u0026amp; 1 \\ 1 \u0026amp; -1 \\end{bmatrix}\\)，调整后便可以了 一个例子便是Rotation Matrix $$T(\\vec{x}) = \\begin{bmatrix}\r\\cos(\\theta) \u0026 -\\sin(\\theta) \\\\\r\\sin(\\theta) \u0026 \\cos(\\theta)\r\\end{bmatrix} \\vec{x}$$\r对于Orthogonal Matrix来说，\\(Q^TQ=I\\) $$\\mathbf{Q} = \\begin{bmatrix} \\mathbf{q}_1 \u0026 \\cdots \u0026 \\mathbf{q}_n \\end{bmatrix}, \\quad \\mathbf{Q}^\\top \\mathbf{Q} = \\begin{bmatrix} \\mathbf{q}_1^\\top \\\\ \\vdots \\\\ \\mathbf{q}_n^\\top \\end{bmatrix} \\begin{bmatrix} \\mathbf{q}_1 \u0026 \\cdots \u0026 \\mathbf{q}_n \\end{bmatrix} = \\mathbf{I}$$\rOrthogonal transformations preserve orthogonality 角度不变性 #\rOrthogonal linear transformations不仅保持向量的长度，也保持向量间的角度和orthogonality 正交性 变换前后角度不变的变换是Orthogonal transformation\nProof #\r根据Pythoarorian Theorm $$||\\vec x^2+\\vec y^2||=||\\vec x^2||+||\\vec y^2||$$\r需要证明\\(|T(\\vec{v}) + T(\\vec{w})|^2 = |T(\\vec{v})|^2 + |T(\\vec{w})|^2\\) 对于两个Orthogonal Vector \\(\\vec v ~\u0026amp; ~\\vec w\\)，T是Linear Transformation，有 $$\\|T(\\vec{v}) + T(\\vec{w})\\|^2 = \\|T(\\vec{v} + \\vec{w})\\|^2$$\r由于Orthogonal Linear Transformation preserves the norm of vector $$\\|T(\\vec{v} + \\vec{w})\\|^2=||\\vec v+\\vec w||^2$$\r根据Pythoarorian Theorm $$||\\vec v+\\vec w||^2=||\\vec v^2||+||\\vec w||^2$$\r同理 $$||\\vec v^2||+||\\vec w||^2= \\|T(\\vec{v})\\|^2 + \\|T(\\vec{w})\\|^2$$\rOrthogonal linear transformations preserves dot product 点积不变性 #\rT : \\(\\mathbb{R}^n \\to \\mathbb{R}^n\\) is an orthogonal transformation if and only if $$ T(\\vec{v}) \\cdot T(\\vec{w}) = \\vec{v} \\cdot \\vec{w} \\text{ for all } \\vec{v}, \\vec{w} \\in \\mathbb{R}^n$$\rif \\(\\vec{u}\\) and \\(\\vec{v}\\) are orthogonal, then \\(T(\\vec{u})\\) and \\(T(\\vec{v})\\) are also orthogonal 变换前后dot product不变的变换就是Orthogonal Transformation\nProof #\rT : \\(R^n → R^n\\) is an orthogonal linear transformation $$T(\\vec{u}) \\cdot T(\\vec{v}) = (u_1 T(\\vec{e}_1) + \\dots + u_n T(\\vec{e}_n)) \\cdot (v_1 T(\\vec{e}_1) + \\dots + v_n T(\\vec{e}_n))$$\r根据\\(q_i^T q_j = \\begin{cases} 0 \u0026amp; \\text{若 } i \\neq j \\1 \u0026amp; \\text{若 } i = j \\end{cases}\\) $$T(\\vec{u}) \\cdot T(\\vec{v}) = u_1 v_1 T(\\vec{e}_1) \\cdot T(\\vec{e}_1) + \\ldots + u_n v_n T(\\vec{e}_n) \\cdot T(\\vec{e}_n)$$\r$$= u_1 v_1 \\|T(\\vec{e}_1)\\|^2 + \\ldots + u_n v_n \\|T(\\vec{e}_n)\\|^2 \\\\\r= u_1 v_1 + \\ldots + u_n v_n = \\vec{u} \\cdot \\vec{v}$$\rConverse statement of orthogonal linear transformation 逆命题的成立 #\rif a linear map preserves orthonormality, it should preserve length and hence is an orthogonal map Orthogonal transformations and orthonormal bases 正交基底保证正交变换 #\rA linear transformation T : \\(R^n → R^n\\) is an orthogonal transformation if and only if the vectors \\(T (\\vec e_1), T(\\vec e_2), . . . , T (\\vec e_n)\\) form an orthonormal basis for \\(R^n\\) 当Column Space为Orthogonal Vector的时候，Matrix为Orthogonal Transformation\nProof #\r$$\\|T(\\vec{x})\\|^2 = \\|T(x_1 \\vec{e}_1 + x_2 \\vec{e}_2 + x_3 \\vec{e}_3)\\|^2$$\r$$=\\|T(x_1 \\vec{e}_1) + T(x_2 \\vec{e}_2) + T(x_3 \\vec{e}_3)\\|^2 \\quad (\\text{by linearity of } T)$$\r$$= \\|T(x_1 \\vec{e}_1)\\|^2 + \\|T(x_2 \\vec{e}_2)\\|^2 + \\|T(x_3 \\vec{e}_3)\\|^2 \\quad (\\text{by Pythagoras})$$\r$$= x_1^2 \\|T(\\vec{e}_1)\\|^2 + x_2^2 \\|T(\\vec{e}_2)\\|^2 + x_3^2 \\|T(\\vec{e}_3)\\|^2 \\quad (\\text{by linearity of } T)$$\r$$= x_1^2 + x_2^2 + x_3^2 =||\\vec x||^2~(\\text{since columns are length } 1)$$\r$$\\mathbf{Q} = \\frac{1}{3} \\begin{bmatrix} 1 \u0026 -2\\\\ 2 \u0026 -1 \\\\ 2 \u0026 2\r\\end{bmatrix}, \\text{ 我们可以拓展其成为正交矩阵 } \\frac{1}{3} \\begin{bmatrix} 1 \u0026 -2 \u0026 2 \\\\ 2 \u0026 -1 \u0026 -2 \\\\ 2 \u0026 2 \u0026 1 \\end{bmatrix}$$\rHadamard Matrix #\r$$\\mathbf{Q} = \\frac{1}{2} \\begin{bmatrix} 1 \u0026 1 \u0026 1 \u0026 1 \\\\ 1 \u0026 -1 \u0026 1 \u0026 -1 \\\\ 1 \u0026 1 \u0026 -1 \u0026 -1 \\\\ 1 \u0026 -1 \u0026 -1 \u0026 1 \\end{bmatrix}$$\r仅包含-1和1的Orthogonal Matrix $$\\text{Proj}_V(\\vec{x}) = Q Q^T \\vec{x} =\r\\begin{bmatrix}\r\\frac{1}{\\sqrt{2}} \u0026 -\\frac{1}{\\sqrt{2}} \\\\\r0 \u0026 0 \\\\\r\\frac{1}{\\sqrt{2}} \u0026 \\frac{1}{\\sqrt{2}}\r\\end{bmatrix}\r\\begin{bmatrix}\r\\frac{1}{\\sqrt{2}} \u0026 0 \u0026 \\frac{1}{\\sqrt{2}} \\\\\r-\\frac{1}{\\sqrt{2}} \u0026 0 \u0026 \\frac{1}{\\sqrt{2}}\r\\end{bmatrix}\r\\begin{bmatrix}\r\\sqrt{2} \\\\\r\\sqrt{2} \\\\\r\\sqrt{2}\r\\end{bmatrix}\r=\r\\begin{bmatrix}\r1 \u0026 0 \u0026 0 \\\\\r0 \u0026 0 \u0026 0 \\\\\r1 \u0026 0 \u0026 0\r\\end{bmatrix}\r\\begin{bmatrix}\r\\sqrt{2} \\\\\r\\sqrt{2} \\\\\r\\sqrt{2}\r\\end{bmatrix}\r=\r\\begin{bmatrix}\r\\sqrt{2} \\\\\r0 \\\\\r\\sqrt{2}\r\\end{bmatrix}\r$$\rGram-Schmidt 施密特正交化 #\r一般来说，要获得Orthogonal Matrix，先要做一步化简到该形式，这一步的名字就 Gram-Schmidt 从两个线性无关的向量a和b开始，它们张成了一个空间 我们的目标是找到两个标准正交的向量q1，q2能张成同样的空间 Schmidt给出的结论是如果 我们有一组正交基A和B，那么我们令它们除以自己的长度就得到标准正交基 $$\\mathbf{q}_1 = \\frac{\\mathbf{A}}{\\|\\mathbf{A}\\|}, \\quad \\mathbf{q}_1 = \\frac{\\mathbf{A}}{\\|\\mathbf{A}\\|}\r$$\r当确认了一个方向后，要求出orthogonal于改方向的Vector则就是将b投影到a的方向，取B=b-p（e） $$\\mathbf{B} = \\mathbf{b} - \\frac{\\mathbf{A}^\\top \\mathbf{b}}{\\mathbf{A}^\\top \\mathbf{A}} \\mathbf{A}$$\r通过两边乘上\\(A^T\\)证明其Orthogonal性质 $$A^T\\mathbf{B} = A^T(\\mathbf{b} - \\frac{\\mathbf{A}^\\top \\mathbf{b}}{\\mathbf{A}^\\top \\mathbf{A}} \\mathbf{A})=0$$\rThird Vector #\r同理，由ABC三个Vector为 $$\\mathbf{q}_1 = \\frac{\\mathbf{A}}{\\|\\mathbf{A}\\|}, \\quad \\mathbf{q}_1 = \\frac{\\mathbf{A}}{\\|\\mathbf{A}\\|}\\quad \\mathbf{q}_3 = \\frac{\\mathbf{C}}{\\|\\mathbf{C}\\|}$$\r$$\\mathbf{C} = \\mathbf{c} - \\frac{\\mathbf{A}^\\top \\mathbf{c}}{\\mathbf{A}^\\top \\mathbf{A}} \\mathbf{A} - \\frac{\\mathbf{B}^\\top \\mathbf{c}}{\\mathbf{B}^\\top \\mathbf{B}} \\mathbf{B}\r$$\rex. Two Vectors #\r$$\\mathbf{a} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}, \\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix}, \\quad \\text{则有 } \\mathbf{A} = \\mathbf{a}, \\quad \\mathbf{B} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix} - \\frac{3}{3} \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ -1 \\\\ 1 \\end{bmatrix}$$\r- 则有Orthonormal Matrix Q\r$$\\mathbf{Q} = \\begin{bmatrix} \\mathbf{q}_1 \u0026 \\mathbf{q}_2 \\end{bmatrix} = \\begin{bmatrix} 1 / \\sqrt{3} \u0026 0 \\\\ 1 / \\sqrt{3} \u0026 -1 / \\sqrt{2} \\\\ 1 / \\sqrt{3} \u0026 1 / \\sqrt{2} \\end{bmatrix}$$\rLeast Squares 最小二乘 #\rFitting a line，拟合曲线 假设有三个数据点{(1,1), (2,2), (3,2)} 假设直线方程 \\(b=Dt+C\\) 将三个点带入方程就有\\(C+D=1,C+2D=2,C+3D=2\\) $$\\left[\r\\begin{array}{cc}\r1 \u0026 1 \\\\\r1 \u0026 2 \\\\\r1 \u0026 3 \\\\\r\\end{array}\r\\right]\r\\left[\r\\begin{array}{c}\rC \\\\\rD \\\\\r\\end{array}\r\\right]\r=\r\\left[\r\\begin{array}{c}\r1 \\\\\r2 \\\\\r2 \\\\\r\\end{array}\r\\right]\r$$\r可以发现这个Equation是无解的，但目的在于找到最优解 即方程\\(A^TA\\hat x =A^Tb\\)的解 在这之前需要定义一个Error来判断那条直线为最优解，定义为\\(||e^2||=||Ax-b||^2={e_1}^2+{e_2}^2+{e_3}^2\\) 在不存在Outlier 离群值的时候是一种非常好的Regression way \\(C+Dt分别为p1，p2和p3\\)，它们是满足方程并最接近于b的结果 现在需要求解\\(\\hat x= \\left[\\begin{array}{c}C \\D \\\\end{array}\\right]\\)和p \\(A^TA\\hat x=A^Tb\\) 因为\\(A^T(b-A\\hat x)=0\\)\n$$A^TA=\\left[\r\\begin{array}{ccc}\r1 \u0026 1 \u0026 1 \\\\\r1 \u0026 2 \u0026 3 \\\\\r\\end{array}\r\\right]\r\\left[\r\\begin{array}{ccc}\r1 \u0026 1\\\\\r1 \u0026 2 \\\\\r1 \u0026 3\\\\\r\\end{array}\r\\right]\r=\r\\left[\r\\begin{array}{ccc}\r3 \u0026 6\\\\\r6 \u0026 14\\\\\r\\end{array}\r\\right], A^Tb=\\left[\r\\begin{array}{ccc}\r1 \u0026 1 \u0026 1 \\\\\r1 \u0026 2 \u0026 3 \\\\\r\\end{array}\r\\right]\r\\left[\r\\begin{array}{ccc}\r1\\\\\r2\\\\\r2\\\\\r\\end{array}\r\\right]\r=\\left[\r\\begin{array}{cc}\r5 \\\\\r11 \\\\\r\\end{array}\r\\right]$$\r$$\\quad \\text{则有}\r\\left[\r\\begin{array}{cc}\r3 \u0026 6 \\\\\r6 \u0026 14 \\\\\r\\end{array}\r\\right]\r\\left[\r\\begin{array}{c}\r\\hat{C} \\\\\r\\hat{D} \\\\\r\\end{array}\r\\right]\r=\r\\left[\r\\begin{array}{c}\r5 \\\\\r11 \\\\\r\\end{array}\r\\right]$$\r解得\\(\\hat C=2/3,\\hat D=1/2\\) 亦可以通过求Partical Derivative的方法 $$e1^2 + e2^2 + e3^2 = (C + D - 1)^2 + (C + 2D - 2)^2 + (C + 3D - 2)^2$$ $$展开结果为2 e =3C2+14D2+9-10C-22D+12CD$$ $$求偏导为12C-20+24D=0； 28D-22+12C=0。与A^TA\\hat x=A^Tb相同$$ 于是得到结果 可以验证p与e与A的Column Space Orthogonal 矩阵ATA #\r证明：若A的列向量线性无关时，矩阵\\(A^TA\\)为可逆矩阵 要证明此，假设存在x使得\\(A^TAx=0\\)，后证明x只能是Zero Vector 第一步将灯饰两边同时乘以\\(x^T\\)，有\\(x^TA^TAx=0\\) 可以重写成\\((Ax)^T(Ax)=0\\Rightarrow Ax=0\\) 由于A的Column Vector是Linearly Independent的，所以只有\\(x=0时有A^TAx=0\\) 即\\(A^TAx\\) is invertible ","date":"Nov 21 2024","externalUrl":null,"permalink":"/docs/linearalgebra/la7.orthogonalprojection/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit 11/21/2024\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e正交向量Orthogonal vectors \r\n    \u003cdiv id=\"%E6%AD%A3%E4%BA%A4%E5%90%91%E9%87%8Forthogonal-vectors\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%AD%A3%E4%BA%A4%E5%90%91%E9%87%8Forthogonal-vectors\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/LinearAlgebra_Static/LA7.Orthogonal\u0026amp;Projection/LA7.Orthogonal\u0026amp;Projection-3.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"LA 7. Orthogonal and Projection","type":"docs"},{"content":" Last Edit: 11/19/24\nSolution 解 #\r对于一个Vector \\(a=[1,2]^T\\)和一个直线\\(y=0\\) 要研究\\(c[1,2]^T=0\\)的问题的时候，很明显不存在Non-Trivial Solution 由于a在\\(R^2\\)中，而\\([1,0]^T\\)仅Span出了\\(R^2\\)中的一个Subspace，其Dim=1 Least Error Solution (Optimization) 最优解 #\r但是对于a到直线的距离仍存在Optimized Solution 最优解出现在\\([1,2]^T\\)的终点在\\([1,0]\\)方向上最短的情况，即一个Error最小的情况 可以从a出发找到无数个到达向量\\([1,0]^T\\)方向的向量 而其中最短的则是\\(\\vec {e}\\) 也可以说\\(\\vec e\\)是Equation Error最小的Solution R^3 Case #\r对于向量\\([1,1,3]^T\\)来说，要计算其到达平面\\(x+y-2z=0\\)的最短距离 \\(\\vec e\\) 则代表了这一个距离 则e的起点在Plane\\(x+y-2z=0\\)上的位置就是这一个最优解 Projection 投影 #\r可以发现，要找到最优解，一个合理的办法是从Projection开始 在上图中p就是a在\\([1,0]^T\\)方向上的投影 则有\\(e=b-p\\) 而最小化这个e就是目标，这个目标通过Orthogonal 正交实现 具体来说从A出发的orthogonal to p的vector e就是这个Optimized Solution \\(R^3\\)中同理，只不过是将投影的改为了Plane 于是便有\\(e=(b-A\\hat x)\\) 要让e垂直于Plane \\(A=[a1,a2]\\) 有\\(a_1^T(b-A\\hat x )=0\\)并且\\(a_2^T(b-A\\hat x )=0\\) 于是可以得到公式 $$A^T(b-A\\hat x)=0\\Rightarrow A^TA\\hat x=A^Tb$$ Least Squares 最小二乘 #\r直接进入例子 对于三个点{(1,1), (2,2), (3,2)} 构建方程\\(y=wx\\) 带入点后得到\\(1=w,2=2w,2=3w\\) 通过\\(A^TA\\hat x=A^Tb\\) $$A^T A = \\begin{bmatrix}\r1 \u0026 2 \u0026 3\r\\end{bmatrix}\r\\begin{bmatrix}\r1 \\\\\r2 \\\\\r3\r\\end{bmatrix}\r= 1^2 + 2^2 + 3^2\r= 1 + 4 + 9\r= 14$$\r$$A^T b = \\begin{bmatrix}\r1 \u0026 2 \u0026 3\r\\end{bmatrix}\r\\begin{bmatrix}\r1 \\\\\r2 \\\\\r2\r\\end{bmatrix}\r= 1 \\cdot 1 + 2 \\cdot 2 + 3 \\cdot 2\r= 1 + 4 + 6\r= 11\r$$\r便有\\(14w=11\\Rightarrow w=\\frac{11}{14}\\) 几何角度 #\r那么上面的公式在几何空间中干的事就是 找到了这个红色的Vector，也就是最小的e 同理运用到最经典的\\(y=wx+b\\)也是一样 \\(1=w+b,2=2w+b,2=3w+b\\) $$A^T A = \\begin{bmatrix} 1 \u0026 2 \u0026 3 \\\\ 1 \u0026 1 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 1 \\\\ 2 \u0026 1 \\\\ 3 \u0026 1 \\end{bmatrix} = \\begin{bmatrix} 1^2 + 2^2 + 3^2 \u0026 1 + 2 + 3 \\\\ 1 + 2 + 3 \u0026 3 \\end{bmatrix} = \\begin{bmatrix} 14 \u0026 6 \\\\ 6 \u0026 3 \\end{bmatrix}$$\r$$A^T \\mathbf{b} = \\begin{bmatrix} 1 \u0026 2 \u0026 3 \\\\ 1 \u0026 1 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 2 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 1 \\cdot 1 + 2 \\cdot 2 + 3 \\cdot 2 \\\\ 1 \\cdot 1 + 1 \\cdot 2 + 1 \\cdot 2 \\end{bmatrix} = \\begin{bmatrix} 11 \\\\ 5 \\end{bmatrix}$$\r$$\\begin{bmatrix} 14 \u0026 6 \\\\ 6 \u0026 3 \\end{bmatrix} \\begin{bmatrix} w \\\\ b \\end{bmatrix} = \\begin{bmatrix} 11 \\\\ 5 \\end{bmatrix} $$\r于是有\\(w=\\frac{1}{2},b=\\frac{2}{3}\\) 同理几何上找到了向量在Plane上的投影之间的最小Error 所以这就是\\(A^TA\\hat x=A^Tb\\) 在Linear Regression的作用 需要知道的是这个方法（Normal Equation）求得的是解析解，在一般在feature \u0026lt; 10000的时候采用，但是过程可能不可逆 ","date":"Nov 19 2024","externalUrl":null,"permalink":"/docs/linearalgebra/leastsquare/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/19/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eSolution 解 \r\n    \u003cdiv id=\"solution-%E8%A7%A3\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#solution-%E8%A7%A3\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于一个Vector \\(a=[1,2]^T\\)和一个直线\\(y=0\\)\u003c/li\u003e\n\u003cli\u003e要研究\\(c[1,2]^T=0\\)的问题的时候，很明显不存在Non-Trivial Solution\u003c/li\u003e\n\u003cli\u003e由于a在\\(R^2\\)中，而\\([1,0]^T\\)仅Span出了\\(R^2\\)中的一个Subspace，其Dim=1\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/LinearAlgebra_Static/LeastSquare/LeastSquare-1.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"LA Least Square","type":"docs"},{"content":"","date":"Nov 18 2024","externalUrl":null,"permalink":"/docs/displays/","section":"Docs","summary":"","title":"Displays","type":"docs"},{"content":" Last Edit: 18/11/24\nLight #\r当我们讨论为什么像聚甲基丙烯酸甲酯（PMMA）这样的材料能够透明，而像玻璃态金属或单晶金属（如硅和镍基合金）则是不透明的时候，理解光的本质及其与材料的交互作用是至关重要的。 材料是否透明，很大程度上取决于其电子结构，这决定了它如何吸收光 PMMA #\rPMMA we were able to have a transparent polymer because PMMA is 100 % amorphous 在非晶态的材料中，没有晶体和非晶体区域之间的界限，这种界限在晶体材料中可能会散射光线。 PMMA中不存在这样的晶界，光线可以自由穿过，从而保持材料的透明性 Electromagnetic Spectrum 电磁光谱 #\r可见光只是在包含了radio waves, microwaves, infrared radiation, ultraviolet radiation, x-rays, and gamma rays在内的大量辐射光谱中的极小部分 在# Electromagnetic Spectrum中，光子是Electromagnetic Radiation的基本粒子单位，承载能量和信息，跨越不同wave length的电磁波，包括无线电波、微波、红外线、可见光、紫外线、X射线和伽马射线 Electromagnetic Radiation 电磁辐射 #\rPhotons 光子 #\r光子可以在空间中传播，不需要介质，是能量从一个地点传到另一个地点的方式 光的能量不是连续的，而是Quantized 量子化的 $$E = \\frac{hC}{\\lambda}$$\n\\(h~(Plank~ ~Constant) = 6.626×10^{−34}J⋅s\\) \\(c~(Light~speed)=3\\times 10^8 m\\cdot s^{-1}\\) \\(λ~(Wavelength)~m\\cdot s^{-1}\\) 其更加常见的形式为 $$E=hv$$ \\(ν\\) : frequency of the light in Hertz \\((1 Hz = \\frac1s)​\\) Photoelectric effect 光电效应 #\r由Albert Einstein于1905年提出 当光照射到金属表面时，光子将其能量传递给金属内的电子，如果这些光子的能量足够高，超过了金属的逸出功，电子就会被释放出金属表面 由于每个光子的能量由其频率决定，其能量和频率的关系则由公式\\(E=hv\\)给出 逸出功（Work Function）：逸出功是指电子从固体表面逃逸到真空中所需的最小能量。不同材料有不同的逸出功。 光电子（Photoelectron）：如果光子的能量高于逸出功，电子就会被释放，成为光电子 电子的动能（Kinetic Energy）：释放的光电子将具有一个最大动能，这可以通过 \\(Kmax=hf−ϕK_{\\text{max}}\\)来计算，其中 \\(\\phi\\) 是逸出功 Wave-Particle Duality 波粒二象性 #\r指物质（如光和电子）在某些情况下表现为波动性，而在其他情况下表现为粒子性。 Photoelectric effect展示了光的粒子性，而光的波动性则通过其他实验如双缝实验（Double-slit Experiment）得到证明 Electron volt 电子伏特（eV） #\r计算光子能量：使用的公式是 \\(E = \\frac{hc}{\\lambda}\\)， 650纳米的红激光，将其转换成米\\(650 \\times 10^{-9} \\text{ m}\\)，计算得到的能量是 \\(3.06 \\times 10^{-19}\\)焦耳 虽然结果是正确的，但由于在量子力学和粒子物理中常常处理非常小的能量数值，使用焦耳（Joules）单位可能会显得笨拙和难以理解 于是引入了Electron Volt的概念 电子伏特是基于电子通过1伏特电势差加速后获得的能量。一个电子伏特定义为 \\(1.602 \\times 10^{-19}\\) 焦耳 \\(E_{\\text{Red Photon}} = \\frac{3.06 \\times 10^{-19} , \\text{J}}{1.602 \\times 10^{-19} , \\text{J/eV}} = 1.91 , \\text{eV}\\) Atom 原子 #\r一个基本的Atom Structure可以概括如下 Most of the mass of an atom comes from the nucleus 原子核 Isotopes 同位素 #\rNumber of proton in nucleus决定了原子是什么元素 所以# of Protones也称为Atomic Number 原子序数 如Carbon-14, 写作\\(C_{14}\\) 对于6个Proton来说是Carbon，5个是Boron 硼，7个是Nitrogen 氮气 The Bohr Model of the Atom 原子的玻尔模型 #\r历史上出现了许多个不同的Atom Structure 第一个取得了重大进展的则是Bohr Model 玻尔模型的基本特征是中心核和轨道电子，电子与原子核以固定的距离运行 能量跃迁：电子可以通过吸收或释放一个量子（quanta）的能量，从一个轨道跳跃到另一个轨道。这个能量的量正好等于两个轨道之间的能量差 Limitation 局限性 #\r适用范围：波尔模型只能准确地计算具有一个电子的原子，如氢原子（H）、氦离子（He⁺）和双电离锂离子（Li²⁺）的行为 The Quantum-Mechanical Model of the Atom 原子的量子力学模型 #\r在现代量子力学模型中，我们需要使用Four quantum numbers来完全描述一个电子的状态 而在尼尔斯·波尔（Niels Bohr）的早期模型中，只使用了一个量子数 Principal Quantum Number 主量子数 (n) #\rDescribes the size of the electron orbit 描述了电子轨道的大小 可以是any integer value beginning at 1 不同的壳层代表电子与原子核的平均距离不同，能量也不同。 K shell 是当 n=1 时的电子层，这是最接近原子核的电子层，也是能量最低的壳层 L shell 是当 n=2时的电子层 M shell 是当 n=3时的电子层 Angular Momentum Quantum Number 角动量量子数 ℓ #\r角动量量子数（有时也称为方位量子数）描述了电子**轨道的形状 角动量量子数可以具有比主量子数小 0 到 1 的任何值, that is \\(ℓ=0,1,2,\u0026hellip;n−1\\) 当ℓ=0 时，轨道是球形的（s-轨道） s亚层可容纳 2 个电子 当l=1时，亚层是 p 轨道，形状是偶极形（类似哑铃）p亚层可容纳 6 个电子 当l=2时，亚层是 d 轨道，形状更加复杂，通常有四叶或更多叶的形状 d亚层可容纳 10 个电子 当l=3时，亚层是 f 轨道，形状更为复杂 f亚层可容纳 14 个电子 当 ℓ=1 时，轨道呈哑铃形（p-轨道） 更高的ℓ值对应更复杂的轨道形状 The Magnetic Quantum Number 磁量子数 ml #\r磁量子数主要用于指定原子轨道在三维空间中的取向，并与外部磁场中的能级分裂有关 Describes how many different ways each subshell can be orientated 磁量子数 mℓ​ 可以取从−ℓ到+ℓ的整数值，包括零，其中 ℓ是角动量量子数。这表示对于给定的角动量量子数，存在2ℓ+1个可能的磁量子数。 例如，如果电子处于p轨道ℓ=1，那么mℓ可以是 -1, 0, 或 +1，对应轨道在空间中的三个不同取向。 Spin Quantum Number 自旋量子数 (s) #\r自旋量子数ms并不直观地描述电子的物理自旋，因为电子实际上并不是在空间中围绕某个轴物理旋转。 将电子描述为“旋转”的说法可能会引起误解 量子数值：自旋量子数的可能值为\\(\\frac{1}{2}\\)​ 或\\(-\\frac{1}{2}\\)​，通常表示为电子的自旋向上（up-spin）和自旋向下（down-spin） Eletron‘s Spin 电子的自旋 #\r电子的“自旋”这一术语实际上并不指电子在空间中像地球绕其轴旋转那样的物理旋转 电子自旋是一种量子力学性质，表现为一种内在的角动量 尽管这个性质被称为“自旋”，但它并不涉及电子在任何可见的或传统意义上的物理旋转 Summarize #\r大概总结一下，对于一个电子，有四个变量能决定他的属性，也就是四个Quantum Numbers 这四个变量的由来是由Pauil Exclusion Principle规定的 即同一层级，同一轨道类型，同一轨道编号下最多存在两个电子 当四个Quantum Nubers 全部相同的时候，则两个电子一致 1. Principle Quantum Number 主量子数 #\r以电子所作在的电子层级区分 n = 1 or 2 or 3 or 4 or 5 2. Angular Momentum Qunatum 角量子数 #\r通过同一层级下的不同轨道（以形状）区分 n = 2 \u0026amp; l = 1 or 2 3. Magnetic Quantum Number 磁量子数 #\r同一层级下，同一类型（形状）轨道，不同轨道编号区分 n = 2 \u0026amp; l = 2 \u0026amp; m = -1 4. Spin Quantum Number 自旋量子数 #\r同一层级，同一轨道类型，同一轨道编号的不同电子 根据Pauil Exclusion Principle，同一层级，同一轨道类型，同一轨道编号下最多存在两个电子，其中一个上旋为1/2，下旋为-1/2 n = 2 \u0026amp; l = 2 \u0026amp; m = -1 \u0026amp; s = 1/2 Electron Configuration #\r但是想要描述一个元素的Electron Configuration，只需要描述到亚层就够了，每一个亚层都有它能存在的固定电子数 The Electron Configuration of Carbon #\r元素周期表中可以确认，我们的老朋友碳的原子序数为 6， 这意味着一个碳原子的原子核中有六个质子 因此，要构建一个中性碳原子，我们需要将六个电子放入原子核周围的外壳和子壳中 要注意1s中的1是Pricipal Quantum Number，s是Angular Momentum Quantum Number 而且一个亚层是可以包含2个电子的，所以一个n = 2中的 l =1 的亚层p可以有6个电子，写作\\(2p^6\\) 那么对于Carbon来说就有 $$1s^2 , 2s^2 , 2p^2$$ 有的时候为了省略，可以从该元素的前一个Nobel Gas的Electron Configuration开始写起 对于Carbon来说则是Helium $$[\\text{He}] 2s^2 , 2p^2 $$ When 4s is Closer Than 3d Writting Format #\r在上面的Electron Configuration里可以看到4s层的能量实际上是低于3d的，这主要是因为电子层级不是主要只依靠其Primary Quantum Number决定 但是在书写时统一按照了国际惯例，即按照Primary Quantum Number顺序书写 Physical Reason Under #\r尽管在填充电子时，4s能量低于3d（因此4s轨道先填满），但在元素离子化或化学反应中，4s电子往往更容易被移除。 Titanium #\r所以Ti的完整规定写法是 $$1s^2 2s^2 2p^6 3s^2 3p^6 3d^2 4s^2 ~ and ~ [\\text{Ar}] 3d^2 4s^2$$ 可以发现前一个的3d应该是10个，但只写了2个就到s了 Few Exceptions 特例 #\r在3d亚层处于半满或全满状态时，即4，9时 系统可以通过重新分配电子来达到更稳定的状态 Vanadium #\r$$1s^2 2s^2 2p^6 3s^2 3p^6 3d^3 4s^2$$\n可以发现3d亚层只有3个，不处于即将Half-Filled or Completely Filled的水平 Chromium #\r$$1s^2 2s^2 2p^6 3s^2 3p^6 3d^5 4s^1$$\n4s（小于3d的层级）的电子被3d拿去了，以达到了Half-Filled的水平 Copper #\r$$1s^2 2s^2 2p^6 3s^2 3p^6 3d^{10} 4s^1$$\n4s（小于3d的层级）的电子被3d拿去了，以达到了Full-Filled的水平 Octet Stability #\r\\(He=1s^2\\) \\(Ne=1s^2 2s^2 2p^6\\) \\(Ar=1s^2 2s^2 2p^6 3s^2 3p^6\\) \\(Kr=1s^2 2s^2 2p^6 3s^2 3p^6 4s^2 4p^6\\) 可以发现，由于Nobel Gas的电子构型使其具有八电子（octet）结构，遵循八隅规则 所以他们的Electron Configuration通常可以表示为\\(ns^2 np^6\\)的形式 Ionic Bond #\r离子键的形成过程 #\rCl的Atomic Number是17，其电子构型为\\(1s^2 2s^2 2p^6 3s^2 3p^5\\) 它缺一个电子就可以达到Octet的稳定结构 Na的Atomic Number是11，电子构型为\\(1s^2 2s^2 2p^6 3s^1\\) 或简写为 \\([Ne]3s^1\\) 它如果失去一个电子，也可以达到类似稀有气体的稳定构型 电子转移与离子形成 #\r钠会失去一个电子，形成带正电的钠离子（Na⁺）。 氯会接受一个电子，形成带负电的氯离子（Cl⁻）。 这种电子的转移使得钠和氯都达到了稳定的电子构型，形成了Ionic Bond 离子键的特性 #\r这种静电吸引力是non-directional，即在所有相邻的正负离子之间普遍存在，使得离子晶体结构非常稳定 在晶体中，所有电子都被紧密束缚在各自的离子中，不自由移动，因此固态的NaCldo not conduct electricity 图中显示了NaCl晶体的结构，红色小球表示Na⁺，蓝色大球表示Cl⁻。 黄色箭头表示离子间的静电吸引力。 由于正负离子的规则排列，晶体内每个离子都被周围的异性离子包围，形成稳定的晶格结构 Colvaent Bond #\rColvaent Bond涉及Electron Sharing，即原子通过共享价电子来达到稳定的Octet结构 甲烷（CH₄）是一个简单的例子：碳和氢通过共价键结合，形成一个稳定的分子。 共价键只在Specific Atoms形成，例如在CH4中，Carbon仅与四个Hydrogen Bond形成共价键，而不会与其他原子相连。这种键称为Directional Bond 共价键的本质区别在于电子共享，而离子键则是电子转移 Metallic Bonding #\r金属键通常用两种模型描述：sea-of-electrons model, and the band theory of solids Sea of Electrons Model #\r电子海模型中，Valence electrons不固定在特定的原子核上，而是自由移动，形成一个电子的“海洋”（sea of electrons） 要注意Inner electrons (non-valence electrons)是不在Electron Sea中的，因为他们并不参与反应 Ion Core周围的蓝色区域全是电子 Valence electrons 价电子 #\r原子最外层的电子，直接参与化学反应和形成化学键。它们决定了元素的化学性质，例如其反应性、与其他元素形成的键类型等 这些自由移动的电子使得金属具有Conductivity和延展性，因为电子可以在整个晶体中自由流动 Ion core 离子核 #\r在金属或其他离子化合物结构中，不参与化学键的原子核和内层电子的组合 Conductivity of Sea of Electrons Model 导电性\n模型中，electrons are free to move past the ion cores (or so-called delocalized) 离域化 自由移动的电子可以在金属内传导电流 相较于Covalent Bond来说，其被局限在特定原子之间，因此像聚合物这样的材料通常是电的绝缘体 Ductility #\r金属晶体受到足够大的应力时，一个原子平面可以滑过另一个原子平面 在金属中，原子是按照晶体结构排列的，周围有自由移动的电子（电子海） 当对金属施加较大的力（如拉伸力或剪切力）时，金属中的一个原子平面会滑动到另一个原子平面之上 即使发生滑动，由于电子海的存在，这些自由电子能够迅速重新分布并填补原子之间的空隙，从而保持金属的整体结构稳定，不会断裂 Ceramic #\r而对于Ionic \u0026amp; Covalent Bonding来说，由于其结构性，导致一旦发生了滑动，其负电荷会和负电荷处于同一平面导致Repulsion 在陶瓷材料中正负离子交替排列形成晶体结构。 当试图使一个原子层滑过另一个时，同性电荷的离子（例如两个正离子或两个负离子）会短暂靠近。 同性电荷靠近时会产生强烈的静电排斥力。 结果：导致了陶瓷在变形前就会发生脆性断裂。 Polymer #\rDuality #\r聚合物主要通过covalent bonds将分子内部连接，而分子间的连接靠次级键（如范德华力或氢键）。 在塑性变形中，Secondary Bonds被克服，聚合物分子链滑动，而共价键不会断裂。 结果：聚合物表现出较大的可变形性（如韧性），而不会像陶瓷那样容易断裂。 Conductivity #\r聚合物中，all of the valence electrons are tightly bound in the strong covalent bonds due to the lack of any free electrons 聚合物是electrically insulating Form of Crystal of Salt #\rI know that NaCl forms an ordered solid, but why?\n这是因为物质趋向于从things tend to proceed from higher energy to lower energy 当某些事情发生（如盐形成晶体）是因为这样的状态对能量来说是更“有利”的，也就是“lower energy” $$Na_{(s)} + \\frac{1}{2}Cl_{2(g)} \\rightarrow NaCl_{(s)}$$ 对于上面的反应，我们将其拆分成子反应 Sublimation of Sodium 钠的升华 #\r$$Na(s)​→Na(g)​$$\n固态钠\\(Na_{(s)}\\)直接转化为气态钠原子\\(Na_{(g)}\\)，称为升华（sublimation） 这种物质从固体转变为气体的过程需要能量，称为升华焓\\(\\Delta H_{\\text{sublimation}}\\)，对于钠为\\(ΔHsublimation​=109kJ/mol\\) 这里正值代表了：系统需要吸收能量便反应从左向右进行 也就是说，需要能量来熔化然后煮沸钠 Ionization of Sodium Atom 钠原子电离 #\r气态钠原子\\(Na_{(g)}\\)进一步被电离为钠离子\\(Na^+_{(g)}\\)和一个电子\\(e^-\\) $$Na(g)​→Na(g)^+​+e^−$$ Ionization energy is \\(IENa​=497kJ/mol\\) 可以发现这目前还是一个Posititve，则代表还需要吸收能量 Bond Dissociation of Chlorine Molecule 氯的解离 #\r$$\\frac{1}{​2}Cl_2(g)​→Cl(g)​$$\n\\(BDE_{Cl_2} = 121 , \\frac{kJ}{mol}\\) 这仍然是吸热过程（需要能量输入） Formation of a chlorine anion #\r$$Cl(g)​+e^−→Cl(g)^−​$$\n这一过程中的Electron Affinity为\\(EACl​=−364\\frac{mol}{kJ}​\\) 可以发现能量第一次变为了负的，这是第一个释放能量的步骤 Forming the ionic crystal #\r$$Na(g)+​Cl(g)^−​→NaCl(s)$$\n这一个过程包含了Crystallization energy\\(Ecrystallization​=−777\\frac{mol}{kJ}​\\) 可以发现这一步消耗了很多能量 如果我们将这些能量项中的每一个相加，形成 NaCl 的总能量变化为−414 虽然第一步是吸热的，但整个反应通过后续的强烈放热步骤补偿了这一点。整体反应的自由能变化 (ΔG\\Delta GΔG) 是负的，因而是自发的。这解释了为什么钠和氯最终可以自然形成盐晶体\nThe Band Theory 能带效应 #\r电子能级由于相互的排斥作用发生分裂\n在孤立的原子中，电子能量被量子化，存在于离散的能级中（如s,p,d,f轨道） 这些能级之间的能量差是固定的，不会受到其他原子的影响。 对于每个原子原本的一个能级，靠近后会产生多个稍微不同的能级。 例如：对于两个原子，一个能级会分裂成两个能级；对于N个原子，会分裂成N个能级 在固体中，原子之间的距离非常近，并且一个晶格中会有\\(10^{23}\\)个原子 原子的数量极其庞大时，原本分裂的离散能级数量非常多，且间距变得极其微小，最终看起来像是连续的能量区域——这就是能带（Energy Band） 原子越多，能带越“密集” 当对于一个原子，其存在多个能级，但当多个原子组合在一起的时候，电子的能量状态不再是离散的，而是形成了一个几乎连续的能量区域 孤立原子：电子有固定的、离散的能量（如轨道能级 s,p,d） 固体中：原子靠得很近，电子能级由于相互的排斥作用发生分裂。 分裂后的能量状态数量非常多，间隔非常小，看起来像是连续的，这就形成了能带 Bonding in Metals Like Copper #\r用Copper的Electron Configuration举例 $$Cu =1s^2 , 2s^2 , 2p^6 , 3s^2 , 3p^6 , 3d^{10} , 4s^1$$ 在4s中的两个Sublayer中只存在一个电子 Conductivity #\r导电的本质是低能量跃迁的累积：导电依赖于大量电子在价带和导带之间进行低能量的跃迁。如果3s电子要跃迁到4s或4p，势必要消耗更多的能量，而这在常温下不容易实现。因此，这些高能跃迁对导电贡献很小，甚至可以忽略不计。 所以说当一个轨道中存在Empty States的时候，Valence Electron才能在其中跃迁 Bonding in Metals Like Magnesium #\r对于Mg来说\\(Mg=1s^2 , 2s^2 , 2p^6 , 3s^2\\)，从表面看，3s轨道已经完全填满，因此看起来它不应该有可用的电子来参与导电 但是可以发现3p轨道是空的，但它并不是不可用的 这就像在剧院里，空座位虽然没有人坐，但仍然在那里，可以被占用 可以被占用。3s轨道和3p轨道的能级相互重叠，因此电子可以从3s轨道很容易地被激发到3p轨道 Bonding in Ceramics and Polymers #\r回想一下，Ceramic往往通过Ionic Bond结合在一起，而Ionic Bond涉及Electron在Atom间的转移 还要记住，这种电子转移的发生是为了让每个原子都能获得填充的Valence Shell 由于Valence Shell是填充的，因此没有紧邻填充态的电子能态。此外，这些电子与原子核紧密结合，因此没有自由电子 Polymer也是如此，只是他是Covalent Bond Valence Band 价带 #\rValence Band是指电子填满的最高能量带 拿Si举例，其Electron Configuration为\\(1s^22s^22p^63s^23p^2\\) 其Valence Band即为\\(3s^2\\)，3p虽然是最高能量带，但他并没有填充满 导电性：满带的电子不能自由流动，因为能量状态已经填满，没有空位供电子移动 Full Band满带 #\rFull Band是指电子完全填满的能量带。 在硅（Si）的例子中，\\(1s^2 2s^2 2p^6\\) 层被完全填满，这些内层电子构成了满带 这些满带主要是低能级的核心电子带，电子在这些带中被完全填满，无法参与到导电过程中 导电性：满带的电子由于能态完全填满，没有额外的空间或能级供电子跃迁，因此不参与导电。这些带在正常条件下对材料的导电性几乎没有贡献 Conduction Band 导带 #\r导带是指紧邻满带之上的未填满能量带 拿Si举例，其Electron Configuration为\\(1s^22s^22p^63s^23p^2\\) 其Valence Band即为\\(3p^2\\) 当电子被激发到导带后，它们可以在材料中自由移动，从而参与导电 Conduction Band通常是空的，或者仅有少量电子占据（在导体中可能存在部分填充） 导带中的电子是Valence electrons AKA Free Electrons，可以在材料中移动并产生电流 Simiconductor 半导体 #\r一些材料，即半导体，具有的Bond Gap没有绝缘体那么大 这很重要，因为这意味着我们可以控制这些材料中的电子流动。这是太阳能光伏、LED 照明和我们所有现代电子产品的基础 但大约 4 eV 通常是一个不错的数字。如果材料的带隙大于 4 eV，我们可以将其视为绝缘体，如果带隙小于 4 eV（但不为零） Conductors, Insulators, and Semiconductors #\r重新根据导电效率定义这三种的区别 从左到右依次为 conductors semiconductors and insulators Back To Light #\r可见光由光子能量在 2-3 eV 之间的光子组成 如果材料的带隙大于 3 eV（例如 SiO₂，二氧化硅），那么可见光光子的能量不足以激发电子从价带跃迁到导带。 结果：光子通过材料时不会被吸收，因此材料对可见光是透明的。 举例：玻璃主要由 SiO₂ 构成，因此玻璃是透明的。 Energy efficiency of the building #\r光穿过窗户进入室内会导致热量积聚，从而增加空调的能耗 解决方案：在窗户上镀金属薄层 金属薄层可以反射部分阳光（尤其是紫外线光子）。 如果金属层够薄，它仍然允许大部分可见光通过，同时减少紫外线和热量的传递。 优点：提高建筑的能源效率，降低室内过热问题。 Light \u0026amp; Metal #\r金属的特点：没有明显的带隙（导带和价带重叠） 结果1：光子容易激发电子：\n可见光光子的能量足够将金属中的自由电子激发到更高能级\n因此，金属吸收光，并且是不透明的\n结果2：金属的光泽（反射性）：\n被光子激发的电子会迅速返回到较低能量状态，在这个过程中重新发射光子\n这种现象导致金属表面反射光，从而看起来有光泽（“金属光泽”）\nSilicon 硅 #\r实验表明，每个硅原子会形成 four identical bonds 但是，根据电子配置，3s 和 3p 轨道的能量不同，这意味着它们的性质不同 可以推出结论“Our model is limited. It can\u0026rsquo;t explain bonding in silicon” sp3 Hybridization 轨道杂化理论 #\r这里提出的解决方法是这样的：让我们只拿一个s轨道和3p轨道并将它们混合在一起 Diamond Cubic #\r现在我们有四个等效的轨道，这些轨道的分布是对称的，彼此之间具有等价性 it wouldn\u0026rsquo;t make sense for, say, three of them to be clumped close to one another and one bond to be all alone 也就是说，它们在空间中的位置分布是均匀的 Tetrahedral Configuration #\rSemiconductors #\r能够控制半导体的导电性对我们来说很重要 可以通过将杂质引入Semiconductors中以改变其导电性 Intrinsic Semiconductors 本征半导体 #\r拿Silicon举例，其在3p轨道上，存在了4个Valence Electron 不同的Silicon则和其他的通过Covalent Bond组合成如下 Intrinsic Semiconductors一种纯净的半导体，没有杂质掺杂 在Absolute Zero的时候可以形成如上图的结构 Hole 空穴 #\r当温度上升了之后，Electrons会被Promoted进入Conduction Band导带 电子从Valence Band跃迁到Conduction Band后，会在原来的位置留下一个hole，即一个缺少电子的位置 其中，Electron和Hole空穴（电子缺失造成的正电荷）的数量是平衡的 没多一个Electron被promote后，都会留下对应的Hole，亦可说他们是成对出现的 种类型的半导体称为Intrinsic Semiconductors，因为所有可用于导电的东西都来自半导体本身，而不是我们添加到其中的任何东西 Intrinsic Semiconductors在实践中并不是特别有用，因为我们几乎总是添加杂质来控制Conductivity 电导率 Conductivity 电导率 #\r计算一个Simiconductor的 Conductivity的公式为 $$\\sigma = nq\\mu_n + pq\\mu_p $$ 而对于Intrinsic Semiconductors的特殊情况来说，由于存在Concentration of holes = Concentration of electons，于是就有 $$\\sigma = nq(\\mu_n + \\mu_p)$$ Concentration of electrons 电子浓度 n #\rSince electrons carry a negative charge 所以可以通过\\(\\frac{noofelectorns}{m^3}\\) Concentration of holes 空穴浓度 #\r在本征半导体中，电子浓度（n）和空穴浓度（p）是相同的 这是因为Intrinsic Semiconductors中的电子和空穴都是由相同数量的价带电子激发到导带产生的 因此，在热平衡状态下，电子的生成和复合是平衡的，所以电子浓度和空穴浓度相等 Mobility 迁移率 #\r对于Mobility来说存在Electron Mobility和Hole Mobility，分别通过\\(\\mu_n和\\mu_p\\)来表示 其单位为\\(\\frac{m^2}{V_s}\\) Charge 电荷 #\rCharge指的是Magnitude of the fundamental charge \\(1.602\\times 10^{-19}C\\) Extrinsic Semiconductors 外延半导体 #\r本征半导体并不是特别实用，因为我们通常会向半导体中添加Impurities（称为dopants）以仔细控制其Conductivity 我们向半导体中添加Small amount of dopant的Dopants时，掺杂剂引入的电导率会压倒任何本征半导体，因此我们称之为Extrinsic Semiconductors 基本上存在两种加入Dopants的方式，使用额外的Electron或者Hole的方法 由于电子是Negataive Charged的，将添加Electron的叫做n- type Semiconductor 而Hole是Positive的（虽然其是Neutral的，但由于Hole存在于Electron的中间，所以看上去是“Positive”的），所以添加Hole的叫做p-type Semiconductor Extrinsic n-Type Semiconductors 外本征n型半导体 #\r想要在Intrinsic Semiconductor中添加Extra Electrons，可以通过Zero Dimension Inpurity的Point Defects来添加Inpurities Atoms，而添加的这一个Atom会带来额外的电子 已知对于Silicon来说其存在4个Valence Electrons：\\(3s^23p^2\\)，一种合适的做法便是将位于元素周期表右侧的Atom加入，即一个存在5个Valence Electron的Atom，这便是P，磷 已知磷的Atomic Number为15，其Electron Configuration为\\(1s^2 2s^2 2p^6 3s^2 3p^3\\) 因此添加到硅晶格中时，当与相邻的硅原子形成四个共价键时，将有一个额外的电子踢来踢去 如上图所示，元素中出现了一个多余的电子，由于没有足够的周围硅原子来形成稳定的共价键，因此这个电子不像其他共价键中的电子那样稳定地束缚 Donor Level供体能级 #\r在Gap Band内，接近导带底部的蓝色线表示磷原子提供的额外电子的能级 这个能级非常接近导带，因此只需很少的能量就可以将电子激发到导带中。 由于Impurity P为Simiconductor贡献的 Charge carriers，亦或者说是价带比通过本征促进产生的电荷载流子多得多 因此我们可以忽略\\(\\mu_p\\)，只用电子浓度和迁移率来计算 n 型半导体的电导率 $$σ_{n−type​}=nqμ_n​$$ Extrinsic p-Type Semiconductors #\r同理对于Silicon来说，选他左边的元素，B 在Extrinsic p-Type Semiconductors中，电子不需要被激发到Conduction Band才能导电 相反，价带中的电子可以轻易被激发到B提供的一个Hole上，从而填补那里的空穴，也就是Bnad Diagram上的Acceptor Level 同理可以忽略\\(\\mu_n\\)的大小 $$σ_{p−type}​=pqμ_p​$$ Solid Ionic Conductivity #\r当我们思考和谈论固体材料中的导电性时，我们会考虑电子的运动，就半导体而言，还会考虑“空穴”的运动 然而，导电性也可以通过Solid Ionic内的运动来实现 ","date":"Nov 18 2024","externalUrl":null,"permalink":"/docs/engineering-chemistry--materials-science/ecms7.lightquantum/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 18/11/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eLight \r\n    \u003cdiv id=\"light\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#light\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e当我们讨论为什么像聚甲基丙烯酸甲酯（PMMA）这样的材料能够透明，而像玻璃态金属或单晶金属（如硅和镍基合金）则是不透明的时候，理解光的本质及其与材料的交互作用是至关重要的。\u003c/li\u003e\n\u003cli\u003e材料是否透明，很大程度上取决于其电子结构，这决定了它如何吸收光\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003ePMMA \r\n    \u003cdiv id=\"pmma\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#pmma\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003ePMMA we were able to have a transparent polymer because PMMA is 100 % amorphous\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS7.Light\u0026amp;Quantum/ECMS7.LIGHT.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"ECMS 7. Light and Quantum","type":"docs"},{"content":"\rYour browser does not support the video tag.\rfrom manim import *\rimport numpy as np\rimport torch\rimport random\rclass LinearRegression(Scene):\rdef construct(self):\rdef data_generator(w, b, num):\rX = torch.normal(0, 1, (num, len(w)))\ry = torch.matmul(X, w) + b\ry += torch.normal(0, 0.01, y.shape)\rreturn X, y.reshape((-1, 1))\rtrue_w = torch.tensor([2, -3.4])\rtrue_b = 4.2\rfeatures, labels = data_generator(true_w, true_b, 1000)\rhead = Text(\u0026#34;Linear Regression Display - Buezwqwg\u0026#34;)\rhead.set_color(BLUE)\rself.play(Create(head))\rself.wait(1)\rself.play(Uncreate(head))\rfeature_one = features[:, [0]].tolist()\rfeature_two = features[:, [1]].tolist()\rlabels_list = labels.tolist()\raxes_1 = Axes(\rx_range=[min(feature_one)[0]-1, max(feature_one)[0]+1, 1],\ry_range=[min(labels_list)[0]-1, max(labels_list)[0]+1, 5],\rx_length=5,\ry_length=5,\raxis_config={\u0026#34;color\u0026#34;: BLUE},\r)\raxes_2 = Axes(\rx_range=[min(feature_two)[0]-1, max(feature_two)[0]+1, 1],\ry_range=[min(labels_list)[0]-1, max(labels_list)[0]+1, 5],\rx_length=5,\ry_length=5,\raxis_config={\u0026#34;color\u0026#34;: BLUE},\r)\raxes = VGroup(axes_1, axes_2)\raxes.arrange(RIGHT, buff=1)\rself.play(Create(axes))\rpoints_1 = []\rfor i in range(len(labels_list)):\rdot_position = axes_1.coords_to_point(feature_one[i][0], labels[i][0])\rpoints_1.append(Dot(point=dot_position, radius=0.03, color=YELLOW))\rpoints_2 = []\rfor i in range(len(labels_list)):\rdot_position = axes_2.coords_to_point(feature_two[i][0], labels[i][0])\rpoints_2.append(Dot(point=dot_position, radius=0.03, color=YELLOW))\rpoints_group_1 = VGroup(*points_1)\rpoints_group_2 = VGroup(*points_2)\rself.play(Create(points_group_1), Create(points_group_2))\r# Draw the true model lines\rtrue_line_1 = axes_1.plot(lambda x: true_w[0].item() * x + true_b, color=GREEN)\rtrue_line_2 = axes_2.plot(lambda x: true_w[1].item() * x + true_b, color=GREEN)\rself.play(Create(true_line_1), Create(true_line_2))\r# Initialize parameters\rw = torch.normal(0, 0.01, size=(2, 1), requires_grad=True)\rb = torch.zeros(1, requires_grad=True)\rw_1 = w.detach().numpy()[0][0]\rw_2 = w.detach().numpy()[1][0]\rb_0 = b.detach().numpy()[0]\rline_1 = axes_1.plot(lambda x: w_1 * x + b_0, color=BLUE)\rline_2 = axes_2.plot(lambda x: w_2 * x + b_0, color=BLUE)\rself.play(Create(line_1), Create(line_2))\r# Add text to display loss, w, b\rloss_text = MathTex(f\u0026#34;\\\\text{{Loss}} = {0:.4f}\u0026#34;)\rloss_text.to_edge(UP)\rw_text = MathTex(f\u0026#34;w_1 = {w_1:.4f},\\\\ w_2 = {w_2:.4f}\u0026#34;)\rw_text.next_to(loss_text, DOWN)\rb_text = MathTex(f\u0026#34;b = {b_0:.4f}\u0026#34;)\rb_text.next_to(w_text, DOWN)\rparam_text = VGroup(loss_text, w_text, b_text)\rself.play(Write(param_text))\rdef data_iter(batch_size, features, labels):\rnum = len(features)\rindex = list(range(num))\rrandom.shuffle(index)\rfor i in range(0, num, batch_size):\rbatch_index = torch.tensor(index[i:min(i+batch_size, num)])\ryield features[batch_index], labels[batch_index]\rbatch_size = 10\rdef linreg(X, w, b):\rreturn torch.matmul(X, w) + b\rdef squared_loss(y_hat, y):\rreturn (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\rdef sgd(params, lr, batch_size):\rwith torch.no_grad():\rfor param in params:\rparam -= lr * param.grad / batch_size\rparam.grad.zero_()\rlr = 0.03\rnum_epochs = 3 # Changed to 3 epochs\rnet = linreg\rloss = squared_loss\rupdate_interval = 1 # Update after every batch\rbatch_counter = 0\r# Start training and update after every backpropagation\rfor epoch in range(num_epochs):\rfor X, y in data_iter(batch_size, features, labels):\rl = loss(net(X, w, b), y)\rl.sum().backward()\rsgd([w, b], lr, batch_size)\rbatch_counter += 1\r# Get the latest parameters\rnew_w_1 = w.detach().numpy()[0][0]\rnew_w_2 = w.detach().numpy()[1][0]\rnew_b_0 = b.detach().numpy()[0]\r# Update lines\rnew_line_1 = axes_1.plot(lambda x: new_w_1 * x + new_b_0, color=BLUE)\rnew_line_2 = axes_2.plot(lambda x: new_w_2 * x + new_b_0, color=BLUE)\rself.play(\rTransform(line_1, new_line_1),\rTransform(line_2, new_line_2),\rrun_time=0.1 # Adjusted animation time for smoother update\r)\r# Update loss and parameter displays\rwith torch.no_grad():\rtrain_l = loss(net(features, w, b), labels)\rcurrent_loss = float(train_l.mean())\rnew_loss_text = MathTex(f\u0026#34;\\\\text{{Loss}} = {current_loss:.4f}\u0026#34;)\rnew_loss_text.to_edge(UP)\rnew_w_text = MathTex(f\u0026#34;w_1 = {new_w_1:.4f},\\\\ w_2 = {new_w_2:.4f}\u0026#34;)\rnew_w_text.next_to(new_loss_text, DOWN)\rnew_b_text = MathTex(f\u0026#34;b = {new_b_0:.4f}\u0026#34;)\rnew_b_text.next_to(w_text, DOWN)\rself.play(\rTransform(loss_text, new_loss_text),\rTransform(w_text, new_w_text),\rTransform(b_text, new_b_text),\rrun_time=0.1\r)\r# Output current epoch\u0026#39;s loss\rprint(f\u0026#39;epoch {epoch + 1}, loss {current_loss:f}\u0026#39;)\rself.wait(2) ","date":"Nov 18 2024","externalUrl":null,"permalink":"/docs/displays/linearregression_display/","section":"Docs","summary":"\u003cvideo width=\"640\" height=\"360\" controls\u003e\r\n  \u003csource src=\"LG_Display.mp4\" type=\"video/mp4\"\u003e\r\n  Your browser does not support the video tag.\r\n\u003c/video\u003e\r\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efrom manim import *\r\nimport numpy as np\r\nimport torch\r\nimport random\r\n\r\nclass LinearRegression(Scene):\r\n    def construct(self):\r\n        def data_generator(w, b, num):\r\n            X = torch.normal(0, 1, (num, len(w)))\r\n            y = torch.matmul(X, w) + b\r\n            y += torch.normal(0, 0.01, y.shape)\r\n            return X, y.reshape((-1, 1))\r\n\r\n        true_w = torch.tensor([2, -3.4])\r\n        true_b = 4.2\r\n        features, labels = data_generator(true_w, true_b, 1000)\r\n\r\n        head = Text(\u0026#34;Linear Regression Display - Buezwqwg\u0026#34;)\r\n        head.set_color(BLUE)\r\n        self.play(Create(head))\r\n        self.wait(1)\r\n        self.play(Uncreate(head))\r\n\r\n        feature_one = features[:, [0]].tolist()\r\n        feature_two = features[:, [1]].tolist()\r\n        labels_list = labels.tolist()\r\n        axes_1 = Axes(\r\n            x_range=[min(feature_one)[0]-1, max(feature_one)[0]+1, 1],\r\n            y_range=[min(labels_list)[0]-1, max(labels_list)[0]+1, 5],\r\n            x_length=5,\r\n            y_length=5,\r\n            axis_config={\u0026#34;color\u0026#34;: BLUE},\r\n        )\r\n        axes_2 = Axes(\r\n            x_range=[min(feature_two)[0]-1, max(feature_two)[0]+1, 1],\r\n            y_range=[min(labels_list)[0]-1, max(labels_list)[0]+1, 5],\r\n            x_length=5,\r\n            y_length=5,\r\n            axis_config={\u0026#34;color\u0026#34;: BLUE},\r\n        )\r\n        axes = VGroup(axes_1, axes_2)\r\n        axes.arrange(RIGHT, buff=1)\r\n        self.play(Create(axes))\r\n\r\n        points_1 = []\r\n        for i in range(len(labels_list)):\r\n            dot_position = axes_1.coords_to_point(feature_one[i][0], labels[i][0])\r\n            points_1.append(Dot(point=dot_position, radius=0.03, color=YELLOW))\r\n        points_2 = []\r\n        for i in range(len(labels_list)):\r\n            dot_position = axes_2.coords_to_point(feature_two[i][0], labels[i][0])\r\n            points_2.append(Dot(point=dot_position, radius=0.03, color=YELLOW))\r\n        points_group_1 = VGroup(*points_1)\r\n        points_group_2 = VGroup(*points_2)\r\n        self.play(Create(points_group_1), Create(points_group_2))\r\n\r\n        # Draw the true model lines\r\n        true_line_1 = axes_1.plot(lambda x: true_w[0].item() * x + true_b, color=GREEN)\r\n        true_line_2 = axes_2.plot(lambda x: true_w[1].item() * x + true_b, color=GREEN)\r\n        self.play(Create(true_line_1), Create(true_line_2))\r\n\r\n        # Initialize parameters\r\n        w = torch.normal(0, 0.01, size=(2, 1), requires_grad=True)\r\n        b = torch.zeros(1, requires_grad=True)\r\n        w_1 = w.detach().numpy()[0][0]\r\n        w_2 = w.detach().numpy()[1][0]\r\n        b_0 = b.detach().numpy()[0]\r\n        line_1 = axes_1.plot(lambda x: w_1 * x + b_0, color=BLUE)\r\n        line_2 = axes_2.plot(lambda x: w_2 * x + b_0, color=BLUE)\r\n        self.play(Create(line_1), Create(line_2))\r\n\r\n        # Add text to display loss, w, b\r\n        loss_text = MathTex(f\u0026#34;\\\\text{{Loss}} = {0:.4f}\u0026#34;)\r\n        loss_text.to_edge(UP)\r\n        w_text = MathTex(f\u0026#34;w_1 = {w_1:.4f},\\\\ w_2 = {w_2:.4f}\u0026#34;)\r\n        w_text.next_to(loss_text, DOWN)\r\n        b_text = MathTex(f\u0026#34;b = {b_0:.4f}\u0026#34;)\r\n        b_text.next_to(w_text, DOWN)\r\n        param_text = VGroup(loss_text, w_text, b_text)\r\n        self.play(Write(param_text))\r\n\r\n        def data_iter(batch_size, features, labels):\r\n            num = len(features)\r\n            index = list(range(num))\r\n            random.shuffle(index)\r\n            for i in range(0, num, batch_size):\r\n                batch_index = torch.tensor(index[i:min(i+batch_size, num)])\r\n                yield features[batch_index], labels[batch_index]\r\n\r\n        batch_size = 10\r\n\r\n        def linreg(X, w, b):\r\n            return torch.matmul(X, w) + b\r\n\r\n        def squared_loss(y_hat, y):\r\n            return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\r\n\r\n        def sgd(params, lr, batch_size):\r\n            with torch.no_grad():\r\n                for param in params:\r\n                    param -= lr * param.grad / batch_size\r\n                    param.grad.zero_()\r\n\r\n        lr = 0.03\r\n        num_epochs = 3  # Changed to 3 epochs\r\n        net = linreg\r\n        loss = squared_loss\r\n\r\n        update_interval = 1  # Update after every batch\r\n        batch_counter = 0\r\n\r\n        # Start training and update after every backpropagation\r\n        for epoch in range(num_epochs):\r\n            for X, y in data_iter(batch_size, features, labels):\r\n                l = loss(net(X, w, b), y)\r\n                l.sum().backward()\r\n                sgd([w, b], lr, batch_size)\r\n\r\n                batch_counter += 1\r\n                # Get the latest parameters\r\n                new_w_1 = w.detach().numpy()[0][0]\r\n                new_w_2 = w.detach().numpy()[1][0]\r\n                new_b_0 = b.detach().numpy()[0]\r\n\r\n                # Update lines\r\n                new_line_1 = axes_1.plot(lambda x: new_w_1 * x + new_b_0, color=BLUE)\r\n                new_line_2 = axes_2.plot(lambda x: new_w_2 * x + new_b_0, color=BLUE)\r\n                self.play(\r\n                    Transform(line_1, new_line_1),\r\n                    Transform(line_2, new_line_2),\r\n                    run_time=0.1  # Adjusted animation time for smoother update\r\n                )\r\n\r\n                # Update loss and parameter displays\r\n                with torch.no_grad():\r\n                    train_l = loss(net(features, w, b), labels)\r\n                    current_loss = float(train_l.mean())\r\n                new_loss_text = MathTex(f\u0026#34;\\\\text{{Loss}} = {current_loss:.4f}\u0026#34;)\r\n                new_loss_text.to_edge(UP)\r\n                new_w_text = MathTex(f\u0026#34;w_1 = {new_w_1:.4f},\\\\ w_2 = {new_w_2:.4f}\u0026#34;)\r\n                new_w_text.next_to(new_loss_text, DOWN)\r\n                new_b_text = MathTex(f\u0026#34;b = {new_b_0:.4f}\u0026#34;)\r\n                new_b_text.next_to(w_text, DOWN)\r\n                self.play(\r\n                    Transform(loss_text, new_loss_text),\r\n                    Transform(w_text, new_w_text),\r\n                    Transform(b_text, new_b_text),\r\n                    run_time=0.1\r\n                )\r\n\r\n            # Output current epoch\u0026#39;s loss\r\n            print(f\u0026#39;epoch {epoch + 1}, loss {current_loss:f}\u0026#39;)\r\n\r\n        self.wait(2)\n\u003c/code\u003e\u003c/pre\u003e","title":"Linear Regression Display","type":"docs"},{"content":"","date":"Nov 13 2024","externalUrl":null,"permalink":"/tags/econ/","section":"Tags","summary":"","title":"Econ","type":"tags"},{"content":"Notes taken from 小Lin说的个人空间-小Lin说个人主页-哔哩哔哩视频. space.bilibili.com/520819684?spm_id_from=333.337.search-card.all.click. Requires further completion\n","date":"Nov 13 2024","externalUrl":null,"permalink":"/docs/economic/","section":"Docs","summary":"\u003cp\u003eNotes taken from 小Lin说的个人空间-小Lin说个人主页-哔哩哔哩视频. space.bilibili.com/520819684?spm_id_from=333.337.search-card.all.click.\nRequires further completion\u003c/p\u003e","title":"Economics","type":"docs"},{"content":" Last Edit: 11/13/2024\n交易量最大的市场\n货币 #\r行业标准，每种货币用三个字母来代替 一维理解 #\r假设什么都没有，借1.6mJPY去换10kUSD 这时候可以获得USD的利息，但同时需要支付JPY的利息 但如果USD/JPY涨了，而JPY没变，则赚了对应的JPY Forex的特殊性 #\r其覆盖面极广，同时涉及专业公司与市场中的每一个人 Decentralized 去中心化 #\r对于Stock Market可能存在Nasdaq这类的交易所 但是Foreign exchange没有一个中央的交易机构 Market Maker 做市商 #\r提供交易流动性的场所 由于Foreign Exchange是去中心化的，但为了保持资金的流通一般散户甚至公司都会去找到到Marker Marker来做交易 导致了Market Maker的交易量极大的前提下，参与人数极少 Hedge 对冲 #\r而这些Market Maker并不靠与客户的对赌赚钱 而是通过强大的风险管控能力去做对冲 Censorship 监管 #\r由于其Decentralized的特点，其Censorship一般都比较松 这也导致了在交易中动手脚的可能性上升 Fixing 定盘价 #\r在每天London 4PM的时候前后一分钟交易量算出来的均价 类似于Stock的收盘价 全球大量的衍生产品都将高度依赖于这一个价格 只要交易员每天在指定时间只做指定的一个货币，改货币价格直接就上升了 High Frequency Trading #\r依靠算法套利的公司 一笔赚的非常少但是量大 Foreign Payment #\r对于企业，Foreign Exchange的维度又引入了时间的概念 假设造手机，在成本投入的半年后才能开始实现收益，但未来的汇率是不稳定的 Foreign Exchange Forward Comtract 外汇远期合约 #\r在现在对冲掉未来的风险 对于实际情况可能复杂的多，对于供应链上的供应商来说存在更多的情况 债 #\r在当地企业景气的时候，可能存在外资的涌入 但是外资的投资将采用其货币，而为了规避汇率风险则需要引入Cross Currency Swap Cross Currency Swap 货币利率互换协议 #\r可以实现虽然借的是USD债 但通过互换协议相当于规避了Currency的风险 Swap #\r互换的主要交易时基于未来的 其主要是因为对于未来Currency的不确定性导致的 Forex Products by Trading Volume #\rCurrency #\r对于一个国家，货币就衡量了当下所有商品的标尺 但犹豫利率的存在，导致一个3%年利率的国家一年后的103等价于当下的100 （纯理论） 而将两个维度结合便可以形成一个Plane 而Foreign Exchange 则是不同坐标系的转换 即Basis Change Central Bank \u0026amp; Government 央行和政府 #\r央行可以通过一系列操作影响整个市场，但是其并不能起到做庄的效果 互换协议，双边政府互相给钱，促进双方货币在国际贸易上的占比 也是去美元化的一种方法 ","date":"Nov 13 2024","externalUrl":null,"permalink":"/docs/economic/foreignexchange/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/13/2024\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e交易量最大的市场\u003c/p\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e货币 \r\n    \u003cdiv id=\"%E8%B4%A7%E5%B8%81\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E8%B4%A7%E5%B8%81\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/Economic_Static/ForeignExchange/ForeignExchange%E5%A4%96%E6%B1%87.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"Foreign Exchange","type":"docs"},{"content":" Last Edit: 11/10/24\nPolymer 聚合物 #\r前缀“poly-”意指“很多”，暗示了这些聚合物分子结构中有许多重复的部分。 而“mer”指的是“重复单元”或“基元”，这是一种分子的基本单元 Basic Structure #\r与Crystal Structure不同，他们的基本结构是Cubics。并且其会在三维空间（即沿着三个方向）重复排列，形成一个规则的晶体结构 Polymer的结构则不同，它的基元通常只在One Dimnesion上重复，这种重复形成了一条长链 可以看到Polymer的内部结构为长线，而线其实是由很小的分子所组成的 Polyethylene and Polymer #\rPolymer #\r聚合物是一个广义术语，指的是由许多重复单元（基元）组成的长链分子。 聚合物的基元可以是各种各样的分子结构，不限于某一种类型。 Polyethylene #\r聚乙烯是一种具体的聚合物，由重复的乙烯单元（C₂H₄）构成。乙烯单元经过聚合反应形成长链，从而产生聚乙烯。 它是最常见的合成聚合物之一，但只是聚合物的一种类型。 放大上图可以发现 Polyethylene由String结构组成，而String则由分子组成 分子内部，如上图的Polyethylene则是由Hydrogen和Carbon Atoms组成，而Atom之间的作用力则为Intramolecular Bonds（作用在分子内部的相互作用力） Polymer\u0026rsquo;s Deformation #\r在观察超市购买了重物，并将它们放入一个塑料袋中后，可能会发现袋子的把手开始拉伸，甚至感到不适，因为它开始压入手中。随着重量的增加，把手继续拉伸，但在某个点，它似乎停止了延展。有时你甚至能在被拉伸的地方看到颜色的轻微变化 这一现象也可以通过String Model解释 Initial Stage #\r拉伸初期，由于Polymer内部结构仍是Randomly Oriented的Polymer chains没有按照拉伸的方向对齐 于是就可以像拉开松散的线一般将他们分开 Bonds #\rPrimary Bond #\rPrimary bond是 intramolecular bond，存在于一个分子内部的原子之间，例如Covelent Bond或Ionic Bond 这种键非常强，是构成Polymer Chians的基本骨架。 Secondary Bond #\rSecondary bond 是 intermolecular bond，即分子之间的作用力，比如范德华力或氢键 这种键相对较弱，存在于不同分子链之间，允许它们在一定条件下滑动或重新排列 Plastic Deformation Stage #\r随着拉伸的继续，Polymer chains开始发生滑动 滑动可以类比为面条互相滑动的情形 这就是分子间的“Friction”——在Polymer中我们称之为“Intermolecular Force”，也叫“secondary bond” （次级键） Alignment Stage #\r在Polymer Chain到位了之后，Secondary Bond（Inter Molecular Bond）的作用逐渐减小，变为了Primary Bond（Intra Molecular Bond） 所以Polymer的Plastic Deformation所需要的Stress反而会上升 Yield Strength #\r由于对于Polymer来说在发生了Plastic Deformation后其Polymer Chain将会变为Secondary Bond受力，其Stress反而上升了，所以将Curve在Plastic Deformation时候的峰值作为Yield Strength是合理的 The change of mer Units #\r已知Polymer由Polymer Chain组成，而Polymer Chain则是由很多Molecular (Mer)组成的 所以改变Molecular的元素便直接改变了Polymer Polypropylene 聚丙烯 #\r聚丙烯 (PP) 是一种非常常见且有用的聚合物。星巴克® 的那些漂亮的可重复使用杯子就是用 PP 制成的 在塑料瓶的底下可以看到其Recycling Code 为5 通常来说Polypropylene会比Polythylene更加坚固，其来自于额外的\\(CH_3\\) Polyvinylchloride (PVC) #\r出于某些原因，PVC的名字里就出现了Cl，所以其分子当然也包含Cl 而对于PVC中的V来说，其代表了Vinyl，是这种结构 Periodic Table 元素周期表 #\r对于周期表来说，其具有以下特性 周期（横向）趋势：当从左到右观察周期表时，原子半径逐渐减小，电子更接近原子核，因此核对外层电子的吸引力增强，Electronegativity增大 族（纵向）趋势：从周期表的顶端向底部移动时，原子半径增大，外层电子距离原子核更远，核对电子的吸引力减弱，因此Electronegativity减小 Electronegativity 电负性 #\r反应了Atom吸引电子的强弱程度 Bonding 分子键 #\rCovalent Bond 共价键 #\r十分熟悉的一种Bonding Type 一个Molecule中的两个Atom共享Electron Nonpolar Covalent Bond 非极性共价键 #\r当两个原子的Electronegativity几乎相等的时候，形成Nonpolar Covalent Bond 其特性为Electorn将均匀的分布于Atom之间 Polar Covalent Bond 极性共价键 #\r两个Atom的Electronegativity具有明显差异的时候 其仍然是Covalent Bond，但是Sharing的Atom会明显的偏向于其中一个Electronegative更大的Atom 可以发现Cl带有了部分的负电荷（Electron），所以其是具有更高Electronegativity的那个 并且Electrons在Covalent Bond中将会偏向于Cl Ionic Bond 离子键 #\r两个原子间的Electronegativity差极大时，一个Atom将会抢走另外一个的Electron形成Ionic Bond Polytetrafluoroethylene 聚四氟乙烯 #\r一种非反应性的Polymer 每一个Carbon Atom上都结合了大量的Floride，它们很大可以防止PTFE内部不被波坏 虽然Floride的electronegativity很高，但由于其Molecule中的对称性结构，所以形成了一个NonPolar Covalent Bond Hydrophobic 疏水性 #\rPTFE的特殊点在于其为一种Hydrophobic Polymer，具体来说Liquid无法通过其缝隙进入材料，而Gas却可以自由的通过 这就是户外服装在雨中保持干爽的愿意，一般称其为“Breathing\u0026quot; Polymethylmethacrylate 聚甲基丙烯酸甲酯 PMMA #\r一种透明的Polymer 每个合并单元上的大侧基团（通常称为 \u0026ldquo;笨重 \u0026ldquo;侧基）会阻止分子相互靠近组织。 这就确保了聚合物是完全无组织的，或者说是无定形的。 当聚合物结晶时，其折射率与无定形时不同。 如果聚合物中既有无定形的部分，也有结晶的部分（即所谓的半结晶），那么穿过聚合物的光线就不会沿着直接的路径传播，聚合物就会呈现半透明或不透明的状态。 因此，PMMA 之所以是透明的，部分原因是合并单元确保其保持 100% 透明 Length of Polymer Chain #\r前面提到过Polymer Chain是很长的，但却没有给出一个量化的办法 在合成Polymer的时候，控制其分子长度是很困难的 但可以得到一个其长度的分布图 假定一个理想的Polymer Sample，其Polymer Chain的存在需要通过一种分布来描述 描述这个分布的方式并不是通过长度而是重量 具体来说，假设有如下盒子，其里面包含了绳子 木盒子，里面有一段绳子。 你不能打开盒子，你需要确定盒子里绳子的长度。 给你一个空盒子的质量、一根一米长的绳子和一个天平。 你可以用质量来确定盒子里绳子的长度 发现可以通过绳子单位长度的质量计算盒子里绳子的长度 Number Average Molecular Weight 数均分子量 #\r$$\\overline{M}{\\text{number}} = \\frac{\\sum{n=1}^{i} M_n x_n}{\\sum x_n}$$\n所有分子的分子量加总后除以分子总数得到的平均分子量 \\(M_{number}\\)​：数均分子量 \\(M_n​\\)：第n类分子的分子量 \\(x_n\\)：第n类分子的数量比例（即该类别分子数占总分子数的比例） Analogy Candy Box #\rWeight Average Molecular Weight 重均分子量 #\r$$\\overline{M}{\\text{weight}} = \\sum{n=1}^{i} M_n w_n $$\n\\(M_{weight}\\)​：重均分子量 \\(M_n​\\)：第n类分子的分子量 \\(x_n\\)：第n类分子的质量分数（即该类别分子总质量占总所有分子总质量的比例） Analogy #\r用同样的模型说明 Dispersity 分散性 #\r$$\\mathcal{D} = \\frac{\\overline{M}{\\text{weight}}}{\\overline{M}{\\text{number}}} $$\n\\(\\mathcal{D}\\): 分散性 Dispersity \\(M_{weight}\\)​：重均分子量 \\(M_{number}\\)​：数均分子量 当\\(\\mathcal{D} \u0026gt;1\\)时：分子量分布较宽，即多分散（Polydisperse）。随着\\(\\mathcal{D}\\)值增大，分子量的差异越大，分布越宽 Why Molecular Weight Anyway? #\r当面条较长时，很难将一根面条从其他面条中分离出来。 聚合物也是如此，当然，这也是了解分子量如此重要的原因。 随着聚合物分子量的增加，强度也会增加，而且由于长分子的缠结增加，断裂应变通常也会增加。 Ways of molecules stack up #\r聚合物分子虽然通常是线性的，但并非直线。 也就是说，它们是曲线形的 但这并不意味着它们总是完全无序的。 我们还看到，当聚合物发生塑性变形( chain Orientation) 时，会产生一些有序性 Crystalline Polymer 半结晶聚合物 #\r在某些情况下，它们可以在没有任何外部负载的情况下自行有序化 聚乙烯等简单聚合物中的分子通常会在自身上来回折叠 但是由于分子非常长，聚合物永远不可能 100% 结晶 并且由于Crystal Region比Amorphous通过Secondary Bond更牢固地结合在一起，因此这些区域的强度更高 Change of Crystal Density of Polymer 改变聚合物的结晶度 #\r对于Polymer Chain来说，几乎总是有一些所谓的分支从主分子上延伸出来，其仍然是分子的一部分 事实上，我们经常会专门设计一种聚合物，使其具有分支。 低密度聚乙烯LDPE就是这种情况 低密度聚乙烯LDPE中更多和更长的分支降低了分子相互靠近排列的能力，降低了结晶度，从而降低了密度、强度甚至弹性模量 Change of the Intramolecular Bonds #\r想要通过mer unit 改变Polymer整体强度，则可以use elements that are very electronegative We could also ensure that they are bonded to something that is very easy to make positive 于是就可以想到Hydrogen Hydrogen #\r对于Hydrogen来说其有很低的Electronegativity，其Electron很容易被抢走，剩下其Proton 只需要一个有点电负性的元素，氢就会变成正元素 Hydrongen Bond #\r犹豫Hydrogen具有的特小的Electronegativity，导致了其极易产生一个High Strengh Polar Covalent Bond（强偶极子键），所以一种特殊的Bond则尤其命名：Hydrogen Bond Introducing Hydrogen Bond between Molecules #\r将分子之间引入氢键是一种增强分子间相互作用的方式 Cross Link 交联 #\r交联则是通过强的主键（即分子内的共价键）将聚合物分子永久地连接起来，从而显著增强聚合物的强度和弹性。交联聚合物的一个经典例子是天然乳胶橡胶。 在制作弹性体时，交联程度需要适中。如果交联过多，聚合物会变得硬且脆，失去弹性，不再适合作为弹性体 Temperature #\r聚合物的许多特性都是由分子间的弱键造成的 这些键（有时也称为相互作用）更容易被热能破坏，即使温度相对较低：接近室温 在金属或陶瓷中，大部分特性都是由将它们连接在一起的强键、主键的性质决定的（稍后将详细介绍），这些键的键能远远高于接近室温时的热能。 Melting Temperature 熔点温度（Tm​） #\r熔点温度指的是聚合物从固态转变为液态的温度 超过这个温度后，聚合物会像厚液体一样流动 Glass Transition Temperature 玻璃化转变温度 (Tg) #\r通常适用于非晶态或半晶态聚合物 表示的是聚合物从硬脆的“玻璃态”转变为柔软、易变形的“橡胶态”的温度 低于Tg的温度下，聚合物链段的运动受到限制，材料表现出类似玻璃的刚性 高于Tg的温度下，链段有更多的活动空间，材料变得柔软。 Melting Process #\r在加热过程中，热能将首先在Amorphous Region开始破坏分子间的键能。 随着持续加热，热能最终将足以破坏Crystal Region的分子间键 因此，Amorphous Region被破坏时的较低温度被称为Glass Transition Temperature 当Polymer低于Tg时，其像普通窗玻璃一样又硬又脆 Loading Time 施加负载的时间 #\r快速施加负荷：当它被快速拉伸时会像脆性材料一样断裂，且无永久变形。这是因为其分子链较短，在快速拉伸时分子之间没有足够的时间进行重新排列，导致聚合物直接破裂。 长时间施加负荷，聚合物会发生蠕变，即随着时间的延长，材料会逐渐变形 弹性变形（Elastic Deformation） #\r特点：弹性变形是瞬时的，即加载后立即产生变形，卸载后立即恢复原状。 变形性质：弹性变形是可逆的，即材料可以恢复到原始形状，不会有永久的变形残留。 应用场景：在桌子短暂放置在地毯上的情况下，地毯纤维受到压力后会产生弹性变形，但桌子移开后，地毯几乎立即恢复原状。 分子运动：在弹性变形中，聚合物分子链段的变形非常有限，分子间没有发生显著的滑动或重新排列。 粘性变形（Viscous Deformation） #\r特点：粘性变形是随时间累积的，即需要长时间加载才能显现。 变形性质：粘性变形是不可逆的，即变形在卸载后不完全恢复，会留下永久变形。 应用场景：当桌子长时间放置在地毯上（例如一年），地毯纤维会缓慢移动或滑动，导致永久变形，即使桌子移开后，地毯也无法完全恢复原状。 分子运动：在粘性变形中，聚合物分子链段逐渐滑动，重新排列，表现为类似液体流动的行为，这个过程不可逆。 粘弹性变形（Viscoelastic Deformation） #\r聚合物材料通常表现出粘弹性变形，即兼具弹性和粘性变形的特性。它们在短时间内表现为弹性变形，但在长时间加载下逐渐表现出粘性变形。不同聚合物在粘弹性方面有所差异：\nLimits of the noodle model #\r一个模型几乎总是有缺点的。 如果不是这样，我们就会称之为定律 再次考虑前面提到的Transparent Glass， 我们说过，部分原因是由于这种聚合物是完全无定形的，这是事实 但是，这并不能解释为什么Amorphous Polymer本身就应该是透明的 要真正理解这一点，我们需要进一步了解可见光的本质以及光与材料中电子的相互作用 这是因为材料的透明性主要取决于光在其中的传播方式 当可见光照射到材料上时，光会与材料中的电子发生相互作用，而这种相互作用的方式决定了光是被吸收、反射还是通过材料 在透明的非晶态聚合物（如Plexiglas®）中，分子的电子结构允许可见光穿过，而不会显著散射或吸收光，因此表现出透明性。 相比之下，在非晶态金属中，电子结构密集且自由度较高，能够大量吸收和反射光，从而使材料表现为不透明和反光 ","date":"Nov 10 2024","externalUrl":null,"permalink":"/docs/engineering-chemistry--materials-science/ecms6.plastics/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/10/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003ePolymer 聚合物 \r\n    \u003cdiv id=\"polymer-%E8%81%9A%E5%90%88%E7%89%A9\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#polymer-%E8%81%9A%E5%90%88%E7%89%A9\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e前缀“poly-”意指“很多”，暗示了这些聚合物分子结构中有许多重复的部分。\u003c/li\u003e\n\u003cli\u003e而“mer”指的是“重复单元”或“基元”，这是一种分子的基本单元\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eBasic Structure \r\n    \u003cdiv id=\"basic-structure\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#basic-structure\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e与Crystal Structure不同，他们的基本结构是Cubics。并且其会在三维空间（即沿着三个方向）重复排列，形成一个规则的晶体结构\u003c/li\u003e\n\u003cli\u003ePolymer的结构则不同，它的基元通常只在One Dimnesion上重复，这种重复形成了一条长链\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS6.Plastics/ECMS6.Plastics.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"MCMS 6. Plastics","type":"docs"},{"content":" Last Edit: 11/4/2024\nYour browser does not support the video tag. Full Code is Provided\nimport numpy as np import torch import random class LinearRegression(Scene): def construct(self): def data_generator(w,b,num): X = torch.normal(0, 1, (num, len(w))) y = torch.matmul(X, w) + b y += torch.normal(0, 0.01, y.shape) return X, y.reshape((-1, 1)) true_w = torch.tensor([2,-3.4]) true_b = 4.2 features, labels = data_generator(true_w,true_b,1000) normal_data = features[:,[0]].numpy() #plt.hist(normal_data,bins=100,density=True,color=\u0026#39;lightblue\u0026#39;) head = Text(\u0026#34;Linear Regression - Buezwqwg\u0026#34;) head.set_color(BLUE) self.play(Create(head)) head_0 = Text(\u0026#34;In one process of Linear Regression, there bascially includes 5 steps\u0026#34;,font_size=30) self.play(Uncreate(head),Write(head_0)) self.play(head_0.animate.move_to(UP*3.5)) head_1 = Text(\u0026#34;1. Initial Parameters\u0026#34;,font_size=30) head_2 = Text(\u0026#34;2. Defining Model and Loss Function\u0026#34;,font_size=30) head_3 = Text(\u0026#34;3. Optimization\u0026#34;,font_size=30) head_4 = Text(\u0026#34;4. Loop\u0026#34;,font_size=30) head = VGroup(head_1,head_2,head_3,head_4) head.arrange(DOWN) self.play(Write(head)) # -------------------------------------------------------------------------------------------- head_5 = Text(\u0026#34;In this animate, we start with generating the data\u0026#34;,font_size=30) head_5.move_to(UP*3.5) self.play(Uncreate(head),Uncreate(head_0),Write(head_5)) code_text = \u0026#39;\u0026#39;\u0026#39; def data_generator(w, b, num): X = torch.normal(0, 1, (num, len(w))) y = torch.matmul(X, w) + b y += torch.normal(0, 0.01, y.shape) return X, y.reshape((-1, 1)) true_w = torch.tensor([2,-3.4]) true_b = 4.2 features, labels = data_generator(true_w,true_b,1000) \u0026#39;\u0026#39;\u0026#39; code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;) self.play(Write(code),Uncreate(head_5),run_time=3) self.wait(3) self.play(Unwrite(code)) axes = Axes( x_range=[-4, 4, 1], y_range=[0, 0.5, 0.1], axis_config={\u0026#34;color\u0026#34;: BLUE}, ).add_coordinates() # 正态分布函数 y = (1/sqrt(2*pi)) * exp(-x^2 / 2) normal_curve = axes.plot( lambda x: (1 / (2 * PI) ** 0.5) * np.exp(-x**2 / 2), color=YELLOW ) # 绘制均值为0的竖线 mean_line = DashedLine( start=axes.c2p(0, 0), end=axes.c2p(0, (1 / (2 * PI) ** 0.5)), color=RED ) # 添加图形和标注 self.play(Create(axes)) self.play(Create(normal_curve), Create(mean_line)) # 标注均值和标准差 mean_label = MathTex(r\u0026#34;\\mu=0\u0026#34;).next_to(mean_line, DOWN) std_label = MathTex(r\u0026#34;\\sigma=1\u0026#34;).next_to(normal_curve, UP, buff=0.5) self.play(Write(mean_label), Write(std_label)) # 展示最终效果 self.wait(2) self.play(Unwrite(mean_label),Unwrite(std_label),Uncreate(axes),Uncreate(normal_curve),Uncreate(mean_line)) # -------------------------------------------------------------------------------------------- head = Text(\u0026#34;Displaying the distribution of features\u0026#34;) feature_one = features[:,[0]].tolist() feature_two = features[:,[1]].tolist() labels = labels.tolist() axes_1 = Axes( x_range=[min(feature_one)[0], max(feature_one)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=5, # x轴的长度 y_length=5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes_2 = Axes( x_range=[min(feature_two)[0], max(feature_two)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=5, # x轴的长度 y_length=5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes = VGroup(axes_1,axes_2) axes.arrange(RIGHT,buff=1) self.play(Create(axes)) points_1 = [] for i in range(len(labels)): dot_position = axes_1.coords_to_point(feature_one[i][0], labels[i][0]) points_1.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_1 = [Create(dot) for dot in points_1] points_2 = [] for i in range(len(labels)): dot_position = axes_2.coords_to_point(feature_two[i][0], labels[i][0]) points_2.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_2 = [Create(dot) for dot in points_2] self.play(Succession(*animations_1, lag_ratio=0.005),Succession(*animations_2, lag_ratio=0.005)) # 抽取样本-------------------------------------------------------------------------------------------- head = Text(\u0026#39;Shuffle the data and divided into samples(batches)\u0026#39;,font_size=30) self.play(Uncreate(axes),Write(head),Uncreate(VGroup(*points_1)),Uncreate(VGroup(*points_2))) head.move_to(UP*3.5) code_text = \u0026#39;\u0026#39;\u0026#39; def data_iter(batch_size,features,labels): num = len(features) index = list(range(num)) random.shuffle(index) for i in range(0,num,batch_size): batch_index = torch.tensor(index[i:min(i+batch_size,num)]) yield features[batch_index], labels[batch_index] \u0026#39;\u0026#39;\u0026#39; code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;) self.play(Write(code)) self.wait(2) self.play(Uncreate(code),Unwrite(head)) def data_iter(batch_size,features,labels): num = len(features) index = list(range(num)) random.shuffle(index) for i in range(0,num,batch_size): batch_index = torch.tensor(index[i:min(i+batch_size,num)]) return batch_index.tolist() axes_1 = Axes( x_range=[min(feature_one)[0], max(feature_one)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=2.5, # x轴的长度 y_length=2.5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes_2 = Axes( x_range=[min(feature_one)[0], max(feature_one)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=2.5, # x轴的长度 y_length=2.5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes_3 = Axes( x_range=[min(feature_one)[0], max(feature_one)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=2.5, # x轴的长度 y_length=2.5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes_4 = Axes( x_range=[min(feature_one)[0], max(feature_one)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=2.5, # x轴的长度 y_length=2.5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes_5 = Axes( x_range=[min(feature_one)[0], max(feature_one)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=2.5, # x轴的长度 y_length=2.5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes = VGroup(axes_1,axes_2,axes_3,axes_4,axes_5) axes.arrange(RIGHT) sample_1 = data_iter(10,features,labels) points_1 = [] for i in sample_1: dot_position = axes_1.coords_to_point(features[i][0],labels[i][0]) points_1.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_1 = [Create(dot) for dot in points_1] sample_2 = data_iter(10,features,labels) points_2 = [] for i in sample_2: dot_position = axes_2.coords_to_point(features[i][0],labels[i][0]) points_2.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_2 = [Create(dot) for dot in points_2] sample_3 = data_iter(10,features,labels) points_3 = [] for i in sample_3: dot_position = axes_3.coords_to_point(features[i][0],labels[i][0]) points_3.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_3 = [Create(dot) for dot in points_3] sample_4 = data_iter(10,features,labels) points_4 = [] for i in sample_4: dot_position = axes_4.coords_to_point(features[i][0],labels[i][0]) points_4.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_4 = [Create(dot) for dot in points_4] sample_5 = data_iter(10,features,labels) points_5 = [] for i in sample_5: dot_position = axes_5.coords_to_point(features[i][0],labels[i][0]) points_5.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_5 = [Create(dot) for dot in points_5] head = Text(\u0026#34;Display five of Sample Batches (Batch Size = 10)\u0026#34;,font_size=30) head.set_color(BLUE) head.move_to(UP*2.5) self.play(Write(head)) self.play(Create(axes),Succession(*animations_1, lag_ratio=0.05),Succession(*animations_2, lag_ratio=0.05),Succession(*animations_3, lag_ratio=0.05),Succession(*animations_4, lag_ratio=0.05),Succession(*animations_5, lag_ratio=0.05)) self.wait(3) self.play(Uncreate(axes),Uncreate(head),Uncreate(VGroup(*points_1)),Uncreate(VGroup(*points_2)),Uncreate(VGroup(*points_3)),Uncreate(VGroup(*points_4)),Uncreate(VGroup(*points_5))) # 定义模型-------------------------------------------------------------------------------------------- head_1 = Text(\u0026#39;Define the Function\u0026#39;) head_1.set_color(BLUE) code_text_1 = \u0026#39;\u0026#39;\u0026#39; def linreg(X, w, b): return torch.matmul(X, w) + b \u0026#39;\u0026#39;\u0026#39; code_1 = Code(code=code_text_1,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;) head_2 = Text(\u0026#39;Define the Loss Function\u0026#39;) head_2.set_color(BLUE) code_text_2 = \u0026#39;\u0026#39;\u0026#39; def squared_loss(y_hat, y): return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2 \u0026#39;\u0026#39;\u0026#39; code_2 = Code(code=code_text_2,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;) head = VGroup(head_1,code_1,head_2,code_2) head.arrange(DOWN,buff=1) self.play(Write(head)) self.wait(2) self.play(Unwrite(head)) # 展示MSE-------------------------------------------------------------------------------------------- head = MathTex(r\u0026#34;Lose~Function~MSE~:(y_i - \\hat{y}_i)^2\u0026#34;) head.set_color(BLUE) head.move_to(UP*3) self.play(Write(head)) axes = Axes( x_range=[-10, 10, 2.5], y_range=[0, 100, 20], x_length=10, y_length=5, axis_config={\u0026#34;color\u0026#34;: GREEN}, ) # 定义MSE函数 mse_curve = axes.plot(lambda x: (x**2), color=BLUE, x_range=[-10, 10]) mse_der = axes.plot(lambda x: (2*x), color=RED, x_range=[-10, 10]) # 将元素添加到场景中 self.play(Create(axes),Create(mse_curve)) self.wait(2) self.play(Uncreate(head)) head = Text(\u0026#34;The MSE Derivative indicates that loss will be increasing as it increase\u0026#34;,font_size=30) head.set_color(BLUE) head.move_to(UP*3) self.play(Write(head),Create(mse_der)) self.wait(3) self.play(Uncreate(head),Uncreate(mse_der),Uncreate(mse_curve),Uncreate(axes)) # 展示SGD-------------------------------------------------------------------------------------------- head = Text(\u0026#34;Now Conduct the Optimization Method\u0026#34;) head.move_to(UP*3) head.set_color(BLUE) code_text = \u0026#39;\u0026#39;\u0026#39; def sgd(params, lr, batch_size): with torch.no_grad(): for param in params: param -= lr * param.grad / batch_size param.grad.zero_() \u0026#39;\u0026#39;\u0026#39; code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;) head_2 = Text(\u0026#39;Apply this optimization method for each batch\u0026#39;) head_2.set_color(BLUE) sgd = MathTex(r\u0026#34;(w,b)\\leftarrow (w,b)-\\eta g\u0026#34;) main = VGroup(head,code,head_2,sgd) main.arrange(DOWN,buff=0.7) self.play(Write(main)) self.wait(2) self.play(Uncreate(main),run_time=0.1) # 计算梯度-------------------------------------------------------------------------------------------- head = Text(\u0026#34;Now Calculate the Gradient\u0026#34;) head.set_color(BLUE) head.move_to(UP*3) grad = MathTex(r\u0026#34;\\frac{\\partial \\text{MSE}}{\\partial w} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\partial}{\\partial w} \\left( y_i - (w x_i + b) \\right)^2\u0026#34;) grad_1 = MathTex(r\u0026#34;= \\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - (wx_i + b)) \\cdot (-x_i)\u0026#34;) grad_2 = MathTex(r\u0026#34;= -\\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - \\hat{y}_i) \\cdot x_i\u0026#34;) main = VGroup(head,grad,grad_1,grad_2) main.arrange(DOWN,buff=0.7) self.play(Write(main)) self.wait(2) self.play(Uncreate(main),run_time=0.01) head = Text(\u0026#34;Then apllies the formula for 1000/10=100 Times\u0026#34;,font_size=45) head.set_color(BLUE) grad = MathTex(r\u0026#39;w := w + \\eta \\cdot \\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - \\hat{y}_i) \\cdot x_i\u0026#39;) grad_1 = MathTex(r\u0026#34;b := b + \\eta \\cdot \\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - \\hat{y}_i)\u0026#34;) main = VGroup(head,grad,grad_1) main.arrange(DOWN,buff=0.7) self.play(Write(main)) self.wait(3) self.play(Uncreate(main),run_time=0.01) # 总结-------------------------------------------------------------------------------------------- code_text = \u0026#39;\u0026#39;\u0026#39; lr = 0.03 num_epochs = 3 net = linreg loss = squared_loss for epoch in range(num_epochs): for X, y in data_iter(batch_size, features, labels): l = loss(net(X, w, b), y) l.sum().backward() sgd([w, b], lr, batch_size) with torch.no_grad(): train_l = loss(net(features, w, b), labels) print(f\u0026#39;epoch {epoch + 1}, loss {float(train_l.mean()):f}\u0026#39;) \u0026#39;\u0026#39;\u0026#39; code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;) head = Text(\u0026#34;Then applies the whole process in epochs and that\u0026#39;s linear regression\u0026#34;,font_size=30) main = VGroup(head,code) main.arrange(DOWN,buff=1) self.play(Write(main)) --- ","date":"Nov 4 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/linearregression/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/4/2024\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cvideo width=\"640\" height=\"360\" controls\u003e\n  \u003csource src=\"LinearRegression.mp4\" type=\"video/mp4\"\u003e\n  Your browser does not support the video tag.\n\u003c/video\u003e\n\u003cp\u003eFull Code is Provided\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-from\" data-lang=\"from\"\u003eimport numpy as np\nimport torch\nimport random\n\nclass LinearRegression(Scene):\n    def construct(self):\n        def data_generator(w,b,num):\n            X = torch.normal(0, 1, (num, len(w)))\n            y = torch.matmul(X, w) + b\n            y += torch.normal(0, 0.01, y.shape)\n            return X, y.reshape((-1, 1))\n\n        true_w = torch.tensor([2,-3.4])\n        true_b = 4.2\n        features, labels = data_generator(true_w,true_b,1000)\n        normal_data = features[:,[0]].numpy()\n        #plt.hist(normal_data,bins=100,density=True,color=\u0026#39;lightblue\u0026#39;)  \n         \n\n        head = Text(\u0026#34;Linear Regression - Buezwqwg\u0026#34;)\n        head.set_color(BLUE)\n        self.play(Create(head))\n\n        head_0 = Text(\u0026#34;In one process of Linear Regression, there bascially includes 5 steps\u0026#34;,font_size=30)\n        self.play(Uncreate(head),Write(head_0))\n        self.play(head_0.animate.move_to(UP*3.5))\n        head_1 = Text(\u0026#34;1. Initial Parameters\u0026#34;,font_size=30)\n        head_2 = Text(\u0026#34;2. Defining Model and Loss Function\u0026#34;,font_size=30)\n        head_3 = Text(\u0026#34;3. Optimization\u0026#34;,font_size=30)\n        head_4 = Text(\u0026#34;4. Loop\u0026#34;,font_size=30)\n        head = VGroup(head_1,head_2,head_3,head_4)\n        head.arrange(DOWN)\n        self.play(Write(head))\n\n        # --------------------------------------------------------------------------------------------\n\n        head_5 = Text(\u0026#34;In this animate, we start with generating the data\u0026#34;,font_size=30)\n        head_5.move_to(UP*3.5)\n        self.play(Uncreate(head),Uncreate(head_0),Write(head_5))\n        code_text = \u0026#39;\u0026#39;\u0026#39;\n        def data_generator(w, b, num):\n            X = torch.normal(0, 1, (num, len(w)))\n            y = torch.matmul(X, w) + b\n            y += torch.normal(0, 0.01, y.shape)\n            return X, y.reshape((-1, 1))\n            \n        true_w = torch.tensor([2,-3.4])\n        true_b = 4.2\n        features, labels = data_generator(true_w,true_b,1000)\n        \u0026#39;\u0026#39;\u0026#39;\n        code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;)\n        self.play(Write(code),Uncreate(head_5),run_time=3)\n        self.wait(3)\n        self.play(Unwrite(code))\n        axes = Axes(\n            x_range=[-4, 4, 1],\n            y_range=[0, 0.5, 0.1],\n            axis_config={\u0026#34;color\u0026#34;: BLUE},\n        ).add_coordinates()\n\n        # 正态分布函数 y = (1/sqrt(2*pi)) * exp(-x^2 / 2)\n        normal_curve = axes.plot(\n            lambda x: (1 / (2 * PI) ** 0.5) * np.exp(-x**2 / 2),\n            color=YELLOW\n        )\n\n        # 绘制均值为0的竖线\n        mean_line = DashedLine(\n            start=axes.c2p(0, 0),\n            end=axes.c2p(0, (1 / (2 * PI) ** 0.5)),\n            color=RED\n        )\n\n        # 添加图形和标注\n        self.play(Create(axes))\n        self.play(Create(normal_curve), Create(mean_line))\n        \n        # 标注均值和标准差\n        mean_label = MathTex(r\u0026#34;\\mu=0\u0026#34;).next_to(mean_line, DOWN)\n        std_label = MathTex(r\u0026#34;\\sigma=1\u0026#34;).next_to(normal_curve, UP, buff=0.5)\n        self.play(Write(mean_label), Write(std_label))\n\n        # 展示最终效果\n        self.wait(2)\n        self.play(Unwrite(mean_label),Unwrite(std_label),Uncreate(axes),Uncreate(normal_curve),Uncreate(mean_line))\n\n        # --------------------------------------------------------------------------------------------\n\n        head = Text(\u0026#34;Displaying the distribution of features\u0026#34;)\n        feature_one = features[:,[0]].tolist()\n        feature_two = features[:,[1]].tolist()\n        labels = labels.tolist()\n        axes_1 = Axes(\n            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=5,  # x轴的长度\n            y_length=5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        axes_2 = Axes(\n            x_range=[min(feature_two)[0], max(feature_two)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=5,  # x轴的长度\n            y_length=5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        axes = VGroup(axes_1,axes_2)\n        axes.arrange(RIGHT,buff=1)\n        self.play(Create(axes))\n\n        points_1 = []\n        for i in range(len(labels)):\n            dot_position = axes_1.coords_to_point(feature_one[i][0], labels[i][0])\n            points_1.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_1 = [Create(dot) for dot in points_1]\n        points_2 = []\n        for i in range(len(labels)):\n            dot_position = axes_2.coords_to_point(feature_two[i][0], labels[i][0])\n            points_2.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_2 = [Create(dot) for dot in points_2]\n        self.play(Succession(*animations_1, lag_ratio=0.005),Succession(*animations_2, lag_ratio=0.005))\n\n        # 抽取样本-------------------------------------------------------------------------------------------- \n\n        head = Text(\u0026#39;Shuffle the data and divided into samples(batches)\u0026#39;,font_size=30)\n        self.play(Uncreate(axes),Write(head),Uncreate(VGroup(*points_1)),Uncreate(VGroup(*points_2)))\n        head.move_to(UP*3.5)\n        code_text = \u0026#39;\u0026#39;\u0026#39;\n        def data_iter(batch_size,features,labels):\n            num = len(features)\n            index = list(range(num))\n            random.shuffle(index)\n            for i in range(0,num,batch_size):\n                batch_index = torch.tensor(index[i:min(i+batch_size,num)])\n                yield features[batch_index], labels[batch_index]\n        \u0026#39;\u0026#39;\u0026#39;\n        code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;)\n        self.play(Write(code))\n        self.wait(2)\n        self.play(Uncreate(code),Unwrite(head))\n\n        def data_iter(batch_size,features,labels):\n            num = len(features)\n            index = list(range(num))\n            random.shuffle(index)\n            for i in range(0,num,batch_size):\n                batch_index = torch.tensor(index[i:min(i+batch_size,num)])\n                return batch_index.tolist()\n\n\n\n        axes_1 = Axes(\n            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=2.5,  # x轴的长度\n            y_length=2.5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        \n\n        axes_2 = Axes(\n            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=2.5,  # x轴的长度\n            y_length=2.5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        \n        axes_3 = Axes(\n            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=2.5,  # x轴的长度\n            y_length=2.5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        axes_4 = Axes(\n            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=2.5,  # x轴的长度\n            y_length=2.5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        axes_5 = Axes(\n            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=2.5,  # x轴的长度\n            y_length=2.5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        axes = VGroup(axes_1,axes_2,axes_3,axes_4,axes_5)\n        axes.arrange(RIGHT)\n\n        sample_1 = data_iter(10,features,labels)\n        points_1 = []\n        for i in sample_1:\n            dot_position = axes_1.coords_to_point(features[i][0],labels[i][0])\n            points_1.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_1 = [Create(dot) for dot in points_1]\n\n        sample_2 = data_iter(10,features,labels)\n        points_2 = []\n        for i in sample_2:\n            dot_position = axes_2.coords_to_point(features[i][0],labels[i][0])\n            points_2.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_2 = [Create(dot) for dot in points_2]\n\n        sample_3 = data_iter(10,features,labels)\n        points_3 = []\n        for i in sample_3:\n            dot_position = axes_3.coords_to_point(features[i][0],labels[i][0])\n            points_3.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_3 = [Create(dot) for dot in points_3]\n\n        sample_4 = data_iter(10,features,labels)\n        points_4 = []\n        for i in sample_4:\n            dot_position = axes_4.coords_to_point(features[i][0],labels[i][0])\n            points_4.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_4 = [Create(dot) for dot in points_4]\n\n        sample_5 = data_iter(10,features,labels)\n        points_5 = []\n        for i in sample_5:\n            dot_position = axes_5.coords_to_point(features[i][0],labels[i][0])\n            points_5.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_5 = [Create(dot) for dot in points_5]   \n        head = Text(\u0026#34;Display five of Sample Batches (Batch Size = 10)\u0026#34;,font_size=30)\n        head.set_color(BLUE)\n        head.move_to(UP*2.5)\n        self.play(Write(head))\n        self.play(Create(axes),Succession(*animations_1, lag_ratio=0.05),Succession(*animations_2, lag_ratio=0.05),Succession(*animations_3, lag_ratio=0.05),Succession(*animations_4, lag_ratio=0.05),Succession(*animations_5, lag_ratio=0.05))\n        self.wait(3)\n        self.play(Uncreate(axes),Uncreate(head),Uncreate(VGroup(*points_1)),Uncreate(VGroup(*points_2)),Uncreate(VGroup(*points_3)),Uncreate(VGroup(*points_4)),Uncreate(VGroup(*points_5)))\n\n        # 定义模型-------------------------------------------------------------------------------------------- \n\n        head_1 = Text(\u0026#39;Define the Function\u0026#39;)\n        head_1.set_color(BLUE)\n        code_text_1 = \u0026#39;\u0026#39;\u0026#39;\n        def linreg(X, w, b):\n            return torch.matmul(X, w) + b\n        \u0026#39;\u0026#39;\u0026#39;\n        code_1 = Code(code=code_text_1,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;)\n        head_2 = Text(\u0026#39;Define the Loss Function\u0026#39;)\n        head_2.set_color(BLUE)\n        code_text_2 = \u0026#39;\u0026#39;\u0026#39;\n        def squared_loss(y_hat, y):\n            return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\n        \u0026#39;\u0026#39;\u0026#39;\n\n\n        code_2 = Code(code=code_text_2,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;)\n        head = VGroup(head_1,code_1,head_2,code_2)\n        head.arrange(DOWN,buff=1)\n        self.play(Write(head))\n        self.wait(2)\n        self.play(Unwrite(head))\n\n        # 展示MSE--------------------------------------------------------------------------------------------    \n        head = MathTex(r\u0026#34;Lose~Function~MSE~:(y_i - \\hat{y}_i)^2\u0026#34;)\n        head.set_color(BLUE)\n        head.move_to(UP*3)\n        self.play(Write(head))\n        axes = Axes(\n            x_range=[-10, 10, 2.5],\n            y_range=[0, 100, 20],\n            x_length=10,\n            y_length=5,\n            axis_config={\u0026#34;color\u0026#34;: GREEN},\n        )\n        \n        # 定义MSE函数\n        mse_curve = axes.plot(lambda x: (x**2), color=BLUE, x_range=[-10, 10])\n        mse_der = axes.plot(lambda x: (2*x), color=RED, x_range=[-10, 10])\n        # 将元素添加到场景中\n        self.play(Create(axes),Create(mse_curve))\n        self.wait(2)\n        self.play(Uncreate(head))\n        head = Text(\u0026#34;The MSE Derivative indicates that loss will be increasing as it increase\u0026#34;,font_size=30)\n        head.set_color(BLUE)\n        head.move_to(UP*3)\n        self.play(Write(head),Create(mse_der))\n        self.wait(3)\n        self.play(Uncreate(head),Uncreate(mse_der),Uncreate(mse_curve),Uncreate(axes))\n\n\n        # 展示SGD--------------------------------------------------------------------------------------------\n        head = Text(\u0026#34;Now Conduct the Optimization Method\u0026#34;)\n        head.move_to(UP*3)\n        head.set_color(BLUE)\n        code_text = \u0026#39;\u0026#39;\u0026#39;\n        def sgd(params, lr, batch_size):\n        with torch.no_grad():\n            for param in params:\n                param -= lr * param.grad / batch_size\n                param.grad.zero_()\n        \u0026#39;\u0026#39;\u0026#39;\n        code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;)\n        head_2 = Text(\u0026#39;Apply this optimization method for each batch\u0026#39;)\n        head_2.set_color(BLUE)\n        sgd = MathTex(r\u0026#34;(w,b)\\leftarrow (w,b)-\\eta g\u0026#34;)\n        main = VGroup(head,code,head_2,sgd)\n        main.arrange(DOWN,buff=0.7)\n        self.play(Write(main))\n        self.wait(2)\n        self.play(Uncreate(main),run_time=0.1)\n        \n        # 计算梯度--------------------------------------------------------------------------------------------\n        head = Text(\u0026#34;Now Calculate the Gradient\u0026#34;)\n        head.set_color(BLUE)\n        head.move_to(UP*3)\n        grad = MathTex(r\u0026#34;\\frac{\\partial \\text{MSE}}{\\partial w} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\partial}{\\partial w} \\left( y_i - (w x_i + b) \\right)^2\u0026#34;)\n        grad_1 = MathTex(r\u0026#34;= \\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - (wx_i + b)) \\cdot (-x_i)\u0026#34;)\n        grad_2 = MathTex(r\u0026#34;= -\\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - \\hat{y}_i) \\cdot x_i\u0026#34;)\n\n        main = VGroup(head,grad,grad_1,grad_2)\n        main.arrange(DOWN,buff=0.7)\n        self.play(Write(main))\n        self.wait(2)\n        self.play(Uncreate(main),run_time=0.01)\n        head = Text(\u0026#34;Then apllies the formula for 1000/10=100 Times\u0026#34;,font_size=45)\n        head.set_color(BLUE)\n        grad = MathTex(r\u0026#39;w := w + \\eta \\cdot \\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - \\hat{y}_i) \\cdot x_i\u0026#39;)\n        grad_1 = MathTex(r\u0026#34;b := b + \\eta \\cdot \\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - \\hat{y}_i)\u0026#34;)\n        main = VGroup(head,grad,grad_1)\n        main.arrange(DOWN,buff=0.7)\n        self.play(Write(main))\n        self.wait(3)\n        self.play(Uncreate(main),run_time=0.01)\n\n        # 总结--------------------------------------------------------------------------------------------\n        code_text = \u0026#39;\u0026#39;\u0026#39;\n        lr = 0.03\n        num_epochs = 3\n        net = linreg\n        loss = squared_loss\n\n        for epoch in range(num_epochs):\n            for X, y in data_iter(batch_size, features, labels):\n                l = loss(net(X, w, b), y)\n                l.sum().backward()\n                sgd([w, b], lr, batch_size)\n            with torch.no_grad():\n                train_l = loss(net(features, w, b), labels)\n                print(f\u0026#39;epoch {epoch + 1}, loss {float(train_l.mean()):f}\u0026#39;)\n        \u0026#39;\u0026#39;\u0026#39;\n        code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;)\n        head = Text(\u0026#34;Then applies the whole process in epochs and that\u0026#39;s linear regression\u0026#34;,font_size=30)\n        main = VGroup(head,code)\n        main.arrange(DOWN,buff=1)\n        self.play(Write(main))\n---\n\u003c/code\u003e\u003c/pre\u003e","title":"Linear Regression","type":"docs"},{"content":" Last Edit: 10/24/24\nIntroduction to Determinate #\r行列式是一个每个方阵都具有的数值 Determinate measures the factor by which the area of a given region increases or decreases The \u0026ldquo;determinant\u0026rdquo; of a transformation Determinate in R^2 #\rDeterminant计算的是Linear Transformation改变的Basis Vector所围成的面积的大小\n而对于一个Linear Transformation，大部分情况下Basis Vector围成的面积都是一个长方形\n而[[MAT188 Chapter 2 Linear Transformations#2.2 Linear Transformations in Geometry]]中存在一种Sheer Transformation，即对于一个Basis Vector来说，其出现了不属于其方向上的分量\n如上图中的\\(\\vec e_2\\)来说，其为\u0026lt;2,2\u0026gt;，即产生了Sheer\n在这种情况下，所围成的面积便成为了Parallelogram\n于是就有了两种计算\\(\\mathbb R^2\\)行列式的办法 $$det(A)=|A||B|sin\\theta$$ 这个平行四边形同时适用于Cross Product于Determinate\n这一个公式同样也是[[Cross Product 向量叉乘]]的大小（Norm），同时也是一个3x3Determinate的大小（体积）\n如果说Cross Product要找的是一个向量，Determinate要找的则是一个体积\n总的来说，要找\\(R^2\\)中的Determinate的值，其本质在求Linear Transformation后Basis Vector围成的面积\n而这一个面积可以通过\\(|A||B|sin\\theta\\)求，其同时也可以通过\n两个向量的Position Vector上的点的差值求 其最后化简之后便有 $$\\text{det} \\left( \\begin{bmatrix} a \u0026amp; b \\ c \u0026amp; d \\end{bmatrix} \\right) = (a + b)(c + d) - ac - bd - 2bc = ad - bc $$ 这便是Determinate最初的定义 The Determinate of a 3x3 Matrix #\r$$A = \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; a_{13} \\ a_{21} \u0026amp; a_{22} \u0026amp; a_{23} \\ a_{31} \u0026amp; a_{32} \u0026amp; a_{33} \\end{bmatrix} = \\begin{bmatrix} | \u0026amp; | \u0026amp; | \\ \\vec{u} \u0026amp; \\vec{v} \u0026amp; \\vec{w} \\ | \u0026amp; | \u0026amp; | \\end{bmatrix} $$\n3x3的Matrix的Determinate的几何意义为在\\(\\mathbb R^3\\)中的Parallelepiped的Volume 而对于\\(\\mathbb R^3\\)中的三个向量来说，如果它们线性相关（如共面，即两个向量可以通过Lienar Conbination得到第三个向量的情况下），则他们在3x3Determinate的几何意义也是就是体积便不再存在，其是一个高度为0的长方体 具体来说判断的方法便是\\(\\vec{u} \\cdot (\\vec{v} \\times \\vec{w}) = 0\\)，见下图 Determinate为0的几何意义 #\r具体来说，当\\(det(A)=0\\)的时候，其相当于一个Linear Transformation至少压缩了一个维度 而在维度被压缩之后，此过程并不可逆，见下图 Definition 6.1.1 Determinant of a 3 × 3 matrix, in terms of the Columns #\r在上面提到过了行列式的几何意义为体积，而\\(\\vec u,\\vec v\\)并不会一直出现在xy Plane中，要计算其体积，基本上要用底面积乘以高的形式 而底面积则可以通过\\(\\vec c= \\vec v\\times \\vec w\\)的Cross Product，同时求出其大小与方向 具体来说，其大小即为\\(|u|\\)，而其方向应该是垂直于vw Plane的 而将\\(\\vec u\\cdot \\vec c\\)时，则可以得到Determinate中的第三个Vetor在一个垂直于vw Plane的同时具有方向和大小的向量\\(\\vec c\\)上的Projection长度乘以其向量\\(\\vec c\\)（本身Norm为vw所围成的平行四边形的面积） 则最终得到Determinate中的第三个向量\\(\\vec u\\)在一个垂直于vw Plane的方向上的分量，在几何意义上来说为平行六面体的高 和一个\\(\\vec v\\times \\vec w\\)所得到的两个向量围成的平行四边形的长度，即平行六面体的底面积 两者相乘便可以得到该3x3 Matrix Determinate的值，即这三个Vector所围成的Parallelepiped体积\\ $$\\begin{align}\\text{det} , A = \\vec{u} \\cdot (\\vec{v} \\times \\vec{w}) \\ = \\begin{bmatrix} a_{11} \\ a_{21} \\ a_{31} \\end{bmatrix} \\cdot \\left( \\begin{bmatrix} a_{12} \\ a_{22} \\ a_{32} \\end{bmatrix} \\times \\begin{bmatrix} a_{13} \\ a_{23} \\ a_{33} \\end{bmatrix} \\right) \\ = \\begin{bmatrix} a_{11} \\ a_{21} \\ a_{31} \\end{bmatrix} \\cdot \\begin{bmatrix} a_{22}a_{33} - a_{32}a_{23} \\ a_{32}a_{13} - a_{12}a_{33} \\ a_{12}a_{23} - a_{22}a_{13} \\end{bmatrix} \\ = a_{11}(a_{22}a_{33} - a_{32}a_{23}) + a_{21}(a_{32}a_{13} - a_{12}a_{33}) + a_{31}(a_{12}a_{23} - a_{22}a_{13}) \\ = a_{11}a_{22}a_{33} - a_{11}a_{32}a_{23} + a_{21}a_{32}a_{13} - a_{21}a_{12}a_{33} + a_{31}a_{12}a_{23} - a_{31}a_{22}a_{13}\\end{align} $$\n上述介绍的所有都是有助于理解Determinant的而非考试的重点，意义在于理解，正式的内容将从下面开始\nProperties of Determinant #\rLinearity of Determinant #\r行列式对任何一列或一行都是线性的 也就是说，当我们把一列（或一行）表示为两个向量的和或乘以一个标量时，行列式也可以相应地拆分为两个行列式的和，或乘以标量 当有如下Determinate时 $$L(\\vec{x}) = \\text{det} \\left( \\begin{bmatrix}\r- \u0026 \\vec{v}_1 \u0026 - \\\\\r- \u0026 \\vec{v}_2 \u0026 - \\\\\r- \u0026 \\vec{x}+\\vec y \u0026 -\r\\end{bmatrix}\r\\right)$$\r- Matrix23位置的值为一个Variable x，而因为det在任意一行，列中都是线性的，即其也满足Linear的两个定义\r$$L(\\vec{x} + \\vec{y}) = L(\\vec{x}) + L(\\vec{y}) \\quad \\text{and} \\quad L(k\\vec{x}) = kL(\\vec{x})$$\r- 在Determinate中有\r$$\\text{det} \\left( \\begin{bmatrix}\r- \u0026 \\vec{v}_1 \u0026 - \\\\\r- \u0026 \\vec{v}_2 \u0026 - \\\\\r- \u0026 \\vec{x} + \\vec{y} \u0026-\r\\end{bmatrix}\r\\right)\r= \\text{det} \\left( \\begin{bmatrix}\r- \u0026 \\vec{v}_1 \u0026 - \\\\\r- \u0026 \\vec{v}_2 \u0026 - \\\\\r- \u0026 \\vec{x} \u0026 -\r\\end{bmatrix}\r\\right)\r+ \\text{det} \\left( \\begin{bmatrix}\r- \u0026 \\vec{v}_1 \u0026 - \\\\\r- \u0026 \\vec{v}_2 \u0026 - \\\\\r- \u0026 \\vec{y} \u0026 -\r\\end{bmatrix}\r\\right)\r$$\r$$\\text{det} \\left( \\begin{bmatrix}\r- \u0026 \\vec{v}_1 \u0026 - \\\\\r- \u0026 \\vec{v}_2 \u0026 - \\\\\r- \u0026 k\\vec{x} \u0026 -\r\\end{bmatrix}\r\\right)\r= k \\, \\text{det} \\left( \\begin{bmatrix}\r- \u0026 \\vec{v}_1 \u0026 - \\\\\r- \u0026 \\vec{v}_2 \u0026 - \\\\\r- \u0026 \\vec{x} \u0026 -\r\\end{bmatrix}\r\\right)\r$$\r- 如果在矩阵的一行乘上 t而剩下的n-1行保持不变，则行列式的值就要乘上 t\r$$\\left| \\begin{array}{cc} ta \u0026 tb \\\\ c \u0026 d \\end{array} \\right| = t \\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|\r$$\r- 同理对于Linear Transformation的另外一个性质也通用 $$\\left| \\begin{array}{cc} a + a' \u0026 b + b' \\\\ c \u0026 d \\end{array} \\right| = \\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right| + \\left| \\begin{array}{cc} a' \u0026 b' \\\\ c \u0026 d \\end{array} \\right|\r$$\r- 需要知道的是，这并不是在说$$det(A+B)=det(A)+det(B)$$\r- 而是对于Square Matrxi的每一行来说是Linear的\rChange of matrix\u0026rsquo;s effect on Determinate #\r当交换矩阵的两行，Determinant的值将会变号 如果你交换一个3×3矩阵的两行，行列式的值也会反号 同理也能知道 $$\\left| \\begin{array}{cc} 0 \u0026 1 \\\\ 1 \u0026 0 \\end{array} \\right| = -1\r$$\rNon-Squre Matrix Can\u0026rsquo;t Have Determinate #\rNon-Squre的Matrix会出现在当有两行是完全相同的时候 其证明可以是，当交换了两个相同的Matrix的Row的时候，其根据[[#Change of matrix\u0026rsquo;s effect on Determinate]]会发生变号，而可以观察发现新的Matrix和原来的没有区别，有Det=-Det，所以det=0 Row Operation\u0026rsquo;s influence on Determinate #\r从矩阵的某行 k 减去另一行 i 的倍数，并不改变行列式的数值（消元的过程不改变行列式） $$\\left| \\begin{array}{cc} a \u0026 b \\\\ c - ta \u0026 d - tb \\end{array} \\right| = \\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right| - \\left| \\begin{array}{cc} a \u0026 b \\\\ ta \u0026 tb \\end{array} \\right|\r$$\r$$= \\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|\r- t \\left| \\begin{array}{cc} a \u0026 b \\\\ a \u0026 b \\end{array} \\right|\r$$\r- 根据[[#Change of matrix's effect on Determinate]]，后一项的Determinant为0，即整体Det不变\rZero Rows Determinant #\r矩阵 A 的某一行都是 0，则其行列式为 0 根据[[#Linearity of Determinate]]可以知道，当t=0的时候， $$\\left| \\begin{array}{cc} ta \u0026 tb \\\\ c \u0026 d \\end{array} \\right| = t \\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|$$\r- 有$$\\left| \\begin{array}{cc} 0\\cdot a \u0026 0\\cdot b \\\\ c \u0026 d \\end{array} \\right|= 0 \\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|$$\r即Determinant为0 Trangular Matrix\u0026rsquo;s Determinant #\r$$\\left| \\begin{array}{cccc} d_1 \u0026 * \u0026 \\cdots \u0026 * \\\\\r0 \u0026 d_2 \u0026 \\cdots \u0026 * \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 \\cdots \u0026 d_n \\end{array} \\right| = \\left| \\begin{array}{cccc} d_1 \u0026 0 \u0026 \\cdots \u0026 0 \\\\\r0 \u0026 d_2 \u0026 \\cdots \u0026 0 \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 \\cdots \u0026 d_n \\end{array} \\right|\r= d_1 d_2 \\cdots d_n\r\\left| \\begin{array}{cccc} 1 \u0026 0 \u0026 \\cdots \u0026 0 \\\\\r0 \u0026 1 \u0026 \\cdots \u0026 0 \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 \\cdots \u0026 1 \\end{array} \\right| = d_1 d_2 \\cdots d_n\r$$\r根据[[#Row Operation\u0026rsquo;s influence on Determinate]]，当是通过Row Operation得到Triangular Matrix的时候，正负号可能发生改变 对于非Diagonal上的元素，根据[[#Row Operation\u0026rsquo;s influence on Determinate]]可以做Row Operation在不改变Determinant的前提下将他们全部消掉，有 $$\\left| \\begin{array}{cccc} d_1 \u0026 * \u0026 \\cdots \u0026 * \\\\\r0 \u0026 d_2 \u0026 \\cdots \u0026 * \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 \\cdots \u0026 d_n \\end{array} \\right|= \\left| \\begin{array}{cccc} d_1 \u0026 0 \u0026 \\cdots \u0026 0 \\\\\r0 \u0026 d_2 \u0026 \\cdots \u0026 0 \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 \\cdots \u0026 d_n \\end{array} \\right|$$\r- 再通过[[#Linearity of Determinate]]提取出每个Row Pivot上的d\r$$= d_1 d_2 \\cdots d_n\r\\left| \\begin{array}{cccc} 1 \u0026 0 \u0026 \\cdots \u0026 0 \\\\\r0 \u0026 1 \u0026 \\cdots \u0026 0 \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 \\cdots \u0026 1 \\end{array} \\right| = d_1 d_2 \\cdots d_n$$\rSingular Matrix\u0026rsquo;s Determinant #\r对于Rank小于Row的Square Matrix，其Determinant为0 Numerial Approach of Determinant #\r当有一个Matrix的时候，想要计算其Determinant，即需要将其化为Triangular Matrix，最简单的方式即为化为Upper Triangular Matrix 而要消成Upper Triangular Matrix的方式即为将C化为0（拿2x2Matrix举例） $$\\left[ \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right] \\rightarrow \\left[ \\begin{array}{cc} a \u0026 b \\\\ 0 \u0026 d - \\frac{c}{a}b \\end{array} \\right]\r$$\r$$\\left| \\begin{array}{cc} a \u0026amp; b \\ c \u0026amp; d \\end{array} \\right| = a \\left( d - \\frac{c}{a}b \\right) = ad - bc $$\nDeterminant of Product #\r\\(det(AB)=det(A)\\cdot det(B)\\) \\(det(A+B)\\neq det(A)+det(B)\\) Determinant of Inverse #\r\\(det(A^{-1})\\) 已知\\(A^{-1}A=I\\)，即\\(det(A^{-1})det(A)=det(I)=1\\) 则有\\(det(A^{-1})=\\frac{1}{det(A)}\\) Determinant of Square #\r\\(det(A^2)=det(A)^2=det(A)\\cdot det(A)\\) Determinant of Coefficient before Matrix #\r\\(det(2A)=2^ndet(A)\\) 对于nxn Matrix来说，犹豫每一个Row都乘上的Coefficient 2，即存在\\(2^n\\)的总系数 Determinant of Transpose #\r\\(det(A^T)=det(A)\\) $$\\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|\r= \\left| \\begin{array}{cc} a \u0026 c \\\\ b \u0026 d \\end{array} \\right|\r= ad - bc\r$$\rFormular for Determinant #\r2x2 #\r$$\\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|\r=\r\\left| \\begin{array}{cc} a \u0026 0 \\\\ c \u0026 d \\end{array} \\right|\r+ \\left| \\begin{array}{cc} 0 \u0026 b \\\\ c \u0026 d \\end{array} \\right|\r=\r\\left| \\begin{array}{cc} a \u0026 0 \\\\ c \u0026 0 \\end{array} \\right|\r+ \\left| \\begin{array}{cc} 0 \u0026 d \\\\ 0 \u0026 d \\end{array} \\right|\r+ \\left| \\begin{array}{cc} 0 \u0026 b \\\\ 0 \u0026 d \\end{array} \\right|\r=\r0 + ad - cb + 0\r=\rad - bc\r$$\r3x3 #\r将每一行拆成3部分，每一部分都对应了不同的行上的不同元素 总共会得到\\(3^3\\)个Matrix即27个，而其中大部分Matrix由于行或列上全为0有Det=0 而其中的非零情况出现在每一列都有的情况下（因为我们是从行出发开始分解的，所以每一行都保证了有值） $$\\left| \\begin{array}{ccc} a_{11} \u0026 a_{12} \u0026 a_{13} \\\\ a_{21} \u0026 a_{22} \u0026 a_{23} \\\\ a_{31} \u0026 a_{32} \u0026 a_{33} \\end{array} \\right|\r=\r\\left| \\begin{array}{ccc} a_{11} \u0026 0 \u0026 0 \\\\ 0 \u0026 a_{22} \u0026 0 \\\\ 0 \u0026 0 \u0026 a_{33} \\end{array} \\right|\r+ \\left| \\begin{array}{ccc} a_{11} \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 a_{23} \\\\ 0 \u0026 a_{32} \u0026 0 \\end{array} \\right|\r+ \\left| \\begin{array}{ccc} 0 \u0026 a_{12} \u0026 0 \\\\ a_{21} \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 a_{33} \\end{array} \\right|\r+ \\left| \\begin{array}{ccc} 0 \u0026 a_{12} \u0026 0 \\\\ 0 \u0026 a_{22} \u0026 0 \\\\ a_{31} \u0026 0 \u0026 0 \\end{array} \\right|\r+ \\left| \\begin{array}{ccc} 0 \u0026 0 \u0026 a_{13} \\\\ a_{21} \u0026 0 \u0026 0 \\\\ 0 \u0026 a_{32} \u0026 0 \\end{array} \\right|\r+ \\left| \\begin{array}{ccc} 0 \u0026 0 \u0026 a_{13} \\\\ 0 \u0026 a_{22} \u0026 0 \\\\ a_{31} \u0026 0 \u0026 0 \\end{array} \\right|\r$$\r$$=\ra_{11}a_{22}a_{33} - a_{11}a_{23}a_{32} - a_{12}a_{21}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32} - a_{13}a_{22}a_{31}$$\r- 其中所有的负值，都是用了[[#Change of matrix's effect on Determinate]]将Matrix做Row Exchange成Uppertriangular Matrix而导致的Determinant的变号\r但这个做法再4x4中并不通用，所以需要从2x2，3x3中推导出nxn的公式 Big Formula A #\r$$det(A)=\\sum_{n!}\\pm a_{1\\alpha}a_{2\\beta}a_{3\\gamma}\\dots a_{n\\omega}$$\r\\(n!\\)：由于我们是用Row做的，即在Row1中有n个Column可以选，而到了Row2中，只有n-1个Column可以选，以此类推可能性即为\\(n!\\) \\(\\alpha,\\beta,\\gamma,\\omega\\)：列标号中的任何值 $$\\left| \\begin{array}{cccc} 0 \u0026 0 \u0026 1 \u0026 1 \\\\ 0 \u0026 1 \u0026 1 \u0026 0 \\\\ 1 \u0026 1 \u0026 0 \u0026 0 \\\\ 1 \u0026 0 \u0026 0 \u0026 1 \\end{array} \\right| =\r\\left| \\begin{array}{cccc} 0 \u0026 0 \u0026 0 \u0026 1 \\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \u0026 0 \\\\ 1 \u0026 0 \u0026 0 \u0026 0 \\end{array} \\right|\r+\r\\left| \\begin{array}{cccc} 0 \u0026 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \u0026 0 \\\\ 1 \u0026 0 \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{array} \\right|\r$$\r分解出的两个Matrix中，第一个需要做两次Row Exchange得到Identity，即为1，而第二个则需要1次Row Exchange就可以得到Identify，即为-1，1-1=0 Cofactor Formula 代数余子式 #\r3x3 #\r代数余子式是用较小的矩阵的行列式来写出 n 阶行列式的公式 $$\\text{det} \\left( \\mathbf{A} \\right) = a_{11} \\left( a_{22}a_{33} - a_{23}a_{32} \\right)\r+ a_{12} \\left( -a_{21}a_{33} + a_{23}a_{31} \\right)\r+ a_{13} \\left( a_{21}a_{32} - a_{22}a_{31} \\right)\r$$\r$$=\\left| \\begin{array}{ccc} a_{11} \u0026 0 \u0026 0 \\\\ 0 \u0026 a_{22} \u0026 a_{23} \\\\ 0 \u0026 a_{32} \u0026 a_{33} \\end{array} \\right|\r+\r\\left| \\begin{array}{ccc} 0 \u0026 a_{12} \u0026 0 \\\\ a_{21} \u0026 0 \u0026 a_{23} \\\\ a_{31} \u0026 0 \u0026 a_{33} \\end{array} \\right|\r+\r\\left| \\begin{array}{ccc} 0 \u0026 0 \u0026 a_{13} \\\\ a_{21} \u0026 a_{22} \u0026 0 \\\\ a_{31} \u0026 a_{32} \u0026 0 \\end{array} \\right|$$\r由于第二个Martri在化为Identity时只需要一次Row Exchange而其他的都需要两次，所以第二个Cofactor为减去 Cofactor Formula #\r将原公式中属于矩阵第一行的\\(a_{ij}\\)提出来，其系数即为代数余子式，是一个低阶行列式的值。这个低阶行列式是由原矩阵去掉\\(a_{ij}\\)所在的行和列组成的。 对矩阵中任意元素\\(a_{ij}\\)而言，其代数余子式\\(C_{ij}\\)j就是矩阵的行列式的公式中\\(a_{ij}\\)的系数 \\(C_{ij}\\)等于原矩阵移除第i行和第j列后剩余元素组成的n-1阶矩阵的行列式数值乘以\\((-1)^{i+j}\\) \\(C_{ij}\\)在 i+j 为偶数时为正，奇数时为负数 则可以总结对于n阶Square Matrix来说，有 $$\\text{det} \\left( \\mathbf{A} \\right) = a_{11} C_{11} + a_{12} C_{12} + \\cdots + a_{1n} C_{1n}\r$$\rex. in 2x2 #\rCofactor Formula最简单的应用即为在2x2 Matrix中，有 $$\\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|\r= ad + b(-c)$$\rex. 三对角阵（tridiagonal matrix） #\r只在Tridiagonal Matrix这种特殊结构中可行 $$\\mathbf{A_4} = \\left[ \\begin{array}{cccc} 1 \u0026 1 \u0026 0 \u0026 0 \\\\ 1 \u0026 1 \u0026 1 \u0026 0 \\\\ 0 \u0026 1 \u0026 1 \u0026 1 \\\\ 0 \u0026 0 \u0026 1 \u0026 1 \\end{array} \\right]\r$$\r![[LA6.Determinats-9.png]]\rFormula for A Inverse #\r已知2阶Matrix的Inverse为 $$\\left[ \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right]\r= \\frac{1}{ad - bc} \\left[ \\begin{array}{cc} d \u0026 -b \\\\ -c \u0026 a \\end{array} \\right]\r$$\r- 通过观察上2x2的例子可以得出\r$$\\mathbf{A}^{-1} = \\frac{1}{\\det(\\mathbf{A})} \\mathbf{C}^\\top$$\r通过观察可以发现d是a的C，-b是c的C，-c是b的C，a是d的C Adjoint Matrix 伴随矩阵 #\r此处的Cofactor的Transpose\\(C^T\\)便可以称为Adjoint Martirx，即伴随矩阵 对于Adjoint Matrix来说，其大小总是原Matrix的Dimension-1即为n-1 Proof of A Inverse #\r已知Gauss Jordan Elimination提到\\([A|I]\\)在A被消成I后，I会变成\\(A^{-1}\\) 同时\\(A^{-1}A=I\\)，现在将\\(\\mathbf{A}^{-1} = \\frac{1}{\\det(\\mathbf{A})} \\mathbf{C}^\\top\\)带入 $$A\\cdot \\mathbf{A}^{-1} = A\\cdot\\frac{1}{\\det(\\mathbf{A})} \\mathbf{C}^\\top=I$$\r$$A\\cdot C^T=det(A)\\cdot I$$\r如果上式成立，则\\(\\mathbf{A}^{-1} = \\frac{1}{\\det(\\mathbf{A})} \\mathbf{C}^\\top\\)为真命题 $$\\mathbf{AC}^T = \\begin{bmatrix} a_{11} \u0026 \\cdots \u0026 a_{1n} \\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ a_{n1} \u0026 \\cdots \u0026 a_{nn} \\end{bmatrix}\r\\begin{bmatrix} C_{11} \u0026 \\cdots \u0026 C_{n1} \\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ C_{1n} \u0026 \\cdots \u0026 C_{nn} \\end{bmatrix}\r$$\r- 对于所有结果矩阵对角线上的的元素来说都有\r$$\\sum_{j=1}^{n} a_{1j} C_{1j} = \\det(\\mathbf{A})$$\r即他们本身就是det(A)的展开式 而现在要研究结果矩阵非对角线上的内容 可以发现每一个非对角线上的元素都将为0 $$AC^T = \\begin{bmatrix}\r\\det A \u0026 0 \u0026 0 \u0026 \\cdots \u0026 0 \\\\\r0 \u0026 \\det A \u0026 0 \u0026 \\cdots \u0026 0 \\\\\r0 \u0026 0 \u0026 \\ddots \u0026 \\cdots \u0026 0 \\\\\r\\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 0 \u0026 \\cdots \u0026 \\det A\r\\end{bmatrix} = \\det(A)I\r$$\rCramer’s Rule 克莱姆法则 #\r对于问题Ax=b来说，其解法很简单的就等于\\(x=A^{-1}B\\) 而在知道了\\(A^{-1}\\)的值之后有 $$\\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b} = \\frac{1}{\\det(\\mathbf{A})} \\mathbf{C}^T \\mathbf{b}$$\r选择乘上\\(C^T\\) 的不再是A而是b了，但一个Matrix乘以一个Cofactor Matrix的做法又令人想到了Determinant，可以发现 $$x_j = \\frac{\\det(\\mathbf{B}_j)}{\\det(\\mathbf{A})}\r$$\r其中每一个\\(B_i\\)都是一个第i列被\\(B_i\\)所替换的Matrix A，具体来说有 $$\\mathbf{B}_1 = \\begin{bmatrix}\rb_1 \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n} \\\\\rb_2 \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n} \\\\\rb_3 \u0026 a_{32} \u0026 \\ddots \u0026 \\vdots \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 a_{n-1\\,n} \\\\\rb_n \u0026 a_{n2} \u0026 \\cdots \u0026 a_{nn}\r\\end{bmatrix}\r, \\quad\r\\mathbf{B}_n = \\begin{bmatrix}\ra_{11} \u0026 \\cdots \u0026 a_{1\\,n-1} \u0026 b_1 \\\\\ra_{21} \u0026 \\cdots \u0026 a_{2\\,n-1} \u0026 b_2 \\\\\r\\vdots \u0026 \\ddots \u0026 \\vdots \u0026 \\vdots \\\\\ra_{n-1\\,1} \u0026 \\cdots \u0026 a_{n-1\\,n-1} \u0026 b_{n-1} \\\\\ra_{n1} \u0026 \\cdots \u0026 a_{n2} \u0026 b_n\r\\end{bmatrix}\r$$\r可以发现等式中的\\(C^T_i \\cdot B_i\\)正好等于\\(B_i\\)的Determinant 其实相比于消元法，采用克莱姆法则计算方程的解效率较低。。。\n","date":"Oct 24 2024","externalUrl":null,"permalink":"/docs/linearalgebra/la6.determiants/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 10/24/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eIntroduction to Determinate \r\n    \u003cdiv id=\"introduction-to-determinate\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#introduction-to-determinate\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e行列式是一个每个方阵都具有的数值\u003c/li\u003e\n\u003cli\u003eDeterminate measures the factor by which the area of a given region increases or decreases\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/LinearAlgebra_Static/LA6.Determinants/LA6.Determinats.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"LA 6. Determinants","type":"docs"},{"content":"","date":"Oct 22 2024","externalUrl":null,"permalink":"/docs/mathematicalanalysis/","section":"Docs","summary":"","title":"Mathematical Analysis","type":"docs"},{"content":"\rYour browser does not support the video tag.\r","date":"Oct 22 2024","externalUrl":null,"permalink":"/docs/displays/projectilemotion/","section":"Docs","summary":"\u003cvideo width=\"640\" height=\"360\" controls\u003e\r\n  \u003csource src=\"Projectile.mp4\" type=\"video/mp4\"\u003e\r\n  Your browser does not support the video tag.\r\n\u003c/video\u003e","title":"Projectile Motion when air resisitance is propftional to velocity","type":"docs"},{"content":" “这种方法虽然简单，却展示了数学中的一种用随机的蛮力对抗精确逻辑的思想方法，一种用数量得到质量的计算思想” - 三体\nYour browser does not support the video tag.\r","date":"Oct 17 2024","externalUrl":null,"permalink":"/docs/displays/montecarlomethod/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003e“这种方法虽然简单，却展示了数学中的一种用随机的蛮力对抗精确逻辑的思想方法，一种用数量得到质量的计算思想” - 三体\u003c/p\u003e","title":"Monte Carlo Approach to Calculate π","type":"docs"},{"content":" Last Edit: 10/16/24\nStress-Strain Curve #\r当回头重新看Stress-Strain Curve的时候可以发现一些特殊的点 如Proportion Limit，Ultimate Tensile Strength两个点 Proportional Limit #\r在曲线的最初阶段，存在一个接近于Linear的区域，其代表了Linear Elastic的Region 而也必会存在一个点象征着Linear Elastic Region的结束 但犹豫一些测量的误差或者精度上的问题，将导致最终的这一个Linear Elastic结束的点无法被确定，所以需要一个约定俗成的方法 0.2% Offset Yield Strength #\r在\\(\\epsilon=0.002\\)的位置画一个平行于Linear Elastic Region的直线，其交于SS Curve的位置即为Yield Strength ex. #\rA hypothetical metal has a 0.2% offset yield strength of 358 MPa, an ultimate tensile strength of 522 MPa, and a fracture strength of 460 MPa. A sample of this metal, originally 1 m in length with a cross section of 2 mm × 2 mm is loaded along its long axis. Just before fracture, while the load is still applied, the length is 1.3 m and when the load is released, the length is 1.18 m. Calculate the modulus of elasticity in GPa.（这我做集贸啊）\n之前有公式\\(\\sigma=E\\epsilon\\) 现在需要将其推广到\\(E=\\frac{\\Delta \\sigma}{\\epsilon}\\)上 \\(\\Delta \\sigma\\)：有460MPa-0MPa=460MPa \\(\\epsilon\\)：有0.3-0.18=0.12 Uniform deformation #\r在经历了Linear Elastic Region后，出现的便是Uniform Platic区间 这个阶段内，材料的塑性变形均匀地分布在整个试样或构件中 其具体的Unifrom体现在了变形过程中结构的完整性上 在Non-Unifrom Region中，材料已经发生了局部的Fracture，即产生了Neck 这也解释了为什么在过了Ultimate Tensile strength后Stress开始下降，即当金属样品承受的应力值逐渐增大时，最终会开始失效。 在拉伸过程中，当金属原子间的一些键断裂时，就会出现这种情况 The Dislocation #\rDisloaction广泛存在于各种晶体材料中，不仅限于金属。 它们在不同类型材料中的运动机制和对材料性能的影响各不相同。 例如，在金属中位错运动相对容易，而在陶瓷和半导体中则较为困难，且其作用更为复杂 具体来说存在有4种不同的Imperfections，来自不同的维度 Dislocation Density #\rDislocation Density: 材料中单位体积内存在的位错数量 Dislocation Density越高，材料的强度和硬度可能会有所增加，但延展性会降低 Metal #\rDislocations are always present in metals. 可以通过加热的方式更改Metal的dislocation density Zero-Dimensional Imperfections or Point Defects #\r点缺陷（Point Defect）是指材料的晶体结构中，由于原子或离子位置上的异常，导致的局部晶体结构缺陷 Interstitial Impurities #\rInterstitial Impurities指的是一些较小的Atom（比如碳、氮等）进入了Crystal中本来空着的间隙位置 Substitutional Impurities #\r当一个外来原子取代了晶体中正常位置上的原子时，形成Substitutional Impurities。 这种缺陷在合金中常见，例如铜和锌形成的黄铜 Vacancies #\r在晶体中，一个本应有原子的位置上缺少了一个原子 它会导致周围的原子重新调整位置，影响材料的物理性质 但Vacancies的产生并不会导致Material的Strength发生改变s Zero-Dimension\u0026rsquo;s Influence on Higher Dimension #\r当Zero Dimension Impurity发生的时候，其会对周围的Crystal Structure产生一个Strain Fields 这个Strain Field将会Repel其他的Atom进入Dislocation 其通常会造成一种One-Dimensional Imperfection Ratio of the Number of Vacancies #\r$$\\frac{N_v}{N} = e^{\\frac{-Q_v}{kT}} \\tag{1}$$\nNv​：这是Crystal中Number of Vancancies，即晶体结构中缺失原子的位置数。\nN：Number of Atoms\nQv​：表示生成一个Vacancies所需的Energy，通常以电子伏特（eV）为单位。\nk：这是Boltzmann Constant，数值约为 \\(1.38\\times 10^{-23}J/K\\)，用于将温度与能量联系起来。\nT：这是Thermodynamic temperature，以开尔文（K）为单位，是热力学温度是根据热力学原理来衡量系统绝对温度的一个度量，其零点对应理论上的绝对零度，即系统的分子运动几乎完全停止、能量达到最低的状态。\n从本质上讲，原子在它们的晶格位点上拼命振动，试图跳出它们的位点。 它们真的很努力。 我的意思是说，每秒大约有 1013 次！ 在固态中，由于结合能强于热能，大多数情况下它们都不会成功（实际上，原子形成有序固体有很大的节能作用，但我们稍后会详细介绍）。 但偶尔也会有原子从其晶格位置成功跃迁，并移动到晶格的其他位置。 这就会留下一个缺失的原子或空位。 因此，我们可以将空位的形成看作是将原子固定在晶格位点上的结合能与将原子从晶格位点上挤出的热能之间的持续斗争\nThermodynamics 热力学 #\rThermodynamics说明了在一个物体中，能量是分布在Atoms上而不是对于所有Atom都具有相同能量的 因此，单个原子可能有足够的能量跳出其晶格位置，而其余大多数原子则没有，这是有道理的 如图 10 所示，随着温度的升高，我们发现有更多的原子进入了高能态。 同时，随着温度的降低，高能态原子的数量也在减少。 Boltzmann Distribution #\r在绝对零度（0 K）：所有原子都会处于最低能量状态，因为此时系统没有足够的能量让原子占据更高的能量状态。 在无限温度（∞ K）：系统的温度极高，粒子的能量足以占据任何能量状态。因此所有能量状态的粒子数都会趋于相等，也就是所有能量状态均等分布 在Boltzmann Distribution中，不会出现所有粒子只占据最高能量状态的情况，即使是在极高温度下 One-Dimensional Imperfections or Dislocations #\rCold Work #\r当我们对金属进行Plastic Deformation时，会产生新的Dislocation。 这增加了Dislocation Density，这将在未来中增加Dislocation的难度 当我们观察金属的Stress-Strain Curve，发现应力在Yield Strength之后继续增加时，我们首次观察到金属通过Plastic Deformation而得到强化。 事实上，如果我们Unload一个sample并重新load，其在stress水平达到我们在前一个循环中留下的Stress之前不会开始Plastic Deformation 这是一种通过塑性变形进行的强化，不过在工业上，我们通常是通过轧制或拉动金属零件，或将金属零件压入模具来实现塑性变形，而不是通过简单的拉伸来拉动零件 Hot Work #\r材料被加热到再结晶温度以上，这意味着减少了Dislocation Density Two-Dimensional Imperfections #\rFree Surfaces #\r自由表面（Free Surfaces） 是指材料的外部表面, 这些表面与外界环境直接接触 原子排列不规则：在材料的自由表面，原子周围的配位数（与其他原子结合的数量）比材料内部的原子要少 Grain Boundaries #\r是指多晶材料中不同Crystal Structure交界的地方 当Dislocation在Crystal中移动，其必定要穿过Grain Boundary，然而这对位错来说是一个挑战 如果我们减小金属的晶粒尺寸，就会产生更多的晶界和更多的位错运动障碍，从而有望提高金属的强度 This strengthening mechanism has a pretty self-explanatory name: grain size reduction. Three-Dimensional Imperfections or Second Phase Particles #\rThree-dimensional imperfections occur any time we have a second phase within a solid 从本质上讲，如果固体中存在晶体结构不同的区域，就会出现第二相或三维缺陷 ","date":"Oct 16 2024","externalUrl":null,"permalink":"/docs/engineering-chemistry--materials-science/ecms5.furtheronstressstrain/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 10/16/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eStress-Strain Curve \r\n    \u003cdiv id=\"stress-strain-curve\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#stress-strain-curve\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS5.FurtherOnStressStrain/MCMS5.FurtherOnStressStrain.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e当回头重新看Stress-Strain Curve的时候可以发现一些特殊的点\u003c/li\u003e\n\u003cli\u003e如Proportion Limit，Ultimate Tensile Strength两个点\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eProportional Limit \r\n    \u003cdiv id=\"proportional-limit\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#proportional-limit\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e在曲线的最初阶段，存在一个接近于Linear的区域，其代表了Linear Elastic的Region\u003c/li\u003e\n\u003cli\u003e而也必会存在一个点象征着Linear Elastic Region的结束\u003c/li\u003e\n\u003cli\u003e但犹豫一些测量的误差或者精度上的问题，将导致最终的这一个Linear Elastic结束的点无法被确定，所以需要一个约定俗成的方法\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003e0.2% Offset Yield Strength \r\n    \u003cdiv id=\"02-offset-yield-strength\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#02-offset-yield-strength\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS5.FurtherOnStressStrain/MCMS5.FurtherOnStressStrain-1.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"MCMS 5. Further On Stress Strain","type":"docs"},{"content":"\r元数据 #\r[!abstract] 三体（全集）\n书名： 三体（全集） 作者： 刘慈欣 简介： 每个人的书架上都该有套《三体》！关于宇宙最狂野的想象！就是它！征服世界的中国科幻神作！包揽九项世界顶级科幻大奖！出版16个语种，横扫30国读者！奥巴马、雷军、马化腾、周鸿祎、潘石屹、扎克伯格……强推！刘慈欣获得2018年度克拉克想象力贡献社会奖！刘慈欣是中国科幻小说的最主要代表作家，亚洲首位世界科幻大奖“雨果奖”得主，被誉为中国科幻的领军人物。 出版时间： 2018-12-01 00:00:00 ISBN： 9785214589626 分类： 精品小说-科幻小说 出版社： 海南省电子音像出版社 PC地址：https://weread.qq.com/web/reader/ce032b305a9bc1ce0b0dd2a 高亮划线 #\r第十三章 红岸之二 #\r📌 雷政委说完站起来，迈着军人的稳健步伐离去。叶文洁的双眼盈满了泪水，透过眼泪，屏幕上的代码变成了一团团跳动的火焰。自父亲死后，这是她第一次流泪。 叶文洁开始熟悉监听部的工作，她很快发现，自己在这里远不如在发射部顺利，她已有的计算机知识早已落后，大部分软件技术都得从头学起。虽然有雷政委的信任，但对她的限制还是很严的，她可以看程序源代码，但不许接触数据库。 在日常工作中，叶文洁更多是接受杨卫宁的领导，他对她更加粗暴了，动不动就发火。雷政委多次劝他也没用，好像一见到叶文洁，他就充满了一种无名的焦虑。 ⏱ 2024-08-30 09:52:10 ^695233-17-5851\n第十六章 三体、哥白尼、宇宙橄榄球、三日凌空 #\r📌 很好，哥白尼，很好，你这种现实的、符合实验科学思想的想法是大多数学者不具备的，就凭这一点，你的理论也值得听一听。” 教皇对汪淼点点头，“说说看吧。” 汪淼走到长桌的另一端，让自己镇定了一下，说：“其实很简单：太阳的运行之所以没有规律，是因为我们的世界中有三颗太阳，它们在相互引力的作用下，做着无法预测的三体运动。当我们的行星围绕着其中的一颗太阳做稳定运行时，就是恒纪元；当另外一颗或两颗太阳运行到一定距离内，其引力会将行星从它围绕的太阳边夺走，使其在三颗太阳的引力范围内游移不定时，就是乱纪元；一段不确定的时间后，我们的行星再次被某一颗太阳捕获，暂时建立稳定的轨道，恒纪元就又开始了。这是一场宇宙橄榄球赛，运动员是三颗太阳，我们的世界就是球！” ⏱ 2024-08-30 10:05:15 ^695233-20-2574\n第十七章 三体问题 #\r📌 这时，我就像一个半生寻花问柳的放荡者突然感受到了爱情。 “你不知道庞加莱[插图]吗？”汪淼打断魏成问。 当时不知道，学数学的不知道庞加莱是不对，但我不敬仰大师，自己也不想成大师，所以不知道。但就算当时知道庞加莱，我也会继续对三体问题的研究。全世界都认为这人证明了三体问题不可解，可我觉得可能是个误解，他只是证明了初始条件的敏感性，证明了三体系统是一个不可积分的系统，但敏感性不等于彻底的不确定，只是这种确定性包含着数量更加巨大的不同形态。现在要做的是找到一种新的算法。当时我立刻想到了一样东西：你听说过“蒙特卡洛法”吗？哦，那是一种计算不规则图形面积的计算机程序算法，具体做法是在软件中用大量的小球随机击打那块不规则图形，被击中的地方不再重复打击，这样，达到一定的数量后，图形的所有部分就会都被击中一次，这时统计图形区域内小球的数量，就得到了图形的面积，当然，球越小结果越精确。 ⏱ 2024-08-30 10:16:26 ^695233-21-4188\n📌 这种方法虽然简单，却展示了数学中的一种用随机的蛮力对抗精确逻辑的思想方法，一种用数量得到质量的计算思想。这就是我解决三体问题的策略。我研究三体运动的任何一个时间断面，在这个断面上，各个球的运动矢量有无限的组合，我将每一种组合看做一种类似于生物的东西，关键是要确定一个规则：哪种组合的运行趋势是“健康的”和“有利的”，哪种是“不利的”和“有害的”，让前者获得生存的优势，后者则产生生存困难，在计算中就这样优胜劣汰，最后生存下来的就是对三体下一断面运动状态的正确预测。 ⏱ 2024-08-30 10:16:27 ^695233-21-4775\n第三十二章 古筝行动 #\r📌 叶文洁：如果他们能够跨越星际来到我们的世界，说明他们的科学已经发展到相当的高度，一个科学如此昌明的社会，必然拥有更高的文明和道德水准。 审问者：你认为这个结论，本身科学吗？ 叶文洁：…… ⏱ 2024-09-02 13:19:12 ^695233-36-12335-12543\n危机纪年第20年，三体舰队距太阳系4.15光年 #\r📌 人类大脑的进化需要两万至二十万年才能实现明显的改变，而人类文明只有五千年历史，所以我们目前拥有的仍然是原始人的大脑 ⏱ 2024-10-12 11:38:59 ^695233-47-9290-9347\n📌 政治思想工作是通过科学的理性思维来建立信念。 ⏱ 2024-10-12 11:39:43 ^695233-47-10801-10823\n下部 黑暗森林 #\r📌 普通人的目光，是他们所在地区和时代的文明程度的最好反映。他曾经看到过一组由欧洲摄影师拍摄的清朝末年的照片，最深的印象就是照片上的人呆滞的目光，在那些照片上，不论是官员还是百姓，眼睛中所透出的只有麻木和愚钝，看不到一点生气。 ⏱ 2024-10-12 12:13:19 ^695233-48-2540-2651\n📌 给岁月以文明，而不是给文明以岁月。 ⏱ 2024-10-12 13:19:45 ^695233-48-32277-32294\n📌 章北海停下手中的笔，抬头看着舱外的东方延绪，他的目光平静如水，“同为军人，知道我们之间最大的区别在哪里吗？你们按照可能的结果来决定自己的行动；而我们，不管结果如何，必须尽责任，这是唯一的机会，所以我就做了。 ⏱ 2024-10-12 13:59:12 ^695233-48-84364-84467\n📌 两个多世纪前，阿瑟·克拉克在他的科幻小说《2001：太空奥德赛》中描述了一个外星超级文明留在月球上的黑色方碑，考察者用普通尺子量方碑的三道边，其长度比例是1∶3∶9，以后，不管用何种更精确的方式测量，穷尽了地球上测量技术的最高精度，方碑三边的比例仍是精确的1∶3∶9，没有任何误差。克拉克写道：那个文明以这种方式，狂妄地显示了自己的力量。 ⏱ 2024-10-12 14:10:45 ^695233-48-100308-100477\n危机纪年第208年，三体舰队距太阳系2.07光年 #\r📌 因为在昨天晚上的演讲中，你说人类迟迟未能看清宇宙的黑暗森林状态，并不是由于文明进化不成熟而缺少宇宙意识，而是因为人类有爱。 “这不对吗？” 对，虽然“爱”这个词用在科学论述中涵义有些模糊，但你后面的一句话就不对了，你说很可能人类是宇宙中唯一拥有爱的种族，正是这个想法，支撑着你走完了自己面壁者使命中最艰难的一段。 “当然，这只是一种表达方式，一种不严格的……比喻而已。” 至少我知道三体世界也是有爱的，但因其不利于文明的整体生存而被抑制在萌芽状态，但这种萌芽的生命力很顽强，会在某些个体身上成长起来。 “请问您是……” 我们以前不认识，我是两个半世纪前曾向地球发出警告的监听员。 “天啊，您还活着？”庄颜惊叫道。 也活不了多长时间了，我一直处于脱水状态，但这么长的岁月，脱水的机体也会老化。不过我真的看到了自己想看的未来，我感到很幸福。 “请接受我们的敬意。”罗辑说。 我只是想和您讨论一种可能：也许爱的萌芽在宇宙的其他地方也存在，我们应该鼓励她的萌发和成长。 “为此我们可以冒险。” 对，可以冒险。 “我有一个梦，也许有一天，灿烂的阳光能照进黑暗森林。” 这时，这里的太阳却在落下去，现在只在远山露出顶端的一点，像山顶上镶嵌着的一块光灿灿的宝石。孩子已经跑远，同草地一起沐浴在金色的晚霞之中。 太阳快落下去了，你们的孩子居然不害怕？ “当然不害怕，她知道明天太阳还会升起来的。” ⏱ 2024-10-12 15:08:48 ^695233-49-13253-14291\n危机纪元4年，云天明 #\r📌 程心似乎听到了他心中的话，她慢慢抬起头来，他们的目光第一次这么近地相遇，比他梦中的还近，她那双因泪水而格外晶莹的美丽眼睛让他心碎。 但接着，程心说出一句完全意外的话：“天明，知道吗？安乐死法是为你通过的。” ⏱ 2024-10-14 12:31:36 ^695233-55-21409-21540\n危机纪元1-4年，程心 #\r📌 “你会把你妈卖给妓院吗？”维德问。 ⏱ 2024-10-14 12:31:06 ^695233-56-2751-2768\n威慑纪元61年，执剑人 #\r📌 因为杀的人太少了。杀一个人是要被判死刑的，杀几个几十个更是如此，如果杀了几千几万人，那就罪该万死；但如果再多些，杀了几十万人呢？当然也该判死刑，但对于有些历史知识的人，这个回答就不是太确定了；再进一步，如果杀了几百万人呢？那可以肯定这人不会被判死刑，甚至不会受到法律的惩处，不信看看历史就知道了，那些杀人超过百万的人，好像都被称为伟人和英雄；更进一步，如果这人毁灭了一个世界，杀死了其中的所有生命，那他就成了救世主！ ⏱ 2024-10-15 01:16:23 ^695233-60-4506-4714\n📌 “很复杂，直接原因是：那个恒星系，就是他向宇宙广播了坐标导致其被摧毁的那个，不知道其中有没有生命，但肯定存在有的可能，所以他被指控有世界灭绝罪的嫌疑。这是现代法律中最重的罪了。” ⏱ 2024-10-16 14:17:58 ^695233-60-4831-4920\n📌 如果说面壁计划是人类历史上首次出现的怪物，那黑暗森林威慑和执剑人在历史上却有过先例。公元20世纪华约和北约两大军事集团的冷战就是一个准终极威慑。冷战中的1974年，苏联启动Perimeter计划，建立了一个后来被称为末日系统的预警系统，其目的是在北约核突袭中，当政府决策层和军队高级指挥层均被消灭、国家已失去大脑的情况下，仍具备启动核反击的能力。它利用核爆监测系统监控苏联境内的核爆迹象，所有的数据会汇整到中央计算机，经过逻辑判读决定是否要启动核反击。这个系统的核心是一个绝密的位于地层深处的控制室，当系统做出反击的判断时，将由控制室内的一名值班人员启动核反击。公元2009年，一位曾参加过Perimeter战略值班的军官对记者披露，他当时竟然只是一名刚从伏龙芝军事学院毕业的二十五岁的少尉！当系统做出反击判断时，他是毁灭的最后一道屏障。这时，苏联全境和东欧已在火海之中，他在地面的亲人和朋友都已经死亡，如果他按下启动反击的按钮，北美大陆在半个小时后也将同样成为生命的地狱，随之而来的覆盖全球的辐射尘和核冬天将是整个人类的末日。那一时刻，人类文明的命运就掌握在他手中。后来，人们问他最多的话就是：如果那一时刻真的到来，你会按下按钮吗？ 这位历史上最早的执剑人说：我不知道。 ⏱ 2024-10-16 14:26:20 ^695233-60-9487-10051\n📌 人们发现威慑纪元是一个很奇怪的时代，一方面，人类社会达到空前的文明程度，民主和人权得到前所未有的尊重；另一方面，整个社会却笼罩在一个独裁者的阴影下。有学者认为，科学技术一度是消灭极权的力量之一，但当威胁文明生存的危机出现时，科技却可能成为催生新极权的土壤。在传统的极权中，独裁者只能通过其他人来实现统治，这就面临着低效率和无数的不确定因素，所以，在人类历史上，百分之百的独裁体制从来没有出现过。但技术却为这种超级独裁的实现提供了可能，面壁者和持剑者都是令人忧虑的例子。超级技术和超级危机结合，有可能使人类社会退回黑暗时代。 ⏱ 2024-10-16 14:28:31 ^695233-60-10907-11168\n📌 “看，她是圣母玛丽亚，她真的是！”年轻母亲对人群喊道，然后转向程心，热泪盈眶地双手合十，“美丽善良的圣母，保护这个世界吧，不要让那些野蛮的嗜血的男人毁掉这美好的一切。” ⏱ 2024-10-16 23:16:52 ^695233-60-20469-20553\n威慑纪元62年，奥尔特星云外，“万有引力”号 #\r📌 “三维，在弦理论中，不算时间维，宇宙有十个维度，可只有三个维度释放到宏观，形成我们的世界，其余的都卷曲在微观中。” ⏱ 2024-10-16 23:24:46 ^695233-61-13721-13778\n威慑纪元最后十分钟，62年11月28日16：17：34至16：27：58，威慑控制中心 #\r📌 在程心的潜意识中，她是一个守护者，不是毁灭者；她是一个女人，不是战士。她将用自己的一生守护两个世界的平衡，让来自三体的科技使地球越来越强大，让来自地球的文化使三体越来越文明，直到有一天，一个声音对她说：放下红色开关，到地面上来吧，世界不再需要黑暗森林威慑，不再需要执剑人了。 ⏱ 2024-10-17 01:26:30 ^695233-63-1797-1934\n威慑后一小时，失落的世界 #\r📌 “这都是为什么？”程心喃喃地问，更像是问自己。 “因为宇宙不是童话。” ⏱ 2024-10-17 01:30:38 ^695233-64-4901-4964\n第三部 #\r📌 安逸的美梦彻底破灭，黑暗森林理论得到了最后的证实，三体世界被摧毁了。 ⏱ 2024-10-17 15:58:32 ^695233-70-5401-5435\n广播纪元7年，云天明的童话 #\r📌 AA拿过程心叠好的带篷的小纸船，称赞很漂亮，然后示意程心也进浴室。在盥洗台上，她用小刀片从香皂上切下了小小的一片，然后把小纸船的尾部扎了一个小孔，把那一小片香皂插入小孔中，抬头对程心神秘地一笑，轻轻地把纸船放进已灌满水并且水面已经平静下来的浴缸中。 小船向前移动了，在这片小小的水面上，从此岸航向彼岸。 程心立刻明白了原理：香皂在水中溶解后，降低了小船后方水面的张力，但船前方水面的张力不变，小船就被前方水面的张力拉过去了￼。但这个想法转瞬即逝，程心的思想随即被一道闪电照亮！在她的眼中，浴缸中平静的水面变成了漆黑的太空，白色的小纸船在这无际的虚空中以光速航行… ⏱ 2024-10-17 22:30:43 ^695233-73-48751-49192\n📌 每秒十六点七千米，太阳系的第三宇宙速度，如果达不到这个速度就不可能飞出太阳系。 光也一样。 如果太阳系的真空光速降到每秒十六点七千米以下，光将无法逃脱太阳的引力，太阳系将变成一个黑洞￼。 ⏱ 2024-10-17 22:40:01 ^695233-73-63863-64231\n广播纪元8年，命运的抉择 #\r📌 这让我想起了那天夜里峨眉山的云海，”瓦西里说，“那是中国的一座山，在那山的顶上看月亮是最美的景致。那天夜里，山下全是云海，望不到边，被上空的满月照着，一片银色，很像现在看到的样子。” ⏱ 2024-10-17 22:55:27 ^695233-74-19329-19420\n📌 “其实吧，从科学角度讲，毁灭一词并不准确，没有真正毁掉什么，更没有灭掉什么，物质总量一点不少都还在，角动量也还在，只是物质的组合方式变了变，像一副扑克牌，仅仅重洗而已……可生命是一手同花顺，一洗什么都没了。” ⏱ 2024-10-17 22:55:16 ^695233-74-19474-19578\n第五部 #\r📌 剩下的事就是清理了，歌者再次从仓库中取出那个质量点。他突然想到清理弹星者是不能用质量点的，这个星系的结构与前面已死的那个星系不同，有死角，用质量点可能清理不干净，甚至白费力气，这要用二向箔才行。可是歌者没有从仓库里取二向箔的权限，要向长老申请。 ⏱ 2024-10-18 13:45:16 ^695233-79-5867-5989\n掩体纪元66年，太阳系外围 #\r📌 白Ice笑了起来，“再简单不过的事，你忘记《古兰经》中的故事了？如果大山不会走向穆罕默德，穆罕默德可以走向大山。” ⏱ 2024-10-18 14:26:27 ^695233-81-7378-7435\n📌 丁仪接着说：“在危机初期，当智子首次扰乱加速器时，有几个人自杀。我当时觉得他们不可理喻，对于搞理论的，看到那样的实验数据应该兴奋才对。但现在我明白了，这些人知道的比我多，比如杨冬，她知道的肯定比我多，想得也比我远，她可能知道一些我们现在都不知道的事。难道制造假象的只有智子？难道假象只存在于加速器末端？难道宇宙的其他部分都像处女一样纯真，等着我们去探索？可惜，她把她知道的都带走了。” ⏱ 2024-10-18 14:45:18 ^695233-81-10117-10309\n📌 “我说别傲慢，弱小和无知不是生存的障碍，傲慢才是，想想水滴吧！” ⏱ 2024-10-18 15:50:30 ^695233-81-12293-12325\n📌 “现在逃离，就像在瀑布顶端附近的河面上划船，除非超过一个逃逸速度，否则不论怎样划，迟早都会坠入瀑布，就像在地面向上扔石头，不管扔多高总会落回来。整个太阳系都在跌落区，从中逃离必须达到逃逸速度。” “逃逸速度是多少？” “我反复计算过四遍，应该没错。” “逃逸速度是多少？！” “启示”号和“阿拉斯加”号上的人们屏息凝神，替全人类倾听末日判决，白Ice把这判决平静地说出来： “光速。” ⏱ 2024-10-18 15:55:33 ^695233-81-15419-15751\n掩体纪元67年，二维太阳系 #\r📌 程心现在回想起两次看到《星空》时奇怪的感觉：画面中星空之外的部分，那火焰般的树，暗夜中的村庄和山脉，都呈现出明显的透视和纵深；但上方的星空却丝毫没有立体感，像挂在夜空中的一幅巨画。 因为星空是二维的。 他是怎么画出来的？1889年的凡·高，精神第二次崩溃的凡·高，难道真的用分裂和谵妄的意识，跨越五个多世纪的时空，看到了现在？！或者反过来，他早就看到了未来，这最后审判日的景象才是他精神崩溃和自杀的真正原因？！ ⏱ 2024-10-18 16:17:09 ^695233-83-16582-16843\n📌 隧洞前的罗辑笑了笑，“我要是想走，刚才就跟你们走了，我这样岁数的人，不适合远航了。孩子们，不要为我操心了，我说过的，我什么都没有失去。准备启动空间曲率驱动。” 罗辑的最后一句话是对飞船A.I.说的。 “航线参数？”A.I.问。 “目前航线的延长线吧，我也不知道你们要去哪儿，我想现在你们自己也不知道，要是想起了目的地，在星图上指出来就行了，半径五万光年内的大部分恒星，飞船都可以自动导航到达。” “指令执行中，空间曲率驱动引擎三十秒后启动。”A.I.说。 ⏱ 2024-10-18 16:19:44 ^695233-83-19371-19739\n📌 在宇宙中，曲率驱动航迹既可以成为危险标志，也能成为安全声明。如果航迹在一个世界旁边，是前者；如果把这个世界包裹在其中，则是后者。就像一个手拿绞索的人，他是危险的；但如果他把绞索套到自己的脖子上，他就变成安全的了。 ⏱ 2024-10-18 16:25:06 ^695233-83-22164-22270\n📌 “你们有个约会！”AA说。 “是的，我们有个约会。”程心机械地回答，感情的激荡使她处于呆滞状态。 “那就去你们的星星！” “好的，去我们的星星。”程心激动地对AA说。然后她问飞船A.I.，“能够定位DX3906恒星吗，这是危机纪元初的编号？” “可以，这颗恒星现在的编号是S74390E2，请确认。” ⏱ 2024-10-18 16:27:08 ^695233-83-26179-26441\n第六部 #\r📌 大气成分：氧35%，氮63%，二氧化碳2%，还有微量惰性气体，可以呼吸，但大气压只有0.53个地球标准气压，出舱后不要剧烈活动。”飞船A.I.说。 “站在飞船附近的那个生物是什么？”AA问。 “正常人类。”A.I.简单地回答。 ⏱ 2024-10-18 16:29:13 ^695233-84-4555-4724\n📌 也有人叫它末日飞船。那些光速飞船没有目的地，只是把曲率引擎开到最大功率疯狂加速，无限接近光速，目的就是用相对论效应跨越时间，直达宇宙末日。据他们计算，十年内就可以跨越五百亿年，那他们现在已经到了，哦，当然是以他们的参照系。其实，并不需要有意识地做这事，比如在飞船加速到光速后，曲率引擎出现无法修复的故障，使飞船不能减速，你也可能在有生之年到达宇宙末日。” ⏱ 2024-10-18 16:43:21 ^695233-84-13148-13325\n读书笔记 #\r本书评论 #\r","date":"Oct 16 2024","externalUrl":null,"permalink":"/notes/thethreebodyproblem/","section":"Thoughts","summary":"\u003ch1 class=\"relative group\"\u003e元数据 \r\n    \u003cdiv id=\"%E5%85%83%E6%95%B0%E6%8D%AE\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%85%83%E6%95%B0%E6%8D%AE\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cblockquote\u003e\n\u003cp\u003e[!abstract] 三体（全集）\u003c/p\u003e","title":"The Three Body Problem","type":"notes"},{"content":"Record some thinking\n","date":"Oct 16 2024","externalUrl":null,"permalink":"/notes/","section":"Thoughts","summary":"\u003cp\u003eRecord some thinking\u003c/p\u003e","title":"Thoughts","type":"notes"},{"content":" Last Edit: 11/26/24\nSet Notation 集合 #\rSet is a collection of objects, called elements of the set $$A={t|t\\in R}$$ 这就是一个矩阵，其中A为t，而t可以取任意Real Number 这就是集合的表示方法，用这种方法便可以表示向量，直线和平面 Union of Sets 并集 #\r对于两个集合，其Union是另一个Set，其元素包含了all elements of A and B $$A \\cup B = { x \\in X \\mid x \\in A \\text{ or } x \\in B }$$ Intersection of Sets 交集 #\r对于Intersection来说，这个Set包含了任意同时出现在A与B中的元素 $$A \\cap B = { x \\in X \\mid x \\in A \\text{ and } x \\in B }.$$ Vector 向量 #\r思考一个问题，对于一个坐标轴上的点\\((2,1)\\)和一个向量\\(\\vec v =[2,1]^T\\)，他们的区别 Point：点是空间中的一个位置，用坐标表示，如P = (x, y, z)表示三维空间中的一个具体位置。点没有方向和大小。 Vector：向量是一个有大小和方向的数学对象，通常表示两个点之间的位移。例如，从点 A到点B的向量可以表示为\\(\\mathbf{v} = \\overrightarrow{AB}\\) 亦可以说Point是绝对位置，而向量是一个点到另外一个的有方向的距离 Norm 模 #\r对于\\(\\vec{v} = \\begin{bmatrix} v_1 \\ v_2 \\ \\vdots \\ v_n \\end{bmatrix} \\text{ be in } \\mathbb{R}^n\\) 它的Norm，也就是向量长度即为 $$\\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2}$$ Dot Product 点积 #\rDot Product，用来衡量两个Vector方向相似程度的一个Scalar 其值从-1到1（仅当两个Vector为Unit Vector的情况下），从方向相反，到同方向，在0的时候代表两个Vector Orthogonal 垂直 Definition #\r$$\\mathbf{a} \\cdot \\mathbf{b} = a_1 b_1 + a_2 b_2 + \\cdots + a_n b_n = \\sum_{i=1}^n a_i b_i$$\n公式中的每一项\\(a_i b_i\\)表示两个向量在某个维度上的大小相乘 点积实际上是在将a和b的方向分量进行逐一对比，累加得到两个向量在整个空间上的“相似性”，每一个维度的相似性都将累加到最终的空间相似性上 想要表达这个相似性，还存在另一种方式，即通过Projection $$\\mathbf{a} \\cdot \\mathbf{b} = |\\mathbf{a}| |\\mathbf{b}| \\cos \\theta$$ 其代表了b在a方向上Projection的长度再乘以a Angle Between Vectors #\r同理可以用Dot Product公式推导两个Vector之间的夹角 $$\\theta = \\cos^{-1} \\left( \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{AB} \\right) \\quad 0^\\circ \\leq \\theta \\leq 180^\\circ$$ Application #\rDot Product的一种用法便是Force Vector Directed Along a Line 对于一个在\\(\\vec u\\)方向上的Force F，有 $$\\vec F_u=\\vec F\\cdot \\vec u=(F\\times 1)\\cdot \\cos\\theta=F\\cdot \\cos\\theta$$ 而这一个\\(\\cos\\theta\\)则是 $$\\cos\\theta=\\frac{\\vec v\\cdot \\vec{w}}{|v|\\times|w|}$$ 当把其中一个Vector替换为Direction Vector时，便可以得到Axis-Force\u0026rsquo;s Direction Cosine $$\\cos\\theta = \\frac{{r_xi+r_yj+r_zk}}{\\sqrt{r_x^2+r_y^2+r_z^2}\\cdot 1}$$ 所以就有\\(F\\cdot \\cos \\theta=F\\cdot \\vec u\\)之后便可以得到Force在\\(\\vec u\\)方向上的力的Magnitude（注意Dot Product的结果是一个Scalar） 要想得到Force在\\(\\vec u\\)方向上的Cartesian Vector，需要再次乘以Direction Vector 最终公式 #\r$$\\vec F=F_u\\cdot \\vec u= (\\vec F\\cdot u\\cdot\\cos\\theta)\\cdot \\vec u=(F\\cdot\\frac{{r_xi+r_yj+r_zk}}{\\sqrt{r_x^2+r_y^2+r_z^2}\\cdot 1})\\cdot\\vec u$$\nLine 直线 #\r考虑一个问题Consider the two points P = (1, 2) and Q = (−1, 4)，find an equation for the line y = mx + b which passes through P and Q 通过Point-Point Formula可以算出 $$y_2-y_1=\\frac{y_2 - y_1}{x_2 - x_1}(x_2-x_1)$$ 解得 \\(y=−x+3\\) 现在考虑相似的问题 Suppose x and y satisfy the vector equation $$\\begin{bmatrix} x \\ y \\end{bmatrix} = \\begin{bmatrix} 1 \\ 2 \\end{bmatrix} + k \\begin{bmatrix} 1 \\ -1 \\end{bmatrix}, \\text{ where } k \\in \\mathbb{R}$$ 可以发现两个不同的形式表达了同一个Line，他们之所以等价是因为 \\([1,2​]^T\\)是直线上的一个固定点（在直线上）。 \\(k\\begin{bmatrix} 1 \\ -1 \\end{bmatrix}\\)是一个方向向量，表示直线的方向（斜率），而方程中的斜率为\\(m = \\frac{\\Delta y}{\\Delta x}\\)，用Direction Vector的y分量除以x分量就可以得到一样的结果 而对于Intersection来说，当k=-1的时候，有 $$\\begin{bmatrix} x \\ y \\end{bmatrix} = \\begin{bmatrix} 1 \\ 2 \\end{bmatrix} + \\begin{bmatrix} -1 \\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\ 3\\end{bmatrix}$$ 也就是截距 于是就可以定义如下的Line using Set Notation $$L = { \\vec{u} \\in \\mathbb{R}^2 \\mid \\vec{u} = \\vec{v} + t \\vec{d}, \\text{ for some } t \\in \\mathbb{R} }$$ 为什么需要两个向量 —\u0026gt; 因为需要Position Vector区分不同平行的直线\nPlane #\r同理对于一个Plane，可以通过两个Linearly Independent的Vector与一个Plane上的点表示 至于前面Line中所提到的Slope，在这里便是Partical Derivative $$\\mathcal{P} = { \\vec{u} \\in \\mathbb{R}^3 \\mid \\vec{u} = \\vec{p} + s \\vec{d}_1 + t \\vec{d}_2, \\text{ for some } s, t \\in \\mathbb{R} }$$ 可以发现u是一个\\(\\mathbb R^3\\)中的Subset，这代表了该Subset只含有两个Degree of Freedom，即为三维空间中的一个Plane 注意这里的Plane是一个Subset，不是Subspace，具体原因将在后面指出\nNormal Vector #\r对于平面\\(Ax+By+Cz=D\\)来说，其Normal Vecotr，也就是垂直于整个Plane的Vector即为\\(n=[A,B,C]^T\\) Proof #\r\\(P(x_1​,y_1​,z_1​)\\)和\\(Q(x_2, y_2, z_2)\\)都在平面上，那么它们的坐标满足平面方程 $$Ax_1+By_1+Cz_1=D，Ax_2+By_2+Cz_2=D$$ 则可以构建向量\\(\\vec{v} = \\begin{bmatrix} x_2 - x_1 \\ y_2 - y_1 \\ z_2 - z_1 \\end{bmatrix}\\) 结合方程组则有\\(A(x_2-x_1)+B(y_2-y_1)+C(z_2-z_1)=0\\) 也就是\\(\\vec v \\cdot \\vec n =0\\)，其中\\(\\vec{n} = \\begin{bmatrix} A \\ B \\ C \\end{bmatrix}\\) Second definition #\r结合上面的思想便可以得到Space的第二个Set Notation表达式 $$\\mathcal{P} = { \\vec{u} \\in \\mathbb{R}^3 \\mid \\vec{n} \\cdot (\\vec{u} - \\vec{p}) = 0 }$$ \\(u∈R^3\\)：表示平面上的任意点的坐标。 \\(\\vec{n} \\in \\mathbb{R}^3\\)：表示平面的法向量，即垂直于平面表面的向量。 \\(\\vec{p} \\in \\mathbb{R}^3\\)：表示平面上的一个固定点，用于确定平面的具体位置。 点积\\(\\vec{n} \\cdot (\\vec{u} - \\vec{p}) = 0\\)：表示向量\\((\\vec{u} - \\vec{p})\\)与法向量\\(\\vec{n}\\)正交。 \\(\\vec p\\)为Plane上一点，\\(\\vec n\\)为Plane的Normal Vector，剩下的就是点上的任意位置了，由于任意\\(\\vec u\\)都在平面中，\\(\\vec u-\\vec p\\) 将仍处于Plane中，而\\(\\vec n⋅(\\vec u−\\vec p​)=0\\)是限定他的条件 所有的Vector都为Position Vector，即以坐标系Origin为Head的Vector\nex. #\rFind the equation for a plane \\(\\mathcal{P}\\) which contains the three points P = (0, 1, 1), Q = (2, 0, 4), andR = (0, 0, 1)\nExpress \\(\\mathcal{P}\\) in vector form, in normal form, and as an equation ax + by + cz = d\n用三个点确定Plane上的两个Vector\n$$\\vec{v}_1 = \\begin{bmatrix} 2 - 0 \\\\ 0 - 1 \\\\ 4 - 1 \\end{bmatrix} = \\begin{bmatrix} 2 \\\\ -1 \\\\ 3 \\end{bmatrix}$$\r$$\\vec{v}_2 = \\begin{bmatrix} 0 - 0 \\\\ 0 - 1 \\\\ 1 - 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ -1 \\\\ 0 \\end{bmatrix}$$\r","date":"Oct 15 2024","externalUrl":null,"permalink":"/docs/linearalgebra/la1.vectorlineplane/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/26/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eSet Notation 集合 \r\n    \u003cdiv id=\"set-notation-%E9%9B%86%E5%90%88\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#set-notation-%E9%9B%86%E5%90%88\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eSet is a collection of objects, called elements of the set\n$$A={t|t\\in R}$$\u003c/li\u003e\n\u003cli\u003e这就是一个矩阵，其中A为t，而t可以取任意Real Number\u003c/li\u003e\n\u003cli\u003e这就是集合的表示方法，用这种方法便可以表示向量，直线和平面\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eUnion of Sets 并集 \r\n    \u003cdiv id=\"union-of-sets-%E5%B9%B6%E9%9B%86\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#union-of-sets-%E5%B9%B6%E9%9B%86\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于两个集合，其Union是另一个Set，其元素包含了all elements of A and B\n$$A \\cup B = { x \\in X \\mid x \\in A \\text{ or } x \\in B }$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eIntersection of Sets 交集 \r\n    \u003cdiv id=\"intersection-of-sets-%E4%BA%A4%E9%9B%86\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#intersection-of-sets-%E4%BA%A4%E9%9B%86\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于Intersection来说，这个Set包含了任意同时出现在A与B中的元素\n$$A \\cap B = { x \\in X \\mid x \\in A \\text{ and } x \\in B }.$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eVector 向量 \r\n    \u003cdiv id=\"vector-%E5%90%91%E9%87%8F\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#vector-%E5%90%91%E9%87%8F\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e思考一个问题，对于一个坐标轴上的点\\((2,1)\\)和一个向量\\(\\vec v =[2,1]^T\\)，他们的区别\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePoint\u003c/strong\u003e：点是空间中的一个位置，用坐标表示，如P = (x, y, z)表示三维空间中的一个具体位置。点没有方向和大小。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVector\u003c/strong\u003e：向量是一个有大小和方向的数学对象，通常表示两个点之间的位移。例如，从点 A到点B的向量可以表示为\\(\\mathbf{v} = \\overrightarrow{AB}\\)\u003c/li\u003e\n\u003cli\u003e亦可以说\u003cstrong\u003ePoint是绝对位置，而向量是一个点到另外一个的有方向的距离\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eNorm 模 \r\n    \u003cdiv id=\"norm-%E6%A8%A1\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#norm-%E6%A8%A1\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于\\(\\vec{v} = \\begin{bmatrix} v_1 \\ v_2 \\ \\vdots \\ v_n \\end{bmatrix} \\text{ be in } \\mathbb{R}^n\\)\u003c/li\u003e\n\u003cli\u003e它的Norm，也就是向量长度即为\n$$\\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2}$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eDot Product 点积 \r\n    \u003cdiv id=\"dot-product-%E7%82%B9%E7%A7%AF\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#dot-product-%E7%82%B9%E7%A7%AF\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003eDot Product，用来衡量两个Vector方向相似程度的一个Scalar\u003c/li\u003e\n\u003cli\u003e其值从-1到1（仅当两个Vector为Unit Vector的情况下），从方向相反，到同方向，在0的时候代表两个Vector Orthogonal 垂直\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eDefinition \r\n    \u003cdiv id=\"definition\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#definition\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cp\u003e$$\\mathbf{a} \\cdot \\mathbf{b} = a_1 b_1 + a_2 b_2 + \\cdots + a_n b_n = \\sum_{i=1}^n a_i b_i$$\u003c/p\u003e","title":"LA 1. Vector Line \u0026 Plane","type":"docs"},{"content":" Last Edit: 9/25/24\nYoung’s modulus change with Density #\rOrdered Solids #\r大多数固体材料都是Polycrystaline 多晶体的 尤其是Metal在原子尺度上是按照Crystal Structure排列的 Atomic scale尺度一般在\\(10^{-10}\\)的级别 Unit Cell #\r最小的Convenient Building Block Grains #\r多晶材料的这些晶体被称为晶粒（grains）。每个晶粒内部的原子排列是有序的，但不同晶粒之间的原子排列方向各不相同，这种微观结构对材料的机械性能和物理性质有重要影响 Short Range Order #\r指的是在局部区域内，原子或分子的排列是有规律的 玻璃、液体这样的材料，它们通常是Short Range Order的 Long Range Order #\r在整个材料中，原子或分子的排列是有规律的，并且这种规律性会一直延续到较大的尺度（远远超过单个原子的范围） 晶体材料，如金属和矿物，通常具有长程有序 Simple Cubic #\r简单的一个立方体上的八个角为Atoms的结构 其正方体的边长被定义为a n：1 Atom CN：6 Side Dimension: \\(a=2r\\) Hard Sphere Model #\r所有的Atoms都被当作一个球来模拟，主要是方便描述原子在晶体结构中的排列方式 Reduced Sphere Model #\rReal Graph #\r可以发现这样的Hard Shpere Model看着实在是Messy 所以就将所有Atoms简化为Reduced Sphere Model The Atomic Packing Factor 填充系数 #\r对于一个Unit Cell，APF描述了Atom对于体积的占有率，从100%完全占据到0%一点没有 $$APF=\\frac{Volume_{Spheres}}{Volumn_{Unit~Cell}}$$ 本质上就是一个百分比或者说分数 现在分别计算两个体积 对于Spheres来说，单个的体积为\\(\\frac{4}{3}\\pi R^3\\)，而将他乘上Number of Atoms后便可以得到所有的体积 对于Unit Cell来说，以a为边长，其体积自然为\\(a^3\\) Face Centred Cubic (FCC) Structure #\r结构特点：每个晶胞的八个顶点各有一个原子，此外每个面中心还有一个原子。 n：每个晶胞含有 4 个原子（8 个顶点原子各占 1/8，6 个面心原子各占 1/2）。 CN：12（每个原子有 12 个最近邻原子）。 APF：约 74%（原子占据的体积比例）。 例子：铝、铜、金、银等 在Simple Cubic的基础上加入一些Face Centred Atoms（在每个面中心的Atom） Number of Atoms in FCC #\r对于FCC来说，每一个角上都是\\(\\frac{1}{8}\\)个Atom 每一个面都有\\(\\frac{1}{2}\\)个Atom 所以一共就是\\(\\frac{1}{8}*8+\\frac{1}{2}*6=4\\)个Atom 即\\(n_{FCC}=4\\) Coordination Number of FCC #\r$$CN_{FCC}=12$$\nAtomic Packing Factor of FCC #\r则对于FCC Structure来说，其APF即为 $$APF=\\frac{4\\frac{4}{3}\\pi R^3}{a^3}$$ 现在要将Atom的radius与Unit Cell的边长a做替换好消掉其中一个 有\\(a^2+a^2=(4R)^2\\)，勾股定律 则有\\(2a^2=16R^2\\)，即\\(a_{FCC}=2\\sqrt{2}R\\) 将a带入后便有 $$APF = \\frac{4 \\left( \\frac{4}{3} \\pi R^3 \\right)}{(2\\sqrt{2}R)^3} \\ \\Rightarrow APF_{FCC} = 0.74$$ Avogadro\u0026rsquo;s constant 阿伏伽德罗常数 #\r通常用符号\\(N_A\\)表示，是指在1摩尔物质中包含的微观粒子（如原子、分子、离子等）的数量。其数值大约为： $$N_A=6.022×10^{23 }g\\cdot mol^{−1}$$\nTheoretical Density 理论密度 #\r$$\\text{Mass}{\\text{Atoms in Unit Cell}} = \\text{Number}{\\text{Atoms in Unit Cell}} \\cdot \\frac{\\text{Molar Mass of Atom}}{\\text{Avogadro\u0026rsquo;s Number}}$$\n$$m = n \\cdot \\frac{A}{N_A}$$ $$\\rho = \\frac{nA}{V_C N_A}$$\nDensity密度，即质量和体积的比值 \\(n\\)：Number of Atoms，一个Crystal里的完整分子个数 A: Molar Mass(g/mol)，原子相对质量 \\(V_c\\)：Unit Cell的体积 \\(N_A\\)：阿伏伽德罗常数\\(mol^{-1}\\) \\(\\frac{A}{N_A}\\)：\\(\\frac{g/mol}{mol^{-1}}=g\\)，等于一个Atom有几g，再乘上Atom Nuber得到全部的Mass Rock Salt Structure #\r是一个Common Ceramic的Crystal Structure 结构特点：这是离子晶体结构，通常由两种不同大小的离子（如Na⁺和Cl⁻）组成。大的离子（Cl⁻）形成一个面心立方（FCC）结构，小的离子（Na⁺）填充在八面体间隙中。 A：每个晶胞含有 4 个阳离子和阴离子。 CN：阳离子和阴离子的CN都为6。 APF：约 67%。 例子：氯化钠（NaCl）、氧化镁（MgO）等。 对于Ceramic Structure来说，其拥有多余一种的Atom类型，具体来说有Cation和Anion两种 其是Ionic Compound的一种特有的Crystal Structure 对于Rosk Salt Structure来说，其包含了两种Ion，即Anion（蓝色）与Cation（红色） Anions在Unit Cell的角上（Cation也可以在，他们描述的将是同一种结构，但一般来说体积大的Anion会先占据Unit Cell的角落，将小的Cation挤到中间去） 这个结构看起来像面心立方（FCC），但实际上不是纯粹的FCC，因为阳离子和阴离子之间有相互作用，会推开阴离子，使得阴离子不会像真正的FCC结构那样直接通过面对角线相互接触。 Number of Atoms in Rock Salt (Stoichiometry) #\r对于如NaCl这样的material，其Anion：Cation比都是1：1的，但上图中明显缺少了一个Cation 其正确的位置应该是整个Unit Cell的正中央 Coordination Number for Cations in Rock Salt #\r对于一个Rock Salt来说，拿最中间的Cation举例，可以发现与其接触的Atom有6个 于是就可以说\\(CationCoordinationNumber_{Rock~Salt} = 6\\) Density of Rock Salt #\r对于Rock Slat Structure来说，由于其Atom种类变为了Anion与Cation两个，其[[#Theoretical Density]]的分子也要对应的便为两个的和，即 $$\\rho=\\frac{n_CA_C+n_AA_A}{V_CN_A}$$ \\(n_CA_C\\)：Cation的Number和Moalr Mass，nA同理 对于Vc来说，其a变为了两个Atoms的Radus*2，有\\(V_C=(2R_A+2R_C)^3\\) Theoretical Density of Rock Salt #\r$$\\rho = \\frac{n_C A_C + n_A A_A}{V_C N_A}$$\nAnions #\r在Rock Salt Structure中的Anion看似处于FCC的位置中 但实际上由于附近的Cation和不同Anion之间的相互作用力导致Anion实际上不在精确的FCC位置上 Cations #\rthe cations will always touch their nearest neighbour anions The Body Centred Cubic Crystal (BCC) Structure #\r结构特点：每个晶胞的八个顶点各有一个原子，且晶胞中心还有一个原子。 n：每个晶胞含有 2 个原子（8 个顶点原子各占 1/8，中心原子占 1 个）。 CN：8（每个原子有 8 个最近邻原子）。 APF：约 68%。 例子：铁、钨、铬等。 Number of Atoms in BCC #\r$$\\frac{1}{2}*2+\\frac{1}{8}*8=2$$\nCoordination Number of BCC #\r$$CoordinationNumberBCC​=8$$\nAtomic Packing Factor for BCC #\r$$APF=\\frac{Volume_{Spheres}}{Volumn_{Unit~Cell}}$$\n对于BCC，要取其Unit Cell边长与Atom radius关系得用Cubic Diagonal，即 $$3a^2=16R^2，\\Rightarrow a_{BCC}=\\frac{4}{\\sqrt3}R$$ $$APF = \\frac{2 \\left( \\frac{4}{3} \\pi R^3 \\right)}{(\\frac{4}{\\sqrt3})^3} \\ \\Rightarrow APF_{BCC} = 0.68$$\nInterstitial Sites #\rSpace between other atoms 其体积就代表了Crystal Structure中的间隙的部分 By convention, we name interstitial sites according to the solid geometry that they create Octanhedron Interstitial Site #\r对于Rock Salt中的Anion的Interstitial Sites，将他们命名为Octanhedron Interstitial Site Coordination Number of a Interstitial Site #\r对于Interstitial Site来说，其CN代表了Interstitial Site中心点位置的Atom与最近Atom接触的个数 对于Rock Salt来说，Intersitital Site CN = 6 Simple Cubic Interstitial Site #\r结构特点：每个晶胞的八个顶点各有一个原子，顶点原子通过边连接，但面心和体心没有原子。 n：1Atom（8 个顶点原子各占 1/8）。 CN：6（每个原子有 6 个最近邻原子）。 APF：约 52%。 例子：钋（唯一的自然存在的例子）。 纯的简单立方晶格中，中心位置是空的（这个红点代表的就是Intersititial Site间隙位的大小 但在体心立方或其他某些间隙结构中，这一位置可以被其他原子或离子占据 Coordination Number of Simple Cubic #\r$$CoordinationNumberSimpleCubic​=8$$\nThe Size of Interstitial Sites #\r就Interstitial Site来说，其具有实际大小 前面Rock Salt中提到过Cations will always touch their nearest neighbour anions 阳离子总是会接触它们最近的阴离子，因此阳离子只有在足够大时才会占据晶体结构中的间隙位。如果阳离子太小，它将无法与最近的阴离子接触，因此不会稳定地占据间隙位 $$\\sin 45 = \\frac{2R_A}{2R_A + 2R_C} \\\n(2R_A + 2R_C)\\sin 45 = 2R_A \\\n2R_A\\sin 45 + 2R_C\\sin 45 = 2R_A \\\nR_A\\sin 45 + R_C\\sin 45 = R_A \\\n\\frac{R_A}{R_A}\\sin 45 + \\frac{R_C}{R_A}\\sin 45 = 1 \\\n\\sin 45 + \\frac{R_C}{R_A}\\sin 45 = 1 \\\n\\frac{R_C}{R_A}\\sin 45 = 1 - \\sin 45 \\\n\\frac{R_C}{R_A} = \\frac{1 - \\sin 45}{\\sin 45}=0.414$$\nHexagonal Close Packed (HCP) Structure #\r结构特点：原子以六边形排列，沿c轴有堆叠的结构。原子层是按照ABAB\u0026hellip;的顺序堆叠。 n：每个晶胞含有 6 个原子（从整体堆叠考虑）。 CN：12（类似于FCC，每个原子有12个最近邻原子）。 APF：约 74%。 ex.：镁、钛、锌等 Number of Atoms in HCP #\rCoordination Number of HCP #\rCN = 12 Atomic Packing Factor in HCP #\rHCP有着和FCC一样的APF（都为0.74）所以FCC有时会被称为CCP Different to FCC #\rFCC和HCP的主要区别在于原子的堆积顺序 FCC中的原子堆积顺序是ABCABC 而HCP中的堆积顺序是ABAB 尽管它们的堆积顺序不同，但由于原子排列非常紧密，它们的APF都是0.74 Close Packed #\r要想让Atom排列的更加紧密，需要有Close Packed的结构 当Atom在这种排列下，APF才能更高 在Not Close Packed下，这种排列的方式更加的松散 Closed Packed Plane #\rNot Closed Packed Plane in FCC #\r对于FCC的侧面上的Atom来说，其并不处于Closed Packed状态下 ","date":"Sep 25 2024","externalUrl":null,"permalink":"/docs/engineering-chemistry--materials-science/ecms4.thestructureproperty/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 9/25/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eYoung’s modulus change with Density \r\n    \u003cdiv id=\"youngs-modulus-change-with-density\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#youngs-modulus-change-with-density\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS4.TheStructureProperty/ECMS4.TheStructure-Property-24.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"ECMS 4. The Structure Property","type":"docs"},{"content":" Last Edit 9/24/24\nHooke’s Law #\r$$F=kx$$\nSpring constant (k): Spring Constant Material properties（材料性能） #\r主要指材料的基本机械性能，如弹性模量、屈服强度、抗拉强度等 它们的计算方式应当剔除几何尺寸的影响 Stress 应力 #\r物体在外力作用下，单位面积上承受的内力 $$Stress(\\sigma)=\\frac{F}{A_0}$$ \\(A_0\\): Initial Cross-Sectional Area 应力的单位通常是帕斯卡（Pa） Strain 应变 #\r应变是材料在外力作用下发生的变形程度 $$Strain(\\epsilon)=\\frac{\\Delta l}{l_0}$$\n\\(\\Delta l\\)：change of material\u0026rsquo;s length \\(l_0\\): Initial length of material Young\u0026rsquo;s Modulus 杨氏模量 #\r是固体在载荷下的刚度或对弹性变形的抵抗力的量度\n材料在压缩或拉伸时会发生Elastic Deformation，而在Unloaded之后则会回到之前的Equilibrium $$E=\\frac{\\sigma}{\\epsilon}=\\frac{\\frac{F}{A_0}}{\\frac{\\Delta l}{l_0}}=\\frac{F\\cdot l_0}{A_0\\cdot \\Delta l}$$\nYoung\u0026rsquo;s Modulus (E)\n单位是Pa\nStructure Independent #\r当说\u0026quot;XXX is xxx independent\u0026quot; 时，代表了某个事物不依赖于某个特定因素 这里则是Young\u0026rsquo;s Modulus是不依赖于Structure Young\u0026rsquo;s Modulus其只与材料有关，与形状无关 具体来说是取决与材料的原子级别的相互作用，而不是材料的宏观或微观结构 Micro Perspective of Stress and Strain #\r从微观角度来看，物体由Atoms组成，其中存在Inter Atomic Forces 当Applied External Force的时候，物体将处于Loaded状态，其Shape将会发生改变 具体来说，Shape发生的改变是由于Atoms之间的间距发生了改变 不过只要整个Stress小于Yield Strength，所有的Deformation都将是Elastic的 代表了，当External Force被撤去的时候，既Unloaded之后，Atoms将会回到他们原来的Equilibrium position 需要注意的是，Atom之间的间距将会回到一开始的\\(r=r_0\\) 所以可以得出一个结论：Elastic Strain is Reversible Stress-Strain Curve 应力-应变图 #\r本图实际上为F-r图，即拉力-原子间半径图，但与Stress-Strain图相似，便用SS图讲解\n对于一个材料，在对其施加Stress的时候，其Strain会出现如此的固定趋势 在Stress等于0的时候，物体处于Equilibrium状态，具体来说其Attractive Force = Repulsive Force 在持续施加Stress后，Atoms最终将到达一个Yield Strength（不可逆点）后将会产生Plastic Deformation（将在下一章提到） 将Stress-Strain图放大到\\(r_0\\)两边后观察 可以发现Stress随Strain(Atomic Spacing)基本呈现Linear Trend，便可以说 $$E\\propto \\frac{dF}{dr}|_r=r_0$$ Young\u0026rsquo;s Modulus is directly propotional to slope of interatomic force speration curve at equilibrium spacing 简单的理解便为：杨氏模量等于与Stress对于Strain的变化率 更具图可以看出Stress对Strain的变化速率越大，其Young\u0026rsquo;s Modulus越大 即在Plastic Deformation前，Stress（External Force）越大材料的Young\u0026rsquo;s Modulus越大 既抵抗Elastic Deformation的作用越大 The way to determine material properties #\rTensile(Tension) Test\n图中展示了拉伸测试的基本原理，即通过对材料施加拉力（Tension），使其伸长（elongating），从而获得应力-应变曲线等相关数据 Grip Region（夹持区）：这是样品被测试机夹持的地方，两端施加拉力 Reduced Section（缩小部分）：这是样品的中间区域，它的截面积被减少，以确保样品在这个区域发生断裂或变形。在该区域内，材料会受到均匀的拉伸应力。 通过拉伸测试，可以获得材料的关键参数，如杨氏模量 (Young\u0026rsquo;s Modulus)、屈服强度 (Yield Strength)、极限抗拉强度 (Ultimate Tensile Strength, UTS) 和断裂延伸率 (Fracture Elongation) Disadvantage of Tensile Test #\r这种测试方法仍然存在局限性，例如Ceramics \u0026amp; Glasses等都不能利用这种方式测试Material Properties，具体来说 Low strain to fracture, almost no deformation before breaking：在断裂之间，几乎不发生Elastic Deformation hard to grip：对于Tensile Test所必须的Grip Region，由于一些Material的特殊性，他们无法在Grip Region内被夹住，继而无法进一步测试 Hard to load on Axis: 当Grip Region滑动的时候，无法使力沿轴拉伸 关于为什么这些会发生，如为什么Ceramics会直接断裂等，参考[[ECMS 3. Plastic Deformations]] ","date":"Sep 24 2024","externalUrl":null,"permalink":"/docs/engineering-chemistry--materials-science/ecms2.elasticbehavior/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit 9/24/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eHooke’s Law \r\n    \u003cdiv id=\"hookes-law\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#hookes-law\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003e$$F=kx$$\u003c/p\u003e","title":"ECMS 2. Elastic Behavior","type":"docs"},{"content":"","date":"Sep 23 2024","externalUrl":null,"permalink":"/tags/cover/","section":"Tags","summary":"","title":"Cover","type":"tags"},{"content":"\rLast Edit: 9/23/24\nPlastice Deformation (Permanent Deformation) #\rwe use the term plastic to describe permanent deformation 之所以是Plastic，是因为它derives from the Greek plastikos meaning to sculpt Changes After Plastic Deformation #\r在Plastic Deformation后，Atomic Spacing将保持\\(r=r_0\\) 但是Sequence of atoms将进入一个New Equilibrium 即在Marcro Perspective上发生Shape的Deform Tensile Strain将会保持一定非零大小 Micro Perspective of Plastic Deformation #\rDifferent between Elastic and Plastic Deformation #\rElastic #\r对于Elastic Deformation，开始前物理Atom之间间距应为\\(r_0\\) 泄力后仍应该是\\(r_0\\)，并且Atom将会到他们原有的Equilibrium 并且物体从Marco Perspective上并不发生Deformation Plastic #\r结束后Atom之间间距仍应该是\\(r_0\\) 泄力后Atom将进入一个新的Equilibrium 物体在泄力后，他的Tensile Strain将不会便为0而是保持在一定数 即Shape已经发生了Perminant Change Beyond Elastic Region #\r在Elastic Region外，便是完整的[[ECMS 2. Elastic Behavior#Young\u0026rsquo;s Modulus 杨氏模量]]的模型 Yield Strength: 屈服强度是指材料在发生永久变形之前，能够承受的最大应力。 当Strain到达Yield Strength之后，材料会从Elastic Deformation转变为Plastic Deformation，即Material发生Permanent Deformation 在过了Yield Strength之后Strain再增加后到了一定程度之后便会产生Fracture(Broken into pieces) Stress-Strain Curve for different materials #\rMetals #\r图中的绿色曲线 其特点有在一定位置之后开始产生Permanent Deformation 之后在持续的施加Stress之后其Strain变化率降低最后产生Fracture 相比于Ceramic和Polymer，其Young\u0026rsquo;s Modulus处于中间位置，高于Polymer但小于没有Permanent Deformation阶段的Ceramic Polymer #\r相对来说没有什么特点 具有较低的Young\u0026rsquo;s Modulus和Permanent Deformation区间 Ceramic #\r对于陶瓷类的物质，其没有Permanent Deformation的区间 对于他来说也存在Elastic Region 但可以看出整体Young\u0026rsquo;s Modulus非常高，并且呈现线性 在施加了一定的Stress后会直接Load enough and fracture Three-Point-Blending Test #\r底部两个点用作支撑，上方一个力将物体往下压 $$Stress(\\sigma)=\\frac{3FL}{2wh^2}$$\nTempered Glass 钢化玻璃 #\r![[ECMS 3. Plastic Deformations-5.png]]\n再高温下迅速向表面喷冷凝液将其降温 冷却将使玻璃表面收缩的比内部更快，产生了向心的Compress Stress 而内部由于受力将产生反作用力，向外产生张应力 整体的结构处于一个向内部收缩的趋势，导致当其受到了外力的时候，尝试使其Fracture的导致分子之间结构被破坏的力将被抵消 并且由于其内部存在Residual Stress（残余应力）导致了整体结构破坏的时候其Residual Stress将破坏结构至非常小的结构 ","date":"Sep 23 2024","externalUrl":null,"permalink":"/docs/engineering-chemistry--materials-science/ecms3.plasticdeformation/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 9/23/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003ePlastice Deformation (Permanent Deformation) \r\n    \u003cdiv id=\"plastice-deformation-permanent-deformation\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#plastice-deformation-permanent-deformation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003ewe use the term \u003cstrong\u003eplastic\u003c/strong\u003e to describe permanent deformation\u003c/li\u003e\n\u003cli\u003e之所以是Plastic，是因为它derives from the Greek \u003cstrong\u003eplastikos\u003c/strong\u003e meaning to sculpt\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch5 class=\"relative group\"\u003eChanges After Plastic Deformation \r\n    \u003cdiv id=\"changes-after-plastic-deformation\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#changes-after-plastic-deformation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h5\u003e\r\n\u003cul\u003e\n\u003cli\u003e在Plastic Deformation后，Atomic Spacing将保持\\(r=r_0\\)\u003c/li\u003e\n\u003cli\u003e但是Sequence of atoms将进入一个New Equilibrium\u003c/li\u003e\n\u003cli\u003e即在Marcro Perspective上发生Shape的Deform\u003c/li\u003e\n\u003cli\u003eTensile Strain将会保持一定非零大小\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch5 class=\"relative group\"\u003eMicro Perspective of Plastic Deformation \r\n    \u003cdiv id=\"micro-perspective-of-plastic-deformation\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#micro-perspective-of-plastic-deformation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h5\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS3.PlasticDeformations/ECMS3.PlasticDeformations.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\n\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS3.PlasticDeformations/ECMS3.PlasticDeformations-1.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\n\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS3.PlasticDeformations/ECMS3.PlasticDeformations-2.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"ECMS 3. Plastic Deformation","type":"docs"},{"content":" Ramsay, S. (2024). Engineering Chemistry \u0026amp; Materials Science. Top Hat. https://app.tophat.com/e/797389/content/course-work/item/1213609::72131f51-0d59-4379-85f9-30182e840f9b. ","date":"Sep 23 2024","externalUrl":null,"permalink":"/docs/engineering-chemistry--materials-science/","section":"Docs","summary":"\u003cul\u003e\n\u003cli\u003eRamsay, S. (2024). Engineering Chemistry \u0026amp; Materials Science. Top Hat. \u003ca href=\"https://app.tophat.com/e/797389/content/course-work/item/1213609::72131f51-0d59-4379-85f9-30182e840f9b\" target=\"_blank\"\u003ehttps://app.tophat.com/e/797389/content/course-work/item/1213609::72131f51-0d59-4379-85f9-30182e840f9b\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e","title":"Engineering Chemistry \u0026 Materials Science","type":"docs"},{"content":" Last Edit 7/4/24\n通货膨胀 #\r钱的贬值 CPI Consumer Price Index 消费者物价指数 #\r美国CPI #\r解释通货膨胀的理论 #\rKeynesian 凯恩斯主义 #\rNeo-Keynesian 新凯恩斯主义 #\rMonetarism 货币主义 #\r根本原因 #\r通货膨胀的可控性 #\r非常难以控制 通货膨胀的后果 #\r当把钱藏在床底下时，其购买力在不断的下降 逼迫人们不断的生产和消费 对于经济体来说，主要目标是提高GDP，人均消费水平 而通过适量的通货膨胀可以有助于提高人们的生产热情，提高GDP，对于整个经济体来说是好的 Misery Index 痛苦指数 #\rDeflation 通货紧缩 #\r今年的钱存着会比明年更加之前 90年代的日本就是典型例子 人们就不会消费，不花钱不生产，进入一个低欲望社会，GDP也就下降 HyperInflation 恶心通货膨胀 #\r对于经济的打击是毁灭性的 Target Inflation Rate 目标通胀 #\r保住通胀是底线，即使可能导致段时间的经济下降 导致Inflation的原因 #\r因素一：Demand-Pull 需求拉动 #\r刺激需求，导致产量的上升与价格的上升，形成一个对于经济上升的良心循环 但可以发现副作用是Inflation 政府可以通过直接发钱达到刺激需求，其可以直接刺激经济，但要面临通货膨胀的风险 可以总结出，Inflation和Economic Growth注定是会绑定在一块的 产能过剩 #\r产能直接影响了刺激需求后Inflation的变化 当产能过剩的情况下，即使总需求上升，由于能有产能，并不需要大幅度提高价格以达到供应需求的目的 相反，当产能不够的情况下，需求的价格必定会上涨导致Inflation的发生 判断产能的方式 - Unemployment Rate 失业率 #\r当失业率高的情况下，说明劳动力很多都在休息，既属于产能过剩的情况 所以一般Inflation发生前都会存在Low Unemployment Rate的情况 Philips Curve 菲利普斯曲线 #\r钱发不到实体经济中 #\r所以最简单的方式就是政府直接发钱，直接发到人手里 Cost-push 成本上涨 #\r成本上涨导致的价格上涨 反而抑制了需求，百害而无一益 俄罗斯通胀 #\r由于卢布的下跌导致的成本上升导致的Cost-push Inflation Money Supply 过量的货币供给 #\r几乎所有的HyperInflation都是政府过度印钱导致的 为什么要不断印钱 #\r政府既然看到了为什么不停止 因为陷入了恶性循环 一般都是外因导致的，如战争 政府无节制印钱后，货币量增加，大家需求也就上涨，来到了Demand-Pull中 但由于政府印钱速度太快，导致了实际上Demand-Pull的Inflation来到了不可抑制的情况，但这时候其实还没达到HyperInflation 这时候人民已经有了足够的钱，并且不会存钱，导致了大家都不再工作，导致产量的下降，导致成本的上升，最终进入恶性循环 预期的Inflation #\r当预期了Inflation时，大家都会超前消费，货币流通速度增加了 通货膨胀就自己发生了 ","date":"Jul 4 2024","externalUrl":null,"permalink":"/docs/economic/inflation/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit 7/4/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e通货膨胀 \r\n    \u003cdiv id=\"%E9%80%9A%E8%B4%A7%E8%86%A8%E8%83%80\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E9%80%9A%E8%B4%A7%E8%86%A8%E8%83%80\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e钱的贬值\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eCPI Consumer Price Index 消费者物价指数 \r\n    \u003cdiv id=\"cpi-consumer-price-index-%E6%B6%88%E8%B4%B9%E8%80%85%E7%89%A9%E4%BB%B7%E6%8C%87%E6%95%B0\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#cpi-consumer-price-index-%E6%B6%88%E8%B4%B9%E8%80%85%E7%89%A9%E4%BB%B7%E6%8C%87%E6%95%B0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e美国CPI \r\n    \u003cdiv id=\"%E7%BE%8E%E5%9B%BDcpi\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%BE%8E%E5%9B%BDcpi\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/Economic_Static/Inflation/Inflation%282%29.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"Inflation 通货膨胀","type":"docs"},{"content":" Last Edit 4/15/24\nRegression 回归，是能为一个或多个自变量与因变量之间关系建模的一种方式\n[[Regression 回归]] 3.1.1 线性回归的基本元素 #\rLinear Regression 线性回归可以追溯到19世纪，其基于几个基本的假设 假设自变量与因变量之间为线性关系 假设噪声正常，如遵循正态分布 3.1.1.1 线性模型 #\r[[线性模型]] 线性假设是指目标可以表示为特征的加权和，如下例子 E.X. $$Price=w_{area}\\cdot area+w_{age}\\cdot age+b$$\nw称为Weight权重 b称为Bias，Offset或者Intercept偏置，即特征为0时的预测值 严格来说，上式为输入特征的一个[[Affine Transformation 仿射变换]]\n给定一个数据集，我们的目标即为寻找模型的Weight和Offset 高维数据集 #\r在Deep Learning 领域，我们通常使用的是高纬数据集，建模时采用[[2.3 线性代数]]的表示方法会比较方便。 当我们的输入包含多个特征时，我们将预测结果表示为\\(\\hat{y}\\) 点积形式 #\r可以用点积形式来简洁的表达模型\\(x\\in R^d,w\\in R^d\\) $$\\hat{y}=w^Tx+b$$ Model Parameters 模型参数 #\r在开始寻找最好的模型参数前，我们还需要两个东西 一种模型质量的度量方式 #\r一种能更新模型以提高预测质量的方式 #\r3.1.1.2 损失函数 #\r在开始考虑如何用模型Fit 拟合数据之前，我们需要一个拟合程度的度量 Loss Function 损失函数 #\r量话目标的实际值和预测值之间的差距 通常选用非负数作为Cost，并且数值越小损失越小 平方误差函数 #\r回归问题中最常用的Cost Function是平方误差函数 $$l^{(i)}(w,b)=\\frac{1}{2}(\\hat{y}^{(i)}-y^{(i)})^2$$ 常数\\(\\frac{1}{2}\\)的存在不会带来本质的差别，但当我们对这一方程求导后由于\\(\\frac{1}{2}\\)的存在会使常数等于1 由于平方误差函数中的二次方项，会导致估计值和观测值之间较大的差异造成更大的损失。 为了度量模型在整个数据集上的质量，我们需要计算训练集上的样本损失均值 $$L(w,b)= \\frac{1}{n}\\Sigma^n_{i=1}l^{(i)}(w,b)=\\frac{1}{n}\\Sigma^n_{i=1}\\frac{1}{2}(w^Tx^{(i)}+b-y^{(i)})^2$$ 总的来说训练模型就是为了找到一组参数\\(w^,b^\\)，其 $$w^,b^=argmin~L(w,b)$$ 3.1.1.3 解析式 #\r线性回归是一个很简单的优化问题，与大部分模型不同，其解可以用一个公式简单的表达出来，这类解便称为Analytical Solution 解析解 3.1.1.4 随机梯度下降 #\r即使在无法得到解析解的情况下，我们可以有效的训练模型 Gradient Descent 梯度下降 #\r最简单的方法就是计算Cost Function关于模型参数的导数（梯度） 但由于每次操作前都需要遍历整个数据集，导致执行速度非常之慢 所以通常会在每次更新时候抽取一小批样本，即为Minibatch Stochastic Gradient Descent 小批量随机梯度下降 SGD #\rMinibatch Stochastic Gradient Descent 小批量随机梯度下降 每次迭代中，我们首先随机抽样一个小批量B， 它是由固定数量的训练样本组成的。 然后，我们计算小批量的平均损失关于模型参数的导数（也可以称为梯度）。 最后，我们将梯度乘以一个预先确定的正数，并从当前参数的值中减掉 $$(w,b)\\leftarrow(w,b)-\\frac{\\eta}{|B|}\\Sigma_{i\\in B}\\partial_{w,b}l^{(i)}(w,b)$$ 初始化模型参数的值 从数据集中随机抽取小批量样本在负梯度方向上更新参数，并一直迭代 \\(\\eta\\)表示Learning Rate 学习率 B表示Batch Size 批量大小 Hyperparameter 超参数 #\r这些可以调整但不在训练过程中更新的参数称为超参数 Hyperparameter Tuning为调整Hyperparameter的过程 而训练迭代结果是在独立的验证数据集（validation dataset）上评估得到的 收敛 #\rLinear Regression只会让预测值无限接近于实际值而却不能在有限的步数内非常精确地达到最小值 Generalization 泛化 #\r寻找到一组合适的Hyperparameter纵然困难，但更加困难的是找到一组参数，这组参数能够在我们从未见过的数据上实现较低的损失， 这一挑战被称为Generalization 泛化 3.1.1.5 用模型进行预测 #\r需要指出的是，Deep Learning对于实际值的接近更多是一种Prediction预测而非Inference推断 3.1.2 矢量化加速 #\r为了同时处理整个小批量的样本，同时防止在python中编写开销高昂的for循环 矢量化性能测试 #\r实例化两个全为1的10000维向量，采取两种处理方式，Python的for循环和对+的调用 ###初始化两个Tensor\rn = 10000\ra = torch.ones([n])\rb = torch.ones([n])\r###用for循环完成一次\rc = torch.zeros(n)\rtimer = Timer()\rfor i in range(n):\rc[i] = a[i] + b[i]\rf\u0026#39;{timer.stop():.5f} sec\u0026#39;\r###用线性代数完成矢量化运算\rtimer.start()\rd = a + b\rf\u0026#39;{timer.stop():.5f} sec\u0026#39; 得到的结果为 0.167sec 和0.00042 sec 3.1.3 正态分布与平方损失 #\r接下来，我们通过对噪声分布的假设来解读平方损失目标函数 正态分布 #\r[[Normal Distribution 正态分布]] 均方误差损失函数 #\r均方损失可以用于线性回归的一个原因是：我们假设了观测中包含噪声，其中噪声服从正态分布，如下 $$y=w^Tx+b+\\epsilon$$ \\(\\epsilon\\)代表了噪声 Likehood 似然 #\r[[Likehood 似然]] 通过给定的x观测到特定y的似然（likelihood） $$p(y|x)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp(-\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2)$$ 对于似然函数\\(L(\\theta|data)=P(data|\\theta)= \\Pi^N_{i=1}P(x_i|\\theta)\\) 已知x的正态分布密度函数，也就是x（\\(\\theta\\)取每个值的概率） 要求得给定x（\\(\\theta\\)）（其不固定，但遵循正态分布）观测到特点y的似然，得到公式 \\(L(x|y)=P(y|x)\\) 已知\\(p(y|x)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp(-\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2)\\) 由于\\(P(y|x)=\\Pi^N_{i=1}P(y^{(i)}|x^{(i)})\\)（由x的参数条件下观测到y的可能性为独立的N个子事件的乘积） 根据[[Maximum Likehood Estimation 极大似然估计]]，参数w和b的最优值是使整个数据集的[[Likehood 似然]]最大的值 但又因为乘积最大化问题十分复杂，并且由于历史遗留问题，优化常说的不是最大化，而是最小化 所以我们需要通过最小化对数似然\\(-logP(y|x)\\)，由此可以得到的数学公式为 $$-logP(y|x)=\\sum\\limits^n_{i=1}\\frac{1}{2}log(2\\pi\\sigma^2)+\\frac{1}{2\\sigma^2}(y^{(i)}-w^Tx^{(i)}-b)^2$$ 推导如下 \\(-logP(y|x)=-log\\sum\\limits^n_{i=1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp(-\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2)\\) \\(=-log\\sum\\limits^n_{i=1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}e^{(-\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2)}\\) \\(=-log(\\sum\\limits^n_{i=1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}})+\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2\\) \\(=-log\\sum\\limits^n_{i=1}(2\\pi\\sigma^2)^{-\\frac{1}{2}}+\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2\\) = \\(\\sum\\limits^n_{i=1}\\frac{1}{2}log(2\\pi\\sigma^2)+\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2\\) 现在我们只需要假设�是某个固定常数就可以忽略第一项\\(\\sum\\limits^n_{i=1}\\frac{1}{2}log(2\\pi\\sigma^2)\\)，因为第一项不依赖于w和b 对于第二项，除了常数\\(\\frac{1}{\\sigma^2}\\)外，其余部分与[[#平方误差函数]]是一样的 平方误差函数 #\r$$l^{(i)}(w,b)=\\frac{1}{2}(\\hat{y}^{(i)}-y^{(i)})^2$$\n幸运的是，上面式子的解并不依赖于\\(\\sigma\\) 因此，在高斯噪声的假设下，最小化均方误差等价于对线性模型的极大似然估计 3.1.4 从线性回归到深度网络 #\r到目前，我只谈论了线性模型，而神经网络涵盖了更为丰富的模型，并且我们也可以用描述神经网络的方式来描述线性模型，从而把线性模型看作一个神经网络。可以用“层”符号来重写这个模型 3.1.4.1 神经网络图 #\r制图表可以可视化模型中正在发生的事情，但该图只显示了链接模式，而不包含权重和偏置的值 在上图中，输入为\\(x_1,\\dots x_d\\)，可知输入层的Feature Dimensionality 输入数（或称为特征维度）为d\n网络的输出层为\\(o_1\\)，因此输出层的输出数为1\n需要注意的是，输入值都是已经给定的，并且只有一个_计算_神经元。 由于模型重点在发生计算的地方，所以通常我们在计算层数时不考虑输入层。\nFully-Connected Layer 全连接层 #\r对于线性回归，每个输入都与每个输出（在本例中只有一个输出）相连， 我们将这种变换称为全连接层（Fully-connected layer）或称为稠密层（dense layer）。 3.1.4.2 生物学 #\r即使观察真实的神经元，但当今大多数深度学习的研究几乎没有直接从神经科学中获得灵感\n我们援引斯图尔特·罗素和彼得·诺维格在他们的经典人工智能教科书 Artificial Intelligence:A Modern Approach (Russell and Norvig, 2016) 中所说的：虽然飞机可能受到鸟类的启发，但几个世纪以来，鸟类学并不是航空创新的主要驱动力。 同样地，如今在深度学习中的灵感同样或更多地来自数学、统计学和计算机科学。\n","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.1_linearregression/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit 4/15/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eRegression 回归，是能为一个或多个自变量与因变量之间关系建模的一种方式\u003c/p\u003e","title":"D2L 3.1 Linear Regression","type":"docs"},{"content":"从零开始实现整个方法， 包括数据流水线、模型、损失函数和小批量随机梯度下降优化器。 虽然现代的深度学习框架几乎可以自动化地进行所有这些工作，但从零开始实现可以确保我们真正知道自己在做什么。\n3.2.1 生成数据集 #\r为了简单起见，我们将根据带有噪声的线性模型构造一个人造数据集 使用线性模型参数\\(w=[2,-3.4]^T,b=4.2\\)和噪声项\\(\\epsilon\\)生成数据集及其标签 $$y=Xw+b+\\epsilon$$ \\(\\epsilon\\)可以视为模型预测和标签时的潜在观测误差 3.2.2 读取数据集 #\r3.2.3 初始化模型参数 #\r通过从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重， 并将偏置初始化为0。 w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)\rb = torch.zeros(1, requires_grad=True) 在初始化参数之后，我们的任务是更新这些参数，直到这些参数足够拟合我们的数据 并运用[[2.5 自动微分]]来计算梯度 3.2.4 定义模型 #\r这里我们用的还是线性模型，即$$\\hat y=w^Tx+b$$ def linreg(X, w, b): #@save\r\u0026#34;\u0026#34;\u0026#34;线性回归模型\u0026#34;\u0026#34;\u0026#34;\rreturn torch.matmul(X, w) + b 3.2.5 定义损失函数 #\r模型建立后，开始使用对原函数的损失函数进行梯度下降 这里我们使用[[3.1_LinearRegression#平方误差函数]] 3.2.6 定义优化算法 #\r使用[[3.1_LinearRegression#Minibatch Stochastic Gradient Descent 小批量随机梯度下降]] 3.2.7 训练 #\r本质为执行一下循环 初始化参数 更新梯度，更新参数 ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.2_object-orienteddesignforimplementation/","section":"Docs","summary":"\u003cp\u003e从零开始实现整个方法， 包括数据流水线、模型、损失函数和小批量随机梯度下降优化器。 虽然现代的深度学习框架几乎可以自动化地进行所有这些工作，但从零开始实现可以确保我们真正知道自己在做什么。\u003c/p\u003e","title":"D2L 3.2 Object-Oriented Design for Implementation","type":"docs"},{"content":"本节将介绍如何通过使用深度学习框架来简洁地实现[[3.2_Object-OrientedDesignforImplementation]]中的线性回归模型\n3.3.1 生成数据集 #\rimport numpy as np\rimport torch\rfrom torch.utils import data\rfrom d2l import torch as d2l\rtrue_w = torch.tensor([2, -3.4])\rtrue_b = 4.2\rfeatures, labels = d2l.synthetic_data(true_w, true_b, 1000) d2l.synthetic_data(true_w, true_b, 1000) 是 d2l 库中的一个函数调用。这个函数用于生成合成数据，其中包括特征数据和对应的标签数据。 具体地，这个函数接受三个参数： true_w：真实的权重，用于生成特征数据。 true_b：真实的偏置，用于生成特征数据。 1000：生成数据的数量，这里是指生成1000个样本。 3.3.2 读取数据集 #\rdef load_array(data_arrays, batch_size, is_train=True): #@save\r\u0026#34;\u0026#34;\u0026#34;构造一个PyTorch数据迭代器\u0026#34;\u0026#34;\u0026#34;\rdataset = data.TensorDataset(*data_arrays)\rreturn data.DataLoader(dataset, batch_size, shuffle=is_train)\rbatch_size = 10\rdata_iter = load_array((features, labels), batch_size) 3.3.3 定义模型 #\r对于标准深度学习模型，我们可以使用框架的预定义好的层 ## nn是神经网络的缩写\rfrom torch import nn\rnet = nn.Sequential(nn.Linear(2, 1)) nn.Sequential：这是 PyTorch 中用于构建顺序神经网络模型的类。它允许用户按顺序堆叠多个层或模块，构建神经网络模型。 nn.Linear(2, 1)：这里创建了一个全连接层，其中 nn.Linear 是 PyTorch 中用于定义全连接层的类。构造函数 nn.Linear(in_features, out_features) 接受两个参数： in_features：输入特征的数量。在这个例子中，输入特征的数量为 2。 out_features：输出特征的数量。在这个例子中，输出特征的数量为 1。 因此，net 这个模型包含一个具有 2 个输入特征和 1 个输出特征的全连接层。 这样的模型可以用于简单的二分类问题，其中输入特征有 2 个，输出特征有 1 个，代表着模型对样本的分类结果。 3.3.4 初始化模型参数 #\rnet[0].weight.data.normal_(0, 0.01)\rnet[0].bias.data.fill_(0) 在网络的第一层输入参数 3.3.5 定义损失函数 #\r计算均方误差使用的是MSELoss类，也称为平方�2范数。 默认情况下，它返回所有样本损失的平均值。 loss = nn.MSELoss() 3.3.6 定义优化算法 #\rtrainer = torch.optim.SGD(net.parameters(), lr=0.03) 当我们实例化一个SGD实例时，我们要指定优化的参数 （可通过net.parameters()从我们的模型中获得）以及优化算法所需的超参数字典。 小批量随机梯度下降只需要设置lr值，这里设置为0.03。 3.3.7 训练 #\r通过深度学习框架的高级API来实现我们的模型只需要相对较少的代码。 我们不必单独分配参数、不必定义我们的损失函数，也不必手动实现小批量随机梯度下降。 当我们需要更复杂的模型时，高级API的优势将大大增加。 当我们有了所有的基本组件，训练过程代码与我们从零开始实现时所做的非常相似。\nnum_epochs = 3\rfor epoch in range(num_epochs):\rfor X, y in data_iter:\rl = loss(net(X) ,y)\rtrainer.zero_grad()\rl.backward()\rtrainer.step()\rl = loss(net(features), labels)\rprint(f\u0026#39;epoch {epoch + 1}, loss {l:f}\u0026#39;) num_epochs = 3：定义了训练的轮数，这里设置为 3 for epoch in range(num_epochs):：使用 for 循环迭代每个训练轮数 for X, y in data_iter:：使用 data_iter 迭代器遍历训练数据集，其中 X 是特征，y 是对应的标签 l = loss(net(X) ,y)：计算模型对当前批次数据的预测值，并计算与真实标签之间的损失 trainer.zero_grad()：梯度清零，以避免梯度累积 l.backward()：反向传播，计算损失函数相对于模型参数的梯度 trainer.step()：更新模型参数，采用优化算法更新参数 l = loss(net(features), labels)：计算当前训练轮数结束后整个训练集上的损失 print(f'epoch {epoch + 1}, loss {l:f}')：打印当前训练轮数和对应的损失值 ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.3_syntheticregressiondat/","section":"Docs","summary":"\u003cp\u003e本节将介绍如何通过使用深度学习框架来简洁地实现[[3.2_Object-OrientedDesignforImplementation]]中的线性回归模型\u003c/p\u003e","title":"D2L 3.3 A concise implementation of linear regression","type":"docs"},{"content":"回归可以用于预测_多少_的问题。 比如预测房屋被售出价格，或者棒球队可能获得的胜场数，又或者患者住院的天数。\n事实上，我们也对_分类_问题感兴趣：不是问“多少”，而是问“哪一个”\n3.4.1 分类问题 #\r[[One-hot encoding 独热编码]] 3.4.2 网格架构 #\r为了估计所有可能类别的条件概率，我们需要一个有多个输出的模型，每个类别对应一个输出。 为了解决线性模型的分类问题，我们需要和输出一样多的[[Affine Function 仿射函数]] E.X.\n假设现在有3个未规范化的预测(Logit)：\\(o_1,o_2和o_3\\) \\(o_1=x_1w_{11}+x_2w_{12}+x_3w_{13}+x_4w_{14}+b_1\\) \\(o_2=x_1w_{21}+x_2w_{22}+x_3w_{23}+x_4w_{24}+b_2\\) \\(o_1=x_1w_{31}+x_2w_{32}+x_3w_{33}+x_4w_{34}+b_3\\) 3.4.3 全连接层的参数开销 #\r对于任何具有d个输入和q个输出的全连接层[[3.1_LinearRegression#Fully-Connected Layer 全连接层]]，其参数开销为\\(O(dq)\\)，但可以通过超参数减少到\\(O(\\frac{dq}{n})\\) 3.4.4 softmax 运算 #\r我们希望模型的输出\\(\\hat y_j\\)可以视为属于类\\(j\\)的概率，然后选择具有最大输出值的类别\\(argmaxx_jy_j\\)作为我们的预测，例如\\(\\hat y_1,\\hat y_2\\)和\\(\\hat y_3\\)分别为\\(\\hat y={0.1,0.8,0.1}\\)那么我们的预测变为独热编码的\\(y={0,1,0}\\)，即为鸡 能否将未规范化的预测o直接视作我们感兴趣的输出呢 #\r不行 因为将线性层的输出直接视为概率时存在一些问题 我们没有限制这些输出数字的总和为1 根据输入的不同，它们可以为负值 其违反了[[概率论公理]] 概率论 #\r要将输出视为概率，我们必须保证在任何数据上的输出都是非负的且总和为1 此外，我们需要一个训练的目标函数，来激励模型精准地估计概率 Calibration 校准 #\r例如， 在分类器输出0.5的所有样本中，我们希望这些样本是刚好有一半实际上属于预测的类别 Softmax 函数 #\r社会科学家邓肯·卢斯于1959年在选择模型（choice model）的理论基础上发明的softmax函数 softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持 可导的性质 为了完成这一目标，我们首先对每个未规范化的预测求幂，这样可以确保输出非负 为了确保最终输出的概率值总和为1，我们再让每个求幂后的结果除以它们的总和。如下式$$\\hat y=softmax(o)，其中\\hat y_j=\\frac{exp(o_j)}{\\sum_kexp(o_k)}=\\frac{e^j}{\\sum_ke^k}$$ 这里，对于所有的j总有\\(0\\leq\\hat y_j\\leq1\\)，因此\\(\\hat y\\)可以视为一个正确的概率分布 尽管softmax是一个非线性函数，但softmax回归的输出仍然由输入特征的仿射变换决定。 因此，softmax回归是一个线性模型（linear model）。 3.4.5 小批量样本的矢量化 #\r为了提高计算效率并且充分利用GPU，我们通常会对小批量样本的数据执行矢量计算 3.4.6 损失函数 #\r使用[[Maximum Likehood Estimation 极大似然估计]] 3.4.6.1 对数似然 #\rsoftmax函数给出了一个向量\\(\\hat y\\)， 我们可以将其视为“对给定任意输入x的每个类的条件概率\n通过计算softmax的对数似然，可以推导出他的损失函数\n假设现在有一个数据集 \\({X,Y}\\)，其具有n个样本，其中索引i的样本由特征向量\\(x^{(i)}\\)和独热标签向量\\(y^{(i)}\\)组成，可以将估计值与实际值进行比较$$P(Y|X)=\\prod^n_{i=1}P(y^{(i)}|x^{(i)})$$\n根据[[3.1_LinearRegression#Likehood 似然]]，已知最大化$P(Y|X)，相当于最小化负对数似然 $$P(Y|X)=\\sum^n_{i=1}-logP(y^{(i)}|x^{(i)})=\\sum^n_{i=1}l(y^{(i)},\\hat y^{(i)})$$\n其中对于任何标签y和预测模型\\(\\hat y\\)，损失函数为$$l(y,\\hat y)=-\\sum^{q}_{j=1}y_j\\log \\hat y_j$$\n这个[[3.1_LinearRegression#Loss Function 损失函数]]并没有介绍过，他的名字为Cross-entropy Loss交叉熵损失，将在后面介绍到\n为什么要加入对数，而不是直接取负数 #\r数值稳定性： 在概率模型中，可能会有大量的乘法运算，这可能导致数值下溢或溢出问题，尤其是当概率很小的时候。通过取对数，可以将乘法运算转换为加法运算，从而提高计算的稳定性。 对数函数的导数相对于原函数来说更简单，这使得梯度的计算更加高效。特别是在梯度下降等优化算法中，简化的导数计算可以显著减少计算量。 对数函数的特性使得推导和分析变得更加简单，因为它可以将乘法转换为加法，并且有很多性质，例如对数函数的导数比原函数更容易处理 3.4.6.2 softmax及其导数 #\r由于softmax和相关的损失函数很常见， 因此我们需要更好地理解它的计算方式 将3.4.3带入Cross-entropy Loss Function中，得到 $$\\begin{align}l(y,\\hat y)=-\\sum^{q}{j=1}y_j\\log \\frac{e^{o_j}}{{\\sum^{q}{k=1}e^{o_k}}} \\=-\\sum_{j=1}^{q}y_j[\\ln e^{o_j}-\\ln \\sum^q_{k=1}e^{o_k}] \\=\\sum^q_{j=1}y_j\\log\\sum^q_{k=1}e^{o_k}-\\sum^q_{j=1}y_jo_j \\=\\log \\sum^q_{k=1}e^{o_k}-\\sum^q_{j=1}y_jo_j\\end{align}$$ Softmax结合Cross Entropy的求导过程 #\r已知Cross Entropy Function$$H(y_i,p_i)=-\\sum_iy_i\\log pi$$\n\\(y_i\\)为预测事件，\\(\\log p_i\\)为一个分布的最优编码\n得到[[Home Page]] 3.4.6.3 交叉熵损失 #\r[[Cross-Entropy 交叉熵]] 3.4.7.1 熵 #\r[[Cross-Entropy 交叉熵#2. 熵]] ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.4_softmaxregression/","section":"Docs","summary":"\u003cp\u003e回归可以用于预测_多少_的问题。 比如预测房屋被售出价格，或者棒球队可能获得的胜场数，又或者患者住院的天数。\u003c/p\u003e","title":"D2L 3.4 Softmax Regression","type":"docs"},{"content":"MNIST数据集 (LeCun et al., 1998) 是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单。 我们将使用类似但更复杂的Fashion-MNIST数据集 (Xiao et al., 2017)。\n在此引入这个数据集是因为之后对于算法的评估均给予这一数据集\n%matplotlib inline\rimport sys\rfrom mxnet import gluon\rfrom d2l import mxnet as d2l\rd2l.use_svg_display() 3.5.1 读取数据集 #\r## 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，\r## 并除以255使得所有像素的数值均在0～1之间\rtrans = transforms.ToTensor()\rmnist_train = torchvision.datasets.FashionMNIST(\rroot=\u0026#34;../data\u0026#34;, train=True, transform=trans, download=True)\rmnist_test = torchvision.datasets.FashionMNIST(\rroot=\u0026#34;../data\u0026#34;, train=False, transform=trans, download=True) Fshion-MNIST中包含的10个类别，分别为t-shirt（T恤）、trouser（裤子）、pullover（套衫）、dress（连衣裙）、coat（外套）、sandal（凉鞋）、shirt（衬衫）、sneaker（运动鞋）、bag（包）和ankle boot（短靴）。 以下函数用于在数字标签索引及其文本名称之间进行转换。 def get_fashion_mnist_labels(labels): #@save\r\u0026#34;\u0026#34;\u0026#34;返回Fashion-MNIST数据集的文本标签\u0026#34;\u0026#34;\u0026#34;\rtext_labels = [\u0026#39;t-shirt\u0026#39;, \u0026#39;trouser\u0026#39;, \u0026#39;pullover\u0026#39;, \u0026#39;dress\u0026#39;, \u0026#39;coat\u0026#39;,\r\u0026#39;sandal\u0026#39;, \u0026#39;shirt\u0026#39;, \u0026#39;sneaker\u0026#39;, \u0026#39;bag\u0026#39;, \u0026#39;ankle boot\u0026#39;]\rreturn [text_labels[int(i)] for i in labels] Plt 可视化样本 #\rdef show_images(imgs, num_rows, num_cols, titles=None, scale=1.5): #@save\r\u0026#34;\u0026#34;\u0026#34;绘制图像列表\u0026#34;\u0026#34;\u0026#34;\rfigsize = (num_cols * scale, num_rows * scale)\r_, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\raxes = axes.flatten()\rfor i, (ax, img) in enumerate(zip(axes, imgs)):\rif torch.is_tensor(img):\r# 图片张量\rax.imshow(img.numpy())\relse:\r# PIL图片\rax.imshow(img)\rax.axes.get_xaxis().set_visible(False)\rax.axes.get_yaxis().set_visible(False)\rif titles:\rax.set_title(titles[i])\rreturn axes\rX, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))\rshow_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y)); ![[Pasted image 20240331164614.png]]\n3.5.2 读取小批量 #\r为了使我们在读取训练集和测试集时更容易，我们使用内置的数据迭代器，而不是从零开始创建。 回顾一下，在每次迭代中，数据加载器每次都会读取一小批量数据，大小为batch_size。 通过内置数据迭代器，我们可以随机打乱了所有样本，从而无偏见地读取小批量。 batch_size = 256\rdef get_dataloader_workers(): #@save\r\u0026#34;\u0026#34;\u0026#34;使用4个进程来读取数据\u0026#34;\u0026#34;\u0026#34;\rreturn 4\rtrain_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,\rnum_workers=get_dataloader_workers()) 3.5.3. 整合所有组件 #\r现在我们定义load_data_fashion_mnist函数，用于获取和读取Fashion-MNIST数据集。 这个函数返回训练集和验证集的数据迭代器。 此外，这个函数还接受一个可选参数resize，用来将图像大小调整为另一种形状 def load_data_fashion_mnist(batch_size, resize=None): #@save\r\u0026#34;\u0026#34;\u0026#34;下载Fashion-MNIST数据集，然后将其加载到内存中\u0026#34;\u0026#34;\u0026#34;\rtrans = [transforms.ToTensor()]\rif resize:\rtrans.insert(0, transforms.Resize(resize))\rtrans = transforms.Compose(trans)\rmnist_train = torchvision.datasets.FashionMNIST(\rroot=\u0026#34;../data\u0026#34;, train=True, transform=trans, download=True)\rmnist_test = torchvision.datasets.FashionMNIST(\rroot=\u0026#34;../data\u0026#34;, train=False, transform=trans, download=True)\rreturn (data.DataLoader(mnist_train, batch_size, shuffle=True,\rnum_workers=get_dataloader_workers()),\rdata.DataLoader(mnist_test, batch_size, shuffle=False,\rnum_workers=get_dataloader_workers())) 下面，我们通过指定resize参数来测试load_data_fashion_mnist函数的图像大小调整功能。 train_iter, test_iter = load_data_fashion_mnist(32, resize=64)\rfor X, y in train_iter:\rprint(X.shape, X.dtype, y.shape, y.dtype)\rbreak 我们现在已经准备好使用Fashion-MNIST数据集，便于下面的章节调用来评估各种分类算法 ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.5_imageclassificationdatasets/","section":"Docs","summary":"\u003cp\u003eMNIST数据集 (\u003ca href=\"https://zh-v2.d2l.ai/chapter_references/zreferences.html#id90\"title=\"LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., \u0026amp; others. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278–2324.\" target=\"_blank\"\u003eLeCun \u003cem\u003eet al.\u003c/em\u003e, 1998\u003c/a\u003e) 是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单。 我们将使用类似但更复杂的Fashion-MNIST数据集 (\u003ca href=\"https://zh-v2.d2l.ai/chapter_references/zreferences.html#id189\"title=\"Xiao, H., Rasul, K., \u0026amp; Vollgraf, R. (2017). Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747.\" target=\"_blank\"\u003eXiao \u003cem\u003eet al.\u003c/em\u003e, 2017\u003c/a\u003e)。\u003c/p\u003e","title":"D2L 3.5 Image classification datasets","type":"docs"},{"content":"\r3.6.1 初始化模型参数 #\r和之前线性回归的例子一样，这里的每个样本都将用固定长度的向量表示。 原始数据集中的每个样本都是28×28的图像。 本节将展平每个图像，把它们看作长度为784的向量 在3.5中，我们选择了一个拥有10个类别的数据集，所以softmax网络的输出维度为10 初始化权重w #\r与线性回归一样，我们使用正态分布初始化权重w，偏置初始化为0 num_inputs = 784\rnum_outputs = 10\rW = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\rb = torch.zeros(num_outputs, requires_grad=True) 3.6.2 定义softmax操作 #\r实现softmax操作由三个步骤组成 对每个项求幂 对每一行求和，得到其规范化常数 每一行除以其规范化常数，保持结果的和为1 $$softmax(X){ij}=\\frac{exp(X{ij})}{\\sum_kexp(X_{ik})}$$ 分母或规范化常数，有时也称为_配分函数_（其对数称为对数-配分函数）。 该名称来自统计物理学中一个模拟粒子群分布的方程 def softmax(X):\rX_exp = torch.exp(X)\rpartition = X_exp.sum(1, keepdim=True)\rreturn X_exp / partition # 这里应用了广播机制 keepdim=True: 在进行张量操作时，保持原始张量的维度\ntorch.normal(0, 1, (2, 5)) 是用 PyTorch 生成一个服从均值为 0，标准差为 1 的正态分布的张量。\n其中的 (2, 5) 是指生成的张量的形状为 2 行 5 列的矩阵\n3.6.3 定义模型 #\r定义softmax操作后，我们可以实现softmax回归模型 def net(X):\rreturn softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b) 3.6.4 定义损失函数 #\r引入[[Cross-Entropy 交叉熵]]损失函数 深度学习中，交叉熵函数最为常见，因为分类问题的数量远远超过了回归问题 y = torch.tensor([0, 2])\ry_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\ry_hat[[0, 1], y] y_hat： 包含2个样本在3个类别的预测概率 y：真实类，0代表第一类，1代表第二类，2代表第三类 [[0,1],y]：一种tensor的高级引索功能，其选择了y_hat中的第一行和第二行 而y给予了列的位置，所以输出分别为第一行第0位和第二行第2位 3.6.5 分类精度 #\r给定预测概率分布\\(\\hat y\\)，当我们必须输出Hard Prediciton 硬预测时，我们通常选择概率最高的类 当预测和标签分类y一致时，即是正确的 分类精度指的就是正确预测数量与总预测数量之比 def accuracy(y_hat, y): #@save\r\u0026#34;\u0026#34;\u0026#34;计算预测正确的数量\u0026#34;\u0026#34;\u0026#34;\rif len(y_hat.shape) \u0026gt; 1 and y_hat.shape[1] \u0026gt; 1:\ry_hat = y_hat.argmax(axis=1)\rcmp = y_hat.type(y.dtype) == y\rreturn float(cmp.type(y.dtype).sum()) 扩展到任意数据迭代器data_iter可访问的数据集 #\rdef evaluate_accuracy(net, data_iter): #@save\r\u0026#34;\u0026#34;\u0026#34;计算在指定数据集上模型的精度\u0026#34;\u0026#34;\u0026#34;\rif isinstance(net, torch.nn.Module):\rnet.eval() # 将模型设置为评估模式\rmetric = Accumulator(2) # 正确预测数、预测总数, Accmulator在下面定义\rwith torch.no_grad():\rfor X, y in data_iter:\rmetric.add(accuracy(net(X), y), y.numel())\rreturn metric[0] / metric[1] 首先，如果 net 是 torch.nn.Module 的子类，就将模型设置为评估模式，即调用 net.eval()。在评估模式下，模型的行为可能会略有不同，比如 Dropout 层在评估模式下会关闭，以避免随机丢弃部分节点 创建了一个名为 metric 的累加器（Accumulator）。这个累加器用于记录正确预测数和总预测数，初始化为两个元素的列表 [0, 0] Accumulator：这个类在下面定义 使用 torch.no_grad() 上下文管理器，禁用梯度计算 最后就是将评估结果添加至metric中 Accumulator类 #\r这里定义一个实用程序类Accumulator，用于对多个变量进行累加。 在上面的evaluate_accuracy函数中， 我们在Accumulator实例中创建了2个变量， 分别用于存储正确预测的数量和预测的总数量。 当我们遍历数据集时，两者都将随着时间的推移而累加。 class Accumulator: #@save\r\u0026#34;\u0026#34;\u0026#34;在n个变量上累加\u0026#34;\u0026#34;\u0026#34;\rdef __init__(self, n):\rself.data = [0.0] * n\rdef add(self, *args):\rself.data = [a + float(b) for a, b in zip(self.data, args)]\rdef reset(self):\rself.data = [0.0] * len(self.data)\rdef __getitem__(self, idx):\rreturn self.data[idx] __init__(self, n): 这是类的构造函数，用于初始化累加器。它接受一个参数 n，表示要累加的变量的数量。在初始化时，创建了一个包含 n 个元素的列表，每个元素初始化为 0.0 add(self, *args): 这个方法用于将参数 args 中的值与累加器中的值相加。参数 args 是一个可变参数，可以接受任意数量的参数。通过 zip 函数，将 args 中的值逐个与累加器中对应位置的值相加，并更新累加器中的值 reset(self): 这个方法用于重置累加器的值 __getitem__(self, idx): 这个方法允许通过索引访问累加器中的值。给定一个索引 idx，它返回累加器中对应位置的值 3.6.6 训练 #\r首先，我们定义一个函数来训练一个迭代周期 updater是更新模型参数的常用函数，它接受批量大小作为参数 def train_epoch_ch3(net, train_iter, loss, updater): #@save\r\u0026#34;\u0026#34;\u0026#34;训练模型一个迭代周期（定义见第3章）\u0026#34;\u0026#34;\u0026#34;\r# 将模型设置为训练模式\rif isinstance(net, torch.nn.Module):\rnet.train()\r# 训练损失总和、训练准确度总和、样本数\rmetric = Accumulator(3)\rfor X, y in train_iter:\r# 计算梯度并更新参数\ry_hat = net(X)\rl = loss(y_hat, y)\rif isinstance(updater, torch.optim.Optimizer):\r# 使用PyTorch内置的优化器和损失函数\rupdater.zero_grad()\rl.mean().backward()\rupdater.step()\relse:\r# 使用定制的优化器和损失函数\rl.sum().backward()\rupdater(X.shape[0])\rmetric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\r# 返回训练损失和训练精度\rreturn metric[0] / metric[2], metric[1] / metric[2] if isinstance(net, torch.nn.Module):：检查变量 net 是否是 torch.nn.Module 类的实例 net.train(): 这一行将模型（net）设置为训练模式 metric = Accumulator(3): 创建一个长度为3的累加器 在计算梯度后，根据数据类型，如pytorch类或者自定义类累加处理结果 训练函数 #\rdef train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): #@save\r\u0026#34;\u0026#34;\u0026#34;训练模型（定义见第3章）\u0026#34;\u0026#34;\u0026#34;\ranimator = Animator(xlabel=\u0026#39;epoch\u0026#39;, xlim=[1, num_epochs], ylim=[0.3, 0.9],\rlegend=[\u0026#39;train loss\u0026#39;, \u0026#39;train acc\u0026#39;, \u0026#39;test acc\u0026#39;])\rfor epoch in range(num_epochs):\rtrain_metrics = train_epoch_ch3(net, train_iter, loss, updater)\rtest_acc = evaluate_accuracy(net, test_iter)\ranimator.add(epoch + 1, train_metrics + (test_acc,))\rtrain_loss, train_acc = train_metrics\rassert train_loss \u0026lt; 0.5, train_loss\rassert train_acc \u0026lt;= 1 and train_acc \u0026gt; 0.7, train_acc\rassert test_acc \u0026lt;= 1 and test_acc \u0026gt; 0.7, test_acc ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.6_implementationofsoftmaxregressionfromscratch/","section":"Docs","summary":"\u003ch2 class=\"relative group\"\u003e3.6.1 初始化模型参数 \r\n    \u003cdiv id=\"361-%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#361-%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e和之前线性回归的例子一样，这里的每个样本都将用固定长度的向量表示。 原始数据集中的每个样本都是28×28的图像。 本节将展平每个图像，把它们看作长度为784的向量\u003c/li\u003e\n\u003cli\u003e在3.5中，我们选择了一个拥有10个类别的数据集，所以softmax网络的输出维度为10\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003e初始化权重w \r\n    \u003cdiv id=\"%E5%88%9D%E5%A7%8B%E5%8C%96%E6%9D%83%E9%87%8Dw\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%9D%83%E9%87%8Dw\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e与线性回归一样，我们使用正态分布初始化权重w，偏置初始化为0\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003enum_inputs = 784\r\nnum_outputs = 10\r\n\r\nW = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\r\nb = torch.zeros(num_outputs, requires_grad=True)\n\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003ch2 class=\"relative group\"\u003e3.6.2 定义softmax操作 \r\n    \u003cdiv id=\"362-%E5%AE%9A%E4%B9%89softmax%E6%93%8D%E4%BD%9C\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#362-%E5%AE%9A%E4%B9%89softmax%E6%93%8D%E4%BD%9C\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e实现softmax操作由三个步骤组成\u003c/li\u003e\n\u003cli\u003e对每个项求幂\u003c/li\u003e\n\u003cli\u003e对每一行求和，得到其规范化常数\u003c/li\u003e\n\u003cli\u003e每一行除以其规范化常数，保持结果的和为1\n$$softmax(X)\u003cem\u003e{ij}=\\frac{exp(X\u003c/em\u003e{ij})}{\\sum_kexp(X_{ik})}$$\u003c/li\u003e\n\u003cli\u003e分母或规范化常数，有时也称为_配分函数_（其对数称为对数-配分函数）。 该名称来自\u003ca href=\"https://en.wikipedia.org/wiki/Partition_function_%28statistical_mechanics%29\" target=\"_blank\"\u003e统计物理学\u003c/a\u003e中一个模拟粒子群分布的方程\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edef softmax(X):\r\n    X_exp = torch.exp(X)\r\n    partition = X_exp.sum(1, keepdim=True)\r\n    return X_exp / partition  # 这里应用了广播机制\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ekeepdim=True: 在进行张量操作时，保持原始张量的维度\u003c/p\u003e","title":"D2L 3.6 Implementation of softmax regression from scratch","type":"docs"},{"content":"在了解多层感知机前，需要先了解[[Perceptron 感知机]]\n4.1.1 隐藏层 #\r在[[3.1_LinearRegression#3.1.1.1 线性模型]]中我们描述了[[Affine Transformation 仿射变换]]，如一次函数一般是一种带有偏置项的线性变换 如果预测值在仿射变换后确实与输入数据有线性关系，那么这种方式确实够用 可是大部分情况下，仿射变换中的线性是一个很强的假设 4.1.1.1 线性模型可能会出错 #\r线性意味着单调假设，权重w在正的情况下，任何特征的增大都会导致模型输出的增大 E.X.\n如果我们试图预测一个人是否会偿还贷款，我们可以认为收入较高的申请人比收入较低的申请人更有可能偿还贷款 但上述例子只阐明了单调性而非线性 收入从0到5万会带来比100万到105万更大的还款可能性 在上例中，我们任然可以通过[[2.2 数据预处理]]的方式使线性更加合理，如对数化处理 但一个违反单调性的例子比如体温和死亡率的关系 对于体温高于37度的人来说，温度越高风险越高 而对于体温低于37度的人来说，温度越低风险就越低 这种情况也可以使用理37度的距离作为特征 分类问题，如对于猫狗分类问题，在位置（13，17）处像素强度进行添加，是否整个图像描绘狗的[[Likehood 似然]]会增加？ 这一评估标准注定会失败，如倒置图像后，类别依然保留 对于上面两个例子来说，猫狗的分类问题无法通过简单的预处理解决 对于[[深度神经网络]]，我们将使用隐藏层 4.1.1.2 在网络中加入隐藏层 #\r我们可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制， 使其能处理更普遍的函数关系类型 有全连接层的多层感知机的参数开销可能会高得令人望而却步。 即使在不改变输入或输出大小的情况下， 可能在参数节约和模型有效性之间进行权衡\n4.1.1.3 从线性到非线性 #\r同之前的章节一样，我们通过矩阵\\(X\\in R^{n\\times d}\\)来表示n个样本的小批量，其中每个样本具有d个输入特征\n对于具有h个隐藏单元的单隐藏层多层感知机，用\\(H\\in R^{n\\times h}\\)表示隐藏层的输出，称为Hidden Representatiosn 隐藏表示\n因为隐藏层和输出层都是全连接的， 所以我们有隐藏层权重\\(W^{(1)}\\in R^{R\\times h}\\)和隐藏层偏置\\(b^{(1)}\\in R^{1\\times h}\\)以及输出层\\(W^{(2)}\\in R^{h\\times q}\\)和输出层偏置\\(b^{(2)}\\in R^{1\\times q}\\)\n所以形式上，对于单隐藏层的多层感知机的输出\\(O\\in R^{n\\times q}\\)，有 $$\\begin{align} \\ H=WX^{(1)}+b^{(1)} \\ O=HW^{(2)}+b^{(2)} \\end{align}$$\n现阶段，隐藏层为输入层的放射函数，而输出层为隐藏层的放射函数，即$$O=(XW^{(1)}+b^{(1)})W^{(2)}+b^{(2)}=XW+b$$\n注意到现在在多层感知机的单隐藏层下，模型依然只做到了线性的放射函数\n所以为了发挥多层架构的潜力，我们需要添加一个额外的关键要素：[[Activation Function 激活函数]]，激活函数的输出则称为Activations 活性值\n一般来说，有了激活函数，模型就不会退化成线性模型 $$\\begin{align} \\ H=\\sigma(XW^{(1)}+b^{(1)}) \\ O=HW^{(2)}+b^{(2)} \\end{align}$$\n为了构建更通用的多层感知机，我们可以继续堆叠这样的隐藏层，从而产生更有表达能力的模型\n4.1.1.4 通用近似定理 #\r多层感知机可以通过隐藏神经元，捕捉到输入之间复杂的相互作用， 这些神经元依赖于每个输入的值。 我们可以很容易地设计隐藏节点来执行任意计算 即使是网络只有一个隐藏层，给定足够的神经元和正确的权重， 我们可以对任意函数建模，尽管实际中学习该函数是很困难的 而且，虽然一个单隐层网络能学习任何函数， 但并不意味着我们应该尝试使用单隐藏层网络来解决所有问题。 事实上，通过使用更深（而不是更广）的网络，我们可以更容易地逼近许多函数。 我们将在后面的章节中进行更细致的讨论 4.1.2 激活函数 Activation Function #\r[[Activation Function 激活函数]] ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.3_simpleimplementationofmultilayerperceptron/","section":"Docs","summary":"\u003cp\u003e在了解多层感知机前，需要先了解[[Perceptron 感知机]]\u003c/p\u003e","title":"D2L 4.1 MultilayerPerceptron","type":"docs"},{"content":"深度学习的目的是发现Pattern，即做到模型的Generalization 泛化\n[[Overfitting Problem]] 原因很简单：当我们将来部署该模型时，模型需要判断从未见过的患者。 只有当模型真正发现了一种泛化模式时，才会作出有效的预测\n困难在于，当我们训练模型时，我们只能访问数据中的小部分样本。 最大的公开图像数据集包含大约一百万张图像。 而在大部分时候，我们只能从数千或数万个数据样本中学习。 在大型医院系统中，我们可能会访问数十万份医疗记录。 当我们使用有限的样本时，可能会遇到这样的问题： 当收集到更多的数据时，会发现之前找到的明显关系并不成立。\nOverfitting 过拟合 #\r模型在训练数据上拟合的比在潜在分布中更接近的现象称为过拟合 左： Underfitting 欠拟合 中：拟合 右：Overfitting 过拟合 Regularization 正则化 #\r对抗过拟合的技术称为正则化 [[Regularization 正则化]] 4.4.1 训练误差和泛化误差 #\rTraining Error 训练误差 #\r模型在训练数据集上计算得到的误差 Generalization Error 泛化误差 #\r同样分布样本的无限多个数据的模型误差期望 但问题是对于无限多个数据，我们不可能准确的计算出Genrelization Errorz 4.4.1.1 统计学习理论 #\r我们假设训练数据和测试数据都是从相同的分布中独立提取的。 这通常被称为_独立同分布假设_（i.i.d. assumption） 4.4.1.2 模型复杂性 #\r一个模型的复杂性取决于很多因素 如模型参数，取值范围 Early Stopping 早停 #\r早停（Early Stopping）：这是一种防止过拟合的技术，其中训练过程在验证集上的性能开始恶化时停止。这意味着，如果模型在验证集上的误差开始增加，表明模型可能开始过拟合训练数据，此时停止进一步训练可以避免这种情况。 4.4.2 模型选择 #\r在一个训练中，我们会选择几个候选模型对他们进行评估 4.4.2.1 验证集 #\r训练集，验证集，测试集分别是什么_训练集 验证集 测试集-CSDN博客\n总的来说，对于Superivised Training，一般讲整体划为3个区块 Training Set 训练集 #\r训练集用来训练模型，即确定模型的权重和偏置这些参数，通常我们称这些参数为学习参数 训练集中的参数直接参与到梯度下降中 Validation Set 验证集 #\rz\n而验证集用于模型的选择，更具体地来说，验证集并不参与学习参数的确定，也就是验证集并没有参与梯度下降的过程 验证集只是为了选择超参数，比如网络层数、网络节点数、迭代次数、学习率这些都叫超参数 Test Set 测试集 #\r测试集只使用一次，即在训练完成后评价最终的模型时使用。它既不参与学习参数过程，也不参数超参数选择过程，而仅仅使用于模型的评价 4.4.2.2 K-Fold Cross-Validation K折交叉验证 #\r训练数据稀缺时，我们甚至可能无法提供足够的数据来构成一个合适的验证集 过程描述 #\r数据分组：首先，整个数据集被随机分成K个大小大致相同的子集。 迭代训练与验证：每次迭代中，选择其中一个子集作为验证集，而其余的K-1个子集合并作为训练集。 性能评估：模型在训练集上训练，并在验证集上进行评估。这个过程重复K次，每次选择不同的子集作为验证集。 平均性能：最终模型的性能是所有K次迭代中验证性能的平均值。这样可以更全面地评估模型的性能。 4.4.3 欠拟合还是过拟合？ #\rGenerlization Error高的模型叫做Underfitting Train Error远低于Validation Error的模型叫做Overfitting 4.4.3.1 模型复杂性 #\r![[Pasted image 20240615153938.png]]\n简单来说，从左到右模型经历了从欠拟合到过拟合的一个过程，也是从高损失到高方差的过程 其是因为模型从没学习过参数到对于微小参数（甚至是随机噪声）严重敏感的一个过程 Lost 损失 #\r定义：偏差是指模型在预测中的系统误差，即模型对学习数据的一般性质的理解程度。 高偏差：通常表示模型过于简单（欠拟合），未能捕捉到数据的关键结构，通常会导致在训练集和测试集上都表现不佳。 Variance 方差 #\r定义：方差是指模型对于训练数据的微小变化的敏感度。 高方差：表示模型过于复杂（过拟合），对训练数据中的随机噪声也进行了学习，这可能使得模型在新的、未见过的数据上表现不佳。 4.4.3.2 数据集大小 #\r训练数据集中的样本越少，我们就越有可能（且更严重地）过拟合 而样本更过通常会减小Gerneralization Error 一般来说，更多的数据不会有什么坏处 4.4.4 多项式回归 #\r拟合一个多项式\n[[4.4 Overfitting Normal \u0026amp; Underfitting - Pytorch]]\n4.4.4.1 生成数据集 #\r![[Pasted image 20240616094316.png]]\n噪声值位均值0到标准差0.1的正态分布 在优化的过程中，我们通常希望避免非常大的梯度值或损失值。 这就是我们将特征从$x^i$调整为$\\frac{x^i}{i!}$的原因 max_degree = 20 # 多项式的最大阶数\rn_train, n_test = 100, 100 # 训练和测试数据集大小\rtrue_w = np.zeros(max_degree) # 分配大量的空间\rtrue_w[0:4] = np.array([5, 1.2, -3.4, 5.6])\rfeatures = np.random.normal(size=(n_train + n_test, 1))\rnp.random.shuffle(features)\rpoly_features = np.power(features, np.arange(max_degree).reshape(1, -1))\rfor i in range(max_degree):\rpoly_features[:, i] /= math.gamma(i + 1) # gamma(n)=(n-1)!\r# labels的维度:(n_train+n_test,)\rlabels = np.dot(poly_features, true_w)\rlabels += np.random.normal(scale=0.1, size=labels.shape) max_degree = 20 : 即使多项式仅为三阶，但我们需要用一个20纬的多项式去拟合它，这是复杂模型中的一种 features = np.random.normal(size=(n_train + n_test, 1)): 分配200个一维的特征 np.random.shuffle(features): 随机打乱数据 poly_features = np.power(features, np.arange(max_degree).reshape(1, -1))：分配每个特征的高阶数据 使用伽马正则化防止特征的迅速增大 最后点乘特征和真实权重得到Label，并将Label加上合适的噪声 # NumPy ndarray转换为tensor\rtrue_w, features, poly_features, labels = [torch.tensor(x, dtype=\rtorch.float32) for x in [true_w, features, poly_features, labels]]\rfeatures[:2], poly_features[:2, :], labels[:2] 转化为tensor def evaluate_loss(net, data_iter, loss): #@save\r\u0026#34;\u0026#34;\u0026#34;评估给定数据集上模型的损失\u0026#34;\u0026#34;\u0026#34;\rmetric = d2l.Accumulator(2) # 损失的总和,样本数量\rfor X, y in data_iter:\rout = net(X)\ry = y.reshape(out.shape)\rl = loss(out, y)\rmetric.add(l.sum(), l.numel())\rreturn metric[0] / metric[1] def train(train_features, test_features, train_labels, test_labels,\rnum_epochs=400):\rloss = nn.MSELoss(reduction=\u0026#39;none\u0026#39;)\rinput_shape = train_features.shape[-1]\r# 不设置偏置，因为我们已经在多项式中实现了它\rnet = nn.Sequential(nn.Linear(input_shape, 1, bias=False))\rbatch_size = min(10, train_labels.shape[0])\rtrain_iter = d2l.load_array((train_features, train_labels.reshape(-1,1)),\rbatch_size)\rtest_iter = d2l.load_array((test_features, test_labels.reshape(-1,1)),\rbatch_size, is_train=False)\rtrainer = torch.optim.SGD(net.parameters(), lr=0.01)\ranimator = d2l.Animator(xlabel=\u0026#39;epoch\u0026#39;, ylabel=\u0026#39;loss\u0026#39;, yscale=\u0026#39;log\u0026#39;,\rxlim=[1, num_epochs], ylim=[1e-3, 1e2],\rlegend=[\u0026#39;train\u0026#39;, \u0026#39;test\u0026#39;])\rfor epoch in range(num_epochs):\rd2l.train_epoch_ch3(net, train_iter, loss, trainer)\rif epoch == 0 or (epoch + 1) % 20 == 0:\ranimator.add(epoch + 1, (evaluate_loss(net, train_iter, loss),\revaluate_loss(net, test_iter, loss)))\rprint(\u0026#39;weight:\u0026#39;, net[0].weight.data.numpy() 欠拟合 #\r# 从多项式特征中选择前2个维度，即1和x\rtrain(poly_features[:n_train, :2], poly_features[n_train:, :2],\rlabels[:n_train], labels[n_train:]) 只给予了前两个特征值 ![[Pasted image 20240704160340.png]] 过拟合 #\r# 从多项式特征中选取所有维度\rtrain(poly_features[:n_train, :], poly_features[n_train:, :],\rlabels[:n_train], labels[n_train:], num_epochs=1500) 将w中的20列全部给到了模型导致了过拟合 ![[Pasted image 20240704160346.png]] ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.4_modelselectionunderfittingandoverfitting/","section":"Docs","summary":"\u003cp\u003e深度学习的目的是发现Pattern，即做到模型的Generalization 泛化\u003c/p\u003e","title":"D2L 4.4 Model Selection, Underfitting, and Overfitting","type":"docs"},{"content":" ","date":"Jan 23 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/","section":"Docs","summary":"\u003chr\u003e","title":"Chapter 3. Linear Neural Network","type":"docs"},{"content":" ","date":"Jan 23 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter4multilayerperceptron/","section":"Docs","summary":"\u003chr\u003e","title":"Chapter 4. Multilayer Perceptron","type":"docs"},{"content":"《动手学深度学习》 — 动手学深度学习 2.0.0 documentation. (2023). Zh-V2.D2l.ai. https://zh-v2.d2l.ai/index.html\n‌ #\r","date":"Jan 23 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/","section":"Docs","summary":"\u003cp\u003e《动手学深度学习》 — 动手学深度学习 2.0.0 documentation. (2023). Zh-V2.D2l.ai. \u003ca href=\"https://zh-v2.d2l.ai/index.html\" target=\"_blank\"\u003ehttps://zh-v2.d2l.ai/index.html\u003c/a\u003e\u003c/p\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e‌ \r\n    \u003cdiv id=\"heading\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#heading\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e","title":"Dive Into Deep Learning","type":"docs"},{"content":"","externalUrl":null,"permalink":"/zh-cn/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/zh-cn/","section":"Buezwqwg的博客","summary":"","title":"Buezwqwg的博客","type":"page"},{"content":"","externalUrl":null,"permalink":"/zh-cn/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"Special thanks to those for thier invaluable contributions\n","externalUrl":null,"permalink":"/credits/","section":"Credits","summary":"\u003cp\u003eSpecial thanks to those for thier invaluable contributions\u003c/p\u003e","title":"Credits","type":"credits"},{"content":"","externalUrl":null,"permalink":"/credits/faker/","section":"Credits","summary":"","title":"Faker","type":"credits"},{"content":"","externalUrl":null,"permalink":"/zh-cn/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/credits/ss/","section":"Credits","summary":"","title":"SS","type":"credits"},{"content":"","externalUrl":null,"permalink":"/zh-cn/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"123\nRecord some thinking\n","externalUrl":null,"permalink":"/thoughts/thethreebodyproblem/","section":"Thoughts","summary":"\u003cp\u003e123\u003c/p\u003e\n\u003cp\u003eRecord some thinking\u003c/p\u003e","title":"The Three Body Problem","type":"thoughts"},{"content":"","externalUrl":null,"permalink":"/thoughts/","section":"Thoughts","summary":"","title":"Thoughts","type":"thoughts"},{"content":"","externalUrl":null,"permalink":"/credits/%E9%82%93%E7%B4%AB%E6%A3%8B/","section":"Credits","summary":"","title":"邓紫棋","type":"credits"},{"content":"","externalUrl":null,"permalink":"/credits/%E6%B3%95%E8%80%81/","section":"Credits","summary":"","title":"法老","type":"credits"}]