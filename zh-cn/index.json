


[{"content":"","date":"Sep 8 2025","externalUrl":null,"permalink":"/tags/cfa/","section":"Tags","summary":"","title":"CFA","type":"tags"},{"content":"","date":"Sep 8 2025","externalUrl":null,"permalink":"/docs/chartered-financial-analyst/","section":"Docs","summary":"","title":"Chartered Financial Analyst","type":"docs"},{"content":"","date":"Sep 8 2025","externalUrl":null,"permalink":"/docs/","section":"Docs","summary":"","title":"Docs","type":"docs"},{"content":"","date":"Sep 8 2025","externalUrl":null,"permalink":"/tags/qec/","section":"Tags","summary":"","title":"QEC","type":"tags"},{"content":"\rQEC1.Rates\u0026amp;Returns #\rLast Edit: 9/8/25\n1.1 Interest Rates \u0026amp; Return Measurement #\rInterest Rates 利率 #\rInterest Rate measure the time value of money 衡量了货币的时间价值 Equilibrium Interest Rates 必要的回报率 #\r对于某项投资，Equilibrium Interest Rates 反映了投资人期望的市场回报率 也代表了投资人为了出借资金所要求的 Return Discount Rate 贴现率 #\rDiscount Rate 可以被理解为衡量未来资金的现在价值的利率 因为有 Interest 的存在，未来的钱会增加，假设当前有 100 元，年利率为 5%，那么一年后 100 元会变成 105元 反过来说，如果希望一年后拿到 105 元，今天的价值则是 100 元，而这一比值就是 Discount Rate，把未来的钱转换成今天的价值的比率，有以下公式 $$ ⁍ $$\nPV（Present Value）= 现值，即今天的钱 FV（Future Value）= 未来值，即未来的钱 r（Discount Rate）= 贴现率 t = 未来的时间（通常按年计算） 和 Interest Rate 的关系就是一个是顺着时间推移，一个是逆时间的反过程\nOpportunity Cost 机会成本 #\r例如一个一年期利率为 5%，投资者选择了消费而非储蓄，则 5% 就是放弃储蓄的 Opportunity Cost Real Risk-Free Rate 无风险实际利率 #\r定义：是单期贷款的 Theoretical Interest Rate，不考虑 Inflation 通货膨胀 或 Default risk 违约风险 经济学意义：衡量当前消费相对于未来消费的 Time Preference 时间偏好，也就是说同样的钱，不同时间下的价值就不同，Real Risk-Free Rate 就很好的衡量了不同时间下的价值 Time Preference 时间偏好 #\r指的是人们对于“现在消费”和“未来消费”的偏好程度 High Time Preference 更倾向现在消费放弃未来的收益 Real Rete of Return 实际收益率 #\r定义：经过 Adjusting for inflation 通货膨胀调整后的投资者实际购买力收益 Nominal Risk-Free Rate 名义无风险利率 #\r指的是没有 Default Risk 违约风险的金融工具，但其回报仍受 Inflation 通货膨胀影响 例如，美国国库券（T-bills）的利率属于 Nominal Risk-Free Rate，但包含 Inflation Premium 通胀溢价 也就是说 Nominal Risk-Free Rate 和 Real Risk-Free Rate 和 Expected Inflation Rate 有关 $$ (1 + \\text{Nominal Risk-Free Rate}) = (1 + \\text{Real Risk-Free Rate}) \\times (1 + \\text{Expected Inflation Rate}) $$\n这一关系有时候可以被近似为 $$ \\text{Nominal Risk-Free Rate} \\approx \\text{Real Risk-Free Rate} + \\text{Expected Inflation Rate} $$\nInflation Premium 通胀溢价 #\r是投资者要求的额外回报，用于补偿未来 Inflation 可能带来的货币购买力下降，这个额外的回报，就是 Inflation Premium，有 $$ \\text{Inflation Premium} = \\text{Nominal Risk-Free Rate} - \\text{Real Risk-Free Rate}⁍ $$\nex. Inflation Premium at 3 inflation Rate #\r存 100 元到银行，银行给 5% 的 Nominal Risk-Free Rate，但如果 Inflation Rate 是 3%，那么真正的购买力只增加了 2%（实际收益），这里的 Inflation Premium 就是 3 % Risks 风险 #\r对于一个投资，总结来说存在各种风险，其中的每一个风险都与一个 Risk Premium 所绑定，并会被夹到 Nominal Risk-Free Rates 上，于是 Nominal Risk-Free Rate 就变成了 $$ \\text{nominal risk-free rate} \\approx \\text{real risk-free rate} + \\text{expected inflation rate} $$\nDefault Risk 违约风险 #\r当 Borrower 无法按时 make the promised payments 的风险 Liquidity Risk 流动性风险 #\r当 Investment 无法 Sold Quick for cash 套现时所面临的风险 Maturity Risk 到期风险 #\r债券的到期日越远，其价格对利率变动的敏感性越高，也就具有更高的 Maturity Risk Holding Period Return HPR 持有期收益率 #\rHPR 计算出了投资在给定时间内价值的 Percentage Increase $$ \\text{holding period return} = \\frac{\\text{end-of-period value}}{\\text{beginning-of-period value}} - 1 $$\n单个持有期的HPR计算方法如下： $$ \\text{HPR} = \\frac{P_t + \\text{Div}}{P_0} - 1\\frac{P_t - P_0 + \\text{Div}}{P_0} $$\n\\(P_t\\) 表示持有期末的股票价格 \\(P_0\\) 表示持有期初的股票价格 \\(\\text{Div}\\) 表示在持有期间支付的股息 Dividend 股息，指的公司盈利后把赚到的一部分分给 Shareholders 的形式\n举例来说，如果一支股票在期初价格为20欧元，在持有期间支付了 1 欧元股息，期末价格为22欧元，那么HPR计算如下： $$ \\text{HPR} = \\frac{22 + 1}{20} - 1 = 0.15 $$\n这表明投资者在这个持有期间内的总回报率是15% 22 欧元是股票结束时候的市场价值\n当考虑多个持有期的回报时，我们使用复合回报的概念，公式如下： $$ \\text{HPR} = (1 + \\text{HPR}{\\text{Year 1}})(1 + \\text{HPR}{\\text{Year 2}})(1 + \\text{HPR}_{\\text{Year 3}}) - 1 $$\n这里，每个年度的HPR分别加1后相乘，然后再减1，这样可以计算出整个三年期间的总复合回报率 例如，如果第一年的回报率是5%，第二年是3%，第三年是7%，那么三年的总HPR计算如下： $$ \\text{HPR} = (1 + 0.05)(1 + 0.03)(1 + 0.07) - 1 \\approx 0.1571 \\text{ 或 } 15.71% $$\nAnnualized Return 年化回报率 #\r最后，如果回报需要跨多年计算，通常会使用年化回报率而不是简单的HPR 年化回报率考虑了投资期间的具体长度，并将回报率调整为年度等效值，使得不同期间长度的投资回报率可以公平比较 Average Returns #\r一般来说存在两种计算 Average Returns 的方式，Arithmetic 和 Geometric Mean，也就是算术和几何平均收益率 Arithmetic Mean Return 算数平均收益 #\r最简单的计算 Average 的方式 $$ \\text{arithmetic mean return} = \\frac{R_1 + R_2 + R_3 + \\dots + R_n}{n} $$\n直接计算所有值的总和，然后除以总个数。 适用于独立数据的均值，例如考试成绩、股市单日涨跌平均值等。 Geometric Mean Return #\r当每个 Period 的 Rate of return 不同的时候，Geometric Mean Return 可以用来计算 Compound Rate，当每个 Period 回报率波动比较大的时候，GM 通常小于 AM $$ \\text{geometric mean return} = \\sqrt[n]{(1 + R_1) \\times (1 + R_2) \\times (1 + R_3) \\times \\dots \\times (1 + R_n)} - 1 $$\n先将所有值相乘，再开 n 次方（对数平均） 适用于复利增长或波动性较大的数据，例如投资回报、人口增长率等 类型 适用情况 示例 算术平均数（AM） 适用于加法关系的数据，求一组数值的直接平均 - 计算学生考试平均分- 计算不同年份的气温平均值 几何平均数（GM） 适用于乘法关系的数据，求一组数的复合增长率 - 计算股票的年均回报率- 计算 GDP 增长率 ex. Calculate Geometirc Mean #\rAcme 公司普通股在过去三年的回报率分别是 -9.34%、23.45%、8.92%，求该股票的Compound annual rate of return\n$$ R_G = \\sqrt[3]{(1 - 0.0934) \\times (1 + 0.2345) \\times (1 + 0.0892)} - 1 $$\n因此，该股票的几何平均回报率约为 6.825% ex. Calculater GM in shorter period #\r给出四个 Semiannual periods 的回报率分别为 2.0%、0.5%、-10.0%、1.5% $$ \\text{Geometric mean} = \\sqrt[4]{(1 + 0.02)(1 + 0.005)(1 - 0.10)(1 + 0.015)} - 1 = 0.7435% $$\n几何平均回报约为 0.7435%，这是6个月持有期的回报。 由于四个半年期等于两年，为了获得 Annual return ，我们需要取 2 作为开方的根数： $$ \\text{Annual return} = \\sqrt[2]{(1 + 0.02)(1 + 0.005)(1 - 0.10)(1 + 0.015)} - 1 = 1.49\\ % $$\n最终，年化回报为 1.49% Harmonic Mean 调和平均数 #\rHarmonic Mean 常常用在速率，比率这类场景中，例如计算股票购买的平均成本，有 $$ X_H = \\frac{N}{\\sum \\frac{1}{X_i}} $$\n其中 N 为数据个数，\\(X_i\\) 为各个数值 ex. Harmonic Mean #\r一位投资者每月投资 1,000 购买股份。在过去三个月内，每股支付的价格分别为 8、\\(9、\\)10，求 Harmonic Mean $$ X_H = \\frac{3}{\\frac{1}{8} + \\frac{1}{9} + \\frac{1}{10}} = 8.926 $$\n平均成本价约为 $8.926 每股。 验证方法：计算总购买股份数 $$ \\frac{1,000}{8} + \\frac{1,000}{9} + \\frac{1,000}{10} = 336.11 \\text{ shares} \\frac{3,000}{336.11} = 8.926 \\text{ per share} $$\n对于上面的三个 Mean Values，他们之间有一个数学关系，即 $$ \\text{Arithmetic mean} \\times \\text{Harmonic mean} = (\\text{Geometric mean})^2 $$\n同时，HM\u0026lt;GM\u0026lt;AM 1.2 Time-Weighted And Money-Weighted Returns #\r比较 Money-Weighted Rate of return 资金加权收益率，和 Time Weighted Rate of Return 时间加权收益率，来评估投资组合的表现 Money-weighted Rate of Return 资金加权收益率 #\rMWRR 和 IPR 实际上使用的是相同的计算公式，两者仅在语境上不同，IPR 多用在项目，公司投资商，MWRR 则是个人投资中用的多，但两者都计算了资金投入时间的加权效果 IPR 即内部收益率，是一种衡量投资收益的方式 其核心思路是：找出一个年收益率，使得“所有现金流”的现值加起来刚好等于 0 投资的钱是流出，收到的钱是流入。把这些现金流按照某个收益率来“折现”之后，加起来为 0，那这个收益率就是 IRR\nex. #\r举例来说，在 t = 0 时，投资者买入 1 股，花了 100 这是流出，\\(C(0)=-100\\) t = 1 时，再次买入 1 股，花了 120，同时在年末收到了 2 的 Dividend（股息），\\(C(1)=-120+2=-118\\) t = 2 时，卖出 2 股，收到 130，同时受到每股 2 的 Share Dividend（股息），\\(C(3)=1302+22=264\\) 年份（t） 现金流（Cash Flow） 0 -100 1 -120 2 +134 到了这一步后，就可以开始求 IPR 了，回顾 IPR 含义，一个能使得“所有现金流”的现值（向前贴现）加起来刚好等于 0 的年收益率 也就是说要求一个 r，让下面这个等式成立： $$ -100 + \\frac{-118}{(1 + r)} + \\frac{264}{(1 + r)^2} = 0 $$\n把所有的现金流都 Discount（折现）回 t = 0 时刻，使总和为 0 这个 r，就是 money-weighted rate of return（货币加权收益率），也就是投资的 IRR 最后可以解出 \\(r\\approx13.86%\\) 这个 r 的含义就是，整体的投资等同于把两笔钱在两个时间，2 年前和 1 年前的时候分别放入一个年收益率为 13.86 的账户中 Time-weighted Rate of Return #\r衡量的是 投资组合本身的复利增长率，不受资金流入流出时机的影 在实际应用中，这个指标常用于评价 Fund Manager（资金经理）的投资能力，因为 Fund Manager 无法控制投资者何时申购或赎回 分段计算（每次有资金流入或流出时，把整个期间拆开）\n算每一段的持有期收益率（HPR, Holding Period Return 持有期收益率）\n$$ HPR = \\frac{期末价值 + 分红}{期初价值} - 1 $$\n几何平均：\n$$ (1+TWRR)^n = \\prod (1+HPR_i) $$\nEx. #\r用和 MWRR 一样的例子\n第一年 (t=0 → t=1)\n初始：100 美元 年末：120 美元市值 股息：2 美元 \\(HPR₁ = (120 + 2) / 100 - 1 = 22%\\) 第二年 (t=1 → t=2)\n初始：240 美元（两股，每股120） 年末：260 美元市值 股息：4 美元 \\(HPR₂ = (260 + 4) / 240 - 1 = 10%\\) 总收益率（Geometric Mean）\n$$ (1+TWRR)^2 = (1.22)(1.10) $$\n$$ TWRR = \\sqrt{1.342} - 1 = 15.84% $$\nMWRR V.S. TWRR #\rMoney-weighted return (MWRR) = 13.86% Time-weighted return (TWRR) = 15.84% 差异原因： MWRR 给了 更多权重 给 第二年，因为在第二年时资金更多（两股） 第二年收益率只有 10%，低于第一年的 22%，所以 MWRR \u0026lt; TWRR TWRR 完全去掉了资金流入流出的影响，只反映投资本身的复利效果 MWRR（13.86%）：体现的是投资者个人的真实收益体验，取决于资金投入的时机 TWRR（15.84%）：体现的是投资本身的表现，不受投入时机影响，更适合评价基金经理 1.3 Common Measures of Return #\rReturn 收益率存在多种度量方式 Annualized Return（年化收益率） #\r定义：把一个 HPR, Holding Period Return 持有期收益率换算成一年期的等效收益率\n公式：\n$$ \\text{annualized return} = (1+HPR)^{365/days} - 1 $$\n例子 1（不足一年）：\n存 100 美元，90 天后变 100.75 美元\n\\(HPR = (100.75 − 100)/100 = 0.75%\\) \\(年化 = (1 + 0.0075)^{(365/90)} − 1 ≈ 3.08%\\) 例子 2（超过一年）：\n买一张 500 天国债，970 → 1000。\n\\(HPR = (1000 − 970)/970 = 3.09%\\) \\(年化 = (1 + 0.0309)^{(365/500)} − 1 ≈ 2.25%\\) 👉 作用：不同持有期的收益率可以统一比较\nCompounding Frequency（复利频率） #\r名义年利率 r（quoted annual interest rate）不变，但复利次数 m 越多，有效利率越高\n现值公式：\n$$ PV = FV \\cdot (1 + r/m)^{-mN} $$\nPV：Present Value，FV：Future Value\n例子：未来一年收到 1000 美元，贴现率 6%\n年复利 (m=1): \\(PV = 943.40\\) 半年复利 (m=2): \\(PV = 942.60\\) 季度复利 (m=4): \\(PV = 942.18\\) 月复利 (m=12): \\(PV = 941.91\\) 日复利 (m=365): \\(PV = 941.77\\) 👉 复利次数越多，现值越低（贴现率并不变）\nContinuously Compounded Return（连续复利收益率） #\r定义：当复利频率趋近于无穷时，得到连续复利收益率。\n公式：\n$$ R_{cc} = \\ln(1+HPR) = \\ln\\left(\\frac{\\text{ending value}}{\\text{beginning value}}\\right) $$\n例子：100 → 120\n\\(HPR = 20%\\) \\(连续复利收益率 = ln(1.2) = 18.232%\\) 👉 好处：连续复利收益率是 可加的，多个区间的连续收益率可以直接相加，便于计算\nComparing #\r指标 特点 公式 适用场景 HPR（持有期收益率） 不考虑时间长短 \\((期末价值 + 分红) / 期初价值 - 1\\) 单一投资期间 Annualized Return（年化收益率） 统一成一年期 \\((1+HPR)^{(365/days)} - 1\\) 跨不同持有期比较 有限复利 考虑 m 次复利 \\((1+r/m)^(mN)\\) 银行利率、债券 连续复利 (Rcc) 极限情况，可加性 \\(ln(1+HPR)\\) 数学推导、衍生品定价 以上三个 Returns 主要看时间维度的收益率变化，接下来要研究的是可能造成收益率变化的因素\nGross return vs Net return #\rGross return（毛收益率）\n投资组合的总回报，在扣除交易佣金和费用之前\nNet return（净收益率）\n扣除了佣金、管理费等必要费用后的回报\n👉 更能反映投资者最终拿到的收益。\nPretax nominal return vs After-tax nominal return #\rPretax nominal return（税前名义收益率）\n投资在交税之前的收益，比如股息、利息、资本利得\nAfter-tax nominal return（税后名义收益率）\n扣除了税收之后的收益，才是真正到手的部分\nReal return（实际收益率） #\r定义：名义收益率剔除通货膨胀（inflation）后的收益率，代表 购买力的实际增长 公式：\n$$ 1+ \\text{real return} = \\frac{1+\\text{nominal return}}{1+\\text{inflation rate}} $$\n例子：\n\\(名义收益率 = 7%\\) \\(通胀率 = 2%\\) \\(实际收益率 = (1.07 / 1.02) − 1 = 4.9%\\) 👉 投资赚了 7%，但通胀吞掉了 2%，所以实际购买力只提高了约 5%\nLeveraged return（杠杆收益率） #\r定义：当投资者使用借贷（leverage）来放大投资时，得到的收益率 公式：\n$$ \\text{leveraged return} = \\frac{r \\times (V_0 + V_B) - r_B \\times V_B}{V_0} $$\n其中：\n\\(V_0\\)：自有资金 \\(V_B\\)：借入资金 \\(r\\)：投资收益率 \\(r_B\\)：借款利率 👉 杠杆放大了风险和收益：涨的时候收益率更高，跌的时候亏损更惨\nComparing #\r指标 关注点 是否考虑通胀 是否考虑税收 是否考虑杠杆 Gross return 毛收益率，不含费用 否 否 否 Net return 扣费后的收益率 否 否 否 Pretax nominal return 税前名义收益率 否 否 否 After-tax nominal return 税后名义收益率 否 是 否 Real return 实际收益率（剔除通胀） 是 可加上 否 Leveraged return 杠杆收益率 可包含 可包含 是 ✅ 一句话总结：\n毛/净收益率 → 是否扣费用 税前/税后收益率 → 是否扣税 名义/实际收益率 → 是否剔除通胀 杠杆收益率 → 是否使用杠杆 ","date":"Sep 8 2025","externalUrl":null,"permalink":"/docs/chartered-financial-analyst/qec1.ratesreturns/","section":"Docs","summary":"\u003ch2 class=\"relative group\"\u003eQEC1.Rates\u0026amp;Returns \r\n    \u003cdiv id=\"qec1ratesreturns\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#qec1ratesreturns\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 9/8/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e1.1 Interest Rates \u0026amp; Return Measurement \r\n    \u003cdiv id=\"11-interest-rates--return-measurement\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#11-interest-rates--return-measurement\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eInterest Rates 利率 \r\n    \u003cdiv id=\"interest-rates-%E5%88%A9%E7%8E%87\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#interest-rates-%E5%88%A9%E7%8E%87\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003eInterest Rate measure the time value of money 衡量了货币的时间价值\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eEquilibrium Interest Rates 必要的回报率 \r\n    \u003cdiv id=\"equilibrium-interest-rates-%E5%BF%85%E8%A6%81%E7%9A%84%E5%9B%9E%E6%8A%A5%E7%8E%87\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#equilibrium-interest-rates-%E5%BF%85%E8%A6%81%E7%9A%84%E5%9B%9E%E6%8A%A5%E7%8E%87\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于某项投资，Equilibrium Interest Rates 反映了投资人期望的市场回报率\u003c/li\u003e\n\u003cli\u003e也代表了投资人为了出借资金所要求的 Return\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eDiscount Rate 贴现率 \r\n    \u003cdiv id=\"discount-rate-%E8%B4%B4%E7%8E%B0%E7%8E%87\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#discount-rate-%E8%B4%B4%E7%8E%B0%E7%8E%87\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003eDiscount Rate 可以被理解为\u003cstrong\u003e衡量未来资金的现在价值\u003c/strong\u003e的利率\u003c/li\u003e\n\u003cli\u003e因为有 Interest 的存在，未来的钱会增加，假设当前有 100 元，年利率为 5%，那么一年后 100 元会变成 105元\u003c/li\u003e\n\u003cli\u003e反过来说，如果希望一年后拿到 105 元，今天的价值则是 100 元，而这一比值就是 Discount Rate，把未来的钱转换成今天的价值的比率，有以下公式\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e$$\n⁍\n$$\u003c/p\u003e","title":"QEC1.Rates\u0026Returns","type":"docs"},{"content":"","date":"Sep 7 2025","externalUrl":null,"permalink":"/tags/ei/","section":"Tags","summary":"","title":"EI","type":"tags"},{"content":"\rEI1. Active Investing #\rLast Edit: 9/7/25\nChapter 1. Hedge Fund 对冲基金 #\rHedge Fund 对冲基金是追求用各种 Trading Strategies 来盈利的投资工具 其中，Hedge 指的是通过建立 Long Position 和 Short Position 来降低市场风险 Long 指的是多头，仅表示一种“看涨”的立场，而 Long Position 则是具体的持仓，两者存在细小的差别，一个更加口语，一个更加书面的区别\nHedge Fund 的两个特点就是自由度高加纰漏度低 1.1. Goal and Fees #\r作为 Fund Manager，他们的目标是为客户争取 Basic Interest 之上的高额收益，一般都是以大盘为参考 需要注意的是，Hedge Funds 并不需要打败市场才能获取盈利，而是争取在所有情况下都能盈利，这就是使用 Hedge 对冲的原因 就好比说假设 SP500 Index 下跌了 10%，Fund 基金只下跌了 8%，他的客户会满意，因为它成功的跑赢了大盘 但是如果同样的情况发生在 Hedge Fund 下，这 8 % 的下跌是不应该发生的，因为 Hedge 的存在应该令其即使在大盘下跌的时候也能盈利 解释来说，理论上来说，Hedge Funds 应该和 Index 或者大盘没有强关联性，Investors 更加关注的则是投资组合的 Absolute Return Absolute Return（绝对回报）：即 Fund 本书赚的钱，不管市场的涨跌\n同时由于其与市场的非强相关性，其也可以被当作投资者的 Diversification Toll（分散风险工具） Example #\r拿养老金举例，退休储蓄由养老基金管理，但投资链条上会有很多“层”的成本： 第一层费用：养老基金给自己员工发工资 第二层费用：养老基金请 **investment consultant，**顾问收钱帮忙挑选基金经理 第三层费用：fund manager 自己也要收管理费 第四层费用：如果投的是 fund of funds 母基金 还会多一层收费 第五层费用：基金经理做主动管理时会产生 trading cost，比如付给券商和银行的佣金 → 所以，终端投资者的钱在到达真正投资之前，已经被一层层抽走不少\n在这种情况下，想要盈利打败市场，需要一个 Double Inefficiency Inefficient securities market 证券市场无效 意味着股票等资产的价格不能完全反映所有信息，有“漏洞”可钻 否则主动型基金经理没法比市场更聪明 Inefficient asset management market 资产管理市场无效 意味着投资者能找到一个收费不高但水平很高的基金经理 否则即使市场有机会，收益也会被高费用吃掉 ","date":"Sep 7 2025","externalUrl":null,"permalink":"/docs/reads/efficientlyinefficient/ei1.activeinvesting/","section":"Docs","summary":"\u003ch1 class=\"relative group\"\u003eEI1. Active Investing \r\n    \u003cdiv id=\"ei1-active-investing\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ei1-active-investing\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 9/7/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eChapter 1. Hedge Fund 对冲基金 \r\n    \u003cdiv id=\"chapter-1-hedge-fund-%E5%AF%B9%E5%86%B2%E5%9F%BA%E9%87%91\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#chapter-1-hedge-fund-%E5%AF%B9%E5%86%B2%E5%9F%BA%E9%87%91\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003eHedge Fund 对冲基金是追求用各种 Trading Strategies 来盈利的投资工具\u003c/li\u003e\n\u003cli\u003e其中，Hedge 指的是通过建立 Long Position 和 Short Position 来降低市场风险\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003eLong 指的是多头，仅表示一种“看涨”的立场，而 Long Position 则是具体的持仓，两者存在细小的差别，一个更加口语，一个更加书面的区别\u003c/p\u003e","title":"EI1.Active Investing","type":"docs"},{"content":"","date":"Sep 7 2025","externalUrl":null,"permalink":"/tags/reads/","section":"Tags","summary":"","title":"Reads","type":"tags"},{"content":"","date":"Sep 6 2025","externalUrl":null,"permalink":"/docs/reads/efficientlyinefficient/","section":"Docs","summary":"","title":"Efficiently Inefficient","type":"docs"},{"content":"\rIntroduction #\rLast Edit: 9/6/25\nHypotheis 假说 #\r关于金融市场，存在多种 Hypothesis，他们分别解释了市场价格是否能充分的反映信息，以及对投资者选择投资方式的指示 Efficient Market Hypothesis 有效市场假说 #\r核心观点：一切市场价格在任何时候都反映所有相关信息 在这种假说下，主动性投资者无法获取利润，因为市场永远快于他们 投资建议：使用被 Passive Investing 被动投资，即买 Index，ETF 等 矛盾点：如果没有 Active Investor，那么市场的价格错误就没有人去弥补了，导致了整个市场的有效性无法被保证 现实中：市场的有效性是因为 Active Investor 的参与，他们纠偏了市场 Inefficient Market Hypothesis 无效市场假说 #\r市场价格会受到投资者 Irrational emotions 和 Behavioural biases 的显著影响 在这种假说下，市场的价格和基本面的关系不大，Active Investing 可以轻松打败市场 矛盾点：市场极为复杂，具有 Irrational Emotion 和 Behavioural Biases 的投资者的行为是不可预测的，这就导致了即使专业投资者也无法打败市场 Efficiently Inefficient Markets 高效运行的无效市场 #\r核心观点：市场处于相对高效运行但终归无效的状态 专业投资者之间的竞争会讲整体市场拉向接近有效的情况，但是市场始终保持了一定程度上的无效 高效运行指的是，在专业投资者之间的竞争下，整个市场的定价已经大部分是合理的了，这就使得大多数一般的投资者无法从中套利 同时这又是一个无效的市场，所以在专业投资者的视角下，尽管大部分价格已经合理了，其仍存在不合理性，而专业投资者就可以从中赚钱 基金经理类别于汉堡店，由于组合了肉，沙拉和面包，并且在便利的地段为人们提供汉堡而获取酬劳 Classing Sources of Alpha for Hedge Funds 经典对冲基金投资策略 #\r他们都是 Active Investing 的不同形式，有的靠基本面，有的靠数学模型，有的靠宏观趋势，有的靠特定市场机会 Discretionary equity investing 主观性股票投资策略 #\r通过研究公司的基本面，挑选股票 Dedicated Short Bias 专注股票做空策略 #\r专门 Short 哪些存在问题（如财务造假等）的上市公司 Quantitative Equity Investing 股票量化投资策略 #\r使用科学方法和计算机模型 Global Macro Investing 全球宏观投资策略 #\r使用货币，利率信用等在全球范围内向大方向押注 Managed Futures Strategies 管理期货策略 #\r针对全球 Futures 和 Forwards 的趋势跟踪交易 Fixed-Income Arbitrage 固定收益套利策略 #\r利用定价差异套利 Convertible Bond Arbitrage 可转换债券套利策略 #\r买入价格低的 Convertible Bonds（可以在将来转换成公司股票的债券） 同时做空对应的 Common Stock 来对冲 Event-Driven Arbitrage 时间驱动型投资策略 #\r针对特定公司时间来交易 Investment Styles 投资风格 #\r上面提到的策略更加宏观，类似于整体的大纲，而这部分则介绍了具体某些资产能获得收益，更像是在介绍 Factors 因子 即在什么 Factor 的变化下，投资能产生收益 这些风格（value, trend, liquidity, carry, low-risk, quality）都是常见的Factor Investing 因子投资 它们之所以能赚钱，不是因为市场完全无效，而是因为市场有一些 Systematic Biases 系统性偏差 这些偏差可能来自 Behavioral biases 投资者行为或 Market Frictions 市场结构限制 Value Investing 价值投资 #\r通过分析公司基本面，来多头、空头 常用数据：市净率 P/B、市盈率 P/E 收益来源：风险溢价和过渡反应 Trend-Following Investing 趋势跟踪投资 #\r买入具有上涨趋势的证券，同时做空下跌趋势的 常用策略：CTA，动量策略 收益来源：初始反应不足和延迟眼影 Liquidity Provision 提供流动性投资 #\r买入流动性差的，被人着急卖的证券 收益来源：Liquidity Risk Premium 流动性风险溢价 Carry Trading 套息交易 #\r通过交换低利息的资产买入高利息的资产 收益来源：风险溢价，市场摩擦成本 Low-Risk Investing 低风险投资 #\r买入低风险，安全的证券，同时做空高风险的证券 收益来源：Leverage Constraints 杠杆约束 Quality Investing 质量投资 #\r买入高质量股票，做空低质量股票 收益来源：Slow Adjustment 市场价值偏离理论价值的可能性 #\r在传统的金融学教材中，通常会通过 Equation 给债券和股票定价，而本书将不采用数学公式，而是分析市场价值偏离理论价值的可能性以及投资者的应对方式 市场价值和理论价值的差异的原因 #\r这意味着存在某种交易机会，如果多次出现则是一个交易策略 意味着理论价值原本就是错误的 这些风格（value, trend, liquidity, carry, low-risk, quality）都是常见的因子投资 (factor investing)。\n它们之所以能赚钱，不是因为市场完全无效，而是因为市场有一些 系统性偏差 (systematic biases)。 这些偏差可能来自 投资者行为 (behavioral biases) 或 市场结构限制 (market frictions)。 ","date":"Sep 6 2025","externalUrl":null,"permalink":"/docs/reads/efficientlyinefficient/ei0.introduction/","section":"Docs","summary":"\u003ch1 class=\"relative group\"\u003eIntroduction \r\n    \u003cdiv id=\"introduction\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#introduction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 9/6/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eHypotheis 假说 \r\n    \u003cdiv id=\"hypotheis-%E5%81%87%E8%AF%B4\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#hypotheis-%E5%81%87%E8%AF%B4\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e关于金融市场，存在多种 Hypothesis，他们分别解释了市场价格是否能充分的反映信息，以及对投资者选择投资方式的指示\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eEfficient Market Hypothesis 有效市场假说 \r\n    \u003cdiv id=\"efficient-market-hypothesis-%E6%9C%89%E6%95%88%E5%B8%82%E5%9C%BA%E5%81%87%E8%AF%B4\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#efficient-market-hypothesis-%E6%9C%89%E6%95%88%E5%B8%82%E5%9C%BA%E5%81%87%E8%AF%B4\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e核心观点：一切市场价格在任何时候都反映所有相关信息\u003c/li\u003e\n\u003cli\u003e在这种假说下，主动性投资者无法获取利润，因为市场永远快于他们\u003c/li\u003e\n\u003cli\u003e投资建议：使用被 Passive Investing 被动投资，即买 Index，ETF 等\u003c/li\u003e\n\u003cli\u003e矛盾点：如果没有 Active Investor，那么市场的价格错误就没有人去弥补了，导致了整个市场的有效性无法被保证\u003c/li\u003e\n\u003cli\u003e现实中：市场的有效性是因为 Active Investor 的参与，他们纠偏了市场\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eInefficient Market Hypothesis 无效市场假说 \r\n    \u003cdiv id=\"inefficient-market-hypothesis-%E6%97%A0%E6%95%88%E5%B8%82%E5%9C%BA%E5%81%87%E8%AF%B4\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#inefficient-market-hypothesis-%E6%97%A0%E6%95%88%E5%B8%82%E5%9C%BA%E5%81%87%E8%AF%B4\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e市场价格会受到投资者 Irrational emotions 和 Behavioural biases 的显著影响\u003c/li\u003e\n\u003cli\u003e在这种假说下，市场的价格和基本面的关系不大，Active Investing 可以轻松打败市场\u003c/li\u003e\n\u003cli\u003e矛盾点：市场极为复杂，具有 Irrational Emotion 和 Behavioural Biases 的投资者的行为是不可预测的，这就导致了即使专业投资者也无法打败市场\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eEfficiently Inefficient Markets 高效运行的无效市场 \r\n    \u003cdiv id=\"efficiently-inefficient-markets-%E9%AB%98%E6%95%88%E8%BF%90%E8%A1%8C%E7%9A%84%E6%97%A0%E6%95%88%E5%B8%82%E5%9C%BA\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#efficiently-inefficient-markets-%E9%AB%98%E6%95%88%E8%BF%90%E8%A1%8C%E7%9A%84%E6%97%A0%E6%95%88%E5%B8%82%E5%9C%BA\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e核心观点：市场处于相对高效运行但终归无效的状态\u003c/li\u003e\n\u003cli\u003e专业投资者之间的竞争会讲整体市场拉向接近有效的情况，但是市场始终保持了一定程度上的无效\u003c/li\u003e\n\u003cli\u003e高效运行指的是，在专业投资者之间的竞争下，整个市场的定价已经大部分是合理的了，这就使得大多数一般的投资者无法从中套利\u003c/li\u003e\n\u003cli\u003e同时这又是一个无效的市场，所以在专业投资者的视角下，尽管大部分价格已经合理了，其仍存在不合理性，而专业投资者就可以从中赚钱\u003c/li\u003e\n\u003cli\u003e基金经理类别于汉堡店，由于组合了肉，沙拉和面包，并且在便利的地段为人们提供汉堡而获取酬劳\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eClassing Sources of Alpha for Hedge Funds 经典对冲基金投资策略 \r\n    \u003cdiv id=\"classing-sources-of-alpha-for-hedge-funds-%E7%BB%8F%E5%85%B8%E5%AF%B9%E5%86%B2%E5%9F%BA%E9%87%91%E6%8A%95%E8%B5%84%E7%AD%96%E7%95%A5\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#classing-sources-of-alpha-for-hedge-funds-%E7%BB%8F%E5%85%B8%E5%AF%B9%E5%86%B2%E5%9F%BA%E9%87%91%E6%8A%95%E8%B5%84%E7%AD%96%E7%95%A5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e他们都是 Active Investing 的不同形式，有的靠基本面，有的靠数学模型，有的靠宏观趋势，有的靠特定市场机会\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eDiscretionary equity investing 主观性股票投资策略 \r\n    \u003cdiv id=\"discretionary-equity-investing-%E4%B8%BB%E8%A7%82%E6%80%A7%E8%82%A1%E7%A5%A8%E6%8A%95%E8%B5%84%E7%AD%96%E7%95%A5\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#discretionary-equity-investing-%E4%B8%BB%E8%A7%82%E6%80%A7%E8%82%A1%E7%A5%A8%E6%8A%95%E8%B5%84%E7%AD%96%E7%95%A5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e通过研究公司的基本面，挑选股票\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eDedicated Short Bias 专注股票做空策略 \r\n    \u003cdiv id=\"dedicated-short-bias-%E4%B8%93%E6%B3%A8%E8%82%A1%E7%A5%A8%E5%81%9A%E7%A9%BA%E7%AD%96%E7%95%A5\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#dedicated-short-bias-%E4%B8%93%E6%B3%A8%E8%82%A1%E7%A5%A8%E5%81%9A%E7%A9%BA%E7%AD%96%E7%95%A5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e专门 Short 哪些存在问题（如财务造假等）的上市公司\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eQuantitative Equity Investing 股票量化投资策略 \r\n    \u003cdiv id=\"quantitative-equity-investing-%E8%82%A1%E7%A5%A8%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E7%AD%96%E7%95%A5\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#quantitative-equity-investing-%E8%82%A1%E7%A5%A8%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E7%AD%96%E7%95%A5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e使用科学方法和计算机模型\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eGlobal Macro Investing 全球宏观投资策略 \r\n    \u003cdiv id=\"global-macro-investing-%E5%85%A8%E7%90%83%E5%AE%8F%E8%A7%82%E6%8A%95%E8%B5%84%E7%AD%96%E7%95%A5\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#global-macro-investing-%E5%85%A8%E7%90%83%E5%AE%8F%E8%A7%82%E6%8A%95%E8%B5%84%E7%AD%96%E7%95%A5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e使用货币，利率信用等在全球范围内向大方向押注\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eManaged Futures Strategies 管理期货策略 \r\n    \u003cdiv id=\"managed-futures-strategies-%E7%AE%A1%E7%90%86%E6%9C%9F%E8%B4%A7%E7%AD%96%E7%95%A5\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#managed-futures-strategies-%E7%AE%A1%E7%90%86%E6%9C%9F%E8%B4%A7%E7%AD%96%E7%95%A5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e针对全球 Futures 和 Forwards 的趋势跟踪交易\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eFixed-Income Arbitrage 固定收益套利策略 \r\n    \u003cdiv id=\"fixed-income-arbitrage-%E5%9B%BA%E5%AE%9A%E6%94%B6%E7%9B%8A%E5%A5%97%E5%88%A9%E7%AD%96%E7%95%A5\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#fixed-income-arbitrage-%E5%9B%BA%E5%AE%9A%E6%94%B6%E7%9B%8A%E5%A5%97%E5%88%A9%E7%AD%96%E7%95%A5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e利用定价差异套利\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eConvertible Bond Arbitrage 可转换债券套利策略 \r\n    \u003cdiv id=\"convertible-bond-arbitrage-%E5%8F%AF%E8%BD%AC%E6%8D%A2%E5%80%BA%E5%88%B8%E5%A5%97%E5%88%A9%E7%AD%96%E7%95%A5\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#convertible-bond-arbitrage-%E5%8F%AF%E8%BD%AC%E6%8D%A2%E5%80%BA%E5%88%B8%E5%A5%97%E5%88%A9%E7%AD%96%E7%95%A5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e买入价格低的 Convertible Bonds（可以在将来转换成公司股票的债券）\u003c/li\u003e\n\u003cli\u003e同时做空对应的 Common Stock 来对冲\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eEvent-Driven Arbitrage 时间驱动型投资策略 \r\n    \u003cdiv id=\"event-driven-arbitrage-%E6%97%B6%E9%97%B4%E9%A9%B1%E5%8A%A8%E5%9E%8B%E6%8A%95%E8%B5%84%E7%AD%96%E7%95%A5\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#event-driven-arbitrage-%E6%97%B6%E9%97%B4%E9%A9%B1%E5%8A%A8%E5%9E%8B%E6%8A%95%E8%B5%84%E7%AD%96%E7%95%A5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e针对特定公司时间来交易\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eInvestment Styles 投资风格 \r\n    \u003cdiv id=\"investment-styles-%E6%8A%95%E8%B5%84%E9%A3%8E%E6%A0%BC\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#investment-styles-%E6%8A%95%E8%B5%84%E9%A3%8E%E6%A0%BC\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e上面提到的策略更加宏观，类似于整体的大纲，而这部分则介绍了具体某些资产能获得收益，更像是在介绍 Factors 因子\u003c/li\u003e\n\u003cli\u003e即在什么 Factor 的变化下，投资能产生收益\u003c/li\u003e\n\u003cli\u003e这些风格（value, trend, liquidity, carry, low-risk, quality）都是常见的Factor Investing 因子投资\u003c/li\u003e\n\u003cli\u003e它们之所以能赚钱，不是因为市场完全无效，而是因为市场有一些 Systematic Biases 系统性偏差\u003c/li\u003e\n\u003cli\u003e这些偏差可能来自 Behavioral biases 投资者行为或 Market Frictions 市场结构限制\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eValue Investing 价值投资 \r\n    \u003cdiv id=\"value-investing-%E4%BB%B7%E5%80%BC%E6%8A%95%E8%B5%84\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#value-investing-%E4%BB%B7%E5%80%BC%E6%8A%95%E8%B5%84\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e通过分析公司基本面，来多头、空头\u003c/li\u003e\n\u003cli\u003e常用数据：市净率 P/B、市盈率 P/E\u003c/li\u003e\n\u003cli\u003e收益来源：风险溢价和过渡反应\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eTrend-Following Investing 趋势跟踪投资 \r\n    \u003cdiv id=\"trend-following-investing-%E8%B6%8B%E5%8A%BF%E8%B7%9F%E8%B8%AA%E6%8A%95%E8%B5%84\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#trend-following-investing-%E8%B6%8B%E5%8A%BF%E8%B7%9F%E8%B8%AA%E6%8A%95%E8%B5%84\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e买入具有上涨趋势的证券，同时做空下跌趋势的\u003c/li\u003e\n\u003cli\u003e常用策略：CTA，动量策略\u003c/li\u003e\n\u003cli\u003e收益来源：初始反应不足和延迟眼影\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eLiquidity Provision 提供流动性投资 \r\n    \u003cdiv id=\"liquidity-provision-%E6%8F%90%E4%BE%9B%E6%B5%81%E5%8A%A8%E6%80%A7%E6%8A%95%E8%B5%84\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#liquidity-provision-%E6%8F%90%E4%BE%9B%E6%B5%81%E5%8A%A8%E6%80%A7%E6%8A%95%E8%B5%84\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e买入流动性差的，被人着急卖的证券\u003c/li\u003e\n\u003cli\u003e收益来源：Liquidity Risk Premium 流动性风险溢价\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eCarry Trading 套息交易 \r\n    \u003cdiv id=\"carry-trading-%E5%A5%97%E6%81%AF%E4%BA%A4%E6%98%93\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#carry-trading-%E5%A5%97%E6%81%AF%E4%BA%A4%E6%98%93\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e通过交换低利息的资产买入高利息的资产\u003c/li\u003e\n\u003cli\u003e收益来源：风险溢价，市场摩擦成本\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eLow-Risk Investing 低风险投资 \r\n    \u003cdiv id=\"low-risk-investing-%E4%BD%8E%E9%A3%8E%E9%99%A9%E6%8A%95%E8%B5%84\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#low-risk-investing-%E4%BD%8E%E9%A3%8E%E9%99%A9%E6%8A%95%E8%B5%84\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e买入低风险，安全的证券，同时做空高风险的证券\u003c/li\u003e\n\u003cli\u003e收益来源：Leverage Constraints 杠杆约束\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eQuality Investing 质量投资 \r\n    \u003cdiv id=\"quality-investing-%E8%B4%A8%E9%87%8F%E6%8A%95%E8%B5%84\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#quality-investing-%E8%B4%A8%E9%87%8F%E6%8A%95%E8%B5%84\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e买入高质量股票，做空低质量股票\u003c/li\u003e\n\u003cli\u003e收益来源：Slow Adjustment\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e市场价值偏离理论价值的可能性 \r\n    \u003cdiv id=\"%E5%B8%82%E5%9C%BA%E4%BB%B7%E5%80%BC%E5%81%8F%E7%A6%BB%E7%90%86%E8%AE%BA%E4%BB%B7%E5%80%BC%E7%9A%84%E5%8F%AF%E8%83%BD%E6%80%A7\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%B8%82%E5%9C%BA%E4%BB%B7%E5%80%BC%E5%81%8F%E7%A6%BB%E7%90%86%E8%AE%BA%E4%BB%B7%E5%80%BC%E7%9A%84%E5%8F%AF%E8%83%BD%E6%80%A7\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e在传统的金融学教材中，通常会通过 Equation 给债券和股票定价，而本书将不采用数学公式，而是分析市场价值偏离理论价值的可能性以及投资者的应对方式\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e市场价值和理论价值的差异的原因 \r\n    \u003cdiv id=\"%E5%B8%82%E5%9C%BA%E4%BB%B7%E5%80%BC%E5%92%8C%E7%90%86%E8%AE%BA%E4%BB%B7%E5%80%BC%E7%9A%84%E5%B7%AE%E5%BC%82%E7%9A%84%E5%8E%9F%E5%9B%A0\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%B8%82%E5%9C%BA%E4%BB%B7%E5%80%BC%E5%92%8C%E7%90%86%E8%AE%BA%E4%BB%B7%E5%80%BC%E7%9A%84%E5%B7%AE%E5%BC%82%E7%9A%84%E5%8E%9F%E5%9B%A0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003col\u003e\n\u003cli\u003e这意味着存在某种交易机会，如果多次出现则是一个交易策略\u003c/li\u003e\n\u003cli\u003e意味着理论价值原本就是错误的\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e这些风格（value, trend, liquidity, carry, low-risk, quality）都是\u003cstrong\u003e常见的因子投资 (factor investing)\u003c/strong\u003e。\u003c/p\u003e","title":"EI0.Introduction","type":"docs"},{"content":"","date":"Sep 1 2025","externalUrl":null,"permalink":"/tags/books/","section":"Tags","summary":"","title":"Books","type":"tags"},{"content":"","date":"Sep 1 2025","externalUrl":null,"permalink":"/docs/reads/","section":"Docs","summary":"","title":"Books","type":"docs"},{"content":"","date":"Sep 1 2025","externalUrl":null,"permalink":"/tags/docs/","section":"Tags","summary":"","title":"Docs","type":"tags"},{"content":"","date":"Sep 1 2025","externalUrl":null,"permalink":"/tags/notes/","section":"Tags","summary":"","title":"Notes","type":"tags"},{"content":"","date":"Sep 1 2025","externalUrl":null,"permalink":"/docs/notes/","section":"Docs","summary":"","title":"Notes","type":"docs"},{"content":"","date":"Apr 7 2025","externalUrl":null,"permalink":"/tags/ef/","section":"Tags","summary":"","title":"EF","type":"tags"},{"content":" Last Edit: 3/7/25\nNode Analysis #\r在 Kirchhoff\u0026rsquo;s Voltage Law, KVL 中，规定了在一个完整的 Closed loop 中，所有 Voltage rises 和Voltage drops 的代数和必须等于零 这是因为电压是势能差，一个完整的回路回到起点后，总能量变化应该为零，这是电荷守恒和能量守恒的直接体现 然而，对于 Partial path 或 Non-closed segment 非闭合段，其电压之和不一定为零，而是等于这些局部路径两端 Node 的电压差 以上图为例，在 Node 1 到 2 之间，Potential Difference 为 \\(V_s=V_1+V_a\\) 而需要注意的是，在 Node Analysis 中，由 Battery 提供的初始 Voltage 被视为负值，有 \\(-V_s+V_1+V_a=0\\) 这是因为，当电路闭合的时候，Battery 推动 Electron 从负极向正极移动，并且在到达正极的时候获取了最高的 Electric Potential，之后在通过 Resistor 和其他负载的时候，Electron 会消耗这些 Potential Energy 以克服阻力，这视为 Potential 的下降 但是规定的符号与能量变换相反，即 Battery 提供 Electric Potential 的过程视为负号，用电器小号 Potential 的过程视为正号 总结上图中的 \\(V_1,V_3,V_5\\)，可以得出 $$ I_1 = \\frac{V_1}{9k} = \\frac{V_s - V_a}{9k},I_3 = \\frac{V_3}{3k} = \\frac{V_a - V_b}{3k},I_5 = \\frac{V_5}{9k} = \\frac{V_b - V_c}{9k} $$\n对于 \\(6k\\Omega\\) 和 \\(4k\\Omega\\) 来说，由于 Ground 是电路中所有 Node Potential 的参考零点，所以其本身为 0 V，也就是说 \\(0=V_a-V_{6k\\Omega}\\)，而它所对应的 Current 也就是 $$ I_2=\\frac{V_{6k\\Omega}}{6k}=\\frac{V_a-0}{6k} $$\nPD \u0026amp; Current Direction #\r现在有以下 Circuit Voltage 即 Potential Difference 是一个参考量，即根据参考点的不同具有不同的数据，图中的 4 V 和 -2 V 即为相较于 Ground 也就是 0 V 参考的 而 Current 的 Direction 又和 Fragment 两端的 Node 的 Potential Difference 有关，呈现出的规律为 Current Will flow from higher to lower potential 在这张图中即为，R1 从上往下，R2 从左往右，R3 从下往上 Circuits containing only Independent Current Sources #\r在没有 Voltage Source 而是 Current Source 的时候，Circuit 的行为主要由 Current Source 驱动，而不是 Voltage Source 上图中即存在两个 Current Source，\\(i_A\\) 和 \\(i_B\\) 而对于 Node 来说，Node 1 根据 KCL 有 \\(i_A=i_1+i_2\\)，Node 2 有 \\(i_2=i_B+i_3\\) 现在进一步假设 \\(I_A = 1,mA, R_1 = 12,k\\Omega, R_2 = 6,k\\Omega, I_B = 4,mA, R_3 = 6,k\\Omega\\) 已知 \\({i}_1 = \\frac{v_1}{R_1},{i}_2 = \\frac{v_1 - v_2}{R_2},{i}_3 = \\frac{v_2}{R_3}\\)，将他们带入原来的 Equation 中，有 $$ i_A = \\frac{v_1}{R_1} + \\frac{v_1 - v_2}{R_2},i_B = \\frac{v_1 - v_2}{R_2} + \\frac{v_2}{R_3} $$\n带入数据得到 $$ 1\\times 10^3=\\frac{v_1}{12k}+\\frac{v_1-v_2}{6k},-4\\times10^3=\\frac{v_1-v_2}{6k}=\\frac{v_2}{6k} $$\n解方程组后可以得到 \\(V_1=-6V,V_2=-15V\\)，也就可以对应解出 \\(I_1,I_2\\) 了 同时也可以发现，如果一个 Circuit 中有 N 个 Node，则对应存在 N-1 个 Equation 需要解\n","date":"Apr 7 2025","externalUrl":null,"permalink":"/docs/uoft/24/electrical-fundamentals/ef10.nodalandloopanalysis/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/7/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eNode Analysis \r\n    \u003cdiv id=\"node-analysis\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#node-analysis\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e在 Kirchhoff\u0026rsquo;s Voltage Law, KVL 中，规定了在一个完整的 Closed loop 中，所有 Voltage rises 和Voltage drops 的代数和必须等于零\u003c/li\u003e\n\u003cli\u003e这是因为电压是势能差，一个完整的回路回到起点后，总能量变化应该为零，这是电荷守恒和能量守恒的直接体现\u003c/li\u003e\n\u003cli\u003e然而，对于 \u003cstrong\u003ePartial path\u003c/strong\u003e 或 \u003cstrong\u003eNon-closed segment\u003c/strong\u003e 非闭合段，其电压之和不一定为零，而是等于这些局部路径两端 Node 的电压差\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/uoft/24/electrical-fundamentals/ef10.nodalandloopanalysis/image_hu14836653746222108356.png 330w,\r\n        /docs/uoft/24/electrical-fundamentals/ef10.nodalandloopanalysis/image_hu13701235930078814582.png 660w,\r\n        /docs/uoft/24/electrical-fundamentals/ef10.nodalandloopanalysis/image_hu13007749878243609150.png 1024w,\r\n        /docs/uoft/24/electrical-fundamentals/ef10.nodalandloopanalysis/image_hu2375413442522557764.png 2x\"\r\n        src=\"/docs/uoft/24/electrical-fundamentals/ef10.nodalandloopanalysis/image_hu13701235930078814582.png\"\r\n        alt=\"image.png\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 10. Nodal and Loop Analysis","type":"docs"},{"content":"","date":"Apr 7 2025","externalUrl":null,"permalink":"/docs/uoft/24/electrical-fundamentals/","section":"Docs","summary":"","title":"Electrical Fundamentals","type":"docs"},{"content":"","date":"Apr 7 2025","externalUrl":null,"permalink":"/docs/uoft/","section":"Docs","summary":"","title":"U of T","type":"docs"},{"content":"","date":"Apr 7 2025","externalUrl":null,"permalink":"/tags/uoft/","section":"Tags","summary":"","title":"UofT","type":"tags"},{"content":"","date":"Mar 31 2025","externalUrl":null,"permalink":"/tags/c/","section":"Tags","summary":"","title":"C","type":"tags"},{"content":"","date":"Mar 31 2025","externalUrl":null,"permalink":"/tags/computer-science/","section":"Tags","summary":"","title":"Computer Science","type":"tags"},{"content":"","date":"Mar 31 2025","externalUrl":null,"permalink":"/series/d2l/","section":"Series","summary":"","title":"D2L","type":"series"},{"content":"","date":"Mar 31 2025","externalUrl":null,"permalink":"/tags/d2l/","section":"Tags","summary":"","title":"D2L","type":"tags"},{"content":"","date":"Mar 31 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l6.convolutionneuronnetwork/","section":"Docs","summary":"","title":"D2L 6. ConvolutionNeuronNetwork","type":"docs"},{"content":" Last Edit: 3/31/25\n在处理图像的时候，希望逐渐扩大 Layer 的 Receptive Field，这是因为学习任务通常会和全局的图像相关，如“图像是否包含某个物体？”，所以需要逐渐汇集信息到最后一层时包含整个图像\n而在逐步汇聚的时候，Representation 特征图会变得更加粗略，但是这些图在粗略的同时已经保存饿了 Convolutional Layer 中的关键特征优势了，所以即使没有关注局部细节，但是有用的特征已经被保存下来了\nPooling Layer #\r所以说这一层需要同时做到两个目的，让模型具有更加稳健的 Translation Invariance（平移不变性）的同时降低空间降采样的敏感性（压缩后保留重要信息） 6.5.1 Maximum \u0026amp; Average Pooling Layer #\rPooling Layer 和 Convolution Layer 一样，也有一个 Windows 在 Input Feature Map 上滑动，并且每次都覆盖一个小区域，然后给出对应输出 不同于 Convolution 中的 Cross-correlation 运算，Pooling Layer 本身并不包含参数 计算 Windows 中的最大值的运算的 Layer 叫做 Maximum Pooling Layer，同理计算平均数的就叫做 Average Pooling Layer Pooling Layer 的本质是在一个小范围（比如 2×2）的区域里，选出最大值（或平均值）来代表这块区域的整体特征。 所以只要那个特征还在这个小区域里没走出窗口，它就还能被选中，就还会出现在输出里 想要实现一个 Pooling Layer 也不难，只要拿出一个 Window 滑动就行了 import torch from torch import nn from d2l import torch as d2l # 定义二维汇聚函数 def pool2d(X, pool_size, mode=\u0026#39;max\u0026#39;): # 拆解汇聚窗口的高和宽 p_h, p_w = pool_size # 初始化输出张量 Y，大小为输入尺寸减去窗口尺寸加 1（假设步幅为 1） Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)) # 遍历输出张量的每个位置 for i in range(Y.shape[0]): for j in range(Y.shape[1]): # 如果是最大汇聚模式 if mode == \u0026#39;max\u0026#39;: # 取出当前汇聚窗口内的最大值 Y[i, j] = X[i: i + p_h, j: j + p_w].max() # 如果是平均汇聚模式 elif mode == \u0026#39;avg\u0026#39;: # 取出当前汇聚窗口内的平均值 Y[i, j] = X[i: i + p_h, j: j + p_w].mean() # 返回汇聚后的输出结果 return Y 6.5.2 Padding \u0026amp; Stride #\r与 Convolution 一样，Pooling 的 Windows Size 也可以变换以得到一个想要的输出形状 首先创建一个 Input Tensor x = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4)) ，这会得到一个 [[[[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [12., 13., 14., 15.]]]] 一个没有设置的 Pooling Layer 将会有相同的 Window Size 和 Stide，也就是 $Stride = 3 = dim(win)$，这就导致了pool2d = nn.MaxPool2d(3) 只会截到 [[ 0, 1, 2], [ 4, 5, 6], [ 8, 9, 10]] 也就得到了 10 的输出 这就说明一个 Pooling Window 的参数都需要手动设置 pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1)) pool2d(X) 6.5.3 Multiple Channel #\r同样放到彩色的情况下，对每一个 Channel 的 Pooling 操作最后都是独立的，而不是像 Convolution 一样去求和，几个 Channel 的输入就对应了相等的输出 Channel ","date":"Mar 31 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l6.convolutionneuronnetwork/d2l6.5poolinglayer/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/31/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e在处理图像的时候，希望逐渐扩大 Layer 的 Receptive Field，这是因为学习任务通常会和全局的图像相关，如“图像是否包含某个物体？”，所以需要逐渐汇集信息到最后一层时包含整个图像\u003c/p\u003e","title":"D2L 6.5 Pooling Layer","type":"docs"},{"content":" Last Edit: 3/31/25\n我们在前面章节已经学习了构建完整 Convolutional Neural Network 卷积神经网络，简称 CNN）所需的基础模块，但是为了把这些模块真正用起来，需要介绍一个完整的、早期的 CNN 架构 LeNet（LeNet-5）\n6.6.1 LeNet #\r层 输出形状 输入 1 × 28 × 28 C1 卷积 6 × 28 × 28 S2 池化 6 × 14 × 14 C3 卷积 16 × 10 × 10 S4 池化 16 × 5 × 5 展平后 400（向量） FC1 120 FC2 84 输出 10（分类概率） 每一个 Convolution Layer 包含一个 5x5 Kernel，一个 Sigmoid Activation Function，同时也在增加 Output Channel，而每一个 Pooling Layer 都通过 2x2 的 window 和 2 的 Stride 将宽高减半 其中在 Convolution Layer 和 Full-Connect Layer 中需要进行数据的 Flatten 因为 Full-Connect Layer 只接受一维向量之后送进全连接 最后保留 10 维的输出，对应了 LeNet 的分类 0-9 任务 通过一个简单的 Sequential 块就可以实现 LeNet import torch from torch import nn from d2l import torch as d2l # 使用 nn.Sequential 顺序堆叠每一层，构建 LeNet 网络 net = nn.Sequential( # 第一层：卷积层 # 输入通道数 1（灰度图），输出通道数 6，卷积核大小 5×5，padding=2 保持输出大小不变 nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(), # 激活函数使用 sigmoid（原始 LeNet 使用的激活） # 第一层：平均池化层，窗口 2×2，步幅 2（尺寸减半） nn.AvgPool2d(kernel_size=2, stride=2), # 第二层：卷积层 # 输入通道数 6，输出通道数 16，卷积核大小 5×5，不使用 padding（输出会缩小） nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(), # 第二层：平均池化层 nn.AvgPool2d(kernel_size=2, stride=2), # 将卷积输出展平为一维向量，便于输入到全连接层 nn.Flatten(), # 第一层全连接：输入 16×5×5 = 400 个节点，输出 120 个神经元 nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(), # 第二层全连接：120 → 84 nn.Linear(120, 84), nn.Sigmoid(), # 第三层全连接（输出层）：84 → 10（10 类分类结果） nn.Linear(84, 10) ) 简单概括就是图像尺寸越来越小，但是通道越来越多 6.6.2 Model Train #\r为了使用 GPU，需要作出一些小的改动 def evaluate_accuracy_gpu(net, data_iter, device=None):#@save\u0026#34;\u0026#34;\u0026#34;使用GPU计算模型在数据集上的精度\u0026#34;\u0026#34;\u0026#34;if isinstance(net, nn.Module): net.eval()# 设置为评估模式ifnot device: device = next(iter(net.parameters())).device # 正确预测的数量，总预测的数量metric = d2l.Accumulator(2) with torch.no_grad(): for X, yin data_iter: if isinstance(X, list): # BERT微调所需的（之后将介绍）X = [x.to(device)for xin X] else: X = X.to(device) y = y.to(device) metric.add(d2l.accuracy(net(X), y), y.numel()) return metric[0] / metric[1] 接下来就是主训练函数 定义函数 #\rdef train_ch6(net, train_iter, test_iter, num_epochs, lr, device): \u0026#34;\u0026#34;\u0026#34;用 GPU 训练模型（在第六章定义）\u0026#34;\u0026#34;\u0026#34; 1️⃣ 初始化网络参数（使用 Xavier 初始化） #\rdef init_weights(m): if type(m) == nn.Linear or type(m) == nn.Conv2d: nn.init.xavier_uniform_(m.weight) net.apply(init_weights) 对所有 Linear 和 Conv2d 层使用 Xavier 均匀初始化，其他层是没有参数的，不用管 2️⃣ 设置设备（GPU / CPU）和优化器 #\rprint(\u0026#39;training on\u0026#39;, device) net.to(device) optimizer = torch.optim.SGD(net.parameters(), lr=lr) loss = nn.CrossEntropyLoss() 使用随机梯度下降（SGD） 使用 Cross Entropy Loss 3️⃣ 可视化工具（绘图） #\ranimator = d2l.Animator(...) 4️⃣ 开始训练循环 #\rfor epoch in range(num_epochs): ① 初始化指标收集器（loss、acc、样本数） #\rmetric = d2l.Accumulator(3) # D2L 库的累加器 ② 设置模型为训练模式 #\rnet.train() ③ 遍历每个 batch #\rfor i, (X, y) in enumerate(train_iter): 将数据移到设备上（X 和 y） 前向传播 → 计算损失 → 反向传播 → 梯度更新 timer.start() #开始计时 optimizer.zero_grad() #重置梯度 X, y = X.to(device), y.to(device) y_hat = net(X) #前面的 nn.Sequence 的输出值 l = loss(y_hat, y) #Loss l.backward() #Feed Backward optimizer.step() #Optimizer with torch.no_grad(): #添加值到前面的定义的累加器中 metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0]) timer.stop() #结束计时 train_l = metric[0] / metric[2] train_acc = metric[1] / metric[2] ④ 每训练完一部分，更新动态图（绘图） #\rif (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1: animator.add(...) 5️⃣ 每轮结束后在测试集上评估 #\rtest_acc = evaluate_accuracy_gpu(net, test_iter) animator.add(...) 6️⃣ 最终打印结果 #\rprint(f\u0026#39;loss {train_l:.3f}, train acc {train_acc:.3f}, test acc {test_acc:.3f}\u0026#39;) print(f\u0026#39;{metric[2] * num_epochs / timer.sum():.1f} examples/sec on {str(device)}\u0026#39;) ","date":"Mar 31 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l6.convolutionneuronnetwork/d2l6.6lenet/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/31/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e我们在前面章节已经学习了构建完整 Convolutional Neural Network 卷积神经网络，简称 CNN）所需的基础模块，但是为了把这些模块真正用起来，需要介绍一个完整的、早期的 CNN 架构 LeNet（LeNet-5）\u003c/p\u003e","title":"D2L 6.6 LeNet","type":"docs"},{"content":"https://learningc.org/cover\n","date":"Mar 31 2025","externalUrl":null,"permalink":"/docs/uoft/24/learning-programming-with-c/","section":"Docs","summary":"\u003cp\u003e\u003ca href=\"https://learningc.org/cover\" target=\"_blank\"\u003ehttps://learningc.org/cover\u003c/a\u003e\u003c/p\u003e","title":"Learning Programming with C","type":"docs"},{"content":"","date":"Mar 31 2025","externalUrl":null,"permalink":"/tags/lpc/","section":"Tags","summary":"","title":"LPC","type":"tags"},{"content":" Last Edit: 3/31/25\n11.1 Recursive Functions by Definition #\rRecursion 递归是一个先解决更小问题实例，后解决整体问题的方法 Recursion 这一次特指函数调用自身 Recursion 包含饿了 End Case 和 Loop Case，分别代表了循环条件和终止条件，二者缺一不可 11.1.1 Euclidean Algorithm for GCD #\rEuclidean Algorithm 是一种用于求两个整数最大公约数的方法，这个方法是递归定义的 该算法的核心为，如果 a 和 b 是两个正整数且 $a \u0026gt; b$，则 a 和 b 的最大公约数等于 $a - b$ 和 b 的 GCD $$ \\text{GCD}(a, b) =\\begin{cases}\\text{GCD}(b, a - b) \u0026amp; \\text{if } a \u0026gt; b \\\\text{GCD}(b, a) \u0026amp; \\text{if } a \u0026lt; b \\a \u0026amp; \\text{if } a = b\\end{cases} $$\n将流程写出代码就有 #include \u0026lt;stdio.h\u0026gt; int gcd(int a, int b); int main(void) { int gcdAnswer = gcd(20, 8); printf(\u0026#34;gcd(20, 8) = %d\\n\u0026#34;, gcdAnswer); return 0; } int gcd(int a, int b) { if (a == b) { return a; } else if (a \u0026gt; b) { return gcd(b, a - b); } else { return gcd(b, a); } } 可以发现在 function gcd 中，gcd 函数再次调用了自身 gcd(b, a - b)，这种 function calling itself 的过程就叫做 Recursion 实际上 Recursion 严重降低了代码的可读性\n一个例子可以是 GCD(20, 8) → GCD(8, 12) （20 - 8 = 12） GCD(8, 12) → GCD(8, 4) （12 - 8 = 4） GCD(8, 4) → GCD(4, 4) （8 - 4 = 4） GCD(4, 4) = 4 （因为两个数相等） 11.1.2 Factorial of a Number #\r数学中定义 Factorial 为 n! = n × (n - 1) × (n - 2) × ... × 2 × 1 实现 Factorial 本质上只要一个 Loop，它可以是一个 for loop int factorial(int n) { int fact = 1; for (int i = 1; i \u0026lt;= n; i++) { fact = fact * i; } return fact; } 将这一个用 Recursion 写出来就是 int factorial(int n); int main(void) { int fact = factorial(4); return 0; } int factorial(int n) { return n * factorial(n - 1); } 这个代码并不是正确的，因为他少了一个 End Case，也就是没有一个终止条件，递归会不断重复调用自身，即 n 递减到 0、-1、-2\u0026hellip; 所以加一个 if (n == 0) {return 1;} 就对了 11.2 Recursion in Patterns #\rRecursion 是用来解决具有规律结构的问题的 重新拿回之前的打印 * 的代码，如果最终的目标是打印 n 个 * ，那将其拆分成子任务就变成了打印一个，之后在打印 n - 1 个，最终在 n == 1 的时候为 End Case 11.2.2 Print a Triangle of Stars #\r回到前面的 Loop 中的例子，打印一个 ***** **** *** ** * #include \u0026lt;stdio.h\u0026gt; void printRow(int n); void printTriangle(int n); int main(void) { int rows; printf(\u0026#34;Enter number of rows:\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;rows); printTriangle(rows); return 0; } void printTriangle(int n) { if (n \u0026gt; 0) { printRow(n); printTriangle(n - 1); } } void printRow(int n) { if (n == 1) { printf(\u0026#34;*\\n\u0026#34;); } else { printf(\u0026#34;*\u0026#34;); printRow(n - 1); } } 这里把行操作和列操作都用了 Recursion 写成了两个函数 11.2.3 Print an Inverted Triangle of stars #\r将图像转过来 * ** *** **** ***** 本质上就是给 prinf 和 Recursion 换个位置，先进入最深层的 Recursion 后再从 Base Case 往外 print 11.2.4 Print a Pattern Recursively #\r现在想要打印一个更加复杂的图形 ***** **** *** ** * ** *** **** ***** 这里的行操作是不需要变得，因为还是再第 n 行打赢 n 个 * 的逻辑 而列操作部分，只需要添加一个 printRow(n); // 打印当前行 printPattern(n - 1); // 递归打印下一层（更短的行） printRow(n); 实现 Recursion 前后分别打印就行 11.3 Recursion in arrays #\r本章将解决一些和 Array 相关的 Recursions，包括 Strings （ Array of Characters) 11.3.2 Palindrome Problem #\rPalindrome 回文，指的是从前往后，从后往前都一样的 String，比如 Nolan 导演的 TENET 就是一个 Palindrome 判断的思路就是每次从最外层进入，一层层判断，End Case 即为只剩下一个 Char 的情况，也就是头尾指向相同的 Char 的时候 #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; bool isPalindromeHelper(char *s, int low, int high) { if (low \u0026gt;= high) return true; else if (s[low] != s[high]) return false; else return isPalindromeHelper(s, low + 1, high - 1); } bool isPalindrome(char *s) { return isPalindromeHelper(s, 0, strlen(s) - 1); } int main(void) { printf(\u0026#34;isPalindrome(\\\u0026#34;racecar\\\u0026#34;) = %d\\n\u0026#34;, isPalindrome(\u0026#34;racecar\u0026#34;)); printf(\u0026#34;isPalindrome(\\\u0026#34;e\\\u0026#34;) = %d\\n\u0026#34;, isPalindrome(\u0026#34;e\u0026#34;)); printf(\u0026#34;isPalindrome(\\\u0026#34;\\\u0026#34;) = %d\\n\u0026#34;, isPalindrome(\u0026#34;\u0026#34;)); printf(\u0026#34;isPalindrome(\\\u0026#34;race\\\u0026#34;) = %d\\n\u0026#34;, isPalindrome(\u0026#34;race\u0026#34;)); return 0; } 用 Double Node Recursively 进入 ","date":"Mar 31 2025","externalUrl":null,"permalink":"/docs/uoft/24/learning-programming-with-c/lpc11.recursion/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/31/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e11.1 Recursive Functions by Definition \r\n    \u003cdiv id=\"111-recursive-functions-by-definition\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#111-recursive-functions-by-definition\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003eRecursion 递归是一个先解决更小问题实例，后解决整体问题的方法\u003c/li\u003e\n\u003cli\u003eRecursion 这一次特指函数调用自身\u003c/li\u003e\n\u003cli\u003eRecursion 包含饿了 End Case 和 Loop Case，分别代表了循环条件和终止条件，二者缺一不可\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e11.1.1 Euclidean Algorithm for GCD \r\n    \u003cdiv id=\"1111-euclidean-algorithm-for-gcd\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#1111-euclidean-algorithm-for-gcd\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eEuclidean Algorithm 是一种用于求两个整数最大公约数的方法，这个方法是递归定义的\u003c/li\u003e\n\u003cli\u003e该算法的核心为，如果 a 和 b 是两个正整数且 $a \u0026gt; b$，则 a 和 b 的最大公约数等于 $a - b$ 和 b 的 GCD\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e$$\n\\text{GCD}(a, b) =\\begin{cases}\\text{GCD}(b, a - b) \u0026amp; \\text{if } a \u0026gt; b \\\\text{GCD}(b, a) \u0026amp; \\text{if } a \u0026lt; b \\a \u0026amp; \\text{if } a = b\\end{cases}\n$$\u003c/p\u003e","title":"LPC 11. Recursion","type":"docs"},{"content":" Last Edit: 3/31/25\nData Structure，即一种储存数据的方式，不同的结构会有不同的性能优势和劣势，即被运用到不同的工作上\n12.1 What are Data Structures #\r12.1.1 Define a data Structure #\r12.1.1.1 Method 1: Define and Declare Separately #\rstruct Neuron { int neuronNum; double input1, input2; char areaName[20]; }; int main(void) { struct Neuron neuron; return 0; } 上半部分 Define 了结构体 Neuron ，可以把结构体想象成一个“盒子”📦，里面可以装上： 一个整数（int） 两个小数（double） 一个名字（字符数组 char[]） 之后下半部分才 Declare 了一个 Variable neuron ，他的 Type 为 struct Neuron ，此时才是真正分配 Memory 的时候 11.1.1.2 Method 2: Define and Declare in same statement #\rstruct Neuron { int neuronNum; double input1, input2; char areaName[20]; } neuron; 在定一个 Struct Neuron 的同时 Declare 了一个 Variabel neuron neuron 在 Memory 中的结构如下 neuron ├── neuronNum // int 类型，占据一段内存 ├── input1 // double 类型 ├── input2 // double 类型 ├── areaName[0] // char 类型，字符数组的第一个元素 ├── areaName[1] ├── ... └── areaName[19] // 最后一个字符 12.1.2 Access Members of a data Structure #\r想要访问 Structure 中的 Members，可以使用 Dot Operator . 比如访问 struct Neuron 类型变量 neuron 的 neuronNum 字段，就写成 neuron.neuronNum 12.1.3 Initialize a data Structure #\r#include \u0026lt;stdio.h\u0026gt; struct Neuron { int neuronNum; double input1, input2; char areaName[20]; } globalNeuron = {1, 9.1, 8.3, \u0026#34;Frontal Lobe\u0026#34;}; int main(void) { struct Neuron neuron = {3, 90, 23, \u0026#34;Frontal Cortex\u0026#34;}; printf(\u0026#34;globalNeuron.neuronNum = %d\\n\u0026#34;, globalNeuron.neuronNum); printf(\u0026#34;globalNeuron.input1 = %.2lf\\n\u0026#34;, globalNeuron.input1); printf(\u0026#34;globalNeuron.input2 = %.2lf\\n\u0026#34;, globalNeuron.input2); printf(\u0026#34;globalNeuron.areaName = %s\\n\\n\u0026#34;, globalNeuron.areaName); printf(\u0026#34;neuron.neuronNum = %d\\n\u0026#34;, neuron.neuronNum); printf(\u0026#34;neuron.input1 = %.2lf\\n\u0026#34;, neuron.input1); printf(\u0026#34;neuron.input2 = %.2lf\\n\u0026#34;, neuron.input2); printf(\u0026#34;neuron.areaName = %s\\n\\n\u0026#34;, neuron.areaName); return 0; } 在 Define 好了 Neuron 后，存在两个 Declare，分别为 globalNeuron = {1, 9.1, 8.3, \u0026quot;Frontal Lobe\u0026quot;}; 和 struct Neuron neuron = {3, 90, 23, \u0026quot;Frontal Cortex\u0026quot;}; 他们在 Declare 的同时完成了赋值，通过一个 {} 包装里面的值，其中需要注意的是 所有成员必须按照结构体中定义的顺序赋值 结构体可以在全局、也可以在函数内部初始化 12.1.4 Creating an alias for a data Structure #\r可以给一个 Data Structure 一个别的名字，通过语法 typedef \u0026lt;已有类型\u0026gt; \u0026lt;新名字\u0026gt;; #include \u0026lt;stdio.h\u0026gt; typedef char byte; // 定义 char 的别名为 byte int main(void) { byte oneLetter = \u0026#39;S\u0026#39;; // 相当于 char oneLetter = \u0026#39;S\u0026#39;; byte sentence[20] = \u0026#34;Snefru\u0026#34;; // 相当于 char sentence[20] = \u0026#34;Snefru\u0026#34;; printf(\u0026#34;oneLetter: %c\\n\u0026#34;, oneLetter); // 打印单个字符 printf(\u0026#34;sentence: %s\\n\u0026#34;, sentence); // 打印字符串 return 0; } 已知 char stands for Character，是 C 语言中的字符数据结构，而给他一个 Alias 就是 byte 就把所有 char 的操作同时也给了 byte 也就是说代码中的 byte oneLetter = 'S'; 实际上就代表了 char oneLetter = 'S'; Give Structure a alias #\r截止目前，所有对于 Structure 的操作都要写成 struct Neuron neuron = {3, 90, 23, \u0026quot;Frontal Cortex\u0026quot;}; 这一个 struct 非常的麻烦，可以通过 typedef 的方式直接将 Structure 设置一个 Alias 通过 typedef struct Neuron Neuron;，将 struct Neuron 整体用 Neuron 替换，这样以后就只用写 Neuron 了 同样的操作还有在 Define 的同时 typedef typedef struct Neuron { int neuronNum; double input1, input2; char areaName[20]; } Neuron; 在做了上面的操作了之后，相当于替换 struct Neuron 为 Neuron ，但是到现在为止只完成了 Declare 没有 Define 部分，于是可以有 int main(void) { Neuron neuron; // 使用别名定义变量 neuron.input1 = 7.9; // 给结构体成员赋值 printf(\u0026#34;neuron.input1 = %.2lf\\n\u0026#34;, neuron.input1); // 打印输出 return 0; } 通过 Neuron neuron; 就可以完成一个 Neuron Structure 的 Define 12.2 Pointers to Data Structures #\r12.2.1 Access members through pointes #\r现在初始化一个 DS 后给他赋值 typedef struct Neuron { int neuronNum; double input; } Neuron; int main(void) { Neuron neuron = {901, 5.67}; // 定义并初始化一个结构体变量 neuron Neuron *pNeuron = \u0026amp;neuron; // 定义结构体指针 pNeuron，指向 neuron 于是现在有了一个完整定义的 DS 和一个指向 DS 的 Pointer（比如 pNeuron） 现在有两种访问 DS 内部 Member 的办法 Dereference and dot Operator #\r(*pNeuron).input = 7.94; Arrow Operator #\rpNeuron-\u0026gt;input = 7.94; 等价于上面那句 12.2.2 Dynamic Memory Allocation of Data Structures #\r一切都和上面的一样，做到分配 Memory 的前一步 typedef struct Neuron { int neuronNum; double input; } Neuron; int main(void){ Neuron *pNeuron; } 这时候一个 Pointer Variable pNeuron 被 Declare，但是还没有 Define，也就是指向了一个 Garbage Address，这时候 Pointer 本身是在 Stack 上的 之后动态分配 pNeuron 的 Memory，也就是一个 Neuron 的大小的 Memory pNeuron = (Neuron *)malloc(sizeof(Neuron)); 这时候 pNeuron 就指向了 Heap 上的新 Memory，或者说 pNeuron 作为 Pointer Variable，它的值为在 Heap 上的一个 Neuron 的地址 之后再给 pNeuron-\u0026gt;input = 23.96 赋值，这个操作对于 Dynamic 和 Static Memory 的作用是一样的，就有 最后 free 一下，就完成了一整个 Dynamic Memory Allocation 的过程 ","date":"Mar 31 2025","externalUrl":null,"permalink":"/docs/uoft/24/learning-programming-with-c/lpc12.datastructure/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/31/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eData Structure，即一种储存数据的方式，不同的结构会有不同的性能优势和劣势，即被运用到不同的工作上\u003c/p\u003e","title":"LPC 12. Data Structure ","type":"docs"},{"content":" Last Edit: 3/28/25\nElectric Flux #\r穿一个大小为 A 的平面的 Electric Field 个数 $$ \\Delta \\Phi = (E \\cos \\theta) \\Delta A $$\n也可以替换为 Dot Product，$\\Delta \\Phi = \\vec E \\cdot \\Delta A$，同样的，Total Flux就是 $$ \\Phi=\\sum \\vec E\\cdot \\Delta \\vec A，or~\\Phi=\\int\\vec E\\cdot d\\vec A $$\nex. #\rConsider a cylinder of radius R in a uniform electric field with axis parallel to the field direction, what are the flux through the end caps, cylindrical surface, and the net flux?\nGauss\u0026rsquo;s Law #\rConsider a particle with charge +q is surrounded by an imaginary concentric sphere 这是一个 Gauss‘ Law 的 Special Case\n$$ \\Phi = \\oint \\vec{E} \\cdot d\\vec{A} = \\oint E , dA = E \\oint dA= E \\cdot 4\\pi r^2 = \\left( \\frac{1}{4 \\pi \\varepsilon_0} \\cdot \\frac{q}{r^2} \\right) \\cdot 4 \\pi r^2 = \\frac{q}{\\varepsilon_0} $$\n其中 $\\oint dA$ 指的是一个封闭曲面的总面积 通过上面等式，Gauss’ Law 说明了一个闭合表面即 Gaussian Surface 的 Electric Flux 和其包围的 Net Charge 的关系，即 $$ {\\varepsilon_0}\\Phi = Q_{\\text{enc}} $$\nex. Gauss\u0026rsquo;s Law #\rConsider two charges with opposite signs and equal magnitude (+q and –q). Determine the electric flux of the four Gaussian surfaces are shown below:\nS1：q 是一个 Positive Charge，是一个 Positive Number S2：q 是一个 Negative Charge，是 Negative S3：其所围成的空间中并不包含 Charge，所以 Zero S4：Net charge 为 0，即 Zero A charged Isolated Conductor #\r孤立导体上，所有额外的电荷都会移动到导体的表面，导体内部不会有多余电荷 这是因为导体内部的电荷会通过相互作用重新分布，直到内部电场为零，从而达到静电平衡 同理如果里面出现了一个 Cavity，其也不会存在电荷 当 Conductor 不是一个光滑的 Spherical 的情况下，电荷并不会均匀的分布在表面上，而是受到曲率的影响，导致尖锐的部分会拥有更多的电荷密度 The External Electric Field #\r对于一个贴着 Conductor 的 Gaussian Surface，由于 Conductor 内部 Electric Field 为 0，所以只考虑外部的通量 $$ ε₀EA = σA $$\n导体表面外侧的电场强度等于表面电荷密度除以 $\\varepsilon_0$，但这个关系只在表面成立 Applying Gauss\u0026rsquo;s Law: Cylindrical Symmetry #\r有一个长度为无线的 Plastic Rod，其 Charge Density 为 \\lambda 想求离Central Axis的半径为r的距离处的Electric Field Magnitude 由于Electric Field是从圆柱体中心穿过的，而有Gauss\u0026rsquo; Law $$ \\Phi = \\frac{Q_{\\text{enc}}}{\\epsilon_0}= \\oint \\vec{E} \\cdot d\\vec{A} $$\n可以得出面积等于 $A = 2\\pi rl$ 已知电荷密度为 $\\lambda$，即总电荷数为 $Q_{enclosed}=\\lambda \\cdot L$，所以有 $2\\pi rl E=\\frac{\\lambda L}{E_0}$，也就是 $$ E = \\frac{\\lambda}{2\\pi\\epsilon_0 r} $$\nex. Lighting strikes the tree #\r当雷电击中一棵树的时候，其可以被看作是一个导线，而半径为r内的空气都将被 Ionized，计算出这个半径r，令 E=3\\times 10^6 N/C\n$$ r = \\frac{\\lambda}{2\\pi\\epsilon_0 E}= \\frac{1 \\times 10^{-3}\\ \\text{C/m}}{(2\\pi)(8.85 \\times 10^{-12}\\ \\text{C}^2/\\text{N}\\cdot\\text{m}^2)(3 \\times 10^6\\ \\text{N/C})}= 6\\ \\text{m} $$\nApplying Gauss\u0026rsquo;s Law: Planar Symmetry #\r对于一个无限大的电荷密度为 $\\sigma$ 的Plane，有 $\\sigma=\\frac{Q}{A}$ 根据 Gauss\u0026rsquo; Law $\\Phi = \\frac{Q_{\\text{enc}}}{\\varepsilon_0}$，其中 $Q=\\sigma A$，于是有 $$ \\Phi=\\frac{\\sigma A_0}{\\varepsilon_0} $$\n令其中一个 Cylinder 为高斯面，Flux 从两个Cross-Sectional Area 流过 $$ \\Phi=EA=2EA_0=\\frac{\\sigma A_0}{\\varepsilon_0} \\Rightarrow E=\\frac{\\sigma}{2\\varepsilon_0} $$\nApplying Gauss’s Law Shell Theorem #1 #\r回顾 Shell Theorem #1，它讲的是一个带有均匀电荷的壳层对壳外的粒子的吸引或排斥作用，就像所有电荷集中在球壳的中心一样 $$ \\Phi = \\oint \\vec{E} \\cdot d\\vec{A} = E \\oint dA = E \\cdot 4\\pi r^2 \\\\varepsilon_0 \\Phi = q_{\\text{enc}} \\quad \\text{(where } \\varepsilon_0 \\text{ is the permittivity of free space)} \\\\varepsilon_0 E \\cdot 4\\pi r^2 = q_{\\text{enc}}\\Rightarrow E = \\frac{1}{4\\pi \\varepsilon_0} \\cdot \\frac{q_{\\text{enc}}}{r^2} $$\nApplying Gauss’s Law Shell Theorem #2 #\r第二个 Shell Theorem 说的是如果一个带电粒子处于一个带有均匀电荷分布的壳层内部，那么壳层对该粒子不会产生任何 Electrostatic force 这是因为所有的电荷都在 Shell 的 surface 上，内部 Gauss Surface 所包围的 Charge 为 0，所以内部粒子不会受到任何 Electrostatic Force However, there can still be an electric field within the shell, created by other objects\n需要注意的是，Shell 内部仍可能存在其他物体所产生的电场\nApplying Gauss\u0026rsquo; Law: Spherical Symmetry #\r有一个球壳，上面的Charge均匀分布，电荷总量为q，半径为R 使用两个同心的球形高斯面 $S_1$ 和 $S_2$ 对于内部高斯面 $S_1$ 来说，Electric Field 为 0，Electric Flux 也为 0 对于外部高斯面 $S_2$ 来说，Electric Field公式由 $E=\\frac{q}{4\\pi\\varepsilon_0r^2}$ 给出，由 Shell Theorem 1 证明，球壳外部的 Charge 可以被视为 Point Charge 第二种情况则是一个带电的均匀实心球体（电荷在其中均匀分布） 令整个实心球半径为R，总电荷量为q，且在体积内均匀分布，则体积电荷密度 $$ \\rho ;=; \\frac{q}{\\tfrac{4}{3}\\pi R^3} $$\n在球内取一半径为 $r\u0026lt;R$ 的球面作高斯面，则该高斯面所包围的电荷量 $$ Q_{\\text{enclosed}} ;=; \\rho \\times \\bigl(\\tfrac{4}{3}\\pi r^3\\bigr) = \\frac{q}{\\tfrac{4}{3}\\pi R^3};\\times;\\tfrac{4}{3}\\pi r^3 = q,\\frac{r^3}{R^3} $$\n由对称性，球面上电场大小恒为E，方向辐向向外，故 $$ \\oint \\mathbf{E}\\cdot \\mathrm{d}\\mathbf{A} = E,\\cdot 4\\pi r^2 $$\n高斯定律给出 $$ E \\cdot 4\\pi r^2 = \\frac{Q_{\\text{enclosed}}}{\\varepsilon_0} = \\frac{q,\\tfrac{r^3}{R^3}}{\\varepsilon_0} \\Rightarrow E(r) = \\frac{1}{4\\pi \\varepsilon_0} ,\\frac{q,\\tfrac{r^3}{R^3}}{r^2} = \\frac{1}{4\\pi \\varepsilon_0},\\frac{q}{R^3},r $$\n总的来说空心球壳： 壳外 $r \\ge R$：电场如点电荷，$E=\\frac{1}{4\\pi\\varepsilon_0},\\frac{q}{r^2}$ 壳内 $r \\le R$：电场为 0 实心均匀带电球： 球外 $r \\ge R$：同样表现为点电荷，$E=\\frac{1}{4\\pi\\varepsilon_0},\\frac{q}{r^2}$ 球内 $r \\le R$：$E=\\frac{1}{4\\pi \\varepsilon_0},\\frac{q}{R^3},r$，即随r线性增大 ","date":"Mar 28 2025","externalUrl":null,"permalink":"/docs/uoft/24/electrical-fundamentals/ef3.gausslaw_edited/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/28/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eElectric Flux \r\n    \u003cdiv id=\"electric-flux\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#electric-flux\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e穿一个大小为 A 的平面的 Electric Field 个数\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/uoft/24/electrical-fundamentals/ef3.gausslaw_edited/image_hu8802652043434880325.png 330w,\r\n        /docs/uoft/24/electrical-fundamentals/ef3.gausslaw_edited/image_hu13755665881257866306.png 660w,\r\n        /docs/uoft/24/electrical-fundamentals/ef3.gausslaw_edited/image_hu3513976184223037978.png 1024w,\r\n        /docs/uoft/24/electrical-fundamentals/ef3.gausslaw_edited/image_hu3352758712050547112.png 2x\"\r\n        src=\"/docs/uoft/24/electrical-fundamentals/ef3.gausslaw_edited/image_hu13755665881257866306.png\"\r\n        alt=\"image.png\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 3. Gauss' Law Edited","type":"docs"},{"content":" Last Edit: 25/3/27\nThroughout this book, we study different data types. None of the data types discussed before stores a word or sentence, because in C programming language there is no data type that stores a word/sentence.\n所以在这里将找到一个储存 String 的解决方案\n10.1. What are strings? #\rString 被用来储存句子，例如 printf(\u0026quot;Hello world!\\n\u0026quot;); 10.1.1 Store a String #\rC 语言中储存 String 的办法就是通过 Array of Characters 字符数组 这个 Array 同时也是 Null Terminated 空字符结尾的，这意味着字符串存储在一个特殊的字符数组中，字符串的最后一个字符是 Null character 空字符 空字符（Null Character）：空字符表示为\\0，它的ASCII码（ASCII Code）值是0 存储方式：\\0在ASCII编码中对应于主存储器（main memory）中的0值 例如 String “Hello” 实际上在 Memory 中是 H e l l o \\0 这个设计是为了防止 C 语言的 String 处理函数知道 String 的边界以防越界 10.1.1.1 Declare and Initialize #\r在 C 语言中，我们可以声明一个 1D array of characters，并将其初始化为一个字符串，例如char myString[] = \u0026quot;Hello\u0026quot;; 这一语句的作用是创建一个名为 myString 的字符数组，该数组包含 6 个元素：'H', 'e', 'l', 'l', 'o' 以及 '\\0' 这时一般不需要给 Array 它的 Size，但是如果非要加，多出来的部分则会变成 同样的 Null Character 同时和 1D Array 一般，也可以通过 myString[0] = 'h'; 的做法修改 Array 中 Index 对应的元素 10.1.1.2. Method 2: Declare now and Initialize later #\r第二种做法就是声明字符数组，但不立即初始化，之后通过单独赋值的方式填充字符数组，并手动添加 '\\0' 终止符 char myString[4]; myString[0] = \u0026#39;T\u0026#39;; myString[1] = \u0026#39;h\u0026#39;; myString[2] = \u0026#39;e\u0026#39;; myString[3] = \u0026#39;\\0\u0026#39;; 10.1.1.3. Method 3: Declare a Pointer Pointing to a Constant String #\r第三种方法就是 Pointer，有 char* pStr = \u0026quot;Wow\u0026quot;; ，这种方法中，String Wow 将被储存在 Const + Global Variables 的内存块中，而 pStr pointer 则在 Stack 中指向了第一个字符的地址 当尝试修改他的时候，如 pStr[0] = 'R'; 会报错，因为 pStr 在尝试修改一个 Constant 但是是可以修改 pStr 的值，（修改一个 Pointer 的值也就是修改它指向的内存）的，如 pStr = \u0026quot;Cat\u0026quot;; 就将指向另一个 String 现在举一个具体的 Pointer 换 String 的例子 在这里对于字符数组 char str[] = \u0026quot;It\u0026quot;; 来说，它实际上创建了一个可修改的字符数组，即是一个非 Const 的 Declare 方式，所以它会被存在 Stack 上 而对于字符串常量 \u0026quot;Wow\u0026quot; 来说，定义了一个指针 pStr，指向一个字符串常量，这个常量实际存储在程序的 Const 区 将 pStr 更换位置后pStr 就被重定向到栈上的 str 下一个场景是给 Array of characters 赋值的操作，这同样也是不合法的，因为在C语言中，数组名被视为常量指针，它自动地指向数组的第一个元素的地址。因此，数组名是固定不变的，不能被重新赋值 int main(void) { char str[] = \u0026#34;Hello\u0026#34;; str = \u0026#34;APS105\u0026#34;; // 尝试更改数组标识符 return 0; } 10.1.2. What is the usage of the '\\0' in a string? #\r前面提到过在C语言中，\\0 作为字符串的终止符，表示字符串的结束 当字符串作为参数传递给函数时，函数通过检测 \\0 来判断何时停止处理字符串，这样可以避免超出字符串的实际内容范围，导致未定义的行为或访问违规 10.2 Input/Output Strings #\r10.2.1 Output Strings #\r10.2.1.1 Using pringf #\r对于 String 来说，其采用 %s 的 Format Specifier，printf 将从 str[0] 开始一直打印到（但不会打印）第一个非零 Character 同时作为 Pointer，如果传入 str + 2 来打印，则会输出从 str[2] 开始的剩余 String 如果想要打印特点个数的 String，可以用 %.*s 并将 * 替换为一个数字 #include \u0026lt;stdio.h\u0026gt; int main(void) { char s[] = \u0026#34;Hello\u0026#34;; printf(\u0026#34;%.2s\\n\u0026#34;, s); return 0; } Printing character vs. a string #\rCharacter 打印的是单个字符，而 String 则是一个 Array 10.2.1.2 Using puts #\rputs 是另一种打印方式，但其不需要一个 Format String 它只接收一个参数即为 Pointer to the first character 在打印完后他会自动换行 #include \u0026lt;stdio.h\u0026gt; int main(void) { char s[] = \u0026#34;Hello\u0026#34;; puts(s); return 0; } 10.2.2 Input Strings #\r10.2.2.1 Using scanf #\r想要用 scanf 从用户那里获取一个 String 的输入，同样使用 %s 的 Format Specifier char st[10]; scanf(\u0026#34;%s\u0026#34;, st); 这里 scanf(\u0026quot;%s\u0026quot;, st); 之所以是 st 而不是 \u0026amp;st 是因为 st 本身就是一个 Pointer How does sanf work #\rscanf 函数在处理输入的时候，会忽略输入前的所有空白，也叫做 Leading white space scanf 会读取字符知道遇到 White Space 或者 Endline 在读取完毕后，scanf 会自动给 String 加上 \\0 结尾 #include \u0026lt;stdio.h\u0026gt; int main(void) { char st[10]; printf(\u0026#34;Enter a string: \\n\u0026#34;); scanf(\u0026#34;%s\u0026#34;, st); printf(\u0026#34;s is saved as: %s\\n\u0026#34;, st); scanf(\u0026#34;%s\u0026#34;, st); printf(\u0026#34;s is now saved as: %s\\n\u0026#34;, st); return 0; } 上面的例子展示了当输入为 ABCD ff 的时候，第一次 scanf 读取的将是 ABCD，第二次是 ff What if str is longer than array #\r#include \u0026lt;stdio.h\u0026gt; int main(void) { char st[7 + 1]; printf(\u0026#34;Enter a string: \\n\u0026#34;); scanf(\u0026#34;%s\u0026#34;, st); printf(\u0026#34;s is saved as: %s\\n\u0026#34;, st); return 0; 当输入为 ABCDEFGHIJ 的时候 Enter a string:\rABCDEFJI\rs is saved as: ABCDEFJI Buffer Overflow #\r当把数据写入比他小的数据结构的时候，会就出现的 Buffre Overflow 缓冲区溢出的 Crash 当输入为 ABCDEFGHIJ 实际上只应该被读出 ABCDEFGH，之所以读出了 I 是因为在 char st[7 + 1]; 的时候，默认预留的位置中还加上了一个 \\0 的空间，而 I 正是占用了这个空间所以才被打印了出来 10.2.2.2. Using fgets to avoid buffer overflow in scanf #\r比起 scanf 来说还存在一种更加安全的函数叫做 fgets 来获取输入 和 scanf 不同的是，fgets 可以指定最多读取多少个字符 fgets(st, 3, stdin); 就代表了将从输入中读取最多两个 Character（其中一个为 \\0 ） 后面的 stdin 则代表了 stdio.h 的标准输入库 Enter a string:\rABCDEFGHI\rst is saved as: AB 当输入小于 fgets 的最大读取数量的时候，后续数组元素会被 Garbage Values 替代 比如最大读取数量为 3 的时候，只输入一个 A，后续要么是一个空格，要么是一个换行符，反正都是 Garbage Values 10.2.2.3. Implement a getStringSafely function\n所有的 API 都被规定了，但是他们都大大小小存在一些问题，这时候就需要一个 Function 来规范化所有的输入了 这个 Function 的目标将是读取 String 并储存到 Array 中 getchar() function #\r每一次调用 getchar 都只会接收输入的第一个 char #include \u0026lt;stdio.h\u0026gt; char* getStringSafely(char* s, int n); int main(void) { char st[10]; printf(\u0026#34;Enter string: \\n\u0026#34;); printf(\u0026#34;User entered: %s\\n\u0026#34;, getStringSafely (st, 7)); scanf(\u0026#34;%s\u0026#34;, st); printf(\u0026#34;This is what\u0026#39;s left: %s\\n\u0026#34;, st); return 0; } char* getStringSafely(char* s, int n) { int charCount = 0; char c; while ((charCount \u0026lt; n - 1) \u0026amp;\u0026amp; ((c = getchar()) != \u0026#39;\\n\u0026#39;)) { s[charCount] = c; charCount++; } s[charCount] = \u0026#39;\\0\u0026#39;; return s; } 10.3. String Functions #\r前面的章节中，所有对 String 的处理都是通过 Characters 的 Array 做的，但是 C 语言实际上有一个 String Library #include \u0026lt;string.h\u0026gt;，里面有专门用来处理 String 的 Functions 10.3.1. Length of the string #\r函数 strlen 可以被用来返回 String 长度，其 Prototype 为 size_t strlen(char *str); 其中size_t 是一个 Unsigned integer type 无符号整数类型，可以简单地把它当成 int 来理解 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main(void) { char s[] = \u0026#34;Hello\u0026#34;; int size = strlen(s); printf(\u0026#34;String length is %d.\\n\u0026#34;, size); return 0; } strlen(s) 返回的是字符串 \u0026quot;Hello\u0026quot; 的长度，也就是 5（不包含结尾的 \\0） 10.3.1.1. Implementation of strlen #\r直接从头构造一个 strlen 函数 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; // 函数声明 int stringLength(char* s); int main(void) { char s[] = \u0026#34;Hello\u0026#34;; // 定义字符串 int size = stringLength(s); // 调用自定义的 stringLength 函数 printf(\u0026#34;String length is %d.\\n\u0026#34;, size); // 打印字符串长度 return 0; } // 函数定义 int stringLength(char* s) { int count = 0; while (s[count] != \u0026#39;\\0\u0026#39;) { // 遍历直到遇到 \\0 count++; } return count; } 有的时候为了避免意外造成的修改，可以使用 const 来确保传入的 Str 是只读的 10.3.2. Copy a string into another string #\r10.3.2.1. strcpy #\rstrcpy 函数会将一个 String 中的内容复制到另一个 String 中，它的 Prototype 为 char* strcpy(char *dest, char *src); 将一直负值 src 直到碰到 \\0 ，下面是一个 strcpy 的示例 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main(void) { char s[] = \u0026#34;Hello\u0026#34;; char d[6]; printf(\u0026#34;d after copying has \u0026#39;%s\\\u0026#39;.\\n\u0026#34;, strcpy(d, s)); return 0; } -\u0026gt; d after copying has \u0026#39;Hello\u0026#39; 之所以需要 strcpy 而不是直接赋值一个 str 给另一个，是因为在 C 中，一个 String 被创建的时候是以一个 Characters 的 Array 创建的，而给 Array 赋一个值是非法的 10.3.2.1.1. Implementation of strcpy #\r想要实现一个 strcpy 本质就是一个个赋值直到 \\0 ，下面是具体实现 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; char* stringCopy(char* dest, const char* src); int main(void) { char s[] = \u0026#34;Hello\u0026#34;; // 定义源字符串 s char d[6]; // 定义目标字符串 d，有 6 个字符空间 printf(\u0026#34;d after copying has \u0026#39;%s\u0026#39;.\\n\u0026#34;, stringCopy(d, s)); return 0; } char* stringCopy(char* dest, const char* src) { int ind = 0; while (src[ind] != \u0026#39;\\0\u0026#39;) { dest[ind] = src[ind]; // 逐个字符复制 ind++; } dest[ind] = \u0026#39;\\0\u0026#39;; // 添加结束符 return dest; // 返回目标字符串地址 } 同样因为 Array 就是 Pointer 的特性，也可以不用 Array 的 Index 实现 char* stringCopy(char* pdest, const char* psrc) { char* pdestCopy = pdest; // 保存目标字符串原始地址 while (*psrc != \u0026#39;\\0\u0026#39;) { // 当源字符串未结束 *pdestCopy = *psrc; // 拷贝字符 pdestCopy++; // 移动目标指针 psrc++; // 移动源指针 } *pdestCopy = \u0026#39;\\0\u0026#39;; // 添加字符串结束符 return pdest; // 返回目标字符串起始地址 } 10.3.2.2. strncpy #\r另一种更加安全的赋值 String 的办法，现在 strcpy 的问题是如果目标空间不够，会发生 Buffer Overflow 也就是内存越界的问题，而 strncpy 只比 strcpy 多了一个参数，也就是 char* strncpy(char *dest, const char *src, size_t n); 他会复制源字符串中的前 n 个字符，或遇到 \\0 结束符为止，或者如果 n 比源字符串长，会在剩下的位置补上 \\0 If n is same as the size of src #\r但是他目前存在的问题是，如果 n 设置的和 String 一样长，那就会自动忽略 \\0 ，比如 char d[] = \u0026#34;Hello world!\u0026#34;; strncpy(d, \u0026#34;Hello\u0026#34;, 5); 在这个情况中，Hello 的长度和 5 一样，导致了 \\0 没有空间，所以当 printf d 的时候，输出变成了 Copied exactly 5 characters: Hello world!，因为 d 没有找到 \\0 ，就一直打印了下去 If n is larger than size of src #\r上面的情况是当 n 等于 src 时，现在的是 n 大于 src 时，比如 char d[] = \u0026#34;Hello world!\u0026#34;; strncpy(d, \u0026#34;Hello\u0026#34;, 7); 这时候会自动用 \\0 补完剩下的，有 源字符串 d 原内容： \u0026#39;H\u0026#39; \u0026#39;e\u0026#39; \u0026#39;l\u0026#39; \u0026#39;l\u0026#39; \u0026#39;o\u0026#39; \u0026#39; \u0026#39; \u0026#39;w\u0026#39; \u0026#39;o\u0026#39; \u0026#39;r\u0026#39; \u0026#39;l\u0026#39; \u0026#39;d\u0026#39; \u0026#39;!\u0026#39; \u0026#39;\\0\u0026#39; 复制后变成 ： \u0026#39;H\u0026#39; \u0026#39;e\u0026#39; \u0026#39;l\u0026#39; \u0026#39;l\u0026#39; \u0026#39;o\u0026#39; \u0026#39;\\0\u0026#39; \u0026#39;\\0\u0026#39; ... 字符位置： 1 2 3 4 5 6 7 10.3.3 Concatenating Strings #\r10.3.3.1 strcat #\rstrcat 是用来拼接 String 的，也就是把一个追加到另一个的末尾，他的 Prototype 为 char* strcat(char *dest, const char *src); 它会覆盖 dest 原有的 ****\\0（结束符），从 \\0 开始写入 src 的内容，最后 strcat 会在拼接后的新字符串结尾添加一个新的 \\0 10.3.3.2. strncat #\r同样的也需要一个规定 n 个 String 的用来放置 Buffer Overflow 的函数 strncat strcat 存在的问题是 char s[4] = \u0026#34;Oh\u0026#34;; // s 有 4 个字符空间：\u0026#34;O\u0026#34;, \u0026#34;h\u0026#34;, \u0026#39;\\0\u0026#39;, \u0026#39;\\0\u0026#39; char t[] = \u0026#34;No\u0026#34;; // t 是源字符串：\u0026#34;N\u0026#34;, \u0026#34;o\u0026#34;, \u0026#39;\\0\u0026#39; strcat(s, t); 当两个追加了之后，由于 s 只有 4 个空间，所有位置都满了之后就没地方给 \\0 了，也就非法了 所以就需要使用多一个参数的 strncat ，其 Prototype 为 char* strncat(char *dest, const char *src, size_t n); 10.3.4. Comparing Strings #\r10.3.4.1 strcmp #\r比较两个 String 的办法，prototype 为 int strcmp(const char *s1, const char *s2); ，他的返回值是 大于小于或者等于 具体来说： 小于 0：表示 s1 在字典中排在 s2 前面 等于 0：表示 s1 和 s2 完全相同 大于 0：表示 s1 在字典中排在 s2 后面 这一个比较的过程是按照 Index 顺序依次过去的，比较的是 ASCII，根据他的 Return 值为 int 的特性，可以写出以下示例代码 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main(void) { char s1[40]; char s2[40]; printf(\u0026#34;Enter two strings separated by new line or white space: \u0026#34;); scanf(\u0026#34;%s\u0026#34;, s1); // 输入第一个字符串 scanf(\u0026#34;%s\u0026#34;, s2); // 输入第二个字符串 if (strcmp(s1, s2) \u0026lt; 0) { printf(\u0026#34;\u0026#39;%s\u0026#39; is before \u0026#39;%s\u0026#39; in dictionary!\\n\u0026#34;, s1, s2); } else if (strcmp(s1, s2) \u0026gt; 0) { printf(\u0026#34;\u0026#39;%s\u0026#39; is after \u0026#39;%s\u0026#39; in dictionary!\\n\u0026#34;, s1, s2); } else if (strcmp(s1, s2) == 0) { printf(\u0026#34;\u0026#39;%s\u0026#39; is identical to \u0026#39;%s\u0026#39;!\\n\u0026#34;, s1, s2); } return 0; } 场景 返回值 示例 s1 \u0026lt; s2 小于 0 \u0026quot;apple\u0026quot; VS \u0026quot;banana\u0026quot; s1 \u0026gt; s2 大于 0 \u0026quot;zebra\u0026quot; VS \u0026quot;apple\u0026quot; s1 等于 s2 等于 0 \u0026quot;hello\u0026quot; VS \u0026quot;hello\u0026quot; 10.3.4.2 strncmp #\r它同时也存在一个 n 的版本，有 int strncmp(const char *s1, const char *s2, size_t n); strncmp 会从 s1 和 s2 的开头开始，一共最多比较 n 个字符 如果在前 n 个字符中字符相同但不足 n 个字符，遇到 \\0 也会停止 10.3.5 Looking for in a string #\r10.3.5.1 strchr #\r在一个 String 中找一个 Character 的第一次出现的 Pointer，有 char* strchr(const char *s, int c); ，可以发现，这个 Character 是以一个 int 的数据类型传入的 其中如果没找到，返回 Null 并且要求字符串 s 必须是以 \\0 结尾的有效 C 字符串 由于一般想要的都是 Index 而不是 Pointer，可以用减法得到 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main(void) { char s[] = \u0026#34;Programming\u0026#34;; // 原始字符串 char c = \u0026#39;m\u0026#39;; // 要查找的字符 int dist = strchr(s, c) - s; // 找到字符后，计算其在字符串中的索引 printf(\u0026#34;The first %c is found at index %d in \u0026#39;%s\u0026#39;\\n\u0026#34;, c, dist, s); return 0; } 10.3.5.2 strstr #\r这个是在一个 String 中找另一个 String，其 Prototype 为 char* strstr(const char *s1, const char *s2); 返回值是指向 s2 第一次出现在 s1 中的位置的指针 10.4 Array of Strings #\r前面提到了，一个 String 会以 \\0 作为结尾，但是如果想要在一个 Array 中储存多个 String，有两种方式，1. 2D Array of Characters char arr[12][10]，2. Array of char char* arr[] 10.4.1 2D Array of Characters #\r一个例子是一年的十二个月 char months[][10] = { \u0026#34;January\u0026#34;, \u0026#34;February\u0026#34;, \u0026#34;March\u0026#34;, ... }; 其中每一个行都是一个完整的 String months[0] 是 {\u0026#39;J\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;n\u0026#39;, \u0026#39;u\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;\\0\u0026#39;, \u0026#39;\\0\u0026#39;, \u0026#39;\\0\u0026#39;}\rmonths[1] 是 {\u0026#39;F\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;u\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;\\0\u0026#39;, \u0026#39;\\0\u0026#39;}\r... 10.4.2. 1D array of char* #\r和前面一样，可以通过 Pointer 作为 Array 的内容而不是 character 来储存多个 String，也就是 char* months[12] char* months[12]; months[0] = \u0026#34;January\u0026#34;; months[1] = \u0026#34;February\u0026#34;; ... 通过给每一个手动赋值，这里可以是因为每一个 months[i] 都是一个指针 他会创建 12 个 Pointer 放到 Stack 上，然后 Pointer 再指向 Static 中的 String 声明方式 指针变量位置 指向内容位置 char* p = \u0026quot;abc\u0026quot;; 栈 静态区（只读） static char* p = \u0026quot;abc\u0026quot;; 静态区 静态区（只读） char s[] = \u0026quot;abc\u0026quot;; 栈 栈（拷贝内容） char* p = malloc(...); 栈 堆 特性 char months[12][10] char* months[12] 是否可改内容 ✅ 可以修改字符内容 ❌ 通常不可以（字符串常量） 是否可换整行字符串 ❌ 不行，不能对数组赋值 ✅ 可以 months[0] = \u0026quot;new\u0026quot; 每行长度是否一致 是（固定长度） 否（每个字符串长度可以不同） 字符串存储在哪里 所有内容在栈（stack） 指针在栈，字符串常量在静态区（只读区） 是否可以初始化时一次性写完 ✅ 可以 ✅ 也可以 ","date":"Mar 27 2025","externalUrl":null,"permalink":"/docs/uoft/24/learning-programming-with-c/lpc10.strings/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 25/3/27\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThroughout this book, we study different data types. None of the data types discussed before stores a word or sentence, because in C programming language there is no data type that stores a word/sentence.\u003c/p\u003e","title":"LPC 10. Strings ","type":"docs"},{"content":" Last Edit: 3/25/25\n前面提到，输入图像大小为 3x3，kernel 为 2×2，输出的维数是 2×2，则可以判断出输出维度为\n$$ (n_h - k_h + 1) × (n_w - k_w + 1) $$\n除了 Kernel 大小之外，还存在其他影响输出大小的因素，为 Padding 填充 \u0026amp; Stride 步幅\n6.3.1 Padding 填充 #\r已知当存在多个 Convolution Layers 的时候，随着深度越来越深，最终图像的尺寸会不断缩小，容易丢失边缘信息 而为了保留边缘，常用 Padding 的方法，通常就是在最外围填充一层 0 新的输出形状则为 $$ (n_h - k_h + p_h + 1) × (n_w - k_w + p_w + 1) $$\n通常情况下会把 Kernel 设计为 Odd 的 Dimension，这样做的好处就是可以在上下，左右添加相同数量的行和列 import torch from torch import nn # 定义辅助函数，用于执行卷积并输出去掉批量和通道维度 def comp_conv2d(conv2d, X): # 这里的（1，1）表示批量大小和通道数都是1 X = X.reshape((1, 1) + X.shape) Y = conv2d(X) # 省略前两个维度：批量大小和通道 return Y.reshape(Y.shape[2:]) # 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列 conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1) X = torch.rand(size=(8, 8)) comp_conv2d(conv2d, X).shape 6.3.2 Stride 步幅 #\r在默认的互相关运算中，默认 Kernel 是一个个元素滑动的，但是有的时候是可以跳过的 将每一次滑动的元素的数量称为 Stride 步幅 上图为一个垂直步幅 3，水平步幅 2 的互相关运算 一个垂直步幅为 h，水平步幅为 w 的互相关运算的输出形状为 $$ \\left\\lfloor \\frac{(n_h - k_h + p_h + s_h)}{s_h} \\right\\rfloor \\times \\left\\lfloor \\frac{(n_w - k_w + p_w + s_w)}{s_w} \\right\\rfloor $$\n","date":"Mar 25 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l6.convolutionneuronnetwork/d2l6.3paddingstride/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/25/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e前面提到，输入图像大小为 3x3，kernel 为 2×2，输出的维数是 2×2，则可以判断出输出维度为\u003c/p\u003e","title":"D2L 6.3 Padding \u0026 Stride","type":"docs"},{"content":" Last Edit: 3/25/25\n一张常规的图像通常包含了 RGB 三种颜色，也是就是为互相关运算添加了一个维度\n6.4.1 Multiple Input Channel #\r当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数的卷积核，这个很好理解，就是对每一个通道分别做不同的互相关运算 在每一个通道的互相关运算结果出来了之后，则采取相加的方式得到所有通道互相关运算的结果的和作为最终的输出 图中展示了 2 个通道的运算结果 其中拿出蓝色部分举例，两个通道运算分别为 $$ 00+11+32+34=19 $$\n$$ 11+22+34+45=36 $$\n然后将两个通道结果相加得到 56 作为输出 def corr2d_multi_in(X, K): # 初始化输出为第一个通道的互相关结果 res = d2l.corr2d(X[0], K[0]) # 从第二个通道开始逐个累加 for i in range(1, len(X)): res += d2l.corr2d(X[i], K[i]) return res 6.4.2 Multiple Output Channel #\r到现在为止，无论计算涵盖多少个输入通道，他们最终都会被加到一块得到一个输出 然而在真实的网络中即使上存在多个 Output Channel，这可以帮助模型的提取出更多不同的 Feature 比如边缘、颜色变化、形状等等 这样做就会得到一个形状为 $co × ci × kh × kw$ 的 Kernel，举例来说 输入张量是：2 个通道（ci = 2）卷积核大小是：3×3（kh = kw = 3）我想要输出 4 个通道（co = 4）那么我们需要： 4 个输出通道 × 每个通道有 2 个核 × 每个核大小是 3×3→ 卷积核张量的总形状是：[4, 2, 3, 3] 6.4.3 1x1 Convolution Layer #\r一个 1x1 的 Convolution Layer 看上去啥也没干，这是因为这个 Layer 的功能不是提取特征，而是同于通道的变换和组合 一个 $3\\times3\\times3$ 的输入，$1\\times2\\times3$ 的 Kernel 也就做到了 Linear Algebra 中的 Projection 所有它本质上就是一个矩阵的乘法，Linear Transformation，还是 Not Full Full Rank 的 ","date":"Mar 25 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l6.convolutionneuronnetwork/d2l6.4multipleinputoutput/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/25/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e一张常规的图像通常包含了 RGB 三种颜色，也是就是为互相关运算添加了一个维度\u003c/p\u003e","title":"D2L 6.4 Multiple Input \u0026 Output","type":"docs"},{"content":"","date":"Mar 25 2025","externalUrl":null,"permalink":"/tags/dyn/","section":"Tags","summary":"","title":"DYN","type":"tags"},{"content":" Last Edit: 3/25/25\n当在通过一个固定点观察物体运动的时候，使用 $R-\\theta$ 坐标系描述运动吗会高效很多\nPosition in R-Theta System #\r想要描述一个物体在 Coordinate 中的位置，可以通过 $$ \\vec r=r\\hat e_r $$\nVelocity in R-Theta System #\r将 Position 求导就可以得到 Velocity，有 $$ \\vec{v} = \\frac{d\\vec{r}}{dt} = \\frac{d(r \\hat{e}_r)}{dt} = \\dot{r} \\hat{e}_r + r \\dot{\\hat{e}}_r=\\dot{r} \\hat{e}_r + r \\dot{\\hat{e}}_r= \\dot{r} \\hat{e}r + r \\dot{\\theta} \\hat{e}\\theta $$\n于是就得到了两个方向上的 Velocity ex. Finding the velocity #\rA carousel is turning at the speed of 8 rpm. A child initially at 4m from the center walks toward the center at 2m/s. Find $\\vec v$\n$$ \\vec{V} = \\dot{r} \\hat{e}r + r \\dot{\\theta} \\hat{e}\\theta = -2 \\hat{e}r + (14)(0.84) \\hat{e}\\theta \\quad \\text{m/s} $$\nAcceleration in R-Theta System #\r再次对于 velocity 求导得到 $$ \\vec{a} = \\frac{d\\vec{v}}{dt} = \\frac{d}{dt} (\\dot{r} \\hat{e}r + r \\dot{\\theta} \\hat{e}\\theta) = \\ddot{r} \\hat{e}r + \\dot{r} \\dot{\\hat{e}}r + \\dot{r} \\dot{\\theta} \\hat{e}\\theta + r \\ddot{\\theta} \\hat{e}\\theta + r \\dot{\\theta} \\dot{\\hat{e}}_\\theta = \\hat{e}r (\\ddot{r} - r \\dot{\\theta}^2) + \\hat{e}\\theta (\\ddot{\\theta} + 2 \\dot{r} \\dot{\\theta}) $$\n$$ \\Rightarrow a = \\hat{e}r (\\ddot{r} - r \\dot{\\theta}^2) + \\hat{e}\\theta (r\\ddot{\\theta} + 2 \\dot{r} \\dot{\\theta}) $$\nex. Finding the Acceleration #\rExtracted Problem Statement:\nA shuttle is launched vertically and tracked by a radar station. At the instant when $\\theta = 60^\\circ$, $r = 9 km, $\\ddot{r} = 21 \\text{ m/s}^2$, and $\\dot{\\theta} = 0.02 \\text{ s}^{-1}$, determine the acceleration vector $\\vec{a}$\n计算航天器的加速度 $\\mathbf{a}$，给定数据如下：\n![[DYN4.NormalandTangentialCoordinates-2.png]]\nSpecial Case: Circular Motion #\r对于 Polar Coordinate 中的 Circular Motion，由于 $\\dot r=\\ddot r=0$ 很多公式都会被化简 N-T Coordinate #\r在 Circular Motion 中有 $$ v= ve_t $$\n其本身就由 Tangential Direction 上的 Velocity 决定，不受影响 R-Theta Coordinate #\r对于一个 Polar Coordinate 中的 Circular Motion，有 $$ v=\\dot{r} \\hat{e}r + r \\dot{\\theta} \\hat{e}\\theta $$\n带入 $\\dot r=\\ddot r=0$，得到 $$ v=r \\dot{\\theta} \\hat{e}_\\theta $$\nClockwise \u0026amp; Counter Clockwise #\r对于不同的运动方向，可以建立两个坐标系的关系 对于两个坐标系，其中一个特点就是 N-T Coordinate 中，Normal Force 是指向圆心的，而对于 R-Theta 来说，Radius 是从圆心指向物体 Postion 的，这直接导致了两个 Coordinate 下，有 $\\vec a_n=-\\vec a_r$ 再者就是对于 R-Theta 中的 Angle 来说，Angle 的变化的永远以 Counter Clockwise 为正，但是 N-T 中不同转向的 Tangential Force 的正负不同，所以当 CW 时，有 $\\vec a_t=-\\vec a_\\theta$，在 CCW 中则是 $\\vec a_t=\\vec a_\\theta$ ","date":"Mar 25 2025","externalUrl":null,"permalink":"/docs/uoft/24/dynamics/dyn5.r-thetacoordinate_edited/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/25/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e当在通过一个固定点观察物体运动的时候，使用 $R-\\theta$ 坐标系描述运动吗会高效很多\u003c/p\u003e","title":"DYN 5. R-Theta Coordinate Edited","type":"docs"},{"content":"","date":"Mar 25 2025","externalUrl":null,"permalink":"/docs/uoft/24/dynamics/","section":"Docs","summary":"","title":"Dynamics","type":"docs"},{"content":" Last Edit: 3/25/25\n在之前介绍了 Array 的使用，但那些都是对于 One-Dimensional Arrays 的，但是引入 Multi-Dimension 也非常重要\n9.1 Why and How to use 2D Array #\r最常见的 2D Array 就是 Table，它可以用两个维度表示一个数据 9.1.1 How to Create #\r9.1.1.1 Declaration Only #\r回顾 1D Array，Declare 它的方法为 int array[6]; ，其中 6 就是 Array 的 Size 对于 2D 也一样，只要一下给两个维度的 Size 就行了 int array[2][3]; 在 Declare 后，需要一个个给 Array 赋值 myArray[0][0] = 1; myArray[0][1] = 2; myArray[0][2] = 3; myArray[1][0] = 4; myArray[1][1] = 5; myArray[1][2] = 6; 就能得到以下效果\n一个更加常用的方法就是通过 Nested For Loop #include \u0026lt;stdio.h\u0026gt; int main(void) { int myArray[3][4]; for (int row = 0; row \u0026lt; 3; row++) { for (int col = 0; col \u0026lt; 4; col++) { myArray[row][col] = row * 4 + col; printf(\u0026#34;myArray[%d][%d] = %d\\n\u0026#34;, row, col, myArray[row][col]); } } return 0; } 通过遍历 Array 的 Row Size 和 Column Size 来遍历后依次赋值 9.1.1.2. Declaration and Initialization #\r但是还是直接在 Declare 的时候 Initialize 会更加方便，对于 1D Array 他的操作为 int myArray[] = {1, 2, 3, 4, 5, 6}; 2D 的情况下则多加一个 {}，有 int array[][] = {{1,2,3},{4,5,6}}; , 也可以用一个括号 int myArray[2][3] = {1, 2, 3, 4, 5, 6}; ，这种情况下，编译器会以 Row Major Order 也就是行优先的方式填充，也就是一行一行输入 在只指定了行和列中的一个参数的情况下，编译器会自动算出另外一个维度的数自行填充 9.1.2 2D Array’s Memory #\r一般来说 Array 在内存中都是按照顺序依次储存的，对于 C 语言中的 Array 来说则是 Row Major 的，也就是 [0][0],[0][1],[0][2] 的顺序 同 1D 的 Pointer 一样，array[0][0] 都会指向第一个 Element 的 Pointer，也就是 Base Address，之后通过 \u0026amp;myArray[i][j] = \u0026amp;myArray[0][0] + (i * number_of_columns + j) * sizeof(int); 也就可以算出第 i 个元素的 Memory Address 了 但是对于 2D Array 来说，它同时是指向第一个 Element 的 Pointer，也是指向第一行的，一般来说 *myArray 访问到 [0][0] 元素，相当属于是在访问 *(myArray + 0) ，而 *(myArray + 1) 则会直接访问到第二行 想要访问到第一行的第二个元素，则需要 *((myArray + 0)+1) 来访问，也就是说***(*(myArray + i) + j)** 访问具体的元素，相当于 myArray[i][j] 9.2. How do we pass a 2D array to a function? #\r与 1D 的传入参数一样，2D 下的 Array 也需要一个 Size，现在定义一个简单的 Function 为 void func(int arr2D[][], int rows, int cols){ arr2D[4][5] = 6; // should go dereference the address: // arr2D + row (= 4) * number of columns + col (= 5) // the number of columns is unknown!!! } 这是 Function 目前是有问题的，正确的语法需要通过 Specify Column 的数量在 arr2D 中 同时需要在 arr2D[][] 前定义 cols，有正确格式 void func(int rows, int cols, int arr2D[][cols]){ arr2D[4][5] = 6; // should go dereference the address: // arr2D + row (= 4) * cols + col (= 5) } 9.3 Dynamic Memory Allocation of 2D Arrays #\r当不知道 Array 中存在 Element 数量，或者是希望 Life Time 更加灵活的时候，需要通过 Dynamic Memory Allocation 来调度内存 对于二维数组来说，存在三种 Dynamic Memory Allocation 的办法 9.3.1. Method 1: Dynamic Allocation of an array of pointers #\r第一种办法是分配一组 Array of pointers，其中每一个 Element Pointer 指向二维数组的一行 int** arr = (int**) malloc(3 * sizeof(int*)); 这里，int** arr 是一个指向指针的指针，即double pointer 双重指针 这个语句通过 malloc 函数分配了一个足够容纳三个 int* 指针的空间，每个指针将指向一个整数数组的首元素。这样，arr 就可以通过索引访问每一行的起始地址 第二步是给每一行分配一个对应的一位数组 接下来就是给每一个 Element 赋值，用 Pointer 或者 Array 的访问方式都是可以的 for (int row = 0; row \u0026lt; 3; row++) { for (int col = 0; col \u0026lt; 4; col++) { *( *(arr + row) + col) = row * 4 + col + 1; // 或者 arr[row][col] = row * 4 + col + 1; } } 最后还需要 Free Memory，根据从里往外的顺序定义，先释放每一行所占内存 for (int row = 0; row \u0026lt; 3; row++) { free(*(arr + row)); // OR // free(arr[row]); arr[row] = NULL; } 然后再释放最外层的 Array of pointers free(arr); arr = NULL; 9.3.2. Method 3: Dynamic Allocation of a 1D array #\r首先动态分配一个足够大的一维数组来存储所有元素，具体大小由所有 Element 的个数决定，这样就能存储整个二维数组的数据 由于数组是一维的，直接使用一维索引访问，计算方式为 *(arr + row * cols + col)。这里，row * cols 计算当前行之前的所有元素总数，col 是当前行中的列索引 最后只需要 free(arr); 就可以释放整个 Array 了 #include \u0026lt;stdlib.h\u0026gt; int main(void) { int rows = 3, cols = 4; int* arr = (int*)malloc(rows * cols * sizeof(int)); // 为整个二维数组分配一维数组空间 // 使用一维索引填充数组 for (int row = 0; row \u0026lt; rows; row++) { for (int col = 0; col \u0026lt; cols; col++) { *(arr + row * cols + col) = row * cols + col + 1; } } free(arr); // 释放分配的内存 return 0; } ","date":"Mar 25 2025","externalUrl":null,"permalink":"/docs/uoft/24/learning-programming-with-c/lpc9.multi-dimensionalarrays/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/25/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e在之前介绍了 Array 的使用，但那些都是对于 One-Dimensional Arrays 的，但是引入 Multi-Dimension 也非常重要\u003c/p\u003e","title":"LPC 9. Multi-dimensional Arrays","type":"docs"},{"content":" Last Edit: 3/24/25\n直线运动指的是物体沿着一条直线路径移动。这种运动的特点是，物体的速度和加速度（如果有的话）的方向只在一条直线上\nVelocity \u0026amp; Speed #\rVelocity，瞬时速度，\\(\\vec v=\\frac{d\\vec s}{dt}\\) Average Velocity，一个区间内的平均速度 \\(\\vec{v}_{avg}=\\frac{\\Delta \\vec x}{\\Delta t}\\) Speed，Scalar，\\(|\\vec v|\\) Acceleration 加速度 #\r加速度是 Velocity 的 Second Derivative $$ a=\\frac{d\\vec v}{dt}=\\frac{d^2\\vec x}{dt^2} $$\nAcceleration as a function of time a(t) #\r当 Acceleration 是时间t的函数的时候（也就是说加速度在随着事件 t 变化而变化时），这种情况下，例如一个汽车加速或减速，有s和v等于 $$ a(t) = \\frac{dv}{dt} \\implies \\int_{t_0}^{t} a(t) , dt = \\int_{v_0}^{v} dv = v - v_0 \\implies v = v_0 + \\int_{t_0}^{t} a(t) , dt $$\n$$ v(t) = \\frac{ds}{dt} \\implies \\int_{t_0}^{t} v , dt = \\int_{s_0}^{s} ds = s - s_0 \\implies s = s_0 + \\int_{t_0}^{t} \\left[ v_0 + \\int_{t_0}^{t} a(t) , dt \\right] dt $$\n对于上面的公式，当加速度a是一个Constant的时候 $$ v=v_0+\\int_{t_0}^{t} a , dt=v_0+a\\int_{t_0}^{t} , dt=v_0+a(t-t_0) $$\n同理s也就有 $$ s=s_0+\\int_{t_0}^{t} \\left[ v_0+a(t-t_0) \\right] dt=s_0+\\frac{1}{2}at^2-at_0t+v_0t $$\nAcceleration is a function of position a(s) #\r在这种情况下，加速度取决于位置，这常见于诸如重力势能场中物体的运动 同理Acceleration是速度对于时间的导数，有 $$ a(s)=\\frac{dv}{dt}\\Rightarrow dt=\\frac{dv}{a(s)} $$\n又因为 Velocity 是 Speed 对于时间的导数，有 $$ v=\\frac{ds}{dt}\\Rightarrow dt=\\frac{ds}{v} $$\n建立等式便可得到 $$ \\frac{dv}{a(s)}=\\frac{ds}{v}\\Rightarrow \\int a(s)ds=\\int vdv=\\frac{1}{2}(v^2-{v_0}^2) $$\n同理当a是Constant的时候有 $$ \\frac{1}{2}(v^2-{v_0}^2)=a\\int^s_{s_0}ds=a\\Delta S\\Rightarrow v^2={v_0}^2+2a\\Delta S $$\n在加速度是位置的函数的时候没有对于s的公式\nex. Speed of asteroid falling #\rFind the impact speed of an asteroid falling to earth from a height of 109m (from the center of earth), when 𝑣𝑜 =-50 m/s. Consider m(earth)=6e24 kg, and G=6.67e-11Nm²/kg², and r(earth)=6.4e6 m\n已知u，S0，Sf，求Vf，已知加速度是Position s的函数 \\(a=\\frac{Gm_e}{r^2}\\) $$ v^2={v_0}^2-2\\int\\frac{Gm_e}{s^2}ds={v_0}^2+2Gm_e(\\frac{1}{s}-\\frac{1}{s_0}) $$\nAcceleration as a function of velocity a(v) #\r加速度为速度 v 的函数 $$ a(v)=\\frac{dv}{dt}\\Rightarrow dt=\\frac{dv}{a(v)}\\Rightarrow \\int^t_{t_0}dt=\\int^v_{v_0}\\frac{dv}{a(v)}=t-t_0 $$\nex. Projectile Motion #\rA projectile travels through fluid with an initial velocity of 60 m/s. The acceleration is 𝑎 = −0.4 v3𝑚/𝑠². Find v after 4 s\n可以发现a是v的函数，有 \\(a(v)=-0.4v^3\\) $$ a(v)=\\frac{dv}{dt}\\Rightarrow \\int^t_{t_0} dt=\\int\\frac{dv}{-0.4v^3}=\\frac{-1}{0.4}\\int v^{-3}dv $$\n分别求出积分后得到 $$ t-t_0=\\frac{-1}{0.4}\\frac{-1}{2}=(\\frac{1}{v^2}-\\frac{1}{{v_0}^2})\\Rightarrow v=0.559m/s $$\nSummary #\r加速度 a(t) 是时间的函数 $$ ∫dv=∫a(t) dt\\int dv = \\int a(t) , dt $$\n加速度 a(s) 是位移的函数 $$ ∫v dv=∫a ds\\int v , dv = \\int a , ds $$\n加速度 a(v) 是速度的函数 $$ ∫dva(v)=∫dt\\int \\frac{dv}{a(v)} = \\int dt $$\n当a是常数的时候 $$ V = V_0 + at $$\n$$ S = S_0 + V_0 t + \\frac{1}{2} a t^2 $$\n$$ V^2 = V_0^2 + 2a \\Delta s $$\n","date":"Mar 24 2025","externalUrl":null,"permalink":"/docs/uoft/24/dynamics/dyn1.rectilinearmotion_edited/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/24/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e直线运动指的是物体沿着一条直线路径移动。这种运动的特点是，物体的速度和加速度（如果有的话）的方向只在一条直线上\u003c/p\u003e","title":"DYN 1. Rectilinear Motion Edited","type":"docs"},{"content":" Last Edit: 3/24/25\nPlane Curvilinear Motion #\rPlane Curvilinear Motion 是指物体在二维平面内沿曲线路径的运动。这种运动比直线运动复杂，因为物体的速度向量不仅大小可能变化，方向也在不断变 物体的运动轨迹是一条二维曲线，表示物体在x-y平面中的运动。 位置矢量 \\(\\vec{r}(t)\\) 的是物体在时间t的时候从原点到物体当前所在位置的 Vector 轨迹点 P(t) 和 \\(P\u0026rsquo;(t + \\Delta t)\\) 是物体在时刻t的位置 当时间t改变时，物体沿着曲线移动，位置矢量 \\(\\vec{r}\\) 也会随时间变化 曲线运动中的速度和加速度是通过 \\(\\vec{r}(t)\\) 的导数来确定的 $$ \\vec{r}(t) = x(t)\\hat{i} + y(t)\\hat{j} $$\n$$ \\vec{v}(t) = \\frac{d\\vec{r}(t)}{dt} = \\frac{dx(t)}{dt}\\hat{i} + \\frac{dy(t)}{dt}\\hat{j} $$\n$$ \\vec{a}(t) = \\frac{d\\vec{v}(t)}{dt} = \\frac{d^2x(t)}{dt^2}\\hat{i} + \\frac{d^2y(t)}{dt^2}\\hat{j} $$\n如果Velocity的Magnitude没有发生改变，其加速度依然存在，具体来说速度不仅与速度的大小变化相关，还与速度的方向变化相关 Instantaneous Direction 瞬时方向 #\r对于曲线运动中的物体，当 \\(\\Delta t\\rightarrow 0\\) 的时候，其Displacement Vector和Velocity Vector总是与物体运动轨迹的 Tangent 方向一致 ex. Collision Problem in Plane #\rThe motions of two particles (A and B) are described by the position vectors. Find the point at which the particles collide and their speeds just before the collision\n$$ \\vec{r}_A = \\left[ 3t , \\hat{i} + 9t(2 - t) , \\hat{j} \\right] , \\text{m} ,\\vec{r}_B = \\left[ 3(t^2 - 2t + 2) , \\hat{i} + 3(t - 2) , \\hat{j} \\right] , \\text{m} $$\n想要做到碰撞，令i和j分别相等就行，之后就是求解了 Rectangular Coordinate System #\r对于3D的情况，就是多了一个Freedom of motion其Position Vector以及Magnitude为 $$ \\vec{r} = x\\hat{i} + y\\hat{j} + z\\hat{k},|\\vec{r}| = \\sqrt{x^2 + y^2 + z^2} $$\nVelocity #\r同理只要对Position对时间t求导就是速度了 $$ \\vec{v} = \\frac{d\\vec{r}}{dt} = \\frac{d}{dt} \\left( x\\hat{i} + y\\hat{j} + z\\hat{k} \\right) $$\n$$ \\vec{v} = \\left( \\frac{dx}{dt}\\hat{i} + x\\frac{d\\hat{i}}{dt} \\right) + \\left( \\frac{dy}{dt}\\hat{j} + y\\frac{d\\hat{j}}{dt} \\right) + \\left( \\frac{dz}{dt}\\hat{k} + z\\frac{d\\hat{k}}{dt} \\right) $$\n由于i，j，k是Unit Vector，其不受时间影响，所以可以去掉 $$ vec{v} = \\frac{dx}{dt}\\hat{i} + \\frac{dy}{dt}\\hat{j} + \\frac{dz}{dt}\\hat{k} $$\nAcceleration #\r同理对速度求导就有 $$ \\vec{a} = \\frac{dv_x}{dt} \\hat{i}+ \\frac{dv_y}{dt} \\hat{j} + \\frac{dv_z}{dt} \\hat{k} $$\n","date":"Mar 24 2025","externalUrl":null,"permalink":"/docs/uoft/24/dynamics/dyn2.planecurvilinearmotionandrectangularcoordinate_edited/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/24/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003ePlane Curvilinear Motion \r\n    \u003cdiv id=\"plane-curvilinear-motion\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#plane-curvilinear-motion\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003ePlane Curvilinear Motion 是指物体在二维平面内沿曲线路径的运动。这种运动比直线运动复杂，因为物体的速度向量不仅大小可能变化，方向也在不断变\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/uoft/24/dynamics/dyn2.planecurvilinearmotionandrectangularcoordinate_edited/image_hu13392097281712320818.png 330w,\r\n        /docs/uoft/24/dynamics/dyn2.planecurvilinearmotionandrectangularcoordinate_edited/image_hu1633320577644258215.png 660w,\r\n        /docs/uoft/24/dynamics/dyn2.planecurvilinearmotionandrectangularcoordinate_edited/image_hu12345705633840858989.png 1024w,\r\n        /docs/uoft/24/dynamics/dyn2.planecurvilinearmotionandrectangularcoordinate_edited/image_hu16175045965759161878.png 2x\"\r\n        src=\"/docs/uoft/24/dynamics/dyn2.planecurvilinearmotionandrectangularcoordinate_edited/image_hu1633320577644258215.png\"\r\n        alt=\"image.png\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"DYN 2. Plane Curvilinear Motion and Rectangular Coordinate Edited","type":"docs"},{"content":" Last Edit: 3/24/25\nAssumptions #\r斜抛运动其实就是在分析物体在两个自由度上的运动 现在为了简化问题，做出以下假设，忽略空气阻力，地球自转，并令重力为常数 Velocity #\r于是有以下两个方向的初速度为 Axis Initial Velocity Acceleration x \\(v_0 \\cos \\theta\\) 0 y \\(v_0 \\sin \\theta\\) \\(\\downarrow g, , -g \\uparrow\\) 总结便可以得出以下表格 Axis Velocity (\\(v = v_0 + at\\)) Position (\\(s = s_0 + v_0t + \\frac{1}{2}at^2\\)) No \u0026ldquo;t\u0026rdquo; (\\(v^2 = v_0^2 + 2a\\Delta s)\\) x \\(v_x = v_0 \\cos \\theta\\) \\(x = x_0 + (v_0 \\cos \\theta)t\\) N/A y \\(v_y = v_0 \\sin \\theta - gt\\) \\(y = y_0 + (v_0 \\sin \\theta)t - \\frac{1}{2}gt^2\\) \\(v_y^2 = (v_0 \\sin \\theta)^2 - 2g\\Delta y\\) 可以发现之所以x的第三列为 N/A 是因为 x 方向的加速度为零 Maximum Height #\r通过分析这里的公式就可以得出一些二级结论 物体在 Projectile Motion 中到达最高点后的Velocity会降到0 到达这一点的时间可以通过 \\(0=v_y-gt\\) 得到，有 $$ t=\\frac{v_y}{g} $$\n其高度则是根据 \\(v^2 = v_0^2 + 2a\\Delta s\\) 解得 $$ \\Delta y = \\frac{v_{y0}^2}{2g} $$\nex. Messi kicks the ball #\rex. Snowmobile #\rSnowmobile is going 15 𝑚/𝑠 at point A. Find: The horizontal distance it travels (𝑅) and the time (𝑡) in the air\n","date":"Mar 24 2025","externalUrl":null,"permalink":"/docs/uoft/24/dynamics/dyn3.projectilemotion_edited/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/24/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eAssumptions \r\n    \u003cdiv id=\"assumptions\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#assumptions\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e斜抛运动其实就是在分析物体在两个自由度上的运动\u003c/li\u003e\n\u003cli\u003e现在为了简化问题，做出以下假设，忽略空气阻力，地球自转，并令重力为常数\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eVelocity \r\n    \u003cdiv id=\"velocity\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#velocity\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e于是有以下两个方向的初速度为\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003eAxis\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eInitial Velocity\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eAcceleration\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003ex\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\\(v_0 \\cos \\theta\\)\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e0\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003ey\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\\(v_0 \\sin \\theta\\)\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\\(\\downarrow g, , -g \\uparrow\\)\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/uoft/24/dynamics/dyn3.projectilemotion_edited/image_hu13999105778689987923.png 330w,\r\n        /docs/uoft/24/dynamics/dyn3.projectilemotion_edited/image_hu12538984780851019553.png 660w,\r\n        /docs/uoft/24/dynamics/dyn3.projectilemotion_edited/image_hu14974553588324427500.png 1024w,\r\n        /docs/uoft/24/dynamics/dyn3.projectilemotion_edited/image_hu3129130145504408335.png 2x\"\r\n        src=\"/docs/uoft/24/dynamics/dyn3.projectilemotion_edited/image_hu12538984780851019553.png\"\r\n        alt=\"image.png\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"DYN 3. Projectile Motion Edited","type":"docs"},{"content":" Last Edit: 3/24/25\nWhy N-T #\r当已知了物体运动的轨迹的时候，可以更加简便的通过 Normal 法线，和 Tangential 切线坐标来描述粒子的运动 t -axis：切线方向，与粒子所在位置的曲线切线方向一致，并且方向为粒子运动的正方向 n -axis：法线方向，垂直于 t 轴，正方向指向曲线的曲率中心 eₙ 和 eₜ：分别是法线和切线方向的单位向量 Radius of curvature 曲率半径 #\rRadius of Curvature 曲率半径是描述曲线在某点处弯曲程度的量度，具体来说，它是通过该点的曲线能够最佳拟合的圆的半径来定义的 $$ \\rho = \\frac{(1 + y\u0026rsquo;^2)^{3/2}}{|y\u0026rsquo;\u0026rsquo;|} $$\nDistance in n-t System #\r在一个 Circular Motion 中，物体移动的距离由 Radius of curvature 和滑过角度的积分得出，因为 Radius of Curvature 描述的就是在一点的曲线的完整圆的半径，半径乘以距离就得到了 Arc Length，具体来说有 $$ ds=\\rho d \\beta $$\nVelocity in n-t System #\r在 n-t 系统中，Velocity 的方向永远指向 Path of motion 的 tangent 方向，也就是说 V 就是 Tangent 方向上 V 的 Magnitude $$ \\vec{v} = v \\vec{e}_t $$\n同理在上面描述了 n-t System 中的 Distance，Velocity 也可以通过对其求导得到，有 $$ v = \\dot{s} = \\frac{ds}{dt} = \\frac{\\rho d\\beta}{dt} = \\rho \\dot{\\beta} \\Rightarrow \\vec{v} = v \\vec{e}_t = \\rho \\dot{\\beta} \\vec{e}_t $$\n这一个公式同时又可以推导出 Angle 关于 time 的导数，有 $$ \\frac{d\\theta}{dt} = \\dot{\\theta} = \\frac{v}{\\rho} $$\nAcceleration in n-t System #\r再次对 Velocity 求导就可以得到 $$ \\vec{a} = \\frac{d\\vec{v}}{dt} = \\frac{d \\left( v \\hat{e}_t \\right)}{dt} = \\dot{v} \\hat{e}_t + v \\frac{d\\hat{e}_t}{dt} $$\n其中，因为 Velocity 方向的导数由 Angle 的变化量决定，因为其本身 Magnitude 并不会发生改变，一直都是一，并且方向是圆心方向，所以有 \\(d\\hat{e}_t = d\\theta \\hat{e}_n\\)，带入得到 $$ \\vec{a} = \\dot{v} \\hat{e}_t + v \\frac{d\\theta}{dt} \\hat{e}_n = \\dot{v} \\hat{e}_t + \\frac{v^2}{\\rho} \\hat{e}_n $$\n而 a 的 Magnitude 就可以通过勾股定律得到 Tangential Acceleration #\r总结上面的所有公式，可以得到 $$ a_t = \\frac{dV}{dt} $$\nNormal Acceleration #\r同理对于 Normal 方向上的，有 $$ a_n = V \\dot{\\theta}=\\rho \\dot{\\theta}^2 = \\frac{V^2}{\\rho} $$\n","date":"Mar 24 2025","externalUrl":null,"permalink":"/docs/uoft/24/dynamics/dyn4.n-tcoordinates_edited/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/24/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eWhy N-T \r\n    \u003cdiv id=\"why-n-t\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#why-n-t\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e当已知了物体运动的轨迹的时候，可以更加简便的通过 Normal 法线，和 Tangential 切线坐标来描述粒子的运动\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/uoft/24/dynamics/dyn4.n-tcoordinates_edited/image_hu7893211967565200209.png 330w,\r\n        /docs/uoft/24/dynamics/dyn4.n-tcoordinates_edited/image_hu11422299664533672993.png 660w,\r\n        /docs/uoft/24/dynamics/dyn4.n-tcoordinates_edited/image_hu8472462913601878249.png 1024w,\r\n        /docs/uoft/24/dynamics/dyn4.n-tcoordinates_edited/image_hu4297689936235695212.png 2x\"\r\n        src=\"/docs/uoft/24/dynamics/dyn4.n-tcoordinates_edited/image_hu11422299664533672993.png\"\r\n        alt=\"image.png\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"DYN 4. N-T Coordinates Edited","type":"docs"},{"content":" Last Edit: 3/21/25\nCoulomb\u0026rsquo;s Law 库仑定律 #\r电荷之间相互作用力遵循的公式 Coulomb\u0026rsquo;s Law 描述了两个 Charged Partials 之间的 Electrostatic Force（或Electric Force） Electrostatic Force专指静止或相对静止的电荷之间的作用力 Electric Force则为更广义的术语，指电场对电荷施加的作用力\n$$ F = \\frac{1}{4 \\pi \\varepsilon_0} \\frac{|q_1||q_2|}{r^2} \\quad (\\text{Coulomb\u0026rsquo;s law}) $$\n\\(\\varepsilon_0 = 8.85 \\times 10^{-12} , \\text{C}^2/\\text{N} \\cdot \\text{m}^2\\) Vacancies Permittivity Constant 真空介电常数 Permittivity Constant 体现了材料对电场的响应能力。真空介电常数是固定值，而不同材料的介电常数决定了其在电场中的行为特性\n\\(\\frac{1}{4πε0}=k = 8.99 \\times 10^9 , \\text{N} \\cdot \\text{m}^2/\\text{C}^2\\) 通常被 Electrostatic constant 静电常数 \\(k\\) 替代 由于两个Charged Particle之间的作用力是一条直线，所以其Electrostatic Force Vector 要么直接指向第二个Particle（相反的电荷符号），要么直接远离第二个粒子（相同的电荷符号） 如果多个 Electrostatic Force 作用在一个粒子上，则 Net Force 是各个力的 Vector Sum ex. Electrostatic Force’s Net Force #\rIn the figure four particles form a square with edge length \\(a = 3.64 × 10⁻²\\) m. The charges are \\(q₁ = q₄ = 1.77 × 10⁻¹⁵\\) C and \\(q₂ = q₃ = q\\)\n(a) What is q if the net electrostatic force on particle 1 is zero?\nShell Theorem 壳定理 #\rShell Theorem #1 #\r对于一个带电粒子，如果它位于一个带电球壳的外部，且球壳的电荷均匀分布在表面上，该粒子受到的力等效于球壳的电荷全部集中在球壳的中心（即外部粒子感受到的电场与球壳的半径无关，只与球壳的总电荷有关） Shell Theorem #2 #\r对于一个带电粒子，如果它位于一个带电球壳的内部，且球壳的电荷均匀分布在表面上，那么该粒子不会受到来自球壳的净电场作用力。 （即在球壳内部，电场为零） Charge on Conducting Spherical Shell 导体球壳 #\r一个中空的球形壳体，由导电材料制成 在一个导体球壳上，Charges会均匀地分布在其外表面，而不是内表面，这是因为导体内电荷会相互排斥，最终达到平衡分布 Conductor \u0026amp; Insulator 导体和绝缘体 #\r我们通常可以根据Charge穿过它们的能力对材料进行分类 Conducting Path 传导路径 #\r用羊毛摩擦铜棒时，电荷会从羊毛转移到铜棒，使铜棒带电。 如果此时握着铜棒，并接触一个与金属管道相连的水龙头，那么铜棒cannot be charged，这是因为人、铜棒、水龙头与地球表面通过管道形成了一条导电路径。多余的电荷会通过这条路径流向地球（地球是一个巨大的导体）。因此，铜棒上的电荷会扩散到地球表面，最终使铜棒变得电中性。 Grounding 接地 #\r通过设置一条导体路径连接物体和地球，可以消除物体上的多余电荷，这个过程称为Grounding Discharge 放电 #\r这一个Grounding的将Exceed的Charge Neutralize的过程被称为Discharge Charged Particles 带电粒子 #\r原子由带正电的质子、带负电的电子和电中性中子组成 质子和中子紧密地堆积在一个原子核中 单个电子的电荷和单个质子的电荷具有相同的大小，但符号相反 Conduction electrons 价电子 #\r在导体中Conduction electrons（价电子）因其与原子核的吸引力较弱而变得自由移动。 当导体原子形成固体结构时，这些导电电子在导体中形成“电子海”，可以在整个导体内自由流动 而在在绝缘体中，原子的电子与原子核结合得非常紧密，几乎没有自由电子 Induced Charge 感应电荷 #\rInduced Charge指的是由于邻近电荷的影响，导体内的电荷重新分布，形成正负电荷分离的现象 如图将一个Charged Plastic Rod放置到Neutral的Copper Rod旁边，Positive Charge将会被吸引到Copper Rod的左侧，Negative Charge则会被排斥到右侧，此时虽然Copper Rod是Neutral的，但其有一个 Induced Charge 感应电荷 需要注意的是，在Induced Charge形成的过程中，并不是Positive Charge移动了，而是因为原来均匀分布在整个Copper Rod上的Positive \u0026amp; Negative Charge中的Negative Charge移动了，所以才会有Positive Charge的出现 换句话说，Positive Charge不是“增加”来的，而是因为失去了Negative Charge，所以显得“正” Charge is Quantized 量化电荷 #\r在Benjamin Franklin的时代，电荷被认为是一种连续的流体——这个想法有很多用途。然而，我们现在知道流体本身，例如空气和水，不是连续的，而是由原子和分子组成的;物质是离散的 实验表明，Electrical fluid也不是连续的，而是由某种基本电荷的倍数组成。任何可以检测到的正电荷或负电荷 q 都可以写成 $$ q = n e, \\quad n = \\pm 1, \\pm 2, \\pm 3, \\ldots $$\nCharge of three Particles #\rParticle Symbol Charge Antiparticle Symbol Charge Electron e or e⁻ -e Positron e⁺ +e Proton p +e Antiproton p̅ -e Neutron n 0 Antineutron n̅ 0 Electron的Symbol为e是因为其通常表示电子作为一种粒子的名称，而不特别强调它的电荷性质\nCharge on two quarks #\rQuark Symbol Charge Antiparticle Symbol Charge Up u \\(+\\frac{2}{3}e\\) Antiup \\(\\bar{u}\\) \\(-\\frac{2}{3}e\\) Down d \\(-\\frac{1}{3}e\\) Antidown \\(\\bar{d}\\) \\(+\\frac{1}{3}e\\) 由于Quark不能单独存在（被限制在强相互作用中），我们通常不将它们的电荷视为基本电荷 Charge is Conserved 电荷守恒 #\r摩擦不会产生电荷，而只会将其从一个物体转移到另一个物体，从而在此过程中破坏每个物体的电中性 任何孤立系统的净电荷总是守恒的，无论系统内部发生什么变化（如粒子的生成、湮灭或分裂），系统的总电荷量不会改变，下面给出一些常见的例子说明这一现象 Electron Capture 电子捕获 #\r母核中的质子“捕获”原子的一个内部电子以形成中子（保留在子核中）并释放中微子 $$ p + e^- \\rightarrow n + \\nu $$\n","date":"Mar 21 2025","externalUrl":null,"permalink":"/docs/uoft/24/electrical-fundamentals/ef1.coulombslaw_edited/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/21/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eCoulomb\u0026rsquo;s Law 库仑定律 \r\n    \u003cdiv id=\"coulombs-law-%E5%BA%93%E4%BB%91%E5%AE%9A%E5%BE%8B\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#coulombs-law-%E5%BA%93%E4%BB%91%E5%AE%9A%E5%BE%8B\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e电荷之间相互作用力遵循的公式\u003c/li\u003e\n\u003cli\u003eCoulomb\u0026rsquo;s Law 描述了两个 Charged Partials 之间的 Electrostatic Force（或Electric Force）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/uoft/24/electrical-fundamentals/ef1.coulombslaw_edited/image_hu7098555360533024946.png 330w,\r\n        /docs/uoft/24/electrical-fundamentals/ef1.coulombslaw_edited/image_hu7648078660818927912.png 660w,\r\n        /docs/uoft/24/electrical-fundamentals/ef1.coulombslaw_edited/image_hu3052726973708541951.png 1024w,\r\n        /docs/uoft/24/electrical-fundamentals/ef1.coulombslaw_edited/image_hu8723941724131963656.png 2x\"\r\n        src=\"/docs/uoft/24/electrical-fundamentals/ef1.coulombslaw_edited/image_hu7648078660818927912.png\"\r\n        alt=\"image.png\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 1. Coulomb's Law Edited","type":"docs"},{"content":" Last Edit: 3/21/25\nElectric Field 电场 #\r在科学中存在多个 Field的概念，其中包含了 Teperature Field，Pressure Field 等 而 Electric Field 则是一个 Vector Field，矢量场，其包含了大小与方向 具体来说，定义 Electric Field的方式是在 Electric Field \\(\\vec{E}\\) 的某个点 P 处放置一个 Small Positive Charge 的 \\(q_0\\)，其为 Test Charge We want the charge to be small so that it does not disturb the object’s charge distribution\nElectric Field Strength 电场强度 #\r一个表示电场强弱的物理量 电场 \\(\\vec{E}\\) 在点 P 由带电对象产生，对试验电荷 \\(q_0\\) 产生了静电力 \\(\\vec{F}\\) 由于 \\(p_0\\) 是一个正的Charge，所以电场的方向是电力的方向，而电场的大小有 $$ \\vec{E} = \\frac{\\vec{F}}{q_0} $$\nElectric Field 的国际单位系统 (SI) 单位是牛顿每库仑（N/C） Electric Field Lines 电场线 #\r由于需要一种方式可视化电场，Eletric Field Lines出现了 Electric Field Line 的方向是由正电荷指向负电荷 根据 Electric Field 的性质，电场线的密集程度反映了电场的强度。电场线越密集，电场强度越大 ex. Graph Interpretation of Electric Field #\rIn the figure the electric field lines on the left have twice the separation as those on the right. (a) If the magnitude of the field at A is 39 N/C, what is the magnitude of the force on a proton at A? (b) What is the magnitude of the field at B?\nThe Electric Field Due to a charged Particle #\r为了找到 Charged Particle（通常称为点电荷）产生的 Electric Field，我们在粒子距离 r 的位置放置一个正测试电荷 前面知道 Coulomb\u0026rsquo;s Law 有 $$ F = \\frac{1}{4 \\pi \\varepsilon_0} \\frac{|q||q_0|}{r^2} $$\n将 \\(\\vec F\\) 代入到 \\(\\vec E\\) 中便可以得到 $$ \\vec{E} = \\frac{\\vec{F}}{q_0} = \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r^2}\\quad \\text{(charged particle)} $$\nPrinciple of superposition 电场的叠加原理 #\r如果在某点有多个电荷产生的电场，可以通过叠加原理来计算该点的总电场。文中用到了叠加原理，表达式为 $$ \\vec{E} = \\vec{E}_1 + \\vec{E}_2 + \\cdots + \\vec{E}_n $$\n这说明总电场是各个单独电场向量的矢量和 ex. Electric Field Superposition #\rIn the figure the four particles are fixed in place and have charges \\(q_1 = q_2 = 4e\\), \\(q_3 = 2e\\), and \\(q_4 = -8e\\). Distance d=4.75d = 4.75 µm. What is the magnitude of the net electric field at point P due to the particles?\nA Point Charge in an Electric Field #\r当一个 Particle 有着 q 的 Charge 被放置在 Electric Field \\(\\vec E\\) 中的时候，Electric Field 会对其产生\\(\\vec F=q\\vec E\\) 的Electrostatic Force Millikan Oil-drop Experiment #\r罗伯特·A·密立根在1910年进行的著名实验油滴实验，用于测量电子的基本电荷e ","date":"Mar 21 2025","externalUrl":null,"permalink":"/docs/uoft/24/electrical-fundamentals/ef2.electricfield_edited/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/21/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eElectric Field 电场 \r\n    \u003cdiv id=\"electric-field-%E7%94%B5%E5%9C%BA\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#electric-field-%E7%94%B5%E5%9C%BA\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e在科学中存在多个 Field的概念，其中包含了 Teperature Field，Pressure Field 等\u003c/li\u003e\n\u003cli\u003e而 Electric Field 则是一个 Vector Field，矢量场，其包含了大小与方向\u003c/li\u003e\n\u003cli\u003e具体来说，定义 Electric Field的方式是在 Electric Field \\(\\vec{E}\\) 的某个点 P 处放置一个 Small Positive Charge 的 \\(q_0\\)，其为 Test Charge\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003eWe want the charge to be small so that it does not disturb the object’s charge distribution\u003c/p\u003e","title":"EF 2. Electric Field Edited","type":"docs"},{"content":" Last Edit: 3/7/25\n前面提到过了 Array 中的 Memory 的分配方式是固定的连续内存，而想要修改 Array 的大小则变得困难，这时候就需要通过 Dynamic Memory Allocation 来动态的分布内存\n8.1 Dynamic Memory Allocation #\rDynamic Memory Allocation 的核心就是在 Runtime 即时分配内存空间的过程，分配的内存量在编译时不需要预先知道 8.1.1 Different Options when array size is unknown #\r一种可以采取的方法就是直接给一个非常大的 Array size，但这不可避免的会造成浪费 一般来说，一个程序的 Main Memory 主要会被分成四个主要部分 Code #\r代码段负责储存代码 Const + Global #\r所有的程序常量和变量都会被存储在这 Heap #\r储存动态分配的内存 Stack #\r储存 function 的局部变量，如果一个函数调用另一个函数，他的局部变量会被储存于此 Stack Overflow 栈溢出 #\r当 Stack 部分的 Memory 被耗尽的情况下，没有更多空间的时候会报的错 Variable Size Array #\rArray 的大小可以被用一个 Variable 决定，这是一种灵活的分配方式，根据需要分配实际大小，以下是一种示例 #include \u0026lt;stdio.h\u0026gt; int main(void) { int size; printf(\u0026#34;Enter size of array: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;size); int arr[size]; printf(\u0026#34;Array allocated from %p to %p\u0026#34;, arr, arr+size); return 0; } 使用这种方式，即使使用了 Variable 决定 Array 的 Size，其本质上还是在 Array 上分配的，如果 Stack 的空间不足后，还是会报错 Dynamically Allocate Memory #\r通过将 Memory 放置到 heap 上，这需要 stdlib.h: malloc 库里的内容 malloc(size_t size)会分配指定字节数的内存块，并返回指向该内存块首地址的指针。如果分配失败，返回NUL 当使用malloc为数组分配内存时，需要指定分配的总字节数，通常是数组元素的数量乘以单个元素的大小 例如，要为5个 int 分配内存，可以使用表达式malloc(5 * sizeof(int)) Memory Leak #\r在 Dynamic 分配完了 Memory 后，临时放置在 Stack 中的储存 malloc 中第一个 Element 的 Pointer 也会消失，而这时候如果没有收回之前分配的 Memory，会导致 Memory Leak #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; double getAverage(int); int main(void) { int size; printf(\u0026#34;Enter size of array:\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;size); double avg = getAverage(size); printf(\u0026#34;Average is %.2lf\\n\u0026#34;, avg); return 0; } double getAverage(int size) { int* myArray = (int*)malloc(size * sizeof(int)); printf(\u0026#34;Enter grades:\u0026#34;); for (int index = 0; index \u0026lt; size; index++) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;myArray[index]); } int sum = 0; for (int index = 0; index \u0026lt; size; index++) { sum += myArray[index]; } return (double)sum / size; } 简单来说，由于 Pointer 的丢失，已经无法再次访问这个 Array，但是其还在那个地方，会导致 1. 无法再次访问，2. 空间仍然被占用 一个合理的解决方案就是在 return 之前将已有的空间收回，也就是 free free 的 Prototype 为 void free(void *pointer); free函数用于释放 malloc 分配的内存，它接受一个指向要释放内存的 Pointer，并释放该内存块，但是一旦 Memory 被释放，原有的指针变量仍然存在，但其指向的是一个不再有效的内存区域，这时候需要将 Pointer 设置为 Null #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; double getAverage(int); int main(void) { int size; printf(\u0026#34;Enter size of array:\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;size); double avg = getAverage(size); printf(\u0026#34;Average is %.2lf\\n\u0026#34;, avg); return 0; } double getAverage(int size) { int* myArray = (int*)malloc(size * sizeof(int)); printf(\u0026#34;Enter grades:\u0026#34;); for (int index = 0; index \u0026lt; size; index++) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;myArray[index]); } int sum = 0; for (int index = 0; index \u0026lt; size; index++) { sum += myArray[index]; } free(myArray); myArray = NULL; return (double)sum / size; } ","date":"Mar 7 2025","externalUrl":null,"permalink":"/docs/uoft/24/learning-programming-with-c/lpc8.dynamicmemoryallocation/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/7/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e前面提到过了 Array 中的 Memory 的分配方式是固定的连续内存，而想要修改 Array 的大小则变得困难，这时候就需要通过 Dynamic Memory Allocation 来动态的分布内存\u003c/p\u003e","title":"LPC 8. Dynamic Memory Allocation ","type":"docs"},{"content":"","date":"Mar 6 2025","externalUrl":null,"permalink":"/tags/cal/","section":"Tags","summary":"","title":"Cal","type":"tags"},{"content":"Calculus\n","date":"Mar 6 2025","externalUrl":null,"permalink":"/docs/uoft/24/calculus/","section":"Docs","summary":"\u003cp\u003eCalculus\u003c/p\u003e","title":"Calculus","type":"docs"},{"content":" Last Edit: 3/6/25\nIntegration by part #\r当 Integral 内存在两个函数的乘积的时候，可以使用 Integration by parts 已知有 Derivative\u0026rsquo;s Product Rule $$ \\left( u(x) v(x) \\right)\u0026rsquo; = u\u0026rsquo;(x) v(x) + u(x) v\u0026rsquo;(x) $$\n将两边同时积分可以得到 $$ \\int u(x) v\u0026rsquo;(x) ,dx = \\int (u(x) v(x))\u0026rsquo; ,dx - \\int v(x) u\u0026rsquo;(x) ,dx $$\n等式右边的第一项化简后可以得到 $$ \\int u(x) v\u0026rsquo;(x) ,dx = u(x) v(x) - \\int v(x) u\u0026rsquo;(x) ,dx $$\n于是就得到了 Integral By Parts 的公式 $$ \\int u ,dv = uv - \\int v ,du $$\n在得到了处理 Integral 内部有乘积时候的公式后，只需要选择乘积中的一个作为 u，另一个作为 v，并对一个求导，一个积分就可以得到 Integral By Parts 的结果了 Guidelines for Integration by Parts #\ru 和 v 的选择直接关系到了 Integral By Parts 的难度 u求导后应该比u简单 dv积分后应该比v简单 通常使用 LIATE 法则（Logarithmic, Inverse trig, Algebraic, Trigonometric, Exponential） 优先选择 LIATE 顺序靠前的函数作为 u，然后把剩下的部分作为 dv\nex. Integral By Parts #\r考虑积分 $\\int xe^{2x}dx$\n在这里由于 e 的特殊性质，应该求 x 的 Derivative，求 dv 的 Integral，求出 $x\u0026rsquo;=1,\\int e^{2x}dx=\\frac{1}{2}e^{2x}$，可以得到 $$ \\underbrace{x \\frac{1}{2} e^{2x}}{uv} - \\int \\underbrace{\\frac{1}{2} e^{2x}}{v} \\underbrace{dx}_{du} $$\n再求得 $vdu$ 项的积分有 $$ \\int xe^{2x}dx=\\int \\underbrace{x}{u} \\underbrace{e^{2x} ,dx}{dv} = \\underbrace{x \\frac{1}{2} e^{2x}}{uv} - \\int \\underbrace{\\frac{1}{2} e^{2x}}{v} \\underbrace{dx}_{du} = \\frac{1}{2} x e^{2x} - \\frac{1}{4} e^{2x} + C $$\nex. Getting the original Integral #\r求 $\\int x^2 sinx dx$\n令 $x^2$ 为 u, sinx 为 dv $$ \\int x^2 \\sin x ,dx = -x^2 \\cos x + \\int 2x \\cos x ,dx= -x^2 \\cos x + x^2 \\cos x + \\int x^2 \\sin x ,dx $$\n化简后发现得到了 $$ \\int x^2 \\sin x ,dx=\\int x^2 \\sin x ,dx $$\nTabular Method #\r当一个 Integral 中两个函数相乘的时候，如果其中一个能在有限次数的求导内得到0，便可以使用 Tabular Method 左边必须是 Alternate Sign，从 + 开始，对 u 反复求导，对 dv 反复积分，最终将 u 乘以 dv，然后将所有项包含正负号加在一块就是答案 Trigonometric Substitute #\r三角恒等式可以将 Integral 中的根号表达式通过如 $1 - \\sin^2\\theta = \\cos^2\\theta$ 的简单形式，从而让积分变得更容易计算，特别是对于以下三种形式 $$ \\sqrt{a^2 - x^2} → 令~ x=asinθ \\ \\sqrt{a^2 + x^2}→ 令 x=atanθ \\ \\sqrt{x^2 - a^2} → 令x=asecθ $$\n\\sqrt{a^2 - x^2} 的积分 #\r对于积分 $\\int \\frac{dx}{\\sqrt{a^2 - x^2}}$ 因为 $x=asin⁡θ,dx=acos⁡θ$ 有三角恒等式 $1 - \\sin^2\\theta = \\cos^2\\theta$ 可以得到 $\\sqrt{a^2 - x^2} = a \\cos\\theta$ 这里的 a 是为了化简根号中的被减数的\nex. #\r有 Integral $\\int \\frac{dx}{\\sqrt{4 - x^2}}$\n观察发现 Constant Term 是被减数，可以使用的三角恒等式为 $1 - \\sin^2\\theta = \\cos^2\\theta$，令 $x=2sin⁡θ,dx=2cos⁡θ$ 将 x 带入之后可以得到 $$ \\sqrt{4-4\\sin^2\\theta}\\Rightarrow \\sqrt{4(1-\\sin^2\\theta)}=2\\cos\\theta $$\n带入后可以得到 $$ \\int \\frac{2\\cos\\theta , d\\theta}{2\\cos\\theta} = \\int d\\theta = \\theta + C $$\n已知 $\\theta = \\arcsin\\frac{x}{2}$ $$ \\int \\frac{dx}{\\sqrt{4 - x^2}} = \\arcsin\\frac{x}{2} + C $$\n\\sqrt{a^2 + x^2} #\r对于形如 $\\int \\frac{dx}{\\sqrt{a^2 + x^2}}$ $$ x=atan⁡θ,dx=asec⁡^2θ dθ $$\n观察发现可以使用三角恒等式 $1 + \\tan^2\\theta = \\sec^2\\theta$，和上面一样可以得到 $$ \\sqrt{a^2 + x^2} = a \\sec\\theta $$\nex. #\r$$ \\int \\frac{dx}{\\sqrt{9 + x^2}} $$\n观察发现 Constant Term 为 9，并且根号内为加法，可以使用 $1 + \\tan^2\\theta = \\sec^2\\theta$，替换 $x=3tan⁡θ,dx=3sec⁡2θ dθ$ $$ \\sqrt{9 + x^2} = 3\\sec\\theta \\int \\frac{3\\sec^2\\theta , d\\theta}{3\\sec\\theta} = \\int \\sec\\theta , d\\theta= \\ln | \\sec\\theta + \\tan\\theta | + C $$\n最后可以得到 $$ \\int \\frac{dx}{\\sqrt{9 + x^2}} = \\ln \\left| \\frac{\\sqrt{9 + x^2}}{3} + \\frac{x}{3} \\right| + C $$\n\\sqrt{x^2 - a^2} 的积分 #\r对于形如 $\\int \\frac{dx}{\\sqrt{x^2 - a^2}}$，和前面的都一样，有 $$ x = a \\sec\\theta, \\quad dx = a \\sec\\theta \\tan\\theta , d\\theta $$\n使用三角恒等式 $$ \\sec^2\\theta - 1 = \\tan^2\\theta \\Rightarrow \\sqrt{x^2 - a^2} = a \\tan\\theta $$\nex. #\r解 $\\int \\frac{dx}{\\sqrt{x^2 - 16}}$\n观察得到 Constant 是减数，而根式内是减号，观察可以使用 $\\sec^2\\theta - 1 = \\tan^2\\theta$，令 $x = 4\\sec\\theta, \\quad dx = 4\\sec\\theta \\tan\\theta , d\\theta$ $$ \\int \\frac{4\\sec\\theta \\tan\\theta , d\\theta}{4\\tan\\theta} = \\int \\sec\\theta , d\\theta\\ln | \\sec\\theta + \\tan\\theta | + C $$\nSummary #\r根式形式 代换方式 结果表达式 $\\sqrt{a^2 - x^2}$ $x = a\\sin\\theta$ $\\sqrt{a^2 - x^2} = a\\cos\\theta$ $\\sqrt{a^2 + x^2}$ $x = a\\tan\\theta$ $\\sqrt{a^2 + x^2} = a\\sec\\theta$ $\\sqrt{x^2 - a^2}$ $x = a\\sec\\theta$ $\\sqrt{x^2 - a^2} = a\\tan\\theta$ Partial Fraction #\r对于一个分式 $$ \\int\\frac{1}{x^2-5x+6}dx $$\n无法对其直接做积分，于是可以通过 Partial Fraction 化简 Partial Fraction #\r对于一个分式，如果分母可以因式分解成不同的一次因式，如下形式 $$ \\frac{P(x)}{(x-a)(x-b)} $$\n那么它就可以化简为 Partial Fraction $$ \\frac{P(x)}{(x-a)(x-b)} = \\frac{A}{x-a} + \\frac{B}{x-b} $$\n接下来就需要更具步骤依次求解 A 和 B 首先将等式两边分别通分，可以得到 $$ P(x)=A(x-b)+B(x-a) $$\n现在的阶段，a 和 b 是 Constant，设 x = b 就可以解出 B，令 x = a 就可以解出 A ex. #\r因式分解 $\\frac{3x + 5}{(x-1)(x+2)}$\n$$ \\frac{3x + 5}{(x-1)(x+2)} = \\frac{A}{x-1} + \\frac{B}{x+2} $$\n通分得到 $$ 3x+5=A(x+2)+B(x-1) $$\n令 $x=-2$，有 $-1=-3B \\Rightarrow B = \\frac{1}{3}$ ，同理解出 $A=\\frac{8}{3}$ ex. Quadratic Factors #\r现在有 $\\frac{2x^3 - 4x - 8}{(x^2 - x)(x^2 + 4)} , dx$\n化简分母 $(x^2 - x)(x^2 + 4) = x(x - 1)(x^2 + 4)$ 当分母中出现二次不可约因子（即不能因式分解为两个一次因子），对应的分子必须是一次多项式，即 Cx + D 通过 Partial Fraction 可以得到 $$ \\frac{2x^3 - 4x - 8}{x(x - 1)(x^2 + 4)} = \\frac{A}{x} + \\frac{B}{x - 1} + \\frac{Cx + D}{x^2 + 4} $$\n通分后可以得到 $$ 2x^3 - 4x - 8 = A(x - 1)(x^2 + 4) + Bx(x^2 + 4) + (Cx + D)(x)(x - 1) $$\n用普通方式计算 A 和 B $x=0\\Rightarrow A=2, x=1 \\Rightarrow B =-2$ 现在将 A，B 和两个任意的 $x\\neq 0,1$ 带入原式后就可以得到一个二元一次方程组，之后就可以解出 C 和 D 了 Improper Integrals #\r在 Integral 被定义的时候，限制了他的 a 和 b 需要是一个有限的值，而有的时候上下界不可避免的会出现 Infinite 的情况，这就需要 Improper Integral 简单来说 Improper Integral 就是给 Integral 前面添加一个 Limit，在这之外就没有其他的变化 $$ \\int_{a}^{\\infty} f(x) , dx = \\lim_{b \\to \\infty} \\int_{a}^{b} f(x) , dx $$\nex. #\r计算积分 $\\int_{1}^{\\infty} \\frac{dx}{x}dx$\n通过 $\\lim_{b\\rightarrow \\infty}$ 替换上界，有 $$ \\int_{1}^{\\infty} \\frac{dx}{x} = \\lim_{b \\to \\infty} \\int_{1}^{b} \\frac{dx}{x}= \\lim_{b \\to \\infty} \\left[ \\ln x \\right]{1}^{b} = \\lim{b \\to \\infty} (\\ln b - 0) = \\infty $$\n","date":"Mar 6 2025","externalUrl":null,"permalink":"/docs/uoft/24/calculus/calculus8.methodsofintegration/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 3/6/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eIntegration by part \r\n    \u003cdiv id=\"integration-by-part\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#integration-by-part\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e当 Integral 内存在两个函数的乘积的时候，可以使用 Integration by parts\u003c/li\u003e\n\u003cli\u003e已知有 Derivative\u0026rsquo;s Product Rule\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e$$\n\\left( u(x) v(x) \\right)\u0026rsquo; = u\u0026rsquo;(x) v(x) + u(x) v\u0026rsquo;(x)\n$$\u003c/p\u003e","title":"Calculus 8. Methods of Integration","type":"docs"},{"content":"\rEF9.ResistiveCircuits #\rLast Edit: 3/3/25\nOhm’s Law #\rOhm’s Law是以德国物理学家 Georg Simon Ohm 的名字命名的，他确立了 Voltage 和 Current 之间的关系，其发现了 Resistor 两端的 Voltage 和通过的 Current 成正比 Symbol for a Resistor #\rMathematical Relationship #\rOhm\u0026rsquo;s Law 指出 $$ v(t) = Ri(t), \\text{ where } R \\geq 0 $$\n其中 Ohms 的符号为 \\(\\Omega,1\\Omega=1V/A\\) Graphical representation of V vs. I #\r不同用电器有着不同的 Voltage-Current Relationship 一个线性电阻器 一个 Light Bulb 的则是非线性的关系 Conductance 电导 #\rConductance 由符号 G 表示，其是 Resistor 的倒数 它的单位是 Siemens，有 \\(1S=1A/V\\) Power Relationships #\rPower 的最基础的定义为 W = VI，也就是 $$ p(t) = v(t) i(t) $$\n当把 \\(V=Ri\\) 带入，有 $$ p(t) = Ri^2(t) = \\frac{v^2(t)}{R} $$\n带入 Conductance \\(i(t) = Gv(t)\\) 可以得到 $$ p(t) = \\frac{i^2(t)}{G} = Gv^2(t) $$\nConductor\u0026rsquo;s Influence in Circuit #\r对于一个位于 Circuit 中的 Resistor 来说，其可以通过变换对 Circuit 整体造成不同的影响 如上图所示，当 Resistor 减小到零的时候，电源两端直接连线，形成 Short Circuit 而到了 C 中，Resistor 增大到无限大时，形成 Open Circuit Kirchhoff\u0026rsquo;s Laws #\rKirchhoff\u0026rsquo;s Laws 具体表现为 Kirchhoff\u0026rsquo;s Current Law 和 Kirchhoff\u0026rsquo;s Voltage Law KCL Current Law #\r对于一个 Circuit 中的 Node 来说，其 Algebraic Sum of the Current leaving or entering a node is zero，说明从节点流出或流入的电流 之代数和为零 想要解决 Circuit 中每一个 Node 的 Current 的办法就是通过解线性方程组，而并不是每一个节点的 Equation 都在 System 中是 Linearly Independent 的，这说明仅需要选择线性独立的方程来进行分析 Kirchhoff’s Voltage Law #\rKVL 指出，在任何闭合回路中，电压的代数和必须为零 Voltage Division #\r在 Series, Parallel Circuit 中，需要进一步通过 Current 和 Voltage 在不同情况下的性质在写出 Linear Equation 后进一步求解 当 Circuit 中存在一个 Series 的时候，可以得到d $$ -v(t) + v_{R1} + v_{R2} = 0\\Rightarrow v(t) = v_{R1} + v_{R2} $$\n根据 Ohm\u0026rsquo;s Law 可以知道，\\(v_{R1} = R_1i(t),v_{R2} = R_2i(t)\\)，有 \\(v(t)=R_1i(t)+R_2i(t)\\)，可以解出 \\(i(t) = \\frac{v(t)}{R_1 + R_2}\\) 带回 \\(v_{R_1}=R_1 i(t)\\) 后可以得到 $$ = R_1 \\left[ \\frac{v(t)}{R_1 + R_2} \\right] = \\frac{R_1}{R_1 + R_2} v(t) $$\nMultiple-Source/Resistor Networks #\r有的时候的 Circuit 会非常复杂，比如存在多个 Voltage Sources 的情况，这时候就需要通过 Simplified Equivalent Circuit 来分析 Circuit 上图中，a 存在了多个 Voltage Sources 和 Resistors，沿着 Closed Loop 列出所有 KVL 方程 \\(+vR1+v2(t)−v3(t)+vR2+v4(t)+v5(t)−v1(t)=0\\)，将所有非 Resistor 的 Voltage 移动到等式右边，有 \\(vR1+vR2=v1(t)−v2(t)+v3(t)−v4(t)−v5(t)\\) 根据 KVL ，就可以创建一个 \\(R_S=R_1+R_2+R_3+R_4+R_5\\) 的等效电路 于是就把整个 Circuit 化简为了 b 中的等效电路 ex. Find Voltage in a fragment #\r有以下图 a，求 bd 段的等效电路\n在同时存在 Resistor 和 Battery 的情况下，要先求得他们的 Current （串联分压不分流） 根据 KVL，有 $$ 10kI + 20kI + 12 + 30kI - 6 = 0\\Rightarrow60kI = -6 \\Rightarrow I = -0.1 , \\text{mA} $$\nbd 段的 Voltage 自然可以通过 \\(10kI + V_{bd} + 30kI - 6 = 0\\) 得到，代入 \\(I = -0.1 , \\text{mA}\\) 后得到 \\(V_{bd}=10V\\) ex2. #\r求出 \\(V_S\\) 段的 Voltage\n已知 Parallel Circuit 分流不分压，有 \\(I_L=458.3/220=2.083~kA\\) 后面又进入了一个 Series Circuit，有 \\(V_{line}=20\\cdot 2. 083=41.66 ~kV\\) 根据 KVL，可以得到 \\(V_S=V_{line}+V_{load}=500 ~kV\\) Single-Node-Pair Circuits #\r串联分压，并联分流的原理也可以通过 KVL 进一步验证 对于上面的电路，有 $$ i(t) = \\frac{v(t)}{R_1} + \\frac{v(t)}{R_2} = \\left( \\frac{1}{R_1} + \\frac{1}{R_2} \\right) v(t) = \\frac{v(t)}{R_p} $$\n能总结出公式为 $$ i_1(t) = \\frac{v(t)}{R_1}\\Rightarrow i_1(t) = \\frac{R_2}{R_1 + R_2} i(t) $$\n可以用于计算 Parallel Circuit 中的 Current Multiple-Source/Resistor Networks #\r对于具有 n 个 Parallel Resistor 的 Circuit，根据 KVL 可以得出 $$ i_0(t) = i_1(t) + i_2(t) + \\ldots + i_N(t) = \\left( \\frac{1}{R_1} + \\frac{1}{R_2} + \\ldots + \\frac{1}{R_N} \\right) v(t) $$\n其中每一个 Parallel Circuit 上的 Resistor 可以通过 $$ i_j(t) = \\frac{v(t)}{R_j} \\quad \\quad i_j(t) = \\frac{R_p}{R_j} i_o(t) $$\n得出答案 ","date":"Mar 3 2025","externalUrl":null,"permalink":"/docs/uoft/24/electrical-fundamentals/ef9.resistivecircuits/","section":"Docs","summary":"\u003ch2 class=\"relative group\"\u003eEF9.ResistiveCircuits \r\n    \u003cdiv id=\"ef9resistivecircuits\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ef9resistivecircuits\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003eLast Edit: 3/3/25\u003c/p\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eOhm’s Law \r\n    \u003cdiv id=\"ohms-law\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ohms-law\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eOhm’s Law是以德国物理学家 Georg Simon Ohm 的名字命名的，他确立了 Voltage 和 Current 之间的关系，其发现了 Resistor 两端的 Voltage 和通过的 Current 成正比\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eSymbol for a Resistor \r\n    \u003cdiv id=\"symbol-for-a-resistor\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#symbol-for-a-resistor\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/uoft/24/electrical-fundamentals/ef9.resistivecircuits/EF9.ResistiveCircuits_hu8924352349811077473.png 330w,\r\n        /docs/uoft/24/electrical-fundamentals/ef9.resistivecircuits/EF9.ResistiveCircuits_hu14817147965503634486.png 660w,\r\n        /docs/uoft/24/electrical-fundamentals/ef9.resistivecircuits/EF9.ResistiveCircuits_hu14812148851474538778.png 1024w,\r\n        /docs/uoft/24/electrical-fundamentals/ef9.resistivecircuits/EF9.ResistiveCircuits_hu7439742641865735479.png 2x\"\r\n        src=\"/docs/uoft/24/electrical-fundamentals/ef9.resistivecircuits/EF9.ResistiveCircuits_hu14817147965503634486.png\"\r\n        alt=\"EF9.ResistiveCircuits.png\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 9. Resistive Circuits","type":"docs"},{"content":" Last Edit: 2/22/25\n很多情况下，需要连续处理多个值，而分别给他们赋值则显得特别麻烦，于是就需要一种更加高效的数据结构\n7.1 Why and how to use arrays ? #\r假设现在需要统计全班 400 个人的成绩，不可能创建 400 个 Varibale 将成绩和名称一一赋值，更高效的做法是创建一个 Array 通过 int grades[7] 就可以 Declare 一个 Array 想要挨个指定 Array 内 Element 的值，则需要挨个指定 grades[0] = 100; grades[1] = 95; grades[2] = 67; grades[3] = 99; grades[4] = 72; grades[5] = 101; grades[6] = 200; 在 C 语言中，访问 Array 的第一个值，需要用 0 作为 Index 如果不想要一一赋值，可以直接 Initialize Array，直接 `int grades[7] = {100,95,67,99,72,101,200} 就可以完成定义并赋值 对于 Array 来说，他的 Size 在整个程序中都是固定的，定义他的大小的方式有很多种 #define SIZE 7 int main(void) { int arr[SIZE]; // 等价于 int arr[7]; int x = SIZE; // 等价于 int x = 7; return 0; } 使用 Macro #define 作为宏定义，他的作用是给 7 取了个 Alias 别名 叫做 SIZE，这样在运行的时候，所有 SIZE 都会被替换成 7 int main(void) { const int Size = 7; int arr[Size]; // 在某些编译器中可能不合法 int x = Size; return 0; } 或者常规的使用 const 来定义 ex. Find Avg of an array #\r整体思路就是累加 Array 的每一个元素，后将和处以元素个数 #include \u0026lt;stdio.h\u0026gt; #define SIZE 7 int main(void){ int grades[SIZE] = {100, 95, 67, 99, 72, 101, 200}; int sum = 0; double avg = 0; for (int index = 0; index \u0026lt; SIZE; index++){ sum = sum + grades[index]; } avg = (double) sum / SIZE; printf(\u0026#34;Average is %.2lf\u0026#34;, avg); return 0; } 对于上面的常规遍历操作，会出现以下常见问题 Array Index Range Error #\r想要遍历整个 Array，正确的 index 应该是 0 到 SIZE - 1，也就是说 Array 的最后一个元素是 SIZE - 1，若遍历为 index \u0026lt;= SIZE 则会出现越界错误 同样的，Array 的 start point 也是 index = 0，要从 0 开始不然无法访问到第一个元素 还有就是要将 sum 定义成 double 类型以确保除法不会出现精度问题 7.1.1 ex. Reverse the Elements in an Array #\r这里有很多种方法，书中采取了 Swap 的办法，即把 Low 和 High 配对然后 Swap #include \u0026lt;stdio.h\u0026gt; #define SIZE 6 int main(void){ int arr[SIZE] = {2, 5, 7, 8, 9, 12}; for (int index = 0; index \u0026lt; SIZE; index++){ printf(\u0026#34;%d, \u0026#34;, arr[index]); } printf(\u0026#34;\\n\u0026#34;); for(int low = 0, high = SIZE - 1; low \u0026lt; high; low++, high--){ int temp = arr[low]; arr[low] = arr[high]; arr[high] = temp; } for (int index = 0; index \u0026lt; SIZE; index++){ printf(\u0026#34;%d, \u0026#34;, arr[index]); } printf(\u0026#34;\\n\u0026#34;); return 0; } 7.1.2 Summary of Important Features of Arrays #\r以下总结了一些重要的 Array 的注意事项 第一个元素从 Index = 0 开始 当 Declaring Array 的时候，不是一定需要将 SIZE 给到 [] 中，因为 Compiler 编译器会自动计算 Array 中的元素个数 当 SIZE 大小大于实际元素的时候，如 int array [5] = {1,2} 的情况下，实际上它相当于 int array [5] = {1,2,0,0,0} 的效果，不会报错 同样的，当 SIZE 小于实际元素的时候，如 int array [5] = {1,2,3,4,5,6} 的情况下，程序会提示 warning: excess elements in array initializer 当访问的 index 超出 Array 有的 Elements 个数的时候，会得到 Segmentation Fault 7.2 What are arrays, and how are they stored ? #\r当使用 Array 的时候，所有元素会被 Contiguously Stored in the main memory 假设有 int x[3] = {1,7,3}，首先这是一个 int Array，而一个 int 在 Memory 中会占用 4 Bytes，所以从 Array 的第一个 Element 开始，每一个 Element 都会间隔 4 个 Bytes 既然 Elements 之间是 Contiguously 的，那么可以发现，Array 自身的名字本质上就是一个指向 Array 中第一个元素的 Pointer，即 x == \u0026amp;x[0] 既然 Array 的本质就是 Pointer，那么就有 x+1 等价于 \u0026amp;x[1]，总结就是 x[i] == *(x + i) == *( \u0026amp;x[i] ) Array 的第 i 个元素等价于 x+i 的解引用等价于 Array 的 index 为 i 的元素的 Address 的解引用 7.2.1 Pointer Arithmetic #\r明白了 Array Identifier 是一个指向第一个 Element 的 Pointer 后，Pointer Arithmetic 在理解 Array 中的 Elements 是如何连 Contiguously Stored 在 Memory 中有很重要的作用 简单来说，Pointer 和正常的 Variable 不一样，它有着自己的加减乘除方法\n假设有一个 int x[] = {1,7,3}，现在有如下代码 #include \u0026lt;stdio.h\u0026gt; int main(void) { const int size = 3; int x[size] = {1, 7, 3}; // 定义数组 x int *q = \u0026amp;x[2]; // 指针 q 指向 x[2] int dist = q - x; // 计算指针之间的偏移量 printf(\u0026#34;Dist is %d\\n\u0026#34;, dist); // 输出偏移量 return 0; } 注意这里的 dist 是两个 Pointer 之间的差而不再是普通的值运算，他的值为 $$Dist =\\frac{80-72}{4}$$ 这是因为 Pointer 之间的加减运算以 Data Type 作为单位，而不是 Bytes，或者说 Pointer 之间计算的差值为 Number of Elements 而不是 Address 的 Bytes Difference 这里由于一个 int 为 4 Bytes，所以需要处以 4 作为单位长度 7.3 How do we pass an Array to a function ? #\r在 C 语言中，将 Array 传递给 Function 实际上是传递 Array 第一个 Element 的 Pointer 给到 Function 中，这意味着，Array 本身并不会被复制，因为 Function 接收到的是 Pointer 指向的 Address，Function 内部对 Array 的修改会影响到原 Array，因为他们用的是同一块 Memory #include \u0026lt;stdio.h\u0026gt; double f(int []); // 声明函数，接受一个整数数组 int main(void){ int x[3] = {1, 7, 3}; // 定义一个数组 double result = f(x); // 传递数组 x 给函数 f return 0; } double f(int list[]){ // 这里 list[] 实际上是指针 // statements; } 7.3.1 Size of array in a function is unknown #\r前面提到了，Array 作为一个参数被传入的时候，本质上是传入了指向 First Element 的 Address 的 Pointer，这导致了 Function 并不知道 Array 的实际大小 这就使得想要让 Function 知道 Array 的 Size，必须将 Size 也作为参数传入 #include \u0026lt;stdio.h\u0026gt; int sumData(int[], const int); // 函数声明 int main(void){ int x[3] = {1, 7, 3}; // 定义数组 int result = sumData(x, 3); // 传递数组和大小 printf(\u0026#34;Sum of elements in the array: %d.\\n\u0026#34;, result); return 0; } int sumData(int list[], const int size) { int sum = 0; for (int index = 0; index \u0026lt; size; index++) { sum = sum + list[index]; // 累加数组元素 } return sum; } 可以发现在 int sumData(int[], const int); 部分，指定了 Size 作为参数的传入 7.3.2 Can I use the pointer syntax too ? #\r因为 Array Identifiers 本质上是 Pointer，所以在 Function 内部，*(list + index) 也和 list[index] 等效 #include \u0026lt;stdio.h\u0026gt; int sumData(int*, int); // 使用指针表示数组参数 int main(void) { int x[3] = {1, 7, 3}; int result = sumData(x, 3); // 传递数组 x printf(\u0026#34;Sum of elements in the array: %d.\\n\u0026#34;, result); return 0; } int sumData(int* list, int size) { int sum = 0; for (int index = 0; index \u0026lt; size; index++) { sum = sum + *(list + index); // 使用指针偏移代替数组索引 } return sum; } 可以看到 sumData(int*, int); 直接声明了接受 Pointer，而在 Function 内部则通过偏移量来遍历 Array 这也说明了 int list[] 和 int* list 的等效，无论用这两个的其中哪一个，他们都指向的是 x[0] 所对应的 Address 7.3.3 Are we passing the array by value or by pointers ? #\r下面的例子在其强调了对 Array 的操作都是基于 Address 的特殊性 #include \u0026lt;stdio.h\u0026gt; void swap(int[], int, int); // 交换数组中两个元素 void printArray(int[], const int); // 打印数组元素 int main(void) { int x[5] = {3, 5, 8, 1, 7}; printf(\u0026#34;Before swapping: \u0026#34;); printArray(x, 5); swap(x, 0, 4); // 交换 x[0] 和 x[4] printf(\u0026#34;After swapping: \u0026#34;); printArray(x, 5); return 0; } // 交换 list[i] 和 list[j] void swap(int list[], int i, int j) { int temp = list[i]; list[i] = list[j]; list[j] = temp; } // 遍历并打印数组 void printArray(int list[], const int size) { for (int index = 0; index \u0026lt; size; index++) { printf(\u0026#34;%d \u0026#34;, list[index]); } printf(\u0026#34;\\n\u0026#34;); } 这就说明了代码中，无论是 x 还是 list，拿到的都是同一个 Array 的同一系列地址 ","date":"Feb 22 2025","externalUrl":null,"permalink":"/docs/uoft/24/learning-programming-with-c/lpc7.arrays/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 2/22/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e很多情况下，需要连续处理多个值，而分别给他们赋值则显得特别麻烦，于是就需要一种更加高效的数据结构\u003c/p\u003e","title":"LPC 7. Arrays","type":"docs"},{"content":" Last Edit: 2/20/25\nFaraday’s Law of Induction #\r任何封闭电路中 Induced Current 大小，等于穿过这一电路 Magnetic Flux 的变化率 已知 Magnetic Flux 的定义即为 \\(\\Phi_B=\\int B\\cdot dA\\) Experiment on change of Magnetic Flux #\r如图所示，现在有两个独立闭合电路 当开关 S 闭合后，右侧电路会生成一个 Magnetic Field，此时左侧度数瞬间有读数后消失，这表明了 Change in Magnetic Flux caused the Induced Charge in the left loop EMF Electromotive Force #\rEMF 实际上被叫做 Electromotive Force，即电动势，虽然名字中有 Force，但其实际上是 Potenial Difference，单位是 Volt 在 Faraday\u0026rsquo;s Law 中，emf 由 Induced Charge 引起 EMF 来自来源于早期的电学研究，当时科学家认为电池、电机等装置“推动”电荷，所以称之为“电动势”，尽管它的单位和电压一样（伏特, V），但两者有一些区别\nFaraday\u0026rsquo;s Law 给出 EMF 的数学表达为 $$\\mathcal{E} = -\\frac{d\\Phi_B}{dt}$$ \\(\\mathcal{E}\\) 是 EMF \\(\\Phi_B\\) 是 Magnetic Flux t 是时间 负号（来自Lenz\u0026rsquo;s Law）表示感应电流方向总是抵抗磁通量的变化 也就是说当磁通量随时间变化时，就会在回路中产生 EMF，推动电荷流动，从而形成Induced Charge Coil #\r当存在多匝线圈的时候，Total EMF 为 $$\\mathcal{E} =−N\\frac{dΦB}{dt}​​$$ Ways of changing Magnetic Flux #\r已知 \\(ΦB​=BAcosθ\\)，可以知道想要改变 Magentic Flux，可以改变 Magnitude of Magnetic Flux，Area of Coil \u0026amp; Angle Between A \u0026amp; B Lenz\u0026rsquo;s Law #\rAfter Faraday propsed his law of induction, Heinrich Friedrich Lenz devised a rule for determinging the direction of an induced current in a loop 楞次定律描述了感应电流的方向，它的核心思想是 Induced Current 会产生一个 Magnetic Field 来抵抗 Magnetic Flux 的变化 换句话说，线圈中的 Induced Current 会尽可能 Resisit Magnetic Flux 的增加或减少 *如果磁通量增加，感应电流会产生一个相反方向的磁场来抵抗增加 如果磁通量减少，感应电流会产生一个相同方向的磁场来补偿减少\n当 Magnet 靠近 Coil 时，Magnetic Flux 增加，Coil 会产生一个向北的 Magentic Field 以抵抗 Change in Magnetic Flux，通过 Right Hand Rule 就可以确定这一 Magnetic Field 是由 CCW 方向的 Induced Current 形成的 Induction and Energy Transfers #\r现在有以下场景，一个闭合的导体电路在一个 Uniform Magnetic Field 中被拉出 这一运动的结果是，Magnetic Flux 减少 根据 Faraday\u0026rsquo;s Law，回路中产生 Induced Current 根据 Lenz\u0026rsquo;s Law，Induced Current 方向会抵抗磁通量的减少，形成 CW 前面没有提到的是，这一个过程必然会产生一个 Force，即拉动线圈的过程中，EMF 会产生一个和拉动方向相反的 Force，而这一个 Force 于 Velocity 平行，有 \\(P=Fv\\)，这一做功将最终转换成 Induced Current 中的 Electric Energy，即能量守恒 Induced EMF #\r已知 \\(\\mathcal{E} = -\\frac{d\\Phi_B}{dt}\\)，由于上面的回路在 Magnetic Field 中被拉出，Magnetic Flux 的变化为 $$\\mathcal{E}=BLv$$ Induced Current #\r根据 Ohm\u0026rsquo;s Law， $$i=\\frac{\\mathcal{E}}{R}=\\frac{BLv}{R}$$ Opposing Force #\r根据洛伦兹力作用，有 $$F=iLB=\\frac{B^2L^2v}{R}$$ Rate of Work #\r与上方同理，外力做功为 $$P=Fv=\\frac{B^2L^2v^2}{R}$$ Thermal Energy Dissipation #\rCurrent 在 Resistor 中流动的时候，一部分 Energy 会损耗为 Thermal Energy，有 $$P=i^2R=(\\frac{BLv}{R})^2R=\\frac{B^2L^2v^2}{R}$$ ex. Comparison of EMF #\r现在有四个 Wire Loop，依次要穿过 Magnetic Field，要求比较 EMF 大小，已知 Faraday\u0026rsquo;s Law \\(\\mathcal{E} =BLv​​\\)，只有垂直于运动方向的边长才决定 Induced EMF 大小，有 (a)\\(\\mathcal{E} = B L v\\) (b)\\(\\mathcal{E} = B L v\\) (c)\\(\\mathcal{E} = B (2L) v\\) (d)\\(\\mathcal{E} = B (2L) v\\) Eddy Currents #\rEddy 涡流是闭合导体在变化的磁场中产生的环形感应电流，类似于水中的漩涡 假设我们用 Conductor Board 代替之前的闭合导体回路 由于磁通量变化，根据 Faraday\u0026rsquo;s Law，导体中会产生 Induced Current 但由于导体是连续的金属板，电流不会沿着单一路径流动，而是形成 Eddy Current 这些感应电流与磁场相互作用，产生反作用力，阻碍导体的运动 Inductors and Inductance #\rCapacitor 用于产生所需的 Electric Field，而 Inductor 用于产生所需的 Magnetic Field Solenoid 是最基本的电感器，当电流 i 通过其线圈时，产生磁通量 ΦB​ Inductor L 通过磁通量 \\(\\Phi_B\\) 定义为： $$L = \\frac{N \\Phi_B}{i}$$ N 是线圈的匝数 \\(\\Phi_B\\) 是磁通量 i 是电流 Inductor 的单位是亨利（Henry, H） 1 亨利的定义： \\(1 H = 1 T \\cdot m^2 / A\\) 如果1 安培电流变化 1 秒，导致1 伏特感应电动势（EMF），则电感值为 1 亨利 对于 Solenoid，其单位长度的电感为： $$\\frac{L}{l} = \\mu_0 n^2 A$$ \\(\\mu_0\\) 是真空磁导率（\\(4\\pi \\times 10^{-7} H/m\\)） n 是每单位长度的匝数（匝数密度） A 是螺线管的横截面积 Property of Inductance #\r电感 L 仅取决于电感器的几何结构（类似于电容器的电容取决于板间距离和面积） 线圈匝数的平方关系 若匝数增加 n 倍，则： 磁通量 \\(\\Phi_B\\) 增加 n 倍（因为磁场 B 增加） 电感 L 增加 \\(n^2\\) 倍，因为磁通量和线圈匝数同时增加 Self-Induction #\r就像是一个具有 Mass 的物体存在惯性，抵抗瞬间产生的加速度一样，当 Current 在快速变化的时候，Inductor 会通过 Induced EMF 进行反抗 也就是说当 Current 变化的时候，Inductor 根据公式 \\(\\mathcal{E} =−L\\frac{di}{dt}​​\\) 产生一个 Induced Current Opposing the change 来 “缓冲” 这一变化 Energy Stored in a Magnetic Field #\rInductor 在 Current 流过时会储存能量，该能量由磁场存储，并由以下公式计算 $$U_B​=\\frac{1}{2}Li^2$$ \\(U_B\\)​ 是存储的 Magnetic Energy（单位： J） L 是 Inductor（单位： H） i 是线圈中的 Current（单位： A） 电容器存储电场能量（\\(\\frac{1}{2} C V^2\\)），电感器存储磁场能量（\\(\\frac{1}{2} L i^2\\)）\n","date":"Feb 20 2025","externalUrl":null,"permalink":"/docs/uoft/24/electrical-fundamentals/ef8.inductioninductance/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 2/20/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eFaraday’s Law of Induction \r\n    \u003cdiv id=\"faradays-law-of-induction\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#faradays-law-of-induction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e任何封闭电路中 Induced Current 大小，等于穿过这一电路 Magnetic Flux 的变化率\u003c/li\u003e\n\u003cli\u003e已知 Magnetic Flux 的定义即为 \\(\\Phi_B=\\int B\\cdot dA\\)\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eExperiment on change of Magnetic Flux \r\n    \u003cdiv id=\"experiment-on-change-of-magnetic-flux\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#experiment-on-change-of-magnetic-flux\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e如图所示，现在有两个独立闭合电路\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/uoft/24/electrical-fundamentals/ef8.inductioninductance/EF8.Induction\u0026amp;Inductance-1_hu7387844013605343016.png 330w,\r\n        /docs/uoft/24/electrical-fundamentals/ef8.inductioninductance/EF8.Induction\u0026amp;Inductance-1_hu15348448422353166210.png 660w,\r\n        /docs/uoft/24/electrical-fundamentals/ef8.inductioninductance/EF8.Induction\u0026amp;Inductance-1_hu15379995169890920571.png 1024w,\r\n        /docs/uoft/24/electrical-fundamentals/ef8.inductioninductance/EF8.Induction\u0026amp;Inductance-1_hu1971224904868116517.png 2x\"\r\n        src=\"/docs/uoft/24/electrical-fundamentals/ef8.inductioninductance/EF8.Induction\u0026amp;Inductance-1_hu15348448422353166210.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 8. Induction \u0026 Inductance","type":"docs"},{"content":" Last Edit: 2/20/25\n上一章中提到的所有有关于 Function 的内容都是关于一个函数的输入以及输出的，本章将讨论如何在不同函数间访问 Variables\n6.1 Why Pointers ? #\r前面提到的所有有关 Function 的操作的返回值 return 都是唯一的，这是一个需要解决的问题 6.1.1 Communicate using return #\rbool isPerfectSquare(int x) { if ((int)sqrt(x) != sqrt(x)) { return false; } else { return true; } } 以上是一段代码中的其中一个 Function，其存在了两个函数的输出，这使得 Function 可以提供多种不同的输出 但是这也成为了一个问题，就是当存在多个判断值 if 的时候，可能会导致错误，为了避免这个问题，可以通过将 return 的触发条件简化，如 bool isPerfectSquare(int x) { return ((int)sqrt(x) == sqrt(x)); } 确保了函数存在且只存在一个 return ，其具体的值将由具体Bool Value决定 Calling by Value #\r在一个参数进入Function的时候，实际上传入的是其副本而不是变量本身，这代表了函数中对于变量进行的任何操作实际上不会改变外部定义的Variable本身 #include \u0026lt;stdio.h\u0026gt; void simple(int); int main(void) { int p = 12; simple(p); printf(\u0026#34;The value of p is %d.\\n\u0026#34;, p); return 0; } void simple(int p) { p = p / 2; } -\u0026gt; The value of p is 12. 想要更改就需要首先从函数里 return ，其次再把值传给p，具体代码如下 #include \u0026lt;stdio.h\u0026gt; int simple(int); int main(void) { int p = 12; p = simple(p); //传入数值 printf(\u0026#34;The value of p is %d.\\n\u0026#34;, p); return 0; } int simple(int p) { p = p / 2; return p; //函数主动返回数值 } 6.1.2. Limitation of return #\r前面提到了 return 采取的本质是 Call by Value 按值传递的机制，具体来说，在调用函数的时候参数会接收变量的副本，这使得函数内部进行的更改不会影响外部 #include \u0026lt;stdio.h\u0026gt; void swap(int, int); int main(void) { int a = 9, b = 13; printf(\u0026#34;Before swapping\\nValue of a: %d\\nValue of b: %d\\n\u0026#34;, a, b); swap(a, b); printf(\u0026#34;After swapping\\nValue of a: %d\\nValue of b: %d\\n\u0026#34;, a, b); return 0; } void swap(int x, int y) { int temp = x; x = y; y = temp; } 6.2 What are Pointers ? #\rPointers 指针是存储变量地址的变量\n现在有以下代码 #include \u0026lt;stdio.h\u0026gt; int main(void) { int x = 7; // x 是一个 int 变量 int *p; // p 是一个指向 int 的指针变量 return 0; } 可以说Declear p的过程就是为一个 int 变量预留了内存空间 前面提到过了 declaring a variable without initializing it 使得其变成一个 Garbage Value 这边 Declar 的一个 Piont 就是专门用来指向 Memory 的，但目前还没有指向具体目标 #include \u0026lt;stdio.h\u0026gt; int main(void) { int x = 7; // 声明一个整型变量 x 并初始化为 7 int *p; // 声明一个整型指针 p p = \u0026amp;x; // 将 x 的地址赋给指针 p int y; // 声明一个整型变量 y y = *p; // 将指针 p 指向的地址（x 的地址）中的值赋给 y return 0; // 函数返回 0 } 在上面的代码基础上，令 p 指向了 x的地址，之后再把 x的值赋给了 y 需要注意的是赋值之后 x 的值的改变将不再影响到 y\n#include \u0026lt;stdio.h\u0026gt; int main(void) { int x = 7; int *p; p = \u0026amp;x; int y; y = *p; printf(\u0026#34;Address of x: %p\\n Value of x: %d\\n\u0026#34;, \u0026amp;x, x); printf(\u0026#34;Address of p: %p\\n Value of p: %p\\n\u0026#34;, \u0026amp;p, p); printf(\u0026#34;Address of y: %p\\n Value of y: %d\\n\u0026#34;, \u0026amp;y, y); printf(\u0026#34;Value stored in address %p is %d\\n\u0026#34;, p , *p); return 0; } 通过这段代码就可以看出 x，p 和 y 之间的关系 Address of x: 0x30e2af178\rValue of x: 7\rAddress of p: 0x30e2af170\rValue of p: 0x30e2af178\rAddress of y: 0x30e2af16c\rValue of y: 7\rValue stored in address 0x30e2af178 is 7 x 作为一个很正常的 Variable，地址是 0x30e2af178 ，值是 7，而 p 作为Pointer，地址是一个新的内存，而值应该是 x 的地址 0x30e2af178 ，而 y 也是一个独立的 Variable 6.3 Use Pointers to Communicate #\r既然解决了前面提到的 Call by Value 的问题，就能通过 Points 解决如 loop，function 内部 Variable 的问题了 #include \u0026lt;stdio.h\u0026gt; void swap(int*, int*); int main(void) { int a = 9, b = 13; printf(\u0026#34;Before swapping\\nValue of a: %d\\nValue of b: %d\\n\u0026#34;, a, b); swap(\u0026amp;a, \u0026amp;b); printf(\u0026#34;After swapping\\nValue of a: %d\\nValue of b: %d\\n\u0026#34;, a, b); return 0; } void swap(int* x, int* y) { int temp = *x; *x = *y; *y = temp; } 当 Variable 本身已经是一个 Pointer 的时候，*x 则变成了解析值，也就是该内存下储存的值，上面的例子中，swap 中的 int temp = *x; 则是令 temp 等于 Pointer x 的值也就是 9 *x = *y;，已知 x 是 \u0026amp;a，也就是变量 a 的地址，而 *x则就是变量 a 的 Value，对于 y 同理，那么这一行就代表了 a = b，将 b 的值赋值给 a，有 6.3.1 Size of pointer Variable #\r前面提到了以前的机器采用 32 bits 表示内存，而现今的采用 64 bits， #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(void) { printf(\u0026#34;Size of pointer (int*) is %d.\\n\u0026#34;, sizeof(int*)); printf(\u0026#34;Size of pointer (double*) is %d.\\n\u0026#34;, sizeof(double*)); printf(\u0026#34;Size of pointer (bool*) is %d.\\n\u0026#34;, sizeof(bool*)); printf(\u0026#34;Size of pointer (char*) is %d.\\n\u0026#34;, sizeof(char*)); return 0; } 使用 sizeof 就可以知道一个变量的 Size，即在这里是 8 bytes (64 bits) 6.3.2 Can a pointer hold address of another pointer ? #\r一个 Pointer 确实可以指向另一个 Pointer 的地址，因为他们本质上都是 Address 一个 Int 的 Pointer 为 int* 而他的 Pointer 则是 int**，即每一次加一个 * 变量 存储的地址 存储的值 i 45 10（整数值） pi 46 45（即 i 的地址） ppi 47 46（即 pi 的地址） 6.3.3. Can a function return a pointer? #\r可以，以下 function 就是一个接收 Pointer，在函数内部使用 * 访问 Pointer 值，在比较大小后返回较大的值的 Pointer 的一个函数 #include \u0026lt;stdio.h\u0026gt; double* largestValLoc(double*, double*); double* largestValLoc(double* a, double* b) { double* temp; if (*a \u0026gt; *b) { temp = a; // temp is double* and a is double*, so temp = a is permissible } else { temp = b; } return temp; // temp is double*, and return type is double* } int main(void) { double x = 2.6, y = 7.3; double* p = largestValLoc(\u0026amp;x, \u0026amp;y); // pass address of x to a, and address of y to b // p is (double*) and largestValLoc returns (double*) printf(\u0026#34;Address of x: %p having value %.1lf.\\n\u0026#34;, \u0026amp;x, x); printf(\u0026#34;Address of y: %p having value %.1lf.\\n\u0026#34;, \u0026amp;y, y); printf(\u0026#34;Address of larger variable: %p.\\n\u0026#34;, p); return 0; } 6.3.4. Initialization Vs. Declaration of a pointer variable #\rDeclaration 和 Initialization 也存在着区别 Declaration 声明 #\rDeclaration 告诉了编译器 Variable 的 Type，并为其分配了 Memory，在这时 Variable 仅被创造而未被赋值 （存储了不确定的“垃圾值”） int x; // 仅声明 x，x 里面的值是不确定的（垃圾值） int *p; // 仅声明指针 p，但 p 没有指向任何有效地址（垃圾指针） 上方代码只做了 Variable 的 Declaration 而未赋值，在运行时会报错 #include \u0026lt;stdio.h\u0026gt; int main() { int* p; // 仅声明指针 p，但未初始化 *p = 5; // 试图通过 p 访问地址并赋值 return 0; } -\u0026gt; warning: variable \u0026#39;p\u0026#39; is uninitialized when used here [-Wuninitialized] *p = 5; ^ Initialization 初始化 #\r在 Declare Variable 的同时赋予其一个值 int x = 5; // 声明并初始化 x，x 现在存储 5 int *p = \u0026amp;x; // 声明并初始化指针 p，使其指向 x 这里给 x 赋值了 5，给 Pointer 赋值了 x 的 Address Null #\r在 C 语言中，Null 是一个特殊的值，当用作值时为 0，而代表地址的时候表示 “不指向任何有效地址”，他的主要作用时防止未初始化的指针指向随机地址导致程序崩溃 int *p; // ❌ 未初始化的指针 *p = 5; // 可能会崩溃（指向垃圾地址） 上述代码中，由于 pointer 未被 Initialize，则会产生 Segmentation Fault 问题，修正的办法则是通过 Null int *p = NULL; // ✅ 初始化为 NULL if (p != NULL) { *p = 5; // 只有当 p 指向有效地址时才执行 } 这就提供了一种安全的检查指针是否有效的办法 ex. #\r#include \u0026lt;stdio.h\u0026gt; int *confuse(int *x, int *y) { (*y)++; y = x; *y = 10; return (y); } int main(void) { int a = 6, b = 7; int *f = \u0026amp;b; f = confuse(\u0026amp;a, \u0026amp;b); (*f)++; printf(\u0026#34;a = %d and b = %d\\n\u0026#34;, a, b); return 0; } 步骤 变量 a 变量 b 指针 f 初始化 6 7 \u0026amp;b (*y)++ (b++) 6 8 \u0026amp;b y = x（y 指向 a） 6 8 \u0026amp;b *y = 10（修改 a） 10 8 \u0026amp;b return y;（返回 \u0026amp;a，即 f = \u0026amp;a） 10 8 \u0026amp;a (*f)++（a++） 11 8 \u0026amp;a 所以最后的结果为 a = 11, b = 8 6.4. Rules defining scope of variables #\rScope 代表了在编译器中，Variable 应该出现在哪些位置才能被正确的使用 6.4.1. Variables can only be used after they are declared #\r必须要先 Declare Varibale 后才能赋值 int main() { i = 0; int i; return 0; } 这就会报错 compile-time error Local Variables #\r在 Function 内部声明的变量称为 Local Variables，它的 Scope 从被 Declare 开始到 Function 结束时结束 6.4.2. Use a variable declared in a compound statement #\r在 C 语言中，Variable Scope 受 {} 所限制，即其只能在它被 Declare 的 Compound Statement 内部可见，在 {} 外部的调用会导致 Undeclared Identifier #include \u0026lt;stdio.h\u0026gt; int main() { int i = 0; // 变量 i 在 main() 作用域内有效 { // 复合语句（新的作用域） int x = 5; printf(\u0026#34;Inside compound statement: x = %d.\\n\u0026#34;, x); // ✅ 正确，x 在作用域内 } // ❌ 错误：x 作用域结束，无法访问 printf(\u0026#34;Outside compound statement: x = %d.\\n\u0026#34;, x); return 0; } 对于上面的这种情况，解决方案就是分离 Declaration 和 Initialization #include \u0026lt;stdio.h\u0026gt; int main() { int i = 0; int x; // 声明 x 在整个 main() 内有效 { x = 5; printf(\u0026#34;Inside compound statement: x = %d.\\n\u0026#34;, x); } printf(\u0026#34;Outside compound statement: x = %d.\\n\u0026#34;, x); // ✅ 正确 return 0; } 通过在 Compound Statement 外部的声明使得其 Scope 变化至整个 main() 中 6.4.3. External identifiers/global variables #\r在 C 语言中，Global Varibale 在整个程序中都是可见的 #include \u0026lt;stdio.h\u0026gt; int i = 0; // ✅ 全局变量 i，所有函数都可以访问 void func(); // 函数声明 int main(void) { printf(\u0026#34;In main: Global variable i = %d.\\n\u0026#34;, i); // 输出 i = 0 func(); // 调用 func() printf(\u0026#34;In main after calling func: Global variable i = %d.\\n\u0026#34;, i); // 输出 i = 5 return 0; } void func() { printf(\u0026#34;In func: Global variable i = %d.\\n\u0026#34;, i); // 输出 i = 0 i = 5; // ✅ 修改全局变量 i } 在 C 语言中，External Identifier 通常指的是 在函数外部声明的变量、函数或其他可被多个文件访问的实体，其主要特性是 Scope 覆盖整个程序 6.4.4. Overlapping scope #\r不同 Scope 下可以 Declare 具有相同名称的同名变量，由于这一个 Scope 的 Overlap，可能会导致变量的 Shadowing #include \u0026lt;stdio.h\u0026gt; int main(void) { int i = 1; // ✅ 作用域：整个 main() 函数 printf(\u0026#34;Outer i = %d.\\n\u0026#34;, i); // 输出 1 { int i = 2; // ✅ 作用域：仅限于这个 `{}` 块 printf(\u0026#34;Inner i = %d.\\n\u0026#34;, i); // 输出 2 } printf(\u0026#34;Outer i = %d.\\n\u0026#34;, i); // 输出 1 return 0; } 可以发现，Variable 是否会被修改取决于是否出现了多个 Declarations，对于 6.4.3 中的代码来说，全局只有一个 Declaration，即 int i = 0 ，而在 6.4.4 中存在两个 Declarations，int i = 1，int i = 2，这就导致了 Cpmpound Statement 内部的修改不会影响到外部\n6.5. Goldbach conjecture #\r写一个程序来检查给定偶数是否符合 Goldbach Conjecture 哥德巴赫猜想 6.5.1 Problem Statement #\r他的猜想如下，所有大于 2 的偶数都可以表示为两个质数的和 6.5.2 Divide Problem into sub-problems #\r获取用户输入 —— 读取用户输入的偶数 验证输入是否合法 —— 确保输入是大于 2 的偶数 验证哥德巴赫猜想 —— 查找是否存在两个质数相加等于该数 输出结果 —— 打印该数是否符合哥德巴赫猜想 6.5.2.1. Take input from the user #\r首先要确保 Input 大于 2，有 void getUserInput(int *number) { // Get user input from the keyboard // and validates it is even and greater than 2 do { printf(\u0026#34;Enter a number to test the Goldbach conjecture: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, number); } while (*number \u0026lt;= 2 || *number % 2 != 0); } 优化代码如下 #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; void getUserInput(int*); int main(void) { int num; getUserInput(\u0026amp;num); return 0; } void getUserInput(int *number) { // 获取用户输入，并验证其是否为大于 2 的偶数 bool firstEntry = true; // 标记是否是第一次输入 do { if (firstEntry) { printf(\u0026#34;Enter a number to test the Goldbach conjecture: \u0026#34;); firstEntry = false; } else { printf(\u0026#34;Your input was invalid, please enter another even number \u0026gt; 2: \u0026#34;); } scanf(\u0026#34;%d\u0026#34;, number); } while (*number \u0026lt;= 2 || *number % 2 != 0); } 6.5.2.2. Test the Goldbach #\r现在要验证猜想，给定一个偶数，遍历小于它的一半的质数，依次将他们从偶数上减去，判断差是否为质数，后重复过程 几个需要用到的函数有 bool isPrime(int); ，void nextPrimeNumber(int*); bool testGoldbach(int N) { // 测试哥德巴赫猜想 // 如果验证成功返回 true，否则返回 false int x = 2, y; bool rejected = false; bool verified = false; while (!rejected \u0026amp;\u0026amp; !verified) { y = N - x; if (isPrime(y)) { verified = true; // 找到了 x + y = N 的质数对 } else if (y \u0026lt; x) { rejected = true; // 当 x \u0026gt; y 时，仍未找到符合条件的 x, y } else { nextPrimeNumber(\u0026amp;x); // 递增 x 到下一个质数 } } return verified; // 如果找到了两个质数，则返回 true，否则返回 false } 6.5.2.3. Get the Next Prime Number #\r获取下一个质数的函数需要自己定义，逻辑就是在当前值上 + 1，并判断是否是 Prime Number，若是则返回，不是则循环 void nextPrimeNumber(int *px) { // We will look for the numbers after *pFrist one by one // until we find the next prime number int value = *px + 1; while (!isPrime(value)) { value += 1; } *px = value; } 6.5.2.4. Find If a Number Is Prime or Not #\r判断 Prime Number 的函数也需要实现，有 bool isPrime(int num) { // check if num is prime, by checking the remainder of num / all numbers from // 2 to num - 1 bool prime = true; if (num \u0026lt; 2) { prime = false; } else { for (int denom = 2; denom \u0026lt;= num - 1 \u0026amp;\u0026amp; prime; denom++) { if (num % denom == 0) { prime = false; } } } return prime; } 逻辑就是遍历比它小的所有大于 2 的数，挨个除过去看余数是否为 0 ，若皆不为 0 ，则是 Prime Number 6.5.2.5. Print If the Conjecture Is Verified #\r还需要一个输出函数 完全不需要这个\nvoid printConjResult(int number){ //Call a function to verify the conjecture and prints the result bool verified = testGoldbach(number); if(verified){ printf(\u0026#34;Goldbach conjecture is verified.\\n\u0026#34;); } else{ printf(\u0026#34;Goldbach conjecture not verified.\\n\u0026#34;); } } 6.5.3. Integrate all pieces/functions #\r完成了所有函数的实现后，整合所有函数实现完整流程 int main(void){ int number; getUserInput(\u0026amp;number); printConjResult(number); return 0; } -\u0026gt; Enter a number to test the Goldbach conjecture: **9** Your input was invalid, please enter another number \u0026gt; 2: **8** Goldbach conjecture is verified. ","date":"Feb 20 2025","externalUrl":null,"permalink":"/docs/uoft/24/learning-programming-with-c/lpc6.pointers/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 2/20/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e上一章中提到的所有有关于 Function 的内容都是关于一个函数的输入以及输出的，本章将讨论如何在不同函数间访问 Variables\u003c/p\u003e","title":"LPC 6. Pointers","type":"docs"},{"content":" Last Edit: 2/8/25\nMagnetic Field #\r与 Electric Field 一般，Magnetic Field 也是由 Magnetic Charge 产生的 虽然理论上存在 Individual Magnetic Charges (AKA Magnetic Monopoles) 但是尚未被证实 Creation of Magnetic Fields #\r通常来说磁场通过两种方式形成，一个是 Electrically Charged Particles 比如导线中的电流形成的 Magnetic Field 另一种则是通过 Elementary Particles 基本粒子，如 Electron 等形成的 Intrinsic Magnetic Field 固有磁场 Magnetic Field Strength #\r当 Charged Particle 在 Magnetic Field 中移动的时候，它受到的力为 $$\\vec F_B=q(\\vec v\\times\\vec B)$$ 其中 \\(\\vec v\\) 为 Velocity Vector Magnetic Field Strength 的力的方向则是 Cross Product 方向，即通过 Right Hard Rule 给出 具体来说 Magnitude 为 $$F_B=|q|v_B\\sin\\phi$$ 其中 \\(\\phi\\) 为 Velocity 和 Magnetic Field 之间的夹角 Magnetic Field Strength 的单位为 Tesla，有 $$1 , \\text{tesla} = 1 , \\text{T} = \\frac{1 , \\text{newton}}{(\\text{coulomb})(\\text{meter/second})}$$ Direction of Magnetic Field #\r磁场线从磁体的 North Pole 指向 South Pole，和 Charged Particle 一般，同性相斥异性相吸 ex. Magnetic Force on a moving charged particle #\rA uniform magnetic field \\(\\vec{B}\\), with a magnitude of \\(1.2 , \\text{mT}\\), is directed vertically upward throughout the volume of a laboratory chamber. A proton with kinetic energy \\(5.3 , \\text{MeV}\\) enters the chamber, moving horizontally from south to north. What magnetic deflecting force acts on the proton as it enters the chamber? The proton mass is \\(1.67 \\times 10^{-27} , \\text{kg}\\). (Neglect Earth\u0026rsquo;s magnetic field.)\n先通过 Energy 求得 Proton 的 Velocity 有 $$v = \\sqrt{\\frac{2K}{m}} = \\sqrt{\\frac{(2)(5.3 , \\text{MeV})(1.60 \\times 10^{-13} , \\text{J/MeV})}{1.67 \\times 10^{-27} , \\text{kg}}} = 3.2 \\times 10^7 , \\text{m/s}$$ 再将速度带入 Magnetic Field Strength，有 $$F_B = |q| v B \\sin \\phi\n= (1.60 \\times 10^{-19} , \\text{C})(3.2 \\times 10^7 , \\text{m/s})\n\\times (1.2 \\times 10^{-3} , \\text{T})(\\sin 90^\\circ)\n= 6.1 \\times 10^{-15} , \\text{N}. , (\\text{Answer})$$ Magnetic Force due to straight current wire #\r对于一条有 Current 的 Wire，当它位于一个 Uniform 的 Magnetic Field 中时，其会收到一个 Magnetic Field Strength \\(\\vec F_b\\) 具体来说，Magnetic Field Force 的方向将由 Current 和 Magnetic Field 的方向决定 Magnetic Field Create by Straight Wire #\r当一个 Current 从一根直的 Wire 中通过的时候，其周围会形成环形磁场 \\(\\vec B\\) Magnetic Field 的方向可以通过 Right Hand Rule 判断 Biot - Savart Law #\r非直线导线中一个长度元素 \\(ds\\) 在距离 r 处的点 P 产生的磁场微分为 $$dB = \\frac{\\mu_0}{4 \\pi} \\cdot \\frac{i , ds , \\sin \\theta}{r^2} $$ 其中的 \\(\\mu_0\\) 为真空磁导率，有 \\(μ0​=4π×10^{−7}T⋅m/A=1.26\\times 10^{-6}T\\cdot m/A\\) 可以得到完整的 Law of Biot and Savart 有 $$dB = \\frac{\\mu_0}{4 \\pi} \\cdot \\frac{i , d\\vec s \\ \\times \\hat r}{r^2} $$ Law of Biot and Savart in Straight current-carrying Wire #\r由 Biot and Savart 公式可以得出一个 Long Straight Wire R 远的距离的 Magnetic Field为 $$B=\\frac{\\mu_oi}{2\\pi R}$$ Law of Biot and Savart in circular wire #\r一个圆弧的导线的圆心处的 Magnetic Field Strength 有 $$B = \\frac{\\mu_0 i \\Phi}{4 \\pi R}$$ Force Between Two Parallel Currents #\r已知一根带有 Current i 的 Straight Wire 的 Magnetic Field 有 $$\\vec F_b=i\\vec L\\times \\vec B$$ 两根平行导线之间的力是由于其中一根导线产生的磁场作用在另一根导线上的结果 导线 a 产生的磁场 \\(B_a\\) 在 b 位置为 \\(B_a = \\frac{\\mu_0 i_a}{2 \\pi d}\\)，即 b 收到的 Magnetic Field Strength 为 $$F_{ba} = i_b L B_a \\sin 90^\\circ = i_b L \\cdot \\frac{\\mu_0 i_a}{2 \\pi d} \\Rightarrow F_{ba} = \\frac{\\mu_0 L i_a i_b}{2 \\pi d}$$ Ampere\u0026rsquo;s Law #\rAmpere\u0026rsquo;s Law，通过一个假想的称为安培环（Ampereian Loop）的假想闭合路径来分析电流周围的磁场 Ampereian Loop 安培环 #\rAmpereian Loop 是一个假想的闭合路径，用于计算路径所包围的 Current 对该路径上每一点处磁场的贡献 对于 Ampereian Loop 内部的 Current，有 $$\\oint \\vec{B} \\cdot d\\vec{s} = \\mu_0 i_{enc} \\quad (\\text{Ampere\u0026rsquo;s law})$$ Direction of Magnetic Field #\r通过右手来判断，四指弯曲指向 Integration 方向，大拇指方向则为 Current 方向 Inside \u0026amp; Outside of the Wire #\r在 Long Straight 内外部的 Magnetic Field 是不同的 在外部时，可以通过 Biot - Savart Law 得到 Magnetic Field 为 $$B=\\frac{\\mu_oi}{2\\pi R}$$ ","date":"Feb 8 2025","externalUrl":null,"permalink":"/docs/uoft/24/electrical-fundamentals/ef7.magneticfields/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 2/8/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eMagnetic Field \r\n    \u003cdiv id=\"magnetic-field\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#magnetic-field\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e与 Electric Field 一般，Magnetic Field 也是由 Magnetic Charge 产生的\u003c/li\u003e\n\u003cli\u003e虽然理论上存在 Individual Magnetic Charges (AKA Magnetic Monopoles) 但是尚未被证实\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eCreation of Magnetic Fields \r\n    \u003cdiv id=\"creation-of-magnetic-fields\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#creation-of-magnetic-fields\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e通常来说磁场通过两种方式形成，一个是 Electrically Charged Particles 比如导线中的电流形成的 Magnetic Field\u003c/li\u003e\n\u003cli\u003e另一种则是通过 Elementary Particles 基本粒子，如 Electron 等形成的 Intrinsic Magnetic Field 固有磁场\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eMagnetic Field Strength \r\n    \u003cdiv id=\"magnetic-field-strength\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#magnetic-field-strength\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e当 Charged Particle 在 Magnetic Field 中移动的时候，它受到的力为\n$$\\vec F_B=q(\\vec v\\times\\vec B)$$\u003c/li\u003e\n\u003cli\u003e其中 \\(\\vec v\\) 为 Velocity Vector\u003c/li\u003e\n\u003cli\u003eMagnetic Field Strength 的力的方向则是 Cross Product 方向，即通过 Right Hard Rule 给出\u003c/li\u003e\n\u003cli\u003e具体来说 Magnitude 为\n$$F_B=|q|v_B\\sin\\phi$$\u003c/li\u003e\n\u003cli\u003e其中 \\(\\phi\\) 为 Velocity 和 Magnetic Field 之间的夹角\u003c/li\u003e\n\u003cli\u003eMagnetic Field Strength 的单位为 Tesla，有\n$$1 , \\text{tesla} = 1 , \\text{T} = \\frac{1 , \\text{newton}}{(\\text{coulomb})(\\text{meter/second})}$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eDirection of Magnetic Field \r\n    \u003cdiv id=\"direction-of-magnetic-field\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#direction-of-magnetic-field\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e磁场线从磁体的 North Pole 指向 South Pole，和 Charged Particle 一般，同性相斥异性相吸\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eex. Magnetic Force on a moving charged particle \r\n    \u003cdiv id=\"ex-magnetic-force-on-a-moving-charged-particle\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex-magnetic-force-on-a-moving-charged-particle\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cp\u003eA uniform magnetic field \\(\\vec{B}\\), with a magnitude of \\(1.2 , \\text{mT}\\), is directed vertically upward throughout the volume of a laboratory chamber. A proton with kinetic energy \\(5.3 , \\text{MeV}\\) enters the chamber, moving horizontally from south to north. What magnetic deflecting force acts on the proton as it enters the chamber? The proton mass is \\(1.67 \\times 10^{-27} , \\text{kg}\\). (Neglect Earth\u0026rsquo;s magnetic field.)\u003c/p\u003e","title":"EF 7. Magnetic Fields","type":"docs"},{"content":" Last Edit: 2/7/25\nElectric Current #\r对于一个铜环，内部每一处都处于同一个 Potential 下，即 In Electrostatic Equilibrium 处于静电平衡，并且内部 Electric Field 均为零 通过添加一个 Battery，可以形成一个 Potential Difference，产生一个 Electric Field，之后推动 Charge 移动，导致了 Current 电流的产生\nDirection of electric Current #\r电流的方向被定义为是 Positive 指向 Negative 的，但实际上在电路中移动的是 Electron，由于 Electron 在电路中的移动才产生了 Position Charge 的“移动”，但根据定义，电流方向仍然按照正电荷运动方向定义 约定建立之初，人们尚未了解到电子的存在，导致错误的定义沿用至今\nCurrent #\r对于一个在 Conductor 中的电流，有 $$i=\\frac{dq}{dt}$$ 代表了单位时间内穿过导体截面的电荷量 Kirchhoff\u0026rsquo;s Current Law KCL #\r基尔霍夫电流定律指出，在电路的任意 Junction 处，流入该节点的 Totoal Current 等于流出的 Total Current Current Density #\r电流密度是描述电荷流动分布的重要量，带有方向信息 $$i=\\int\\vec J\\cdot d\\vec A$$ 其中 dA 是垂直于导体表面元素的面积矢量 若电流 i 在截面上均匀分布且平行于 \\(\\vec A\\)，积分就可以化简为 $$i=JA\\Rightarrow J=\\frac{i}{A}$$ Drift Speed #\r在不同 Electirc Force 下，Charge Carriers (Assumed Positive) 会获得一个 Drift Speed \\(\\vec v_d\\)，其方向于 Electric Field 方向一致 并且 Current Density 与 Drift Speed 有 $$\\vec J=(ne)\\vec V_d$$ 其中 n 是单位面积（通常为 \\(1m^3\\) 中 Charge Carrier 的数量） e 则是单个 Charge Carrier 的电荷量 Resistance and Resistivity #\r一个 Conductor 的 Resistance R 被定义为 $$R=\\frac{V}{i}$$ V 是 Conductor 两端的 Potential Difference Resitance 的SI Unit 为 欧姆 \\(\\Omega\\) Resistance 在电路中起到了 Reduce Current Flow，Adjust Signal Levels，Divide Votages 等作用 Resistor Color Code #\r电阻的颜色编码标识了他的电阻值和公差，具体来 前两位代表了电阻值的有效数字，第三位代表了倍率，第四位为公差 例如，红-红-橙-金： 红色（2）、红色（2）、橙色（\\(\\times 1000\\)）、金色（公差 \\(\\pm 5%\\)） 电阻值为 \\(22 \\times 1000 = 22k\\Omega\\)，误差为 \\(\\pm 5%\\) Resitivity 电阻率 #\r与 Capacitance 一样，Resitivity 也是材料的固有属性，用于描述材料对于电流的阻碍能力 $$\\rho=\\frac{1}{\\sigma}=\\frac{E}{J}$$ E 为电场强度，J 为电流密度，Resitivity 的单位是 \\(\\Omega\\cdot m\\) 同样也有 \\(\\vec E=\\rho \\vec J\\)，说明了材料的电阻率越高，相同电流密度下的电场强度就越高 Resistance 电阻 #\rResitivity 描述的是 Material 对 Current 流动的阻碍属性，与其形状和大小无关，而 Resistance 描述的特点物体对电流流动的阻碍，单位是 \\(\\Omega\\)，计算一个 Conductor Resisitance 的方式是 $$R=\\rho\\frac LA$$ A 为 Cross-Sectional Area Temperature \u0026amp; Resisitance #\r大多数材料的 Resistance 会根据温度而变化，由公式 $$\\rho - \\rho_0 = \\rho_0 \\alpha (T - T_0)$$ Ohm\u0026rsquo;s Law #\rOhm\u0026rsquo;s Law 表明，通过一个器件的 Current 总是与施加在器件上的 Potential Difference 成正比 当一个 Conductor 的 Resistance 不依赖于施加的 Potential Difference 的大小和极性时，则其遵守 Ohm\u0026rsquo;s Law 当一个 Material 的 Resitivity 不依赖于施加的 Electric Field 的大小和方向时，其遵守欧姆定律 Ohm\u0026rsquo;s Law 也就是说当它们的 Resistance 和 Resitivity 是固有属性的时候，他们就遵守 Ohm\u0026rsquo;s Law\nPower #\rPower 是能量转换的速率，其最基本的计算公式为 \\(P=iV\\)，单位为瓦特 利用 Ohm\u0026rsquo;s Law，可以改写成 $$P=i^2R=\\frac{V^2}{R}$$ ","date":"Feb 7 2025","externalUrl":null,"permalink":"/docs/uoft/24/electrical-fundamentals/ef6.currentresistance/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 2/7/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eElectric Current \r\n    \u003cdiv id=\"electric-current\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#electric-current\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e对于一个铜环，内部每一处都处于同一个 Potential 下，即 In Electrostatic Equilibrium 处于静电平衡，并且内部 Electric Field 均为零\n\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/uoft/24/electrical-fundamentals/ef6.currentresistance/EF6.Current\u0026amp;Resistance_hu12897430973313359960.png 330w,\r\n        /docs/uoft/24/electrical-fundamentals/ef6.currentresistance/EF6.Current\u0026amp;Resistance_hu13147796366552973561.png 660w,\r\n        /docs/uoft/24/electrical-fundamentals/ef6.currentresistance/EF6.Current\u0026amp;Resistance_hu4088479549258487442.png 1024w,\r\n        /docs/uoft/24/electrical-fundamentals/ef6.currentresistance/EF6.Current\u0026amp;Resistance_hu7321396153845132530.png 2x\"\r\n        src=\"/docs/uoft/24/electrical-fundamentals/ef6.currentresistance/EF6.Current\u0026amp;Resistance_hu13147796366552973561.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 6. Current \u0026 Resistance","type":"docs"},{"content":" Last Edit: 2/6/25\nCapacitor 电容器是一种储存 Electrical Energy 的装置，由两个相互隔离的导体（即极板）组成，分别带有 +q 和 -q 的电荷\n5.1 Capacitance 电容 #\rCapacitance 电容代表了导体储存 Charge 的能力，表示一个电容器在一定的电压下能储存多少电荷，其基本定义是 $$q=CV$$ 其中 \\(V\\) 是两个 Plate 极板之间的 Potential Difference Charging a Capacitor #\r要使 Capacitor 充电，需要利用到电池两侧初始存在的 Potential Difference 由于电池两侧存在 Potential Difference，于是就形成了一个 Electirc Field，电场会对电荷产生一个 Force \\(F=qE\\) ，这使得电荷在电场中受力，正电荷从负极电极到了正极（正电荷是不会移动的，只有负电荷会，这里的“移动”是假设”，负电核到了正极 举一个例子就是假设一开始电池具有 10 V 的电压，充电完成后正极板上有 +10V，负极则有 0V，此时由于两个电极板之间是绝缘的，电荷会积累到电极板表面并形成 Electric Field，从正极指向负极，此时电路中的电极板电压等于电池电压，电荷不在移动，电极板完成整个充电的过程 类比一个水流抽水的过程，电池就是水泵推动水在管道中移动\nProperty of Capacitance #\r与电阻一样，电容是一个电容器的特性，其即使公式为 \\(q=CV\\) ，但实际上其并不依赖于储存的电荷量 q 真正影响电容的因素为形状，尺寸，相对位置以及介质 也就是说 q = CV 这个公式真正定义的是 q 和 V 之间的系数关系\n5.2 Calculating The Capacitance #\r不同类型的电容器，其电容值的计算方式不同，具体取决于几何结构和极板之间的介质\nParallel-Plate Capacitor 平行板电容器 #\r当有两个面积为 A 的平行导体板相距为 d 的时候，其电容有 $$C=\\frac{\\varepsilon_0 A}{d}$$\n可以看出面积增大、电极板距离减小时，电容增大\nCylindrical Capacitor 圆柱形电容器（ #\r两个同轴圆柱导体，内外圆柱的半径分别为 a 和 b，长度为 L $$C = 2 \\pi \\varepsilon_0 \\frac{L}{\\ln(b/a)}$$ 电容与圆柱长度 L 成正比，内外圆柱半径比值决定了电容大小。 Spherical Capacitor 球形电容器 #\r两个同心球形导体，内外球半径分别为 a 和 b $$C = 4 \\pi \\varepsilon_0 \\frac{ab}{b - a}$$ Isolated Spherical Capacitor 孤立球形电容器 #\r仅有一个孤立的球体，半径为 R $$C = 4 \\pi \\varepsilon_0 R$$ 孤立球体的电容只与球体半径有关 ex. Change in Capacitance when change in radius #\rA drop of mercury is an isolated sphere with radius R= 3.83. What is the capacitance of a drop that results from three drops of mercury combined, each with the same radius R\n三个球的总体积为： $$V_{\\text{total}} = 3 \\times \\frac{4}{3} \\pi R^3 = 4 \\pi R^3$$ 此时可以求出新半径 \\(R\u0026rsquo; = \\sqrt[3]{3} R = 1.442 , R\\) 将 R=3.83R = 3.83 代入： $$R\u0026rsquo; = 1.442 \\times 3.83 \\approx 5.524$$ 已知孤立球体的电容公式为： $$C = 4 \\pi \\varepsilon_0 R$$ 带入半径之后得到 $$C≈6.14×10−10 FC \\approx 6.14 \\times 10^{-10} , \\text{F}$$ 5.3 Capacitors in parallel and in series #\r电路中的电容器也将遵循并联和串联的特性 5.3.1 Capacitors in Parallel #\r对于一个电路，其中三个 Capacitors 并联放置，有 $$\\ q_1 = C_1 V, \\ q_2 = C_2 V, \\mbox{ and } \\ q_3 = C_3 V$$ 根据串联分压，并联分流的特性，说明并联的时候每个电容器 V 相等，有 $$q = q_1 + q_2 + q_3 = (C_1 + C_2 + C_3) V$$ $$C_{eq} = \\frac{q}{V} = C_1 + C_2 + C_3$$ 也就是说电容器并联时，总电容 \\(C_{\\text{eq}}\\)​ 增大 5.3.2 Capacitors in Series #\r到了串联的时候，每个电容器电流相同，也就是 q 一致，有 $$V_1 = \\frac{q}{C_1}, \\quad V_2 = \\frac{q}{C_2}, \\text{ and } \\quad V_3 = \\frac{q}{C_3}$$ $$V = V_1 + V_2 + V_3 = q \\left( \\frac{1}{C_1} + \\frac{1}{C_2} + \\frac{1}{C_3} \\right)$$ $$C_{eq} = \\frac{q}{V} = \\frac{1}{\\frac{1}{C_1} + \\frac{1}{C_2} + \\frac{1}{C_3}}$$ $$\\frac{1}{C_{eq}} = \\frac{1}{C_1} + \\frac{1}{C_2} + \\frac{1}{C_3}$$ ex. Capacitors in both Parallel and Series #\rFind charge on C1\n首先计算 C1 和 C2 两个 Parallel Capacitor 的总电容，有并联电路 $$C=C_1+C_2=17.3$$ 之后这个 17.3 再和 4.5 串联，有 $$\\frac1C=\\frac{1}{17.3}+\\frac{1}{4.5}\\Rightarrow C=3.57$$ 5.4 Energy Stored in an Electric Field #\r当外部装置（如电池）对电容器充电时，做的功以势能 U 的形式储存，有 $$U=\\frac{q^2}{2C}$$\n当带入 \\(q =cv\\) 的时候，得到另一种形式 $$U=\\frac 12CV^2$$ 做的功主要是由 Electric Field Strength \\(F=qE\\) 提供，具体来说是将负电荷从一个极板移动到另外一个极板所做的功，完整推导如下 当少量电荷 dq 从一个极板到达另一个的时候，两个极板之间形成一个初始电场 E，导致极板之间产生 Potential Difference \\(V=\\frac qC\\) 想要在移动电荷，则需要 Electric Field Strength，F 做功，有 \\(W=Fd\\)，其中 F就是电场力，那么就有 \\(dW= Fdl\\)，用了 l 替换 d，同时因为 \\(F=qE\\)，有 \\(dW=qE\\cdot dl\\) 现在知道电势差 V 与电场的关系为 $$V=-\\int^b_a\\vec E\\cdot dl$$ 积分在均匀电场和点电荷电场等对称电场中简化，有 \\(V_{AB} = - \\int_A^B \\vec{E} \\cdot d\\vec{l} = - E \\int_A^B \\cos \\theta , dl\\)，\\(V_{AB} = - \\int_A^B \\frac{kq}{r^2} , dr = kq \\left( \\frac{1}{r_A} - \\frac{1}{r_B} \\right)\\) 等\n从上面的 V 中可以推导出 \\(dV=-E \\cdot dl\\)，带回做功的公式中有 \\(dW=q\\cdot dv\\)，观察此时的公式，它描述的是一个电荷在经过路径上不同的 V 的时候产生的功，也就是一个电荷在不同电势的路径下的功 而我们像描述的是一个充电，也就是电荷累加到极板上的一个过程，此时的瞬时电势 V 将会是一个 Constant，但是电容器极板上的 Charge 则会随时间增加，即每增加一个微小的电荷 dq，电场力都要做一个微小功为 \\(dW=V\\cdot dq\\) 两边积分得到 $$W=U=\\int^Q_0 V\\cdot dq=\\int^Q_0\\frac{q}{C}\\cdot dq=\\frac{q^2}{2C}$$ 为什么 W = U 我也不知道\nDistance between plates and Capacitance #\r已知\\(U = \\frac{q^2}{2C}\\) ，将 \\(C = \\frac{\\varepsilon_0 A}{d}\\) 带入，有 \\(U = \\frac{q^2}{2 \\frac{\\varepsilon_0 A}{d}}\\)，整理得到 $$U = \\frac{dq^2}{2 \\varepsilon_0 A}$$ Energy Density #\r能量密度由总能量除以体积得到，有 $$u = \\frac{U}{Ad} = \\frac{CV^2}{2Ad}$$ 带入 \\(C = \\frac{\\varepsilon_0 A}{d}\\) 得到 $$u = \\frac{1}{2} \\varepsilon_0 \\left( \\frac{V}{d} \\right)^2= \\frac{1}{2} \\varepsilon_0 E^2$$ Dielectric #\r介电材料是绝缘的材料，其填充在电容器板之间提高电容 Michael Faraday 于1837年发现了此规律，并且定义加入介电材料后的电容值将会增加一个比例因子 \\(\\kappa\\) ，其中真空中的介电常数默认为 1 Breakdown Potential #\r在电容器中加入了介电材料后，这个材料会存在一个 Maximum Potential （Breakdown Potentioal），当电压超过这个值，Dielectirc 会被 Break Down 击穿并变为导体 Material Dielectric Constant ( \\kappa ) Dielectric Strength (kV/mm) Air (1 atm) 1.00054 3 Polystyrene 2.6 24 Paper 3.5 16 Transformer oil 4.5 Pyrex 4.7 14 Ruby mica 5.4 Porcelain 6.5 Silicon 12 Germanium 16 Ethanol 25 Water (20°C) 80.4 Water (25°C) 78.5 Titania ceramic 130 Strontium titanate 310 8 For a vacuum, ( \\(\\kappa = 1\\) ).*\nCapacitor with a Dielectric #\r当加入了 Dielectric 后，电容公式改变为 $$C = \\kappa \\frac{\\varepsilon_0 A}{d}$$ 同时可以定义一个 \\(l=\\frac{A}{d}\\)，公式就变为 \\(C = \\kappa \\varepsilon_0 \\ell\\) 电压 V 保持恒定（并联电容器）**： $$q = CV = \\kappa \\varepsilon_0 \\ell V$$ 电荷 q 保持恒定（串联电容器） $$V = \\frac{q}{C} = \\frac{q}{\\kappa \\varepsilon_0 \\ell}$$ Super Capacitor #\r对比了超级电容器（Supercapacitor）与锂离子电池（Lithium-ion battery）的性能和特性：\n功能 超级电容器 锂离子电池（通用） 充电时间 1 – 10 秒 10 – 60 分钟 循环寿命 100 万次或 30,000 小时 500 次及以上 单元电压 2.3 至 2.75 伏 3.6 至 3.7 伏 比能量 (Wh/kg) 5（典型值） 100 – 200 比功率 (W/kg) 高达 10,000 1000 – 3000 每 Wh 成本 约 20 美元 0.50 – 1.00 美元（大系统） 超级电容器充电快、循环寿命长、比功率高，但能量密度低，成本较高 锂离子电池有较高的能量密度和较低的成本，但充电时间长，循环寿命较短 ex. Energy change when insert an Dielectirc #\r平行板电容器的电容为 \\(C = 13.5 , \\text{pF}\\)，通过电池充电到电压 \\(V = 12.5 , \\text{V}\\) 断开电池后，插入介电常数 \\(\\kappa = 6.50\\) 的瓷板。 问题：\na) 插入前的电容器电势能是多少？\nb) 插入后的电容器电势能是多少？ 插入前的电势能 \\(U_i\\) 为 \\(U_i = \\frac{1}{2} C V^2\\) $$U_i = \\frac{1}{2} \\times 13.5 \\times 10^{-12} , \\text{F} \\times (12.5 , \\text{V})^2 = 1.055 \\times 10^{-9} , \\text{J} \\approx 1100 , \\text{pJ}$$ 插入后的电势能 \\(U_f\\) $$U_f = \\frac{q^2}{2 \\kappa C} = \\frac{U_i}{\\kappa}$$ 插入介电材料后，能量减少，损失的能量为： $$W = U_i - U_f = 1055 , \\text{pJ} - 162 , \\text{pJ} = 893 , \\text{pJ}$$ 插入介电材料后，电势能因介电常数 \\(\\kappa\\) 的影响减少。 损失的能量可被视为在插入过程中施加的机械功。 ","date":"Feb 6 2025","externalUrl":null,"permalink":"/docs/uoft/24/electrical-fundamentals/ef5.capacitance/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 2/6/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eCapacitor 电容器是一种储存 Electrical Energy 的装置，由两个相互隔离的导体（即极板）组成，分别带有 +q 和 -q 的电荷\u003c/p\u003e","title":"EF 5. Capacitance","type":"docs"},{"content":" Last Edit: 1/29/25\n由于卷积神经网络的设计就是为了处理图像，所以这里直接以图像为例\n6.2.1 Cross-Correlation Calculation #\r严格来说卷积层表达的运算实际上是 Cross-correlation 互相关运算，而不是卷积运算 暂时忽略图像的第三个维度信息，构造输入，卷积核和输出 在二维互相关运算中，卷积窗口从输入张量的左上角开始，从左到右、从上到下滑动 当输入中的卷积窗口移动到一个新位置的时候，窗口内的元素将和卷积核中按位置相乘并计算和得到一个标量值，如下 $0 \\times 0 + 1 \\times 1 + 3 \\times 2 + 4 \\times 3 = 19$ $1 \\times 0 + 2 \\times 1 + 4 \\times 2 + 5 \\times 3 = 25$ $3 \\times 0 + 4 \\times 1 + 6 \\times 2 + 7 \\times 3 = 37$ $4 \\times 0 + 5 \\times 1 + 7 \\times 2 + 8 \\times 3 = 43$ 由于卷积核的长宽是大于一的，导致了输出的大小等于输入大小减去核大小加一 $$(n_h - k_h + 1) \\times (n_w - k_w + 1)$$ 想让输入输出大小一致，可以在四周填充0保证输入的大小\nimport torch from torch import nn from d2l import torch as d2l def corr2d(X, K): #@save \u0026#34;\u0026#34;\u0026#34;计算二维互相关运算\u0026#34;\u0026#34;\u0026#34; h, w = K.shape Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)) for i in range(Y.shape[0]): for j in range(Y.shape[1]): Y[i, j] = (X[i:i + h, j:j + w] * K).sum() return Y X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]) K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) corr2d(X, K) 现在有 Kernel $k=h\\times w$，则每一个Input x上的点 $i,j$ 的输出都将是其 i:i+h, j:j+w 范围内的输入与k进行元素乘法后的和 X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]) K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) corr2d(X, K) -\u0026gt; tensor([[19., 25.], [37., 43.]]) 6.2.2 Convolution Layer 卷积层 #\rclass Conv2D(nn.Module): def __init__(self, kernel_size): super().__init__() self.weight = nn.Parameter(torch.rand(kernel_size)) self.bias = nn.Parameter(torch.zeros(1)) def forward(self, x): return corr2d(x, self.weight) + self.bias nn.Parameter 是 PyTorch 中的一个类，它被用来将一个张量转换为一个模块的参数 当使用 nn.Parameter 包装一个张量时，这意味着你希望这个张量能够在模型的训练过程中被优化器优化（即进行梯度更新） 6.2.3 Edge detection #\r卷积层，或者说互相关层的主要作用就是提取相邻像素的特殊信息，如颜色边缘 现在构造一个黑白色 6x8 图像 X = torch.ones((6, 8)) X[:, 2:6] = 0 X -\u0026gt; tensor([[1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.]]) 现在用一个 Kernel 为 K = torch.tensor([[1.0, -1.0]]) 可以发现这个核的作用是：如果水平相邻的两元素相同，则输出为零，否则输出为非零，具体来说，从1，也就是白色到0黑色的时候，有 $Y[i,j]=1+0*(-0.1)=1$，相反则是 -1，于是整体输出就为 tensor([[ 0., 1., 0., 0., 0., -1., 0.],\r[ 0., 1., 0., 0., 0., -1., 0.],\r[ 0., 1., 0., 0., 0., -1., 0.],\r[ 0., 1., 0., 0., 0., -1., 0.],\r[ 0., 1., 0., 0., 0., -1., 0.],\r[ 0., 1., 0., 0., 0., -1., 0.]]) 现在如果将上面的图片做Transpose，可以发现检测到的垂直边缘消失了，也就是说其只能检测一个自由度上的特征 6.2.4. 学习卷积核 #\r到了更加复杂的 Convolution Layer 的时候不可能手动设计滤波器，需要主动学习这一个Kernel Core，在忽略 Bias 的前提下有 # 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核 conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False) # 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度）， # 其中批量大小和通道数都为1 X = X.reshape((1, 1, 6, 8)) Y = Y.reshape((1, 1, 6, 7)) lr = 3e-2 # 学习率 for i in range(10): Y_hat = conv2d(X) l = (Y_hat - Y) ** 2 conv2d.zero_grad() l.sum().backward() # 迭代卷积核 conv2d.weight.data[:] -= lr * conv2d.weight.grad if (i + 1) % 2 == 0: print(f\u0026#39;epoch {i+1}, loss {l.sum():.3f}\u0026#39;) -\u0026gt; epoch 2, loss 6.422 epoch 4, loss 1.225 epoch 6, loss 0.266 epoch 8, loss 0.070 epoch 10, loss 0.022 此时输出得到的 Tensor 有 tensor([[ 1.0010, -0.9739]]) 6.2.5. Cross-Correlation and Convolution #\r卷积和互相关运算在前面提到过，他们的差别就在 Kernel 是否翻转，但由于DL的历史遗留问题，我们统称 Convolution Feature Map and Receptive Field 特征层和感受野 #\r对于一个 Convolution Layer 的output，其可以被称为 Feature Map，每过一层卷积层都会得到一个新的特征图，他们可以代表图像的特点信息如边缘，颜色，形状等 而 Receptive Field 感受野是指输入中影响单个输出的区域大小的区域，其在单层卷积层时就是 Kernel 大小，而到二零多层堆叠时，感受野就会累加 ","date":"Jan 28 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l6.convolutionneuronnetwork/d2l6.2imageconvolution/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/29/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e由于卷积神经网络的设计就是为了处理图像，所以这里直接以图像为例\u003c/p\u003e","title":"D2L 6.2 Image Convolution","type":"docs"},{"content":" Last Edit: 1/28/25\n5.1 Functions #\rFunction是用来执行特定任务的可重复调用恶的代码块，通过Modular Programming将复杂问题分解\nvoid printStars(int numOfStars) { for (int star = 1; star \u0026lt;= numOfStars; star++) { printf(\u0026#34;%c\u0026#34;, \u0026#39;*\u0026#39;); } printf(\u0026#34;\\n\u0026#34;); // to start a new line } 这个函数包含了一下的属性 返回类型：void（不返回任何值） 函数名称：printStars 输入参数类型：int 输入参数的变量名：numOfStars 函数体：包含用于打印一行星号的指令 5.1.1 Void #\rvoid 用于表示无类型或无值，void 指的是函数的返回类型，表示这个函数在执行完毕后不会返回任何值 5.1.2 Function Prototype #\r在C语言中，Function Prototype 是用来在函数实际定义前声明函数接口的代码，其包含了改函数的调用参数类型和数量，但不包含具体的执行内容 void printPattern(int numOfRows); void printStars(int numOfStars); 这行就是两个Function的Prototype，表明了两个函数均需要整数作为输入 5.1.3 Order of execution #\r在C语言中，存在编译和执行的两个步骤，从编译来说，顺序是从上到下的，这就代表了下方是可以引用上方的定义，但是如果下方需要引用的东西在上方没有出现，则会报错因为找不到目标 具体来说所有函数和参数的下方就是 main 函数，因为C语言在运行的时候是从 main 函数开始的，也就是说所有在 main 中call到的function都应该在上方被定义，但为了[##5.1.4 Another way to write functions]中将要提到的问题，Funtion Prototype被定义用来优化代码 而C语言程序的执行始终从 main 函数开始，这时函数已经完成了编译，也就是已经编译完了整个代码，所以这时的 main 是可以找到任意位置上的 function 的，而不是从源文件的最上方向下逐行执行 通过在 main 函数中调用函数，其能找到任意函数，即编译器可以知道函数的存在以及他的接口是什么 5.1.4 Another way to write functions #\r如果不写 Function Prototype 的话，就需要把所有Function的定义放置在 main 函数的前方以确保在编译 main 的时候不会因为找不到而报错 # include \u0026lt;stdio.h\u0026gt; void printStars(int numOfStars) { for (int star = 1; star \u0026lt;= numOfStars; star++) { printf(\u0026#34;%c\u0026#34;, \u0026#39;*\u0026#39;); } printf(\u0026#34;\\n\u0026#34;); // to start a newline } void printPattern(int numOfRows) { for (int row = 1; row \u0026lt;= numOfRows; row++) { printStars(row); } } int main(void) { int lines; printf(\u0026#34;Enter the number of lines in the pattern:\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;lines); prinntPattern(lies); return 0; } 但是这种写法使得代码的可读性降低了很多，这可能导致 main 函数远离文件的起始位置，使得跟踪程序流程更加困难 同时在多人开发环境中，团队成员通常需要清楚地知道可以调用哪些函数及其参数，而不必查看每个函数的实现。函数原型在头文件中提供了这样的信息，便于团队成员之间的协作 5.1.4.1 Error Case #\r如果代码如下 #include \u0026lt;stdio.h\u0026gt; void printPattern(int numOfRows) { for (int row = 1; row \u0026lt;= numOfRows; row++) { printStars(row); } } void printStars(int numOfStars) { for (int star = 1; star \u0026lt;= numOfStars; star++) { printf(\u0026#34;%c\u0026#34;, \u0026#39;*\u0026#39;); } printf(\u0026#34;\\n\u0026#34;); // to start a new line } int main(void) { int lines; printf(\u0026#34;Enter the number of lines in the pattern: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;lines); printPattern(lines); return 0; } 在上面的代码中，在，代码的printPattern function中调用了 printStars(row) ，但是这个函数的定义位于下方，如果在一个函数被调用之前，编译器没有遇到这个函数的声明或定义，它就不会知道这个函数的存在，导致编译错误 5.2. Communicate from a function #\r前面提到的 Functions 并没有任何返回值，这是因为定义 Function的时候采取的是 void 5.2.1 Return a non-void variable type #\r#include \u0026lt;stdio.h\u0026gt; int factorial(int n); int main(void) { int number = 4; int result = factorial(number); printf(\u0026#34;Factorial of %d: %d.\\n\u0026#34;, number, result); return 0; } int factorial(int n) { int fact = 1; for (int i = 1; i \u0026lt;= n; i++) { fact = fact * i; } return fact; } factorial 函数接收一个 int 参数 n，并返回 n! return fact; 语句将计算结果返回给调用者，即 main 函数 main 通过 result = factorial(number); 获取返回值并存储 printf 用于打印最终结果 5.2.2. Summary of syntax #\r#include \u0026lt;stdio.h\u0026gt; // 函数原型（声明） \u0026lt;return type\u0026gt; functionName(\u0026lt;type\u0026gt;); int main(void) { // 调用有返回值的函数 \u0026lt;type\u0026gt; variableName = functionName(\u0026lt;variable to pass\u0026gt;); // 调用无返回值的函数 functionName(\u0026lt;variable to pass\u0026gt;); return 0; } // 函数实现（定义） \u0026lt;return type\u0026gt; functionName(\u0026lt;type\u0026gt; \u0026lt;input parameter name\u0026gt;) { return \u0026lt;变量，类型与 \u0026lt;return type\u0026gt; 相同\u0026gt;; } 5.3 Variable Scope #\r在前面的Loop单元中提到过 Variable Scope 的概念，即一个变量的定义范围，在前面提到的是loop中的variable只能作用在其循环当中，想要让其作用于循环外则需要在外部声明变量\nint count; for (count = 1; count \u0026lt;= n; count++) { printf(\u0026#34;*\u0026#34;); } count = 10; // ✅ 正确，count 在整个函数内都可用 同样的，Function 中的变量也只能储存在 Function 中 #include \u0026lt;stdio.h\u0026gt; // 函数声明 double divideByTwo(double); int main(void) { double n = 4.2, result; result = divideByTwo(n); printf(\u0026#34;%lf,%lf\u0026#34;, n, result) return 0; } // 函数定义 double divideByTwo(double n) { n = n / 2; return n; } 在这个程序中同时存在两个 n 其中函数中的独立于外部主程序存在 所以这个程序的返回值将会是 4.2,2.1 5.4. Pass more values to a function #\r一个函数可以指定接收多个 Variable #include \u0026lt;stdio.h\u0026gt; int median(int, int, int); // Prototype int main(void) { // Main Function printf(\u0026#34;The median of (%d, %d, %d) is %d\\n\u0026#34;, -105, -28, -73, median(-105, -28, -73)); printf(\u0026#34;The median of (%d, %d, %d) is %d\\n\u0026#34;, 0, -101, 98, median(0, -101, 98)); printf(\u0026#34;The median of (%d, %d, %d) is %d\\n\u0026#34;, -101, -67, 0, median(-101, -67, 0)); return 0; } int median(int x, int y, int z) { // Function Body int result = 0; if ((x \u0026gt;= z \u0026amp;\u0026amp; x \u0026lt;= y) || (x \u0026gt;= y \u0026amp;\u0026amp; x \u0026lt;= z)) result = x; else if ((y \u0026gt;= x \u0026amp;\u0026amp; y \u0026lt;= z) || (y \u0026gt;= z \u0026amp;\u0026amp; y \u0026lt;= x)) result = y; else result = z; return result; } ","date":"Jan 28 2025","externalUrl":null,"permalink":"/docs/uoft/24/learning-programming-with-c/lpc5.functions/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/28/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e5.1 Functions \r\n    \u003cdiv id=\"51-functions\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#51-functions\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cp\u003eFunction是用来执行特定任务的可重复调用恶的代码块，通过Modular Programming将复杂问题分解\u003c/p\u003e","title":"LPC 5. Functions","type":"docs"},{"content":" Last Edit: 1/23/25\n4.1 Electric Potential #\r对于一个重力场，其Field Strength为g，而Gravity所做的功则为\\(W=mgh\\) 可以发现这一个Work Done只和高度差有关，与路径无关（也就是说即使在途中左右摇摆，重力做的功依然不变） 同理可以类比到Electric Field中，电场力做功为\\(W=Eqh\\)，并且同样的与路径无关 Electrical Potential Energy 电势能 #\rElectrical Potential Energy 是带电粒子由于其位置处于电场中而具有的能量 如果Charge在Electric Field中做了Negative的Work，其就是在Electric Field中积累了Electric Potential Energy，于是就有公式 $$U=-W$$ 其中U就是Electric Potential Energy 电势能 具体来说定义Electric Potential Energy的办法就是通过Test Charge的两个参考点，一个是无穷远处电荷之间相互作用力忽略不记的地方，到另一个参考点，Test Charge在这两个点之间做的功便为电势能 Electrical Potential 电势 #\rElectrical Potential 指的是电场中某一点单位电荷所具有的电势能 $$V=\\frac{U}{q}$$ 当Paritical从Electrical Field中的初始点移动到终点时，电势发生变化，用公式表示为 $$\\Delta V = V_f - V_i$$ 电势能的变化可以用公式计算，由于Paritcal的Charge并不发生改变，有 $$\\Delta U = -W=q \\Delta V = q(V_f - V_i)$$ 在这一过程中，总能量是守恒的，这意味着动能和势能之和保持不变 从初始点 i 移动到终点 f 时，机械能守恒关系表示为： $$U_i + K_i = U_f + K_f 或\\Delta K = -\\Delta U$$ 4.2 Equipotential Surfaces 等势面 #\rEquipotential Surfaces 指的是一个Electrical Potential 相等的区域，Partical沿着这一个Surface移动的时候不需要做功 Calculating the Potential from the Field #\r根据Electric Field Magnitude可以计算出Partical移动后的Potential Difference 由于Partical在Electric Field中需要克服电场力做功，则有 $$dW=\\vec E \\cdot d\\vec s\\Rightarrow \\int dW= V_f - V_i = -\\int_i^f \\vec{E} \\cdot d\\vec{s}$$ 4.3 Electrical Potential Due to a Charged Particle #\rCharged Particle在空间中会形成一个Electrical Field，\\(\\vec{E} = \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r^2} \\hat{r}\\)，将其代入积分 $$V = -\\int_\\infty^r \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r^2} dr= \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r}$$ A positively charged particle produces a positive electric potential. A negatively charged particle produces a negative electric potential.\nex. Rank the Electral Potential #\rAssume all dots are Protons 根据\\(V= \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r}\\)，r越小V越大，有 a) Proton 1 has more Electric Potential (v) than Proton 2, since D \u0026gt; d b) Proton 1 has more Electric Potential (v) than Proton 2, since D \u0026gt; d c) Proton 1 has more Electric Potential (v) than Proton 2, since D \u0026gt; d 4.7 Electrical Potential Energy of a system of charged Particles #\r对于空间中的两个Particle，他们之间的距离为 r ，则由他们之间的Electrical Field相互作用而具有的Energy被称为他们的Potential Energy，前面已经提到了一个Partical在空间中会形成一个Electrial Potential \\(V = \\frac{1}{4\\pi \\epsilon_0} \\frac{q}{r}\\) ，而U是Partical在电场中所具有的能量，就有 $$U = \\frac{1}{4\\pi \\epsilon_0} \\frac{q_1 q_2}{r}$$ U：两电荷之间的Electrical Potential Energy \\(q_1、q_2\\)：两个电荷的电荷量（C） \\(r\\)：两电荷之间的距离 \\(\\varepsilon_0\\)：真空介电常数（\\(8.85 \\times 10^{-12} , \\text{F/m}\\)） Sign Convention #\r已知2个Partical可能出现三种不同的系统 如果两电荷都是正电荷，它们会排斥，电势能 U\u0026gt;0 如果两电荷都是负电荷，它们同样会排斥，但电势能公式保持不变，因为两个负电荷相乘仍为正数，因此 U\u0026gt;0 如果两个电荷符号不同（例如，一个是正电荷，另一个是负电荷），它们会吸引，表示系统释放能量 ex. Potential Energy of a system of three charged particles #\r有一个等边三角形的电荷系统，包含三个带电粒子：q1=+q，q2=−4q，q3=+2q，分别间隔12cm，求这个系统的Total Potential Energy\n已知两个电荷之间的电势能为： \\(U_{ij} = \\frac{1}{4\\pi \\epsilon_0} \\frac{q_i q_j}{d}\\)，总电势能是所有电荷对之间电势能的总和： \\(U = U_{12} + U_{13} + U_{23}\\) $$U = U_{12} + U_{13} + U_{23}$$ $$U = -\\frac{4q^2}{4\\pi \\epsilon_0 d} + \\frac{2q^2}{4\\pi \\epsilon_0 d} - \\frac{8q^2}{4\\pi \\epsilon_0 d} $$ $$U = -\\frac{10q^2}{4\\pi \\epsilon_0 d}$$ 代入数据后可以得到 $$U = -\\frac{10 (150 \\times 10^{-9})^2}{4\\pi \\epsilon_0 \\times 0.12}\\Rightarrow U = -1.7 , \\text{J} = -1.7 , \\text{mJ}$$ 负电势能意味着这个带电系统更稳定，或者说如果你想把这些电荷分开到无限远，就需要额外做功才能克服它们之间的相互作用。负值越大，系统的束缚越强。\n","date":"Jan 23 2025","externalUrl":null,"permalink":"/docs/uoft/24/electrical-fundamentals/ef4.electricpotential/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/23/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e4.1 Electric Potential \r\n    \u003cdiv id=\"41-electric-potential\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#41-electric-potential\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于一个重力场，其Field Strength为g，而Gravity所做的功则为\\(W=mgh\\)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/uoft/24/electrical-fundamentals/ef4.electricpotential/EF4.ElectricPotential_hu3013009443759680203.png 330w,\r\n        /docs/uoft/24/electrical-fundamentals/ef4.electricpotential/EF4.ElectricPotential_hu10790805179443622640.png 660w,\r\n        /docs/uoft/24/electrical-fundamentals/ef4.electricpotential/EF4.ElectricPotential_hu15032556861933157744.png 1024w,\r\n        /docs/uoft/24/electrical-fundamentals/ef4.electricpotential/EF4.ElectricPotential_hu2476701224367274999.png 2x\"\r\n        src=\"/docs/uoft/24/electrical-fundamentals/ef4.electricpotential/EF4.ElectricPotential_hu10790805179443622640.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"EF 4. Electric Potential","type":"docs"},{"content":" Last Edit: 1/22/25\nSequences #\rSequence是按照一定顺序排列的一列数。序列可以是有限的也可以是无限的，通常表示为\\(a_1, a_2, a_3, \\ldots\\)，其中\\(a_n\\)表示序列的第n项 Limit of a Sequence #\r对于一个Sequence，如果有 $$\\lim_{n\\rightarrow\\infty}a_n=L,L\\in \\mathbb R$$ 则该Sequence的Limit为L 如果存在这个L，也可以说Sequence是Converge 收敛的 如果不存在，则Sequence Diverge 发散 ex. Nature Number #\r找到Sequence \\(a_n = \\left(1 + \\frac{1}{n}\\right)^n\\)的Limit $$\\lim_{n \\to \\infty} a_n = \\lim_{n \\to \\infty} \\left(1 + \\frac{1}{n}\\right)^n = e$$ Properties of Limits of Sequences #\rLet \\(\\lim_{n \\to \\infty} a_n = L \\text{ and } \\lim_{n \\to \\infty} b_n = K\\) $$\\lim_{n \\to \\infty} (a_n \\pm b_n) = L \\pm K$$ $$\\lim_{n \\to \\infty} c a_n = cL$$ $$\\lim_{n \\to \\infty} (a_n b_n) = LK$$ $$\\lim_{n \\to \\infty} \\frac{a_n}{b_n} = \\frac{L}{K}$$ Squeeze Theorem for Sequences #\rSqueeze Theorem也可以用来解Sequence的Convergence，其通常用在 \\((-1)^n, \\sin(x)\\)等在\\(n\\rightarrow \\infty\\)时oscillate的函数中 ex. Sequence Convergence by Squeeze Theorem #\r证明Sequence \\({ c_n } = \\left{ (-1)^n \\frac{1}{n!} \\right}\\)收敛 使用两个序列\\(a_n=\\frac{1}{2^n}\\)，已知Factorial的扩散速度小于Exponential，有 $$-\\frac{1}{2^n} \\leq (-1)^n \\frac{1}{n!} \\leq \\frac{1}{2^n}, \\quad n \\geq 4$$ Monotonic Sequences #\r当一个Sequence的每一项都单调递增或单调递减时，该Sequence被称为Monotonic Sequence Bounded Sequence #\rBounded Above #\r当存在一个\\(M\\in \\mathbb R\\)使得\\(a_n\\leq M\\)时，称该Sequence Bounded Above Bounded Below #\r当存在一个\\(M\\in \\mathbb R\\)使得\\(a_n\\geq M\\)时，称该Sequence Bounded Below Bounded #\r当一个Sequence同时Bounded Above和Below的时候，其Bounded Theorem - Convergent Sequence are Bounded #\r如果一个Sequence Convergent，则其一定Bounded 同理也可以反推，如果一个Sequence Bounded并且是Monotonic 单调的Sequence的话，该Sequence Convergent 收敛 Series (Infinite Series) #\r对于Sequence来说，它的所有项相加的和便成为了Series $$S_n=\\sum_{n=1}^{\\infty} a_n = a_1 + a_2 + a_3 + \\cdots + a_n + \\cdots$$ Convergent of Series #\r对于一个Series \\(\\sum^\\infty_{n=1}a_n\\)来说，如果其Partial Sum（前n项之和）等于S，则该Series Converge，反则Diverge Telescoping Series 列项级数 #\r通过将级数的两个项组合得到一个新的通项公式求得级数的解 ex. Finding Series Convergency by Telescoping #\r求解\\(\\sum_{n=1}^{\\infty} \\frac{2}{4n^2 - 1}\\) $$a_n = \\frac{2}{4n^2 - 1} = \\frac{2}{(2n - 1)(2n + 1)} = \\frac{1}{2n - 1} - \\frac{1}{2n + 1}$$ 通过观察规律可以看出 $$S_n = \\left( \\frac{1}{1} - \\frac{1}{3} \\right) + \\left( \\frac{1}{3} - \\frac{1}{5} \\right) + \\cdots + \\left( \\frac{1}{2n-1} - \\frac{1}{2n+1} \\right) = 1 - \\frac{1}{2n+1}$$ 最终得出 $$\\sum_{n=1}^{\\infty} \\frac{2}{4n^2 - 1} = \\lim_{n \\to \\infty} S_n = \\lim_{n \\to \\infty} \\left(1 - \\frac{1}{2n+1}\\right) = 1$$ Geometric Series #\r形如\\(\\sum_{n=0}^{\\infty} ar^n\\)的Series被称为Geometric Series，其完整形式为 $$\\sum_{n=0}^{\\infty} ar^n = a + ar + ar^2 + \\cdots + ar^n + \\cdots, \\quad a \\neq 0$$ Convergenvce of Geometric Series #\r当Geometric Series的的敛散性高度取决于其公比r的取值 具体来说当\\(0\u0026lt;|r|\u0026lt;1\\) Geometric Series Converge ，当\\(|r|\\geq 1\\)，其Diverge The Value Geometric Series Converge to #\rGeometric Sereis是很特别的一个Series，于大部分Series不同，当其Converge的时候可以简单的求出Series的值为 $$\\lim_{n \\to \\infty} S_n = \\lim_{n \\to \\infty} \\left[ \\frac{a(1 - r^n)}{1 - r} \\right] = \\frac{a}{1 - r} \\lim_{n \\to \\infty} (1 - r^n) = \\frac{a}{1 - r}$$ Property of Infinite Series #\r如果\\(\\sum a_n\\)和\\(\\sum b_n\\)都是Converge的Series，并且分别收敛到A和B，则有 $$\\sum_{n=1}^{\\infty} c a_n = cA$$ $$\\sum_{n=1}^{\\infty} (a_n + b_n) = A + B$$ $$\\sum_{n=1}^{\\infty} (a_n - b_n) = A - B$$ p-Series and Harmonic Series #\r$$\\sum_{n=1}^{\\infty} \\frac{1}{n^p} = \\frac{1}{1^p} + \\frac{1}{2^p} + \\frac{1}{3^p} + \\cdots$$\nConvergence of p-Series #\r当 \\(p\u0026gt;1\\) 的时候Converge，\\(0\u0026lt;p\\leq 1\\) 的时候Diverge Harmonic Series #\r当p=1时，p-Series变成其特殊形式，即Harmonic Series Alternating Series #\r到目前为止的Series都只含有Postitive的Terms Alternating Series 交错级数指的是一正一负（一负一正）的Terms的级数 Alternating Series Remainder #\r如果一个收敛的交错级数满足以下条件： \\(a_{n+1} \\leq a_n\\)（即正项部分单调递减），\\(\\lim_{n \\to \\infty} a_n = 0\\)， 那么，当用第N项部分和\\(S_N\\)来近似整个级数的和 SS 时，有 $$|S - S_N| = |R_N| \\leq a_{N+1}$$ 换句话说，误差的绝对值小于等于被忽略的第一个正项\\(a_{N+1}\\) Absolute and Conditional Convergence #\r有的Series可能含有正负项，但他们不已一定规律出现 这时候就需要利用Absolute and Conditional Convergence 如果一个级数 \\(\\sum |a_n|\\) Convergence Absolutly（即级数的项的绝对值构成的级数收敛），则原级数 \\(\\sum a_n\\) 也一定Converge Conditionally Converge #\r对于一个Series，当\\(\\sum |a_n|\\) Diverge但是\\(\\sum a_n\\) converge的时候，其Conditionally Converge 条件收敛 Tests for Convergency #\r对于Series存在许多的判断其是否收敛的办法 The Integral Test #\r如果函数f(x)满足以下条件：f(x)在 \\(x \\geq 1\\) 上是positive，continuous，decreasing的，则： $$\\sum_{n=1}^\\infty a_n与\\int_{1}^\\infty f(x), dx$$ 的收敛性是一致的： 要么两者都收敛，要么两者都发散 Direct Comparison Test #\r假设存在两个正项级数 \\(\\sum a_n\\) 和 \\(\\sum b_n\\)，并且对所有n都满足 \\(0 \u0026lt; a_n \\leq b_n\\)，则有： 如果 \\(n\\sum b_n\\) Converge，则 \\(\\sum a_n\\) 也Converge 如果 \\(\\sum a_n\\) Diverge，则 \\(\\sum b_n\\) 也Diverge Limit Comparison Test #\r对于Direct Comparison能做的，Limit都能做到并且会更加简单 假设存在两个正项级数 \\(\\sum a_n\\) 和 \\(\\sum b_n\\)，并且满足： \\(a_n \u0026gt; 0\\) 和 \\(b_n \u0026gt; 0\\) 对所有n成立，存在极限： \\(\\lim_{n \\to \\infty} \\frac{a_n}{b_n} = L\\) 其中\\(0 \u0026lt; L \u0026lt; \\infty\\)\n如果 \\(\\sum b_n\\) Converge，则 \\(\\sum a_n\\) 也Converge 如果 \\(\\sum b_n\\) Diverge，则 \\(\\sum a_n\\) 也Diverge Throrem - nth Test #\rIf \\(\\lim_{n \\to \\infty} a_n \\neq 0\\), then \\(\\sum_{n=1}^{\\infty} a_n\\) diverges Alternating Series Test #\r对于形式为交错级数的两个级数： $$\\sum_{n=1}^\\infty (-1)^n a_n \\quad \\text{和} \\quad \\sum_{n=1}^\\infty (-1)^{n+1} a_n$$ 如果满足以下两个条件，则级数收敛： \\(\\lim_{n \\to \\infty} a_n = 0\\)，\\(a_{n+1} \\leq a_n\\) 对所有n成立（即\\({a_n}\\)是单调递减的正项数列）。 Ratio Test #\rLet \\(\\sum a_n\\) be a series with nonzero terms 当\\(\\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| \u0026lt; 1\\)，级数Converges Absolutely 当\\(\\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| \u0026gt; 1 \\text{ or } \\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| = \\infty\\)，级数Diverge 当\\(\\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| =1\\)时，Ratio Test失效 简单解释一下原理就是通过转化为Geometric Series后计算公比\nThe Root Test #\rLet \\(\\sum a_n\\) be a series with nonzero terms 当\\(\\lim_{n \\to \\infty} \\sqrt[n]{|a_n|} \u0026lt; 1\\)时，级数Converge Absolutely 当\\(\\lim_{n \\to \\infty} \\sqrt[n]{|a_n|} \u0026gt; 1 \\text{ or } \\lim_{n \\to \\infty} \\sqrt[n]{|a_n|} = \\infty\\)时，Diverge 同理\\(\\lim_{n \\to \\infty} \\sqrt[n]{|a_n|} = 1\\)时失效 Taylor Polynomials and Approximations #\r想要通过一个Polynomial来近似一个function，首先找到一点c，其在function的domain中，再给与\\(p(c)\\)和\\(f(c)\\)相同的值，就可以说这个Polynomial是以c点为中心近似function的 由于过一个点的Polynomial非常之多，所以更一步的近似就是同时令function和polynomial在点c处的slope也相似，有\\(p\u0026rsquo;(c)=f\u0026rsquo;(c)\\)满足了以上两个条件，就获得了一个简单的对于function的近似 ex. First Degree Approximation for e^x #\r\\(f(x)=e^x\\) 存在一个特殊的性质，就是其derivate等于原函数，于是有 $$f(0)=f\u0026rsquo;(0)=e^0=1$$ 现在拿出一个One degree polynomial \\(p(x)=a_0+a_1x\\)，分别对齐\\(p(0)\\)和\\(p\u0026rsquo;(0)\\) \\(p(0)=a_0+0=1\\Rightarrow a_0=1\\)，\\(p\u0026rsquo;(0)=a_1=1\\Rightarrow = a_1 =1\\) 可以得到\\(p(x)=1+x\\)，就这样逐渐的往高阶逼近，Polynomial和Function以c为中心的逼近也会越来越精确 Taylor Polynomials #\r在上面的例子中，多项式是以\\(c=0\\)为中心approximate function的，而这一个c可以根据需要进行调整，具体来说这个多项式在n阶下应该为 $$P_n(x) = a_0 + a_1(x-c) + a_2(x-c)^2 + a_3(x-c)^3 + \\cdots + a_n(x-c)^n$$ 这一个polynomial中存在三个参数，其中c为常数，x为variable，于是就要求解a的值 在前面的例子中提到了求解\\(a_0,a_1\\)的办法，具体就是令\\(p_n^{(n)}(c)=f_n^{(n)}(c)\\) 观察polynomial求到第n阶导数的样子，有 $$P_n\u0026rsquo;\u0026rsquo;\u0026rsquo;(x) = 2(3a_3) + \\cdots + n(n - 1)a_n(x - c)^{n-3}$$ $$P_n^{(n)}(x) = n(n - 1)(n - 2) \\cdots (2)(1) a_n$$ 可以发现求解\\(a_n\\)的关键就在于当P求到第n阶导数的时候\\((x-c)^n\\)这一项会只剩下系数（z）乘以\\(a_n\\)，也就是\\(za_n(x-c)^0\\)（具体系数等于多少稍后讨论），那么这时候令\\(x=c\\)，所有高次的项均会被消去只剩下\\(p_n(x)\\)原本的第n项系数，这时候有 $$p_n^{(n)}(c)=f_n^{(n)}(c)=za_n$$ 这就可以得出 $$a_n=\\frac{f_n^{(n)}(c)}{z}$$ 那么问题就来到了z等于多少上，已知到这一步时，\\(P_n(x)\\)已经被求导了n次，也就是说这一项的幂减去了n次1，而系数乘上了\\(n(n-1)(n-2)(n-3)\\ldots 1=n!\\)，总结得出 $$a_n=\\frac{f_n^{(n)}(c)}{n!}$$ 将其带入Polynomial有 $$P_n(x) = f(c) + f\u0026rsquo;(c)(x - c) + \\frac{f\u0026rsquo;\u0026rsquo;(c)}{2!}(x - c)^2 + \\cdots + \\frac{f^{(n)}(c)}{n!}(x - c)^n$$ Maclaurin Polynomial #\r麦克劳林级数是Taylor Series的特殊情况，其发生在\\(c=0\\)的时候，有 $$P_n(x) = f(0) + f\u0026rsquo;(0)x + \\frac{f\u0026rsquo;\u0026rsquo;(0)}{2!}x^2 + \\frac{f\u0026rsquo;\u0026rsquo;\u0026rsquo;(0)}{3!}x^3 + \\cdots + \\frac{f^{(n)}(0)}{n!}x^n$$ ex. Finding a 3 degrees Taylor Polynomial for sin x at pi/6 #\r以\\(\\pi/6\\)为中心找到sinx的泰勒多项式\n找Taylor Polynomial实际上只用求原函数在各阶导数下的值就行 \\(f(x) = \\sin x \\quad f\\left(\\frac{\\pi}{6}\\right) = \\sin\\left(\\frac{\\pi}{6}\\right) = \\frac{1}{2}\\) \\(f\u0026rsquo;(x) = \\cos x \\quad f\u0026rsquo;\\left(\\frac{\\pi}{6}\\right) = \\cos\\left(\\frac{\\pi}{6}\\right) = \\frac{\\sqrt{3}}{2}\\) \\(f\u0026rsquo;\u0026rsquo;(x) = -\\sin x \\quad f\u0026rsquo;\u0026rsquo;\\left(\\frac{\\pi}{6}\\right) = -\\sin\\left(\\frac{\\pi}{6}\\right) = -\\frac{1}{2}\\) \\(f\u0026rsquo;\u0026rsquo;\u0026rsquo;(x) = -\\cos x \\quad f\u0026rsquo;\u0026rsquo;\u0026rsquo;\\left(\\frac{\\pi}{6}\\right) = -\\cos\\left(\\frac{\\pi}{6}\\right) = -\\frac{\\sqrt{3}}{2}\\) $$P_3(x) = f\\left(\\frac{\\pi}{6}\\right) + f\u0026rsquo;\\left(\\frac{\\pi}{6}\\right) (x - \\frac{\\pi}{6}) + \\frac{f\u0026rsquo;\u0026rsquo;\\left(\\frac{\\pi}{6}\\right)}{2!} (x - \\frac{\\pi}{6})^2 + \\frac{f\u0026rsquo;\u0026rsquo;\u0026rsquo;\\left(\\frac{\\pi}{6}\\right)}{3!} (x - \\frac{\\pi}{6})^3 $$ $$= \\frac{1}{2} + \\frac{\\sqrt{3}}{2} \\left(x - \\frac{\\pi}{6}\\right) - \\frac{1}{2(2!)} \\left(x - \\frac{\\pi}{6}\\right)^2 - \\frac{\\sqrt{3}}{2(3!)} \\left(x - \\frac{\\pi}{6}\\right)^3$$ Remainder of a Taylor Polynomial #\r作为一个逼近，其总是存在Error，而Error与实际值之间的差值就是Remainder，有 $$\\text{Error} = |R_n(x)| = |f(x) - P_n(x)|$$ Taylor\u0026rsquo;s Theorem #\r如果一个函数n+1阶可导在一个包含了c的区间I中，则每一个I中的x都有一个\\(z\\in [x,c]\\)使得 $$f(x) = f(c) + f\u0026rsquo;(c)(x - c) + \\frac{f\u0026rsquo;\u0026rsquo;(c)}{2!}(x - c)^2 + \\cdots + \\frac{f^{(n)}(c)}{n!}(x - c)^n + R_n(x)$$ 其中 $$R_n(x) = \\frac{f^{(n+1)}(z)}{(n+1)!} (x - c)^{n+1}$$ 以上就是Taylor\u0026rsquo;s Theorem的完整定理，其可以被总结为一个更加易懂的二级结论，有 $$|R_n(x)| \\leq \\frac{|x - c|^{n+1}}{(n+1)!} \\max |f^{(n+1)}(z)|$$ 简单来说，直接找到Taylor\u0026rsquo;s Theroem中的z是十分困难的，这使得其更多像是一个存在性定理，所以实际上这个定理想表达的是这个z的存在使得Remainder能别限制在一个区间 ex. Determing Accuracy of Approximation #\r有Thrid Degree Maclaurin Polynomial \\(P_3(x) = x - \\frac{x^3}{3!}\\)，求近似\\(x=0.1\\)时的误差 $$\\sin x = x - \\frac{x^3}{3!} + R_3(x) = x - \\frac{x^3}{3!} + \\frac{f^{(4)}(z)}{4!}x^4$$\n在\\(0\u0026lt;z\u0026lt;0.1\\)的区间中，\\(\\sin(0.1)\\)有着最大的值，于是有 $$0 \u0026lt; R_3(0.1) = \\frac{\\sin z}{4!} (0.1)^4 \u0026lt; \\frac{0.0001}{4!} \\approx 0.000004 $$ ex. Approximating a Value to a Desired Accuracy #\rDetermine the degree of the Taylor polynomial expanded about c=1 that should be used to approximate \\(\\ln(1.2)\\) so that the error is less than 0.001\n既然求的是Error Value，直接用Remainder $$|R_n(1.2)| = \\left| \\frac{f^{(n+1)}(z)}{(n+1)!} (1.2 - 1)^{n+1} \\right| = \\frac{n!}{z^{n+1}(n + 1)!} (0.2)^{n+1} = \\frac{(0.2)^{n+1}}{z^{n+1}(n + 1)}$$ 要让这玩意小于0.001，由于在\\(1\u0026lt;z\u0026lt;1.2\\)的区间中 $$\\frac{(0.2)^{n+1}}{z^{n+1}(n + 1)}\u0026lt;\\frac{(0.2)^{n+1}}{n + 1}\u0026lt;0.001$$ 最终可以得到 \\(n=3\\) Power Series #\rPower Series 幂级数是一种形式为无穷多项式的Series，通常用来近似函数，其表示为 $$\\sum_{n=0}^{\\infty} c_n (x-a)^n$$ 其中，\\(c_n\\)是系数，x是变量，a是幂级数展开的中心点 Center of Power Sereis #\r中心点的选择是为了确定一个近似最精确的点，如果想要用Power Series来近似\\(e^x\\)，并且对于\\(x=1\\)这一点的函数更加关心时，就可以选择\\(a=1\\)为展开的中心点，这使得x=1周围的对于函数的逼近更加精确 Radius and Interval of Convergency #\r对于一个Power Series来说，只存在三种收敛的情况 Converges at center 只在中心收敛 Converges within a radius R 收敛于一定半径R之间 Converges absolutely for all x 收敛于任意\\(x\\in R\\) 通过计算Power Series的Ratio或者Radius Test后便可以知道Radius of Convergency ex. Finding the radius of Convergence (R=1) #\r对于Series \\(\\sum_{n=0}^{\\infty} 3(x-2)^n\\)，找到他的Radius of Convergence 利用Ratio Test得到 $$\\lim_{n \\to \\infty} \\frac{u_{n+1}}{u_n} = \\lim_{n \\to \\infty} \\frac{3(x-2)^{n+1}}{3(x-2)^n} = \\lim_{n \\to \\infty} |x-2| = |x-2|$$ 已知当这一个极限\\(\\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| \u0026lt; 1\\)的时候Series Converge，则有 $$|x-2|\u0026lt;1\\Rightarrow -1\u0026lt;x-2\u0026lt;1\\Rightarrow 1\u0026lt;x\u0026lt;3\\Rightarrow R=1$$ ex. Finding the radius of Convergence (\\(R=\\infty\\)) #\r判断Series \\(\\sum_{n=0}^{\\infty} \\frac{(-1)^n x^{2n+1}}{(2n+1)!}\\) $$\\lim_{n \\to \\infty} \\frac{u_{n+1}}{u_n} = \\lim_{n \\to \\infty} \\frac{(-1)^{n+1} x^{2n+3}}{(2n + 3)!} \\div \\frac{(-1)^n x^{2n+1}}{(2n + 1)!} = \\lim_{n \\to \\infty} \\frac{x^2}{(2n + 3)(2n + 2)}=0$$ 这个情况下，无论x取什么值都有\\(\\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| \u0026lt; 1\\)，所以R也为\\(\\infty\\) End Point Convergence #\r在判断了Convergency Radius后，还需要判断两个End Point的取值情况，这是因为在End Point位于\\(\\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| = 1\\)的点，前面提到了这个点处Ratio Test是失效的，所以需要单独计算 ex. Finding Interval of Convergence #\r判断Series \\(\\sum_{n=1}^{\\infty} \\frac{x^n}{n}\\)的Interval of Convergence （注意问题变了） $$\\lim_{n \\to \\infty} \\frac{u_{n+1}}{u_n} = \\lim_{n \\to \\infty} \\frac{x^{n+1} / (n+1)}{x^n / n} = \\lim_{n \\to \\infty} \\frac{nx}{n+1} = |x|$$ 知道了Convergence Radius\\(R=1\\)后分析两个End Point的Behavior $$whenx=1:\\sum_{n=1}^{\\infty} \\frac{1}{n} = \\frac{1}{1} + \\frac{1}{2} + \\frac{1}{3} + \\cdots$$ $$whenx=-1:\\sum_{n=1}^{\\infty} \\frac{(-1)^n}{n} = -1 + \\frac{1}{2} - \\frac{1}{3} + \\frac{1}{4} - \\cdots$$ 最终得到完整Interval of Convergence为 \\([-1,1)\\) Properties of Functions Defined by Power Series #\r如果用一个Power Series来拟合一个function，有 $$f(x) = \\sum_{n=0}^{\\infty} a_n (x - c)^n = a_0 + a_1 (x - c) + a_2 (x - c)^2 + a_3 (x - c)^3 + \\cdots$$ 这个function的Derivative的Integral同样也可以用一个Taylor Polynomial表示 $$f\u0026rsquo;(x) = \\sum_{n=1}^{\\infty} n a_n (x - c)^{n-1} = a_1 + 2a_2(x - c) + 3a_3(x - c)^2 + \\cdots$$ $$\\int f(x) , dx = C + \\sum_{n=0}^{\\infty} a_n \\frac{(x - c)^{n+1}}{n+1} = C + a_0 (x - c) + \\frac{a_1 (x - c)^2}{2} + \\frac{a_2 (x - c)^3}{3} + \\cdots$$ 其Integral和Derivative会有和原函数相同的Radius of convergency，但是由于Series本身发生了改变，导致End Point Behavior可能不同 $$$$ Representation of Functions by Power Series #\r考虑一个function \\(f(x) = \\frac{1}{1 - x}\\) 这个function长得非常像在前面所提到的Geometric Series的Partial Sum，具体来说一个Geometric Series会在\\(0\u0026lt;|r|\u0026lt;1\\)的时候有 $$\\sum_{n=0}^{\\infty} ar^n = \\frac{a}{1 - r}$$ 而对于上面的\\(f(x)\\)，当 \\(a=1,r=x\\) 的时候就有 $$\\frac{1}{1 - x} = \\sum_{n=0}^{\\infty} ar^n = \\sum_{n=0}^{\\infty} x^n = 1 + x + x^2 + x^3 + \\cdots, \\quad |x| \u0026lt; 1. $$ 当然要知道一个Power Series存在Convergence Radius，这使得这个Series仅在\\((-1,1)\\)的区间上拟合了function，如果需要研究函数在其他区间的拟合，则可以更改Power Series的c 比如当 \\(c=-1\\) 的时候就有 $$\\frac{1}{1 - x} = \\frac{1}{2 - (x + 1)} = \\frac{\\frac{1}{2}}{1 -\\frac{(x + 1)}{2}} = \\frac{a}{1 - r}$$ 于是可以得出 \\(a= \\frac{1}{2},r=\\frac{x+1}{2}\\)，带入Power Series中有 $$\\frac{1}{1 - x} = \\sum_{n=0}^{\\infty} \\left(\\frac{1}{2}\\right)\\left(\\frac{x+1}{2}\\right)^n = \\frac{1}{2} \\left[ 1 + \\frac{x+1}{2} + \\left(\\frac{x+1}{2}\\right)^2 + \\left(\\frac{x+1}{2}\\right)^3 + \\cdots \\right], \\quad |x+1| \u0026lt; 2$$ Power Series仅在Convergence Interval中拟合Function\nex. Find Geometeric Power Sereis Centerd at 0 #\r找一个拟合function \\(f(x) = \\frac{4}{x + 2}\\) 的Power Series\n将function写成 \\(\\frac{a}{1-r}\\) 的形式 $$\\frac{4}{2 + x} = \\frac{2}{1 - \\left(-\\frac{x}{2}\\right)} = \\frac{a}{1 - r}$$ 有 \\(a=2,r=\\frac{-x}{2}\\) 于是可以写出Power Series $$\\frac{4}{x + 2} = \\sum_{n=0}^{\\infty} a r^n = \\sum_{n=0}^{\\infty} 2 \\left(-\\frac{x}{2}\\right)^n = 2 \\left(1 - \\frac{x}{2} + \\frac{x^2}{4} - \\frac{x^3}{8} + \\cdots \\right)$$ Operations with Power Series #\r$$f(x) = \\sum_{n=0}^{\\infty} a_n x^n \\text{ and } g(x) = \\sum_{n=0}^{\\infty} b_n x^n$$ $$f(kx) =\\sum_{n=0}^{\\infty} a_n (kx)^n$$ $$f(x^N) =\\sum_{n=0}^{\\infty} a_n (x^N)^n$$ $$f(x) \\pm g(x) = \\sum_{n=0}^{\\infty} (a_n + b_n) x^n$$\nex. Finding Power Series by Integration #\r前面提到了Power Series的Integral和Derivative也都还是Power Series，于是当一个函数的积分或者导数可以被整理为一个Geometric Power Series时，该函数也可以用Power Series来表示 找到Power Series Representation of \\(f(x)=\\ln x\\)\n已知\\(\\int f(x)dx=\\frac1x+C\\)，有 $$\\frac{1}{x} = \\sum_{n=0}^{\\infty} (-1)^n (x - 1)^n$$ 这是一个 \\(a=1,r=-(x-1)\\) 的Power Series，对这个Power Series积分有 $$\\ln x = \\int \\frac{1}{x} , dx + C = C + \\sum_{n=0}^{\\infty} (-1)^n \\frac{(x - 1)^{n+1}}{n+1}= \\frac{(x-1)}{1} - \\frac{(x-1)^2}{2} + \\frac{(x-1)^3}{3} - \\frac{(x-1)^4}{4} + \\cdots $$ ex. 2. Finding a Power Series by Integration #\r找到 \\(g(x)=\\arctan x\\) 的Power Series\n已知\\(\\arctan(x)\\)的Derivative为\\(\\frac{1}{1+x^2}\\)，令\\(x^2\\)为r，就可以写出他的Power Series有 $$f(x^2) = \\frac{1}{1 + x^2} = \\sum_{n=0}^{\\infty} (-1)^n x^{2n}$$ 再对这玩意积分，有 $$\\arctan x = \\int \\frac{1}{1 + x^2} , dx + C = C + \\sum_{n=0}^{\\infty} (-1)^n \\frac{x^{2n+1}}{2n+1}$$ 令 \\(x=1\\) 可以知道 \\(C=0\\)，有 $$= \\sum_{n=0}^{\\infty} (-1)^n \\frac{x^{2n+1}}{2n+1} = x - \\frac{x^3}{3} + \\frac{x^5}{5} - \\frac{x^7}{7} + \\cdots$$ Taylor and Maclaurin Series #\r在前面通过了使用Geometric Series的Partial Sum找到了很多函数对于的Power Series，通过Taylor Series则可以找到那些可以被求导n次的函数的Power Series 前面提到了Taylor Polynomial拟合的function在他的Radius of Convergence中可以表示为 $$f(x) = f(c) + f\u0026rsquo;(c)(x - c) + \\frac{f\u0026rsquo;\u0026rsquo;(c)}{2!}(x - c)^2 + \\cdots + \\frac{f^{(n)}(c)}{n!}(x - c)^n + \\cdots$$ 这个Polynomial也是不同Power的和，当\\(n=\\infty\\)的时候，其也可以被当作一个Series，有 $$\\sum_{n=0}^{\\infty} \\frac{f^{(n)}(c)}{n!} (x - c)^n = f(c) + f\u0026rsquo;(c)(x - c) + \\cdots + \\frac{f^{(n)}(c)}{n!}(x - c)^n + \\cdots $$ 这时候只要Taylor Series Converge，其就完全的拟合了Function Binomial Series #\r对于形如 \\(f(x)=(1+x)^k\\) 的function，可以通过Binomial Serises逼近，因为其本身就是一个Binomial 二项式，当然可以同Series来表示他的二项式展开，经典二项式定理为 $$(1+x)^k = \\sum_{n=0}^k \\binom{k}{n} x^n$$ 但经典二项式定理存在一个前提为 \\(k\\in \\mathbb z^+\\)，当k不为整数的时候，二项式系数不会在某一项后归零，导致级数没有终止，这就导致了二项式展开变成了Seires，有 $$(1 + x)^k = 1 + kx + \\frac{k(k-1)x^2}{2!} + \\frac{k(k-1)(k-2)x^3}{3!} + \\frac{k(k-1)(k-2)(k-3)x^4}{4!} + \\cdots$$ POWER SERIES FOR ELEMENTARY FUNCTIONS #\r$$\\frac{1}{x} = 1 - (x - 1) + (x - 1)^2 - (x - 1)^3 + \\cdots, \\quad 0 \u0026lt; x \u0026lt; 2$$ $$\\frac{1}{1 + x} = 1 - x + x^2 - x^3 + x^4 - \\cdots, \\quad -1 \u0026lt; x \u0026lt; 1$$ $$\\ln x = (x - 1) - \\frac{(x - 1)^2}{2} + \\frac{(x - 1)^3}{3} - \\frac{(x - 1)^4}{4} + \\cdots, \\quad 0 \u0026lt; x \u0026lt; 2$$ $$e^x = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\frac{x^4}{4!} + \\cdots, \\quad -\\infty \u0026lt; x \u0026lt; \\infty$$ $$\\sin x = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\cdots, \\quad -\\infty \u0026lt; x \u0026lt; \\infty$$ $$\\cos x = 1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} - \\frac{x^6}{6!} + \\cdots, \\quad -\\infty \u0026lt; x \u0026lt; \\infty$$ $$\\arctan x = x - \\frac{x^3}{3} + \\frac{x^5}{5} - \\frac{x^7}{7} + \\cdots, \\quad -1 \\leq x \\leq 1$$ $$\\arctan x = x - \\frac{x^3}{3} + \\frac{x^5}{5} - \\frac{x^7}{7} + \\cdots, \\quad -1 \\leq x \\leq 1$$ $$\\arcsin x = x + \\frac{1 \\cdot 3 x^3}{2 \\cdot 4} + \\frac{1 \\cdot 3 \\cdot 5 x^5}{2 \\cdot 4 \\cdot 6} + \\cdots, \\quad -1 \\leq x \\leq 1$$ $$(1 + x)^k = 1 + kx + \\frac{k(k-1)x^2}{2!} + \\frac{k(k-1)(k-2)x^3}{3!} + \\cdots, \\quad -1 \u0026lt; x \u0026lt; 1^*$$\n","date":"Jan 22 2025","externalUrl":null,"permalink":"/docs/uoft/24/calculus/calculus9.series/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/22/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eSequences \r\n    \u003cdiv id=\"sequences\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#sequences\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eSequence是按照一定顺序排列的一列数。序列可以是有限的也可以是无限的，通常表示为\\(a_1, a_2, a_3, \\ldots\\)，其中\\(a_n\\)表示序列的第n项\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eLimit of a Sequence \r\n    \u003cdiv id=\"limit-of-a-sequence\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#limit-of-a-sequence\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于一个Sequence，如果有\n$$\\lim_{n\\rightarrow\\infty}a_n=L,L\\in \\mathbb R$$\u003c/li\u003e\n\u003cli\u003e则该Sequence的Limit为L\u003c/li\u003e\n\u003cli\u003e如果存在这个L，也可以说Sequence是Converge 收敛的\u003c/li\u003e\n\u003cli\u003e如果不存在，则Sequence Diverge 发散\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eex. Nature Number \r\n    \u003cdiv id=\"ex-nature-number\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex-nature-number\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e找到Sequence \\(a_n = \\left(1 + \\frac{1}{n}\\right)^n\\)的Limit\n$$\\lim_{n \\to \\infty} a_n = \\lim_{n \\to \\infty} \\left(1 + \\frac{1}{n}\\right)^n = e$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eProperties of Limits of Sequences \r\n    \u003cdiv id=\"properties-of-limits-of-sequences\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#properties-of-limits-of-sequences\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003eLet \\(\\lim_{n \\to \\infty} a_n = L \\text{ and } \\lim_{n \\to \\infty} b_n = K\\)\n$$\\lim_{n \\to \\infty} (a_n \\pm b_n) = L \\pm K$$\n$$\\lim_{n \\to \\infty} c a_n = cL$$\n$$\\lim_{n \\to \\infty} (a_n b_n) = LK$$\n$$\\lim_{n \\to \\infty} \\frac{a_n}{b_n} = \\frac{L}{K}$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eSqueeze Theorem for Sequences \r\n    \u003cdiv id=\"squeeze-theorem-for-sequences\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#squeeze-theorem-for-sequences\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003eSqueeze Theorem也可以用来解Sequence的Convergence，其通常用在 \\((-1)^n, \\sin(x)\\)等在\\(n\\rightarrow \\infty\\)时oscillate的函数中\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eex. Sequence Convergence by Squeeze Theorem \r\n    \u003cdiv id=\"ex-sequence-convergence-by-squeeze-theorem\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex-sequence-convergence-by-squeeze-theorem\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e证明Sequence \\({ c_n } = \\left{ (-1)^n \\frac{1}{n!} \\right}\\)收敛\u003c/li\u003e\n\u003cli\u003e使用两个序列\\(a_n=\\frac{1}{2^n}\\)，已知Factorial的扩散速度小于Exponential，有\n$$-\\frac{1}{2^n} \\leq (-1)^n \\frac{1}{n!} \\leq \\frac{1}{2^n}, \\quad n \\geq 4$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eMonotonic Sequences \r\n    \u003cdiv id=\"monotonic-sequences\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#monotonic-sequences\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e当一个Sequence的每一项都单调递增或单调递减时，该Sequence被称为Monotonic Sequence\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eBounded Sequence \r\n    \u003cdiv id=\"bounded-sequence\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#bounded-sequence\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eBounded Above \r\n    \u003cdiv id=\"bounded-above\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#bounded-above\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e当存在一个\\(M\\in \\mathbb R\\)使得\\(a_n\\leq M\\)时，称该Sequence Bounded Above\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eBounded Below \r\n    \u003cdiv id=\"bounded-below\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#bounded-below\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e当存在一个\\(M\\in \\mathbb R\\)使得\\(a_n\\geq M\\)时，称该Sequence Bounded Below\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eBounded \r\n    \u003cdiv id=\"bounded\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#bounded\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e当一个Sequence同时Bounded Above和Below的时候，其Bounded\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eTheorem - Convergent Sequence are Bounded \r\n    \u003cdiv id=\"theorem---convergent-sequence-are-bounded\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#theorem---convergent-sequence-are-bounded\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e如果一个Sequence Convergent，则其一定Bounded\u003c/li\u003e\n\u003cli\u003e同理也可以反推，如果一个Sequence Bounded并且是Monotonic 单调的Sequence的话，该Sequence Convergent 收敛\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eSeries (Infinite Series) \r\n    \u003cdiv id=\"series-infinite-series\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#series-infinite-series\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于Sequence来说，它的所有项相加的和便成为了Series\n$$S_n=\\sum_{n=1}^{\\infty} a_n = a_1 + a_2 + a_3 + \\cdots + a_n + \\cdots$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eConvergent of Series \r\n    \u003cdiv id=\"convergent-of-series\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#convergent-of-series\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于一个Series \\(\\sum^\\infty_{n=1}a_n\\)来说，如果其Partial Sum（前n项之和）等于S，则该Series Converge，反则Diverge\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eTelescoping Series 列项级数 \r\n    \u003cdiv id=\"telescoping-series-%E5%88%97%E9%A1%B9%E7%BA%A7%E6%95%B0\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#telescoping-series-%E5%88%97%E9%A1%B9%E7%BA%A7%E6%95%B0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e通过将级数的两个项组合得到一个新的通项公式求得级数的解\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eex. Finding Series Convergency by Telescoping \r\n    \u003cdiv id=\"ex-finding-series-convergency-by-telescoping\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex-finding-series-convergency-by-telescoping\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e求解\\(\\sum_{n=1}^{\\infty} \\frac{2}{4n^2 - 1}\\)\n$$a_n = \\frac{2}{4n^2 - 1} = \\frac{2}{(2n - 1)(2n + 1)} = \\frac{1}{2n - 1} - \\frac{1}{2n + 1}$$\u003c/li\u003e\n\u003cli\u003e通过观察规律可以看出\n$$S_n = \\left( \\frac{1}{1} - \\frac{1}{3} \\right) + \\left( \\frac{1}{3} - \\frac{1}{5} \\right) + \\cdots + \\left( \\frac{1}{2n-1} - \\frac{1}{2n+1} \\right) = 1 - \\frac{1}{2n+1}$$\u003c/li\u003e\n\u003cli\u003e最终得出\n$$\\sum_{n=1}^{\\infty} \\frac{2}{4n^2 - 1} = \\lim_{n \\to \\infty} S_n = \\lim_{n \\to \\infty} \\left(1 - \\frac{1}{2n+1}\\right) = 1$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eGeometric Series \r\n    \u003cdiv id=\"geometric-series\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#geometric-series\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e形如\\(\\sum_{n=0}^{\\infty} ar^n\\)的Series被称为Geometric Series，其完整形式为\n$$\\sum_{n=0}^{\\infty} ar^n = a + ar + ar^2 + \\cdots + ar^n + \\cdots, \\quad a \\neq 0$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eConvergenvce of Geometric Series \r\n    \u003cdiv id=\"convergenvce-of-geometric-series\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#convergenvce-of-geometric-series\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e当Geometric Series的的敛散性高度取决于其公比r的取值\u003c/li\u003e\n\u003cli\u003e具体来说当\\(0\u0026lt;|r|\u0026lt;1\\) Geometric Series Converge ，当\\(|r|\\geq 1\\)，其Diverge\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eThe Value Geometric Series Converge to \r\n    \u003cdiv id=\"the-value-geometric-series-converge-to\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#the-value-geometric-series-converge-to\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003eGeometric Sereis是很特别的一个Series，于大部分Series不同，当其Converge的时候可以简单的求出Series的值为\n$$\\lim_{n \\to \\infty} S_n = \\lim_{n \\to \\infty} \\left[ \\frac{a(1 - r^n)}{1 - r} \\right] = \\frac{a}{1 - r} \\lim_{n \\to \\infty} (1 - r^n) = \\frac{a}{1 - r}$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eProperty of Infinite Series \r\n    \u003cdiv id=\"property-of-infinite-series\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#property-of-infinite-series\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e如果\\(\\sum a_n\\)和\\(\\sum b_n\\)都是Converge的Series，并且分别收敛到A和B，则有\n$$\\sum_{n=1}^{\\infty} c a_n = cA$$\n$$\\sum_{n=1}^{\\infty} (a_n + b_n) = A + B$$\n$$\\sum_{n=1}^{\\infty} (a_n - b_n) = A - B$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003ep-Series and Harmonic Series \r\n    \u003cdiv id=\"p-series-and-harmonic-series\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#p-series-and-harmonic-series\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cp\u003e$$\\sum_{n=1}^{\\infty} \\frac{1}{n^p} = \\frac{1}{1^p} + \\frac{1}{2^p} + \\frac{1}{3^p} + \\cdots$$\u003c/p\u003e","title":"Calculus 9. Series","type":"docs"},{"content":" Last Edit: 1/20/25\nLoops帮助程序节省空间，提高编写效率并减少错误，常见的Loop存在两种，while loop和for loop\n4.1 While Loop #\rwhile (\u0026lt;condition\u0026gt;) { \u0026lt;statements\u0026gt;; } \u0026lt;other statements\u0026gt;; while loop会重复循环直到while内的condition不再成立，也就是说当\u0026lt;condition\u0026gt;为True时，程序将会不断重复执行\u0026lt;statement\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(void) { int i = 1; while (i \u0026lt;= 10) { printf(\u0026#34;%d \u0026#34;, i); i++; } return 0; } 这就是一个很简单的累加器的例子，程序依次打印1到10后跳出循环 4.1.2 Infinite Loops #\r如果永远跳不出Loop，就叫做Infinite Loops 4.2 Do-while Loop #\r与While最大的区别就在于，Do-while Loop会至少执行\u0026lt;statement\u0026gt;一次，之后根据Condition判断是否循环 do { \u0026lt;statements\u0026gt;; } while (\u0026lt;condition\u0026gt;); 可以看出，无论\u0026lt;condition\u0026gt;为True or False，都将先做一遍statement的 4.2.2 Do-While vs. while #\r#include \u0026lt;stdio.h\u0026gt; int main(void) { int num; do { printf(\u0026#34;Please enter a number between 1 and 10 (inclusive): \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;num); } while (num \u0026lt; 1 || num \u0026gt; 10); printf(\u0026#34;The number entered is %d.\\n\u0026#34;, num); return 0; } For loops #\rfor 循环的本质是为了解决重复执行一定次数的任务的问题，尤其是在已知迭代次数或需要遍历某个范围或集合的场景下\n4.3.1 Forming for loop #\rfor (\u0026lt;initialization\u0026gt;;\u0026lt;condition\u0026gt;;\u0026lt;increment\u0026gt;) { \u0026lt;statements\u0026gt;; } \u0026lt;other statements\u0026gt;; 可以看到相比于while，for更像是while的下层应用，将问题具体到了已知范围的事件下 #include \u0026lt;stdio.h\u0026gt; int main(void) { for (int i = 1; i \u0026lt;= 10; i++) { printf(\u0026#34;%d \u0026#34;, i); } return 0; } 对比上方的while，他们干了相同的事件不过用了更加简介的API 4.3.2 Scope of the loop variable #\r对于For loop来说一般都会存在一个变量充当累加器的作用，其Scope 作用域将在Loop结束后不再可用 #include \u0026lt;stdio.h\u0026gt; int main(void) { for (int i = 1; i \u0026lt;= 10; i++) { // declare \u0026amp; initialize the loop variable inside the loop printf(\u0026#34;%d \u0026#34;, i); } printf(\u0026#34;\\nWe exited the loop with i = %d \\n\u0026#34;, i); return 0; } 上述代码展示了Loop内部的i和外部的i的访问，由于printf(\u0026quot;\\nWe exited the loop with i = %d \\n\u0026quot;, i);调用的是out of scope的，所以将会报错 其解决方案就是在执行循环前先定义Variable，也就是在外面加一句int i = 0; 4.3.3 Variations in for loop #\r实际上，for loop存在许多变体使得他可以省略一些参数 #include \u0026lt;stdio.h\u0026gt; int main(void) { for (int i = 1, j = 7; i \u0026lt;= 10; printf(\u0026#34;7 * %d = %d\\n\u0026#34;, i, j), i += 1, j += 7); return 0; } 这本质和以下代码是一样的 #include \u0026lt;stdio.h\u0026gt; int main(void) { for (int i = 1, j = 7; i \u0026lt;= 10;) printf(\u0026#34;7 * %d = %d\\n\u0026#34;, i, j); i += 1; j += 7; return 0; } 变体使得代码在可能略微减少大小的情况下使得整体可读性，是一种非常不健康的写法 4.4 Nested Loop #\rLoop中套Loop，复杂度变成多项式复杂度\n4.4.1 Print 2D pattern #\r如果想要打印出以下图案 * ** *** **** ***** 可以通过设计外层loop构建层，内层loop确定单层打印个数的方式完成 #include \u0026lt;stdio.h\u0026gt; int main(void) { for (int line = 1; line \u0026lt;= 5; line += 1) { // 外层循环控制行数 for (int star = 1; star \u0026lt;= line; star += 1) { // 内层循环控制每行星号的数量 printf(\u0026#34;*\u0026#34;); } printf(\u0026#34;\\n\u0026#34;); // 每行结束后换行 } return 0; } 4.4.2 Tweak a little #\r现在要打印这个 *\r**\r***\r****\r***** 前的部分为空格 #include \u0026lt;stdio.h\u0026gt; int main(void) { int n = 0; printf(\u0026#34;Enter the number of rows:\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); for (int row = 1; row \u0026lt;= n; row += 1) { for (int col = 1; col \u0026lt;= n; col += 1) { if (col \u0026lt;= n - row) { printf(\u0026#34; \u0026#34;); } else { printf(\u0026#34;*\u0026#34;); } } printf(\u0026#34;\\n\u0026#34;); } return 0; } 4.5 Debugging for loops #\r本节将会给出一个loop的错误，需要发现该错误并修正，想要打印一个 Enter the number of rows: **5**\r*\r***\r*****\r*******\r********* #include \u0026lt;stdio.h\u0026gt; int main(void) { int n = 0; printf(\u0026#34;Enter the number of rows: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); for (int row = 1; row \u0026lt;= n; row += 1) { for (int col = 1; col \u0026lt; n; col += 1) { if (col \u0026lt;= n - row) { printf(\u0026#34; \u0026#34;); } else if (col \u0026gt;= n - row || col \u0026lt;= n - 1 + row) { printf(\u0026#34;*\u0026#34;); } } printf(\u0026#34;\\n\u0026#34;); } return 0; } ","date":"Jan 20 2025","externalUrl":null,"permalink":"/docs/uoft/24/learning-programming-with-c/lpc4.repetition/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/20/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLoops帮助程序节省空间，提高编写效率并减少错误，常见的Loop存在两种，while loop和for loop\u003c/p\u003e","title":"LPC 4. Repetition","type":"docs"},{"content":" Last Edit: 1/19/25\n简介 #\rHugo是一个基于Go语言的Github开源项目，其支持Markdown语法并可以托管到Github Pages上 环境准备 #\rGit https://git-scm.com/ Go语言的安装 https://go.dev/doc/install Scoop下载 https://scoop.sh 创建项目 #\r在配置完了环境后，在终端通过Scoop安装Hugo文件 scoop install hugo-extended 之后在准备好的项目路径下通过hugo指令直接创建项目文件 hugo new site {{这里填你的文件名}} 之后提示Congratulation后，cd进入文件下下尝试启动hugo hugo server 如果输出为 - Web Server is available at http://localhost:1313/ (bind address 127.0.0.1)\r- Press Ctrl+C to stop 则说明项目已被成功部署，打开链接可以看到以下界面 显示Page Not Found是正确的\n之后建议Ctrl + C退出后台 安装主题 #\rHugo项目可以通过安装他人准备好的Theme主题来达到轻松的美化效果 Hugo主页上列出了很多个主题，可以任意选择一个喜欢的 这里将以Blowfish作为示范，以下是其Github仓库链接\nhttps://github.com/nunocoracao/blowfish/?tab=readme-ov-file\n更具教程，使用git submodule安装主题\n需要注意的是先要git init，之后在hugo文件夹下安装\ngit submodule add -b main https://github.com/nunocoracao/blowfish.git themes/blowfish 等待主题安装完毕后，打开hugo文件夹下的hugo.toml文件，添加以下代码 - theme = \u0026#39;blowfish\u0026#39; 保存后再次运行hugo便可以预览到该主题已经被成功安装 主题配置 #\r建议在添加Markdown文档之前对主题做出如下更改 打开\\themes\\blowfish\\config`，并将params.toml更改至如下 [homepage] layout = \u0026#34;background\u0026#34; # valid options: page, profile, hero, card, background, custom #homepageImage = \u0026#34;IMAGE.jpg\u0026#34; # used in: hero, and card showRecent = true 这将打开主页上的最佳文档，可以直接在homepage上浏览到最近添加的文档 创建文章 #\r打开Content文件夹，在里面新建文件夹 创建_index.md并写入以下代码 --- title: \u0026#34;Docs\u0026#34; description: \u0026#34;\u0026#34; cascade: showDate: true showAuthor: false invertPagination: true --- 关于具体代码的含义，请查看 Documentation · Blowfish文档 之后保存文件并且在该文件夹下再次新建文件夹 建议采取一个文件夹一个文章方式，如该文件夹为其他页面的父页面，则命名为_index.md，如没有子文档，则文档存放markdown命名为index.md\n之后添加index.md文件，并写入任意Markdown文章，具体语法可以查看 Markdown Guide 预览 #\r在想要预览的时候，于终端输入 hugo server 打开http://localhost:1313/便可以看到创建出来的文档 上传至Github pages #\r打开github创建新仓库，创建一个名为{{id}}.github.io的仓库 来到hugo文件夹下 hugo cd .\\public\\ hugo是令hugo创建准备好的上传的页面，其会被存到public文件夹下，之后cd进入 git init -b main git remote add origin {{仓库链接}} 链接远程git仓库（git设置部分请自行准备） git add .\rgit commit -m \u0026#34;init\u0026#34;\rgit push -u origin main 添加文件后push至github等其完成部署之后就能在{{id}}.github.io访问到了 ","date":"Jan 19 2025","externalUrl":null,"permalink":"/docs/projects/buildapersonalwebsitebyhugo/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/19/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e简介 \r\n    \u003cdiv id=\"%E7%AE%80%E4%BB%8B\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%AE%80%E4%BB%8B\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/projects/buildapersonalwebsitebyhugo/BuildapersonalwebsitebyHugo-3_hu7946849046172097452.png 330w,\r\n        /docs/projects/buildapersonalwebsitebyhugo/BuildapersonalwebsitebyHugo-3_hu5581787319040588473.png 660w,\r\n        /docs/projects/buildapersonalwebsitebyhugo/BuildapersonalwebsitebyHugo-3_hu10522245190111443328.png 1024w,\r\n        /docs/projects/buildapersonalwebsitebyhugo/BuildapersonalwebsitebyHugo-3_hu13328635153818595949.png 2x\"\r\n        src=\"/docs/projects/buildapersonalwebsitebyhugo/BuildapersonalwebsitebyHugo-3_hu5581787319040588473.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"Build a personal website by Hugo","type":"docs"},{"content":"","date":"Jan 19 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l5.deeplearningcomputation/","section":"Docs","summary":"","title":"D2L 5. Deep Learning Computation","type":"docs"},{"content":" Last Edit: 1/19/25\n在整体网络中，存在一些不同的层，他们都是专门用来处理不同事件的，这也令自定义层变得有必要\n5.4.1 Layer without parameter #\rimport torch import torch.nn.functional as F from torch import nn class CenteredLayer(nn.Module): def __init__(self): super().__init__() def forward(self, X): return X - X.mean() 将比之前的层，这个forward过程中仅包含了一个减去平均值的操作，这相当于在模型中以一个层的方式包装了一个函数 5.4.2 Layer with parameter #\rclass MyLinear(nn.Module): def __init__(self, in_units, units): super().__init__() self.weight = nn.Parameter(torch.randn(in_units, units)) self.bias = nn.Parameter(torch.randn(units,)) def forward(self, X): linear = torch.matmul(X, self.weight.data) + self.bias.data return F.relu(linear) 本质上就是重构了一下pytorch的nn.Linear模块 self.weight = nn.Parameter(torch.randn(in_units, units)) self.bias = nn.Parameter(torch.randn(units,)) 权重矩阵W决定了输入X如何被映射到输出空间。 每个输入特征（列）需要与输出特征（列）有连接。 因此，权重矩阵需要有： 行数：输入特征的数量（in_units） 列数：输出特征的数量（units） 转换到pytorch中就相当于 import torch import torch.nn as nn import torch.nn.functional as F class MyLinearWithBuiltin(nn.Module): def __init__(self, in_units, units): super().__init__() self.linear = nn.Linear(in_units, units) # 内置线性层 def forward(self, X): linear = self.linear(X) # 使用内置线性层 return F.relu(linear) # ReLU 激活函数 ","date":"Jan 19 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.4customlayer/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/19/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e在整体网络中，存在一些不同的层，他们都是专门用来处理不同事件的，这也令自定义层变得有必要\u003c/p\u003e","title":"D2L 5.4 Custom Layer","type":"docs"},{"content":"","date":"Jan 19 2025","externalUrl":null,"permalink":"/tags/ma/","section":"Tags","summary":"","title":"MA","type":"tags"},{"content":"","date":"Jan 19 2025","externalUrl":null,"permalink":"/tags/pr/","section":"Tags","summary":"","title":"PR","type":"tags"},{"content":"Projects\n","date":"Jan 19 2025","externalUrl":null,"permalink":"/docs/projects/","section":"Docs","summary":"\u003cp\u003eProjects\u003c/p\u003e","title":"Projects","type":"docs"},{"content":" Last Edit: 1/18/25\nDeferred Initialization是指模型的某些参数在模型创建时并不会立即被初始化，而是会在第一次接收到输入数据时，根据输入数据的实际形状动态地完成初始化 需要知道的是延后初始化的核心目标 就是为了解决 输入维度未知 的问题，而模型内部层之间的维度通常是事先定义好的\n5.3.1 Create Network 实例化网络 #\rclass MyNet(nn.Module): def __init__(self): super().__init__() self.layers = nn.Sequential( nn.Linear(0, 0), nn.ReLU(), nn.Linear(0, 0) ) 先定义模型框架，将两个Linear Layer留空，这样就可以在之后更改 def forward(self, x): if isinstance(self.layers[0], nn.Linear) and self.layers[0].in_features == 0: self.layers[0] = nn.Linear(x.size(1), 256) # 动态初始化第一层 if isinstance(self.layers[2], nn.Linear) and self.layers[2].in_features == 0: self.layers[2] = nn.Linear(256, 10) # 动态初始化第二层 return self.layers(x) 定义前向传播的过程，并在过程中加入初始化的部分，由于不知道具体的输入维度，将self.layers[0] = nn.Linear(x.size(1), 256)这一层的input Feature设置为输入的维度，也就是x.size(1)，而层与层之间的维度都是可以自行调整的，这里就可以设置这一层的output维度为256 分别检查定义模型时的层和运行后的，有 Before input:\rLayer 0 weights: None\rLayer 2 weights: None\rAfter input:\rLayer 0 weights: torch.Size([256, 20])\rLayer 2 weights: torch.Size([10, 256]) ","date":"Jan 18 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.3deferredinitialization/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/18/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eDeferred Initialization是指模型的某些参数在模型创建时并不会立即被初始化，而是会在第一次接收到输入数据时，根据输入数据的实际形状动态地完成初始化\n需要知道的是延后初始化的\u003cstrong\u003e核心目标\u003c/strong\u003e 就是为了解决 \u003cstrong\u003e输入维度未知\u003c/strong\u003e 的问题，而模型内部层之间的维度通常是事先定义好的\u003c/p\u003e","title":"D2L 5.3 Deferred Initialization","type":"docs"},{"content":" Last Edit: 1/17/25\n在训练的过程中，目标是找到使得Cost Function最小化的Parameters，而有些时候需要提取其中一层的参数检查或者移动到其他环境下，这就需要访问参数\n5.2.1 Access parameters 访问参数 #\r现在先用一个简单的MLP import torch from torch import nn net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1)) X = torch.rand(size=(2, 4)) net(X) 当采用pytorch的Sequential定义模型的时候，可以通过Index访问层 print(net[2].state_dict()) -\u0026gt; OrderedDict([(\u0026#39;weight\u0026#39;, tensor([[-0.0861, 0.1627, 0.2363, 0.2068, 0.0122, -0.1120, -0.3021, -0.2810]])), (\u0026#39;bias\u0026#39;, tensor([0.0187]))]) 查看Output，其包含了\u0026rsquo;weight\u0026rsquo; 和 \u0026lsquo;bias\u0026rsquo; 两个参数 需要知道的是每一层的参数的名称都对应唯一的值，如访问所有模型参数时 print(net.state_dict()) -\u0026gt; OrderedDict([(\u0026#39;0.weight\u0026#39;, tensor([[ 0.2787, 0.1086, 0.2637, 0.1725], [ 0.0952, 0.4238, 0.0774, -0.1717], [-0.2244, 0.0670, -0.4168, 0.1995], [ 0.1364, -0.1932, 0.0650, 0.3378], [-0.1094, 0.2522, -0.2162, -0.2466], [ 0.1079, 0.0859, -0.4721, -0.1010], [-0.2436, 0.2096, -0.3895, 0.4636], [ 0.2348, 0.1281, -0.1079, 0.4432]])), (\u0026#39;0.bias\u0026#39;, tensor([-0.0356, 0.3268, 0.3199, -0.4558, -0.2564, -0.3566, -0.1493, 0.0168])), (\u0026#39;2.weight\u0026#39;, tensor([[-0.0861, 0.1627, 0.2363, 0.2068, 0.0122, -0.1120, -0.3021, -0.2810]])), (\u0026#39;2.bias\u0026#39;, tensor([0.0187]))]) 5.2.1.1 Target Parameter 目标参数 #\r既然能访问层下参数，当然也能访问到具体参数 print(type(net[2].bias)) print(net[2].bias) print(net[2].bias.data) -\u0026gt; \u0026lt;class \u0026#39;torch.nn.parameter.Parameter\u0026#39;\u0026gt; Parameter containing: tensor([0.0187], requires_grad=True) tensor([0.0187]) 单个参数是一个复合对象，即不止包含值 5.2.1.3 Collect Parameter from blocks #\rdef block1(): return nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 4), nn.ReLU()) def block2(): net = nn.Sequential() for i in range(4): # 在这里嵌套 net.add_module(f\u0026#39;block {i}\u0026#39;, block1()) return net rgnet = nn.Sequential(block2(), nn.Linear(4, 1)) rgnet(X) 这里构建了一个挺复杂的网络，具体来说block2定义了一个大块，其中input要经过4个block1之后通过一个Linear Layer，完整结构如下 -\u0026gt; rgnet: Sequential( (0): block2: Sequential( (block 0): block1 (block 1): block1 (block 2): block1 (block 3): block1 ) (1): Linear(4, 1) ) 就像多层的List一样，需要通过维度依次访问，最外层为一个Block 2和一个Linear，而Block2 内部依然是一个“二维列表”，通过rgnet[0][1][0].bias.data就可以访问到(block 1): block1的Linear层的bias的值 5.2.2 Parameter Initialization 参数初始化 #\r前面讨论过了一个系统的初始化的重要性，可以简单的通过框架做默认初始化也可以自定义 5.2.2.1 Built-in initialization 内置初始化 #\rdef init_normal(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, mean=0, std=0.01) nn.init.zeros_(m.bias) net.apply(init_normal) net[0].weight.data[0], net[0].bias.data[0] 上面的nn.init.normal_和nn.init.zeros_分别对应了Gaussian Distribution和零值 nn.init.constant_(m.weight,1)则可以将weight全设置为固定值1 5.2.2.2 Custom Initialization 自定义初始化 #\r5.2.3 Combined Parameter 参数绑定 #\r通过在定义模型之间定义层，后将层作为元素直接放入模型中，这样就可以做到模型中的两个层不止在数值上是相等的，其调用的Memory都是同一个（即改一个则全变） 当参数绑定时，梯度会发生什么情况？ 答案是由于模型参数包含梯度，因此在反向传播期间第二个隐藏层 （即第三个神经网络层）和第三个隐藏层（即第五个神经网络层）的梯度会加在一起。 -\u0026gt; 将补充原理\n","date":"Jan 17 2025","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.2parametermanagement/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/17/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e在训练的过程中，目标是找到使得Cost Function最小化的Parameters，而有些时候需要提取其中一层的参数检查或者移动到其他环境下，这就需要访问参数\u003c/p\u003e","title":"D2L 5.2 Parameter Management","type":"docs"},{"content":" Last Edit: 1/13/25\nPolynomial Interpolation #\r如果想要找一个Polynomial，其穿过两个Point，很简单的做法就是建立$P(x)=ax+b$的多项式 但是如果问题变成了三个点甚至更多，问题的复杂度就会上升很多，于是需要考虑另一种做法 对于点$(-1,-1),(1,3),(2,-2)$我们需要找到一个Polynomial穿过这三个点，可以先写出三个Quadratic Polynomial $$L_1(x) := \\begin{cases} 1, \u0026amp; \\text{if } x = -1 \\ 0, \u0026amp; \\text{if } x = 1 \\ 0, \u0026amp; \\text{if } x = 2, \\end{cases} L_2(x) := \\begin{cases} 0, \u0026amp; \\text{if } x = -1 \\ 1, \u0026amp; \\text{if } x = 1 \\ 0, \u0026amp; \\text{if } x = 2, \\end{cases}\nL_3(x) := \\begin{cases} 0, \u0026amp; \\text{if } x = -1 \\ 0, \u0026amp; \\text{if } x = 1 \\ 1, \u0026amp; \\text{if } x = 2. \\end{cases} $$\n之后再令$P_2(x)=−1L_1(x) + 3L_2(x) − 2L_3(x)$ 分别查看三个点的值可以发现 $$P_2(-1) = -1L_1(-1) + 3L_2(-1) - 2L_3(-1) \\ = -1(1) + 3(0) - 2(0) \\ = -1$$ $$P_2(1) = -1L_1(1) + 3L_2(1) - 2L_3(1) \\ = -1(0) + 3(1) - 2(0) \\ = 3$$ $$ P_2(2) = -1L_1(2) + 3L_2(2) - 2L_3(2) \\ = -1(0) + 3(0) - 2(1) \\ = -2$$ 可以发现这样构建的Polynomial是符合要求的，那么问题就变成了如何构建这三个Quadratic Polynomial 已知$L_1(x)$有两个Roots，分别为$x=1$和$x=2$，并且因为$L_1(-1)=1$所以有 $$L_1(-1)=C(-1-1)(-1-2)=1\\Rightarrow C=\\frac{1}{(-1-1)(-1-2)}$$ 同理对于$L_2$和$L_3$来说有 $$P_2(x) = -1 \\frac{(x - 1)(x - 2)}{(-1 - 1)(-1 - 2)} + 3 \\frac{(x + 1)(x - 2)}{(1 + 1)(1 - 2)} - 2 \\frac{(x + 1)(x - 1)}{(2 + 1)(2 - 1)} $$ 这就是Lagrange Interpolation 拉格朗日插值法 ex. #\r将Lagrange Interpolation推广到四个点上，有 $$L_1(x) := \\begin{cases} 1, \u0026amp; \\text{if } x = x_1 \\ 0, \u0026amp; \\text{if } x = x_2 \\ 0, \u0026amp; \\text{if } x = x_3 \\ 0, \u0026amp; \\text{if } x = x_4, \\end{cases} L_2(x) := \\begin{cases} 0, \u0026amp; \\text{if } x = x_1 \\ 1, \u0026amp; \\text{if } x = x_2 \\ 0, \u0026amp; \\text{if } x = x_3 \\ 0, \u0026amp; \\text{if } x = x_4, \\end{cases}\nL_3(x) := \\begin{cases} 0, \u0026amp; \\text{if } x = x_1 \\ 0, \u0026amp; \\text{if } x = x_2 \\ 1, \u0026amp; \\text{if } x = x_3 \\ 0, \u0026amp; \\text{if } x = x_4, \\end{cases}\nL_4(x) := \\begin{cases} 0, \u0026amp; \\text{if } x = x_1 \\ 0, \u0026amp; \\text{if } x = x_2 \\ 0, \u0026amp; \\text{if } x = x_3 \\ 1, \u0026amp; \\text{if } x = x_4. \\end{cases}$$\n其最终的Polynomial将会长这样 $$P_3(x) = y_1 \\frac{(x-x_2)(x-x_3)(x-x_4)}{(x_1-x_2)(x_1-x_3)(x_1-x_4)} + y_2 \\frac{(x-x_1)(x-x_3)(x-x_4)}{(x_2-x_1)(x_2-x_3)(x_2-x_4)} + y_3 \\frac{(x-x_1)(x-x_2)(x-x_4)}{(x_3-x_1)(x_3-x_2)(x_3-x_4)} + y_4 \\frac{(x-x_1)(x-x_2)(x-x_3)}{(x_4-x_1)(x_4-x_2)(x_4-x_3)}$$ ","date":"Jan 13 2025","externalUrl":null,"permalink":"/docs/uoft/24/calculus/calculusa1.polynomialinterpolation/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/13/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003ePolynomial Interpolation \r\n    \u003cdiv id=\"polynomial-interpolation\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#polynomial-interpolation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e如果想要找一个Polynomial，其穿过两个Point，很简单的做法就是建立$P(x)=ax+b$的多项式\u003c/li\u003e\n\u003cli\u003e但是如果问题变成了三个点甚至更多，问题的复杂度就会上升很多，于是需要考虑另一种做法\u003c/li\u003e\n\u003cli\u003e对于点$(-1,-1),(1,3),(2,-2)$我们需要找到一个Polynomial穿过这三个点，可以先写出三个Quadratic Polynomial\n$$L_1(x) := \\begin{cases}\n1, \u0026amp; \\text{if } x = -1 \\\n0, \u0026amp; \\text{if } x = 1 \\\n0, \u0026amp; \\text{if } x = 2,\n\\end{cases}\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eL_2(x) := \\begin{cases}\n0, \u0026amp; \\text{if } x = -1 \\\n1, \u0026amp; \\text{if } x = 1 \\\n0, \u0026amp; \\text{if } x = 2,\n\\end{cases}\u003c/p\u003e","title":"Calculus A1. Polynomial Interpolation","type":"docs"},{"content":" Last Edit: 1/13/25\nIn this chapter, we will discuss how to make decisions in C. We will discuss the if, else and else if statements\n3.1 If-Statement #\r开发一个提示用户输入年龄的程序。如果未满工作的法定年龄，程序会打印“您还没有资格工作”，否则会显示“您有资格工作” if和else的语法在C中如下 if (condition) { // code to execute if condition is true } else { // code to execute if condition is false } 3.1.1 What can this condition be #\rCondition是一个Bool variable，其可以用True表示，也可以用Numerical Value。在C中，任意非零的值都（通常用1）代表了True，而False则是0 Relational Expression #\r关系运算符通常使用以下的符号 ==：Equal to !=：Not Equal to \u0026lt;：Less than \u0026gt;：Greater than \u0026lt;=：Leq \u0026gt;=：Geq 有了这些就可以完整编写一个判断年龄的程序了 #include \u0026lt;stdio.h\u0026gt; int main(void) { int age = 0; printf(\u0026#34;Enter your age: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;age); if (age \u0026lt; 14) { // Condition checking if age is less than 14 printf(\u0026#34;You are not yet eligible to work in Ontario.\u0026#34;); } else { printf(\u0026#34;You are eligible to work in Ontario.\u0026#34;); } return 0; } 3.1.2. What can we do with relational operators? #\r通过Relational Operators，可以实现 比较值的大小：(7.2\u0026gt;5.1) 比较char的大小：'a'\u0026gt;'b'，这里比较的是他们的ASCII 比较char和int：比如(0 == '0')，char的0有ASCII = 48，所以0 != \u0026lsquo;0\u0026rsquo; int x = 0; if (x = 1) { printf(\u0026#34;True\u0026#34;); } 这是一个判断，他最终会输出True，这是因为即使第一行赋值int x = 0;，第二行重新令x = 1，使得判断变成了if (1)，而1就是True 3.2 Multiple Conditions #\r想要同时判断两个Condition的成立，可以通过\u0026amp;\u0026amp;的判断符，这些完整的叫做Logical Operators 3.2.1 Logical/Boolean Operators #\rA B A \u0026amp;\u0026amp; B A || B false false false false false true false true true false false true true true true true 完整的Logical Opeators的判断结果如上，但是记住过程比背下表格更加简单 \u0026amp;\u0026amp;，and，当A和B同为true则为True，其他均为False ||，or，当A和B其中一个为True则整体为True 还有第三个Logial Operators为!，其的作用就是Reverse Bool Value #include \u0026lt;stdio.h\u0026gt; int main(void) { char letter = \u0026#39; \u0026#39;; printf(\u0026#34;Enter a letter: \u0026#34;); scanf(\u0026#34;%c\u0026#34;, \u0026amp;letter); if (letter == \u0026#39;A\u0026#39; || letter == \u0026#39;a\u0026#39;) { printf(\u0026#34;You entered an upper case or lower case A.\u0026#34;); } else { printf(\u0026#34;You did not enter an upper case or lower case A.\u0026#34;); } return 0; } 上面的程序，当输入为A或者a的时候，都会进入if，因为用的是||，or判断符 3.2.1.1 Lazy Evaluation #\r假设执行了x % y \u0026lt; 10的判断，一个问题可能出现在当y=0的时候，所以这就需要在整除之前做一步y!=0的判断 一种做法就是nested-if，嵌套if，这是一个非常lj的做法，虽然可读性高，但占用的时间和空间都是庞大的 if (条件1) { // 条件1满足时执行的代码 if (条件2) { // 条件1和条件2同时满足时执行的代码 } } 另外一种做法就是通过Lazy Evaluation，其实就是使用\u0026amp;\u0026amp; if (y != 0 \u0026amp;\u0026amp; x % y \u0026lt; 10) { // do something } Lazy evaluation将多个判断结合为一个的办法，详细来说他会从左到右的顺序判断 || 这个运算符先评估左侧的表达式（LHS，Left-Hand Side）。 如果LHS为true，那么整个条件表达式结果为true，程序将不再继续评估右侧的表达式（RHS，Right-Hand Side）。 如果LHS为false，程序需要继续评估RHS来决定整个表达式的结果。 \u0026amp;\u0026amp; 这个运算符也先评估LHS。 如果LHS为false，那么整个条件表达式结果为false，程序将不再继续评估RHS。 如果LHS为true，程序需要继续评估RHS来决定整个表达式的结果。 这种评估方式是一种效率优化手段，可以减少不必要的计算 3.2.1.2 De Morgan\u0026rsquo;s Law #\r当一个Lazy Evaluation（注意仅是两个及以上的判断同时发生的情况下）判断的最外侧为一个Not，也就是!的时候，整体的判断将会看上去十分复杂，这可以通过De Morgan\u0026rsquo;s Law化简 具体来说!(A \u0026amp;\u0026amp; B) is equivalent to !A || !B，!(A || B) is equivalent to !A \u0026amp;\u0026amp; !B 同时Relational Expression也可以变换，\u0026gt; 变成了\u0026lt;=，\u0026gt;= 变成 \u0026lt;，== 变成 != 3.3 Nested-if Statement #\r当想要做特别多的判断的时候，可以采取Nested-if Statement，也就是嵌套If 3.3.2 Dangling Else Problem #\r在C语言中，if语句可以不带大括号{}来执行单条语句 if (condition) statement; else statement; 这种写法没有问题，因为每个if和else清晰地对应一条语句。但是，如果没有使用大括号对嵌套的if语句进行清晰的界定，就会产生 Dangling Else 问题 if (condition1) if (condition2) statement; else statement; 在这种情况下，不明确的是这个else应该属于哪个if。按照C语言的规则，else总是匹配最近的未匹配的if，所以在没有大括号明确界定的情况下，上面的else属于if (condition2) 所以没事就加个{} ","date":"Jan 13 2025","externalUrl":null,"permalink":"/docs/uoft/24/learning-programming-with-c/lpc3.decisionmakingstatements/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/13/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e In this chapter, we will discuss how to make decisions in C. We will discuss the \u003ccode\u003eif\u003c/code\u003e, \u003ccode\u003eelse\u003c/code\u003e and \u003ccode\u003eelse if\u003c/code\u003e statements\u003c/p\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e3.1 If-Statement \r\n    \u003cdiv id=\"31-if-statement\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#31-if-statement\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e开发一个提示用户输入年龄的程序。如果未满工作的法定年龄，程序会打印“您还没有资格工作”，否则会显示“您有资格工作”\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eif\u003c/code\u003e和\u003ccode\u003eelse\u003c/code\u003e的语法在C中如下\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003econdition\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// code to execute if condition is true\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e \u003cspan class=\"k\"\u003eelse\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// code to execute if condition is false\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\r\n\r\n\u003ch2 class=\"relative group\"\u003e3.1.1 What can this condition be \r\n    \u003cdiv id=\"311-what-can-this-condition-be\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#311-what-can-this-condition-be\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eCondition是一个Bool variable，其可以用\u003ccode\u003eTrue\u003c/code\u003e表示，也可以用Numerical Value。在C中，任意非零的值都（通常用1）代表了\u003ccode\u003eTrue\u003c/code\u003e，而\u003ccode\u003eFalse\u003c/code\u003e则是0\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eRelational Expression \r\n    \u003cdiv id=\"relational-expression\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#relational-expression\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e关系运算符通常使用以下的符号\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e==\u003c/code\u003e：Equal to\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e!=\u003c/code\u003e：Not Equal to\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e\u0026lt;\u003c/code\u003e：Less than\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e\u0026gt;\u003c/code\u003e：Greater than\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e\u0026lt;=\u003c/code\u003e：Leq\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e\u0026gt;=\u003c/code\u003e：Geq\u003c/li\u003e\n\u003cli\u003e有了这些就可以完整编写一个判断年龄的程序了\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;stdio.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eage\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;Enter your age: \u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nf\"\u003escanf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;%d\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eage\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e14\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e  \u003cspan class=\"c1\"\u003e// Condition \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003echecking\u003c/span\u003e \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eage\u003c/span\u003e \u003cspan class=\"n\"\u003eis\u003c/span\u003e \u003cspan class=\"n\"\u003eless\u003c/span\u003e \u003cspan class=\"n\"\u003ethan\u003c/span\u003e \u003cspan class=\"mi\"\u003e14\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;You are not yet \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eeligible\u003c/span\u003e \u003cspan class=\"n\"\u003eto\u003c/span\u003e \u003cspan class=\"n\"\u003ework\u003c/span\u003e \u003cspan class=\"n\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eOntario\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e}\u003c/span\u003e \u003cspan class=\"k\"\u003eelse\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;You are eligible to \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ework\u003c/span\u003e \u003cspan class=\"n\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eOntario\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\r\n\r\n\u003ch2 class=\"relative group\"\u003e3.1.2. What can we do with relational operators? \r\n    \u003cdiv id=\"312what-can-we-do-with-relational-operators\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#312what-can-we-do-with-relational-operators\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e通过Relational Operators，可以实现\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003e比较值的大小：\u003ccode\u003e(7.2\u0026gt;5.1)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e比较\u003ccode\u003echar\u003c/code\u003e的大小：\u003ccode\u003e'a'\u0026gt;'b'\u003c/code\u003e，这里比较的是他们的ASCII\u003c/li\u003e\n\u003cli\u003e比较\u003ccode\u003echar\u003c/code\u003e和\u003ccode\u003eint\u003c/code\u003e：比如\u003ccode\u003e(0 == '0')\u003c/code\u003e，char的0有ASCII = 48，所以0 != \u0026lsquo;0\u0026rsquo;\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;True\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e这是一个判断，他最终会输出True，这是因为即使第一行赋值\u003ccode\u003eint x = 0;\u003c/code\u003e，第二行重新令\u003ccode\u003ex = 1\u003c/code\u003e，使得判断变成了\u003ccode\u003eif (1)\u003c/code\u003e，而1就是True\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e3.2 Multiple Conditions \r\n    \u003cdiv id=\"32-multiple-conditions\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#32-multiple-conditions\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e想要同时判断两个Condition的成立，可以通过\u003ccode\u003e\u0026amp;\u0026amp;\u003c/code\u003e的判断符，这些完整的叫做Logical Operators\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e3.2.1 Logical/Boolean Operators \r\n    \u003cdiv id=\"321-logicalboolean-operators\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#321-logicalboolean-operators\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003eA\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eB\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eA \u0026amp;\u0026amp; B\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eA || B\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003efalse\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003etrue\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cul\u003e\n\u003cli\u003e完整的Logical Opeators的判断结果如上，但是记住过程比背下表格更加简单\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e\u0026amp;\u0026amp;\u003c/code\u003e，and，当A和B同为true则为True，其他均为False\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e||\u003c/code\u003e，or，当A和B其中一个为True则整体为True\u003c/li\u003e\n\u003cli\u003e还有第三个Logial Operators为\u003ccode\u003e!\u003c/code\u003e，其的作用就是Reverse Bool Value\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;stdio.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"kt\"\u003echar\u003c/span\u003e \u003cspan class=\"n\"\u003eletter\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"sc\"\u003e\u0026#39; \u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;Enter a letter: \u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nf\"\u003escanf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;%c\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003eletter\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eletter\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"sc\"\u003e\u0026#39;A\u0026#39;\u003c/span\u003e \u003cspan class=\"o\"\u003e||\u003c/span\u003e \u003cspan class=\"n\"\u003eletter\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"sc\"\u003e\u0026#39;a\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;You entered an upper case or lower \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003ecase\u003c/span\u003e \u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e}\u003c/span\u003e \u003cspan class=\"k\"\u003eelse\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;You did not enter an upper case or \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003elower\u003c/span\u003e \u003cspan class=\"k\"\u003ecase\u003c/span\u003e \u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e上面的程序，当输入为A或者a的时候，都会进入if，因为用的是\u003ccode\u003e||\u003c/code\u003e，or判断符\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003e3.2.1.1 Lazy Evaluation \r\n    \u003cdiv id=\"3211-lazy-evaluation\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#3211-lazy-evaluation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e假设执行了\u003ccode\u003ex % y \u0026lt; 10\u003c/code\u003e的判断，一个问题可能出现在当y=0的时候，所以这就需要在整除之前做一步\u003ccode\u003ey!=0\u003c/code\u003e的判断\u003c/li\u003e\n\u003cli\u003e一种做法就是nested-if，嵌套if，这是一个非常lj的做法，虽然可读性高，但占用的时间和空间都是庞大的\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"err\"\u003e条件\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e// 条件1满足时执行的代码\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"err\"\u003e条件\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"c1\"\u003e// 条件1和条件2同时满足时执行的代码\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e另外一种做法就是通过Lazy Evaluation，其实就是使用\u003ccode\u003e\u0026amp;\u0026amp;\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e!=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e \u003cspan class=\"o\"\u003e%\u003c/span\u003e \u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// do something\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003eLazy evaluation将多个判断结合为一个的办法，详细来说他会从左到右的顺序判断\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e||\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e这个运算符先评估左侧的表达式（LHS，Left-Hand Side）。\u003c/li\u003e\n\u003cli\u003e如果LHS为\u003ccode\u003etrue\u003c/code\u003e，那么整个条件表达式结果为\u003ccode\u003etrue\u003c/code\u003e，程序将不再继续评估右侧的表达式（RHS，Right-Hand Side）。\u003c/li\u003e\n\u003cli\u003e如果LHS为\u003ccode\u003efalse\u003c/code\u003e，程序需要继续评估RHS来决定整个表达式的结果。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e\u0026amp;\u0026amp;\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e这个运算符也先评估LHS。\u003c/li\u003e\n\u003cli\u003e如果LHS为\u003ccode\u003efalse\u003c/code\u003e，那么整个条件表达式结果为\u003ccode\u003efalse\u003c/code\u003e，程序将不再继续评估RHS。\u003c/li\u003e\n\u003cli\u003e如果LHS为\u003ccode\u003etrue\u003c/code\u003e，程序需要继续评估RHS来决定整个表达式的结果。\u003c/li\u003e\n\u003cli\u003e这种评估方式是一种效率优化手段，可以减少不必要的计算\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003e3.2.1.2 De Morgan\u0026rsquo;s Law \r\n    \u003cdiv id=\"3212-de-morgans-law\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#3212-de-morgans-law\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e当一个\u003cstrong\u003eLazy Evaluation\u003c/strong\u003e（注意仅是两个及以上的判断同时发生的情况下）判断的最外侧为一个Not，也就是\u003ccode\u003e!\u003c/code\u003e的时候，整体的判断将会看上去十分复杂，这可以通过De Morgan\u0026rsquo;s Law化简\u003c/li\u003e\n\u003cli\u003e具体来说\u003ccode\u003e!(A \u0026amp;\u0026amp; B)\u003c/code\u003e is equivalent to \u003ccode\u003e!A || !B\u003c/code\u003e，\u003ccode\u003e!(A || B)\u003c/code\u003e is equivalent to \u003ccode\u003e!A \u0026amp;\u0026amp; !B\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e同时Relational Expression也可以变换，\u0026gt; 变成了\u0026lt;=，\u0026gt;= 变成 \u0026lt;，== 变成 !=\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/uoft/24/learning-programming-with-c/lpc3.decisionmakingstatements/LPC3.DecisionMakingStatements_hu14771444122089271576.png 330w,\r\n        /docs/uoft/24/learning-programming-with-c/lpc3.decisionmakingstatements/LPC3.DecisionMakingStatements_hu3266321974582059814.png 660w,\r\n        /docs/uoft/24/learning-programming-with-c/lpc3.decisionmakingstatements/LPC3.DecisionMakingStatements_hu9341054436462208839.png 1024w,\r\n        /docs/uoft/24/learning-programming-with-c/lpc3.decisionmakingstatements/LPC3.DecisionMakingStatements_hu13158954285452890454.png 2x\"\r\n        src=\"/docs/uoft/24/learning-programming-with-c/lpc3.decisionmakingstatements/LPC3.DecisionMakingStatements_hu3266321974582059814.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"LPC 3. Decision Making Statements","type":"docs"},{"content":" Last Edit: 1/9/25\n1. Imaginary and complex numbers #\rReal Number 实数，包含了Reation \u0026amp; Irrational Number一直以来拥有一个Fundamental Property就是 Square of any real number is always nonnegative 换句话来说，方程\\(x^2=-1\\)在实数域是无解的，但这并不代表这个方程无解 要分析这一问题，首先就需要定义\\(\\sqrt{-1}\\) Definition of Imaginary Number #\rAn imaginary number is a number of the form bi, where b is real and $$i=\\sqrt{-1}$$ 定义指出Complex Number是形式为\\(bi\\)的数，其中b为Real Number 有了这定义，我们便可以为任意Real Number找到对应的Square Root，具体来说 $$(bi)^2=b^2\\cdot i^2=b^2\\cdot -1=-b^2$$ 例如\\((3i)^2=-9,\\sqrt{-9}=3i\\) ex. #\rSolve the equation \\(x^2 +2x+2 = 0\\). Using the quadratic formula $$z_1 = \\frac{-2 + \\sqrt{4 - 8}}{2} = -1 + i \\quad \\text{and} \\quad z_2 = \\frac{-2 - \\sqrt{4 - 8}}{2} = -1 - i. $$\nDefinition of Complex Number #\rA complex number is a number of the form \\(z = a+bi\\), where a and b are real numbers 其中a和b分别被称为z的Real \u0026amp; Imaginary Parts $$a=Re(z)和b=Im(z)$$ If \\(Re(z) = 0\\), then z is an imaginary number and if \\(Im(z) = 0\\), then z is a real number 可以发现对于上面的例子\\(z_1\\)和\\(z_2\\)，\\(Re(z_1)=Re(z_2),Im(z_1)=-Im(z_2)\\)，这并不是一个巧合，而是可以引出另一个Complex Number的特性，Complex Conjugate Definition of Complex Conjugate #\rThe complex conjugate of \\(a+bi\\) is the number \\(a-bi\\). We use a bar over the number to denote the conjugate $$\\overline{a + bi} = a - bi$$ 对于二次方程\\(x^2 + \\beta x + \\gamma = 0\\) 中的\\(\\beta^2 - 4\\alpha\\gamma \u0026lt; 0\\) 时，该方程没有实数解，但可以有复数解。这种情况下，解是共轭复数对。解可以通过标准的二次公式来计算： $$a = \\frac{-\\beta}{2\\alpha},b = \\frac{\\sqrt{|\\beta^2 - 4\\alpha\\gamma|}}{2\\alpha}$$ 其中\\(a + bi\\) 和 \\(a - bi\\) 分别是这个二次方程的两个解。 z = a 是一个实数，则它的复数共轭是它自身，即\\(\\overline{z} = z\\)，这表明实数是它们自己的共轭。此外，任何复数z的共轭的共轭是z本身，即\\(\\overline{\\overline{z}} = z\\) 2. Complex Arithmetic 复数运算 #\rComplex numbers和Real Number一样也可以坐加减乘除运算，并且commutativity, associativity and distributivity等特性依然存在 Addition and Sibtraction #\r要给两个Complex Numbers做加减，分别加减他们的Real and Imaginary Components $$(a+bi)+(c+di)=(a+b)+(b+d)i$$ Propisition 2.1 Complex Number\u0026rsquo;s Conjugate #\r对于任何复数z，\n\\(z + \\overline{z} = 2 \\cdot \\text{Re}(z)\\) \\(z - \\overline{z} = 2 \\cdot \\text{Im}(z) \\cdot i\\) Proof #\r假设\\(z = a + bi\\)，其中a是实部，b是虚部，那么：\n\\(z + \\overline{z} = (a + bi) + (a - bi) = 2a = 2 \\text{Re}(z)\\)。这说明复数和其共轭的和是两倍实部 \\(z - \\overline{z} = (a + bi) - (a - bi) = 2bi = 2 \\text{Im}(z) \\cdot i\\)。这说明复数和其共轭的差是两倍虚部的虚数单位 2.2 Multiplication #\r$$(a +bi) (c+di) = ac+adi +cbi +bdi^2 = (ac-bd)+(ad+bc)i$$\n2.3 Division #\rComplex Number的除法可以视为乘以其逆元。复数\\(z = a + bi\\)的逆元\\(z^{-1}\\)满足\\(z \\cdot z^{-1} = 1\\)。 给定非零复数\\(a + bi\\)，求解使得\\((a + bi)(x + yi) = 1\\)的复数\\(x + yi\\)，整理后得到： \\(ax - by = 1\\) \\(bx + ay = 0\\) 这两个方程可以通过以下步骤解决： 将方程 (2) 乘以a，方程 (3) 乘以b，然后将两个结果相加，消去y得到\\((a^2 + b^2)x = a\\)，从而解得\\(x = \\frac{a}{a^2 + b^2}\\) 类似地，将方程 (2) 乘以−b，方程 (3) 乘以a，然后将两个结果相加，消去x得到\\((a^2 + b^2)y = -b\\)，从而解得\\(y = \\frac{-b}{a^2 + b^2}\\) 这样，复数\\(a + bi\\)的乘法逆元\\(x + yi\\)可以表示为： $$x = \\frac{a}{a^2 + b^2},y = \\frac{-b}{a^2 + b^2}$$ Proposition 2.2 Complex Number\u0026rsquo;s Division #\r所以当Complex Number \\(a+bi\\neq 0\\)，then $$(a + bi)^{-1} = \\frac{a}{a^2 + b^2} - \\frac{b}{a^2 + b^2}i$$ 这样就可以做除法的运算了，便有 $$\\frac{c + di}{a + bi} = (c + di) \\cdot (a + bi)^{-1} = (c + di) \\cdot \\left(\\frac{a}{a^2 + b^2} - \\frac{b}{a^2 + b^2}i\\right) = \\frac{ac + bd}{a^2 + b^2} + \\frac{ad - bc}{a^2 + b^2}i$$ Proposition 2.3 Complex Number\u0026rsquo;s Conjugate\u0026rsquo;s Property #\r对于Complex Numbers z 和 w， $$\\overline{z+w}=\\overline{z}+\\overline{w},\\overline{z\\cdot w}=\\overline{z}\\cdot \\overline{w},if~w\\neq ~\\overline{(\\frac{z}{w})}=\\frac{\\overline{z}}{\\overline{w}}$$ Proof #\r$$\\begin{aligned} \\overline{(a + bi) + (c + di)} \u0026amp;= \\overline{(a + c) + (b + d)i} \\ \u0026amp;= (a + c) - (b + d)i \\ \u0026amp;= (a - bi) + (c - di) \\ \u0026amp;= \\overline{(a + bi)} + \\overline{(c + di)} \\end{aligned}$$ $$\\begin{aligned} \\overline{(a + bi),(c + di)} \u0026amp;= \\overline{(ac - bd) + (ad + bc),i} \\ \u0026amp;= (ac - bd) - (ad + bc),i \\ \u0026amp;= (a - bi),(c - di) \\ \u0026amp;= \\overline{(a + bi)} ,\\cdot, \\overline{(c + di)} \\end{aligned}$$\n3. The Geometry of Complex Numbers #\r对于Complex Number来说，其可以通过Complex Plane来表示，其中两个轴分别是Real Axis和Imaginary Axis 每一个复数可以被视为起始于原点的向量，而复数的加法可以通过向量加法在几何上表示出来 3.2 The modulus of a Complex Number #\r对于Real Number来说，其Magnitude可以通过Absolute Value\\(|a|\\)来得到，这同理也可以运用到Complex Number上 Definition of modulus of Complex Number #\rThe modulus, or absolute value, of a complex number \\(z= a+ bi\\), is denoted by \\(|z|\\) and defined to be the distance in the complex plane between the point z and the point 0 Proposition 3.1 Complex Number\u0026rsquo;s Conjugate \u0026amp; Modulus #\rFor any Complex Number z $$|z|^2=z\\cdot \\overline z$$ Proof #\r假设有Complex Number z，根据Complex Number的Modulus可以得到\\(|z|^2=a^2+b^2\\) $$z\\cdot \\overline z=(a+bi)(a-bi)=a^2-abi+abi-b^2i^2=a^2+b^2=|z|^2$$ 于是当\\(z\\neq 0\\)的情况下， $$z^{-1}=\\frac{\\overline z}{|z|^2}$$ 这与上面Proposition 2.2 Complex Number\u0026rsquo;s Division的内容相似 Proposition 3.2 Commutative Property #\r\\(|z\\cdot w|=|z|\\cdot |w|\\) $$|z \\cdot w|^2 = (z \\cdot w) \\cdot (\\overline{z \\cdot w}) = z \\cdot w \\cdot \\overline{z} \\cdot \\overline{w} = |z|^2 \\cdot |w|^2$$ 两边同时取Square Root可以得到 $$|z \\cdot w| = \\sqrt{|z \\cdot w|^2} = \\sqrt{|z|^2 \\cdot |w|^2} = \\sqrt{|z|} \\cdot \\sqrt{|w|} = |z| \\cdot |w| $$ Proposition 3.3 Inverse #\rIf \\(z\\neq 0,then~|z^{-1}|=(|z|)^{-1}\\) 3.3 The Argument of a Complex Number 复数的辐角 #\r如果说Modulus决定了一个Complex Number的Magnitude，他的Angle则是被Argument决定 The argument (or phase) of \\(z= a+ bi(z\\neq 0)\\)is ‘the’ angle, \\(φ\\) between the positive real axis and the line segment connecting z to 0 The argument of z is denoted by arg(z) 通常情况下，复数的辐角是多值的，因为角度可以通过加上\\(2\\pi\\)的整数倍来得到相同的方向 求的Complex Number的Argument的办法就是通过\\(\\arctan\\)函数 在不同Quadrant下的Complex Number所得到的Argument则需要有所调整，具体来说 第一象限\\(a \u0026gt; 0, b \u0026gt; 0\\)，直接使用\\(\\arctan(b/a)\\)，无需调整。 第二象限\\(a\u0026lt;0,b\u0026gt;0\\)，\\(arctan(b/a)\\) 计算的是一个负值，但实际的Argument应是\\(\\pi\\)加上这个负值。所以，辐角是\\(\\pi + \\text{arctan}(b/a)\\) 第三象限\\(a\u0026lt;0,b\u0026lt;0\\)，此时\\(\\text{arctan}(b/a)\\)产生正值，但由于在第三象限，所需的辐角是这个值减去\\(\\pi\\)，即\\(\\arctan(b/a) - \\pi\\) 第四象限\\(a\u0026gt;0,b\u0026lt;0\\)，在此象限，\\(\\arctan(b/a)\\) 本身就是正确的辐角值，因为它会给出负的角度值。 特殊情况a = 0 时，辐角取决于b的符号： 如果\\(b\u0026gt;0\\)，辐角是\\(\\frac{\\pi}{2}\\)， 如果\\(b\u0026lt;0\\)，辐角是\\(\\frac{3\\pi}{2}\\) 3.4 The polar-coordinate representation of complex numbers. #\r在分别求得了Complex Number的Modulus和Argument后，便可以求出Complex Number的Polar Coordinate 其于正常的Polar Coordinate一样，\\(Re(z)=r\\cos\\theta,Im(z)=r\\sin \\theta,z=r(\\cos \\theta+i\\sin \\theta)\\) Proposition 3.5 Argument\u0026rsquo;s Associative Law #\r\\(arg(z_1z_2)=arg(z_1)+arg(z_2)\\) 有\\(z_1 = r \\bigl(\\cos \\theta + i \\sin \\theta\\bigr), \\quad z_2 = \\rho \\bigl(\\cos \\phi + i \\sin \\phi\\bigr)\\) $$z_1 z_2 = \\bigl(r(\\cos \\theta + i \\sin \\theta)\\bigr) \\cdot \\bigl(\\rho(\\cos \\phi + i \\sin \\phi)\\bigr) =r\\rho ,\\Bigl((\\cos \\theta + i \\sin \\theta),(\\cos \\phi + i \\sin \\phi)\\Bigr)$$ 其中\\((\\cos \\theta + i \\sin \\theta),(\\cos \\phi + i \\sin \\phi)= (\\cos \\theta)(\\cos \\phi) + (\\cos \\theta)(i \\sin \\phi) + (i \\sin \\theta)(\\cos \\phi) + (i \\sin \\theta)(i \\sin \\phi)\\) 当把各项一一对应起来后，就会发现 $$\\cos(\\theta + \\phi) + i,\\sin(\\theta + \\phi)$$ 所以 $$z_1 z_2 = r\\rho ,\\bigl(\\cos(\\theta + \\phi) + i \\sin(\\theta + \\phi)\\bigr)$$ 由此得出\\(\\arg(z_1 z_2) = \\arg(z_1) + \\arg(z_2)\\) 同理Argument的取值范围应为\\((-\\pi,\\pi]\\)，所以 当\\(\\text{arg}(z_1) + \\text{arg}(z_2) \u0026gt; \\pi\\)， 为了将结果拉回到\\((-\\pi, \\pi]\\)的范围内，需要从这个和中减去\\(2\\pi\\) 当\\(\\text{arg}(z_1) + \\text{arg}(z_2) \u0026lt; -\\pi\\) 为了将结果拉回到\\((-\\pi, \\pi]\\)的范围内，需要在这个和中加上\\(2\\pi\\) Proposition 3.6 #\r如果\\(z \\neq 0\\)，且w是任意复数，那么将w乘以z： 会将w的模（大小）按\\(|z|\\)进行伸缩（即缩小或放大） 会将w的辐角（方向角）按\\(\\text{arg}(z)\\)旋转 这说明复数乘法对复数的几何意义是模的缩放和角度的旋转 3.5 Exponential Notation Euler\u0026rsquo;s formula 欧拉公式 #\r对于实数\\(\\theta\\)，复数可以表示为：\\(\\cos\\theta + i\\sin\\theta = e^{i\\theta}\\) 这表明复数的极坐标表示（幅角和模）可以用指数形式表示 Proof #\r对于Euler\u0026rsquo;s Formula的推导从Taylor expansion开始 已知指数函数 exe^x 在实数域中的泰勒展开式为： $$e^x = \\sum_{n=0}^\\infty \\frac{x^n}{n!} = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots$$ 将\\(x\\)替换为\\(i\\theta\\)可以得到 $$e^{i\\theta} = \\sum_{n=0}^\\infty \\frac{(i\\theta)^n}{n!}$$ 已知Imaginary Number i在Even次Exponent下均为\\(-1\\)，可以得到 $$e^{i\\theta} = \\sum_{n=0}^\\infty \\frac{(i\\theta)^n}{n!} = \\sum_{n=0}^\\infty \\frac{(-1)^n\\theta^{2n}}{(2n)!} + i \\sum_{n=0}^\\infty \\frac{(-1)^n\\theta^{2n+1}}{(2n+1)!}$$ 这两个Series分别对应余弦和正弦的泰勒展开式，于是便有 $$e^{i\\theta} = \\cos\\theta + i\\sin\\theta$$ Proposition 3.7 #\rIf \\(z= r \u0026gt; 0\\) and \\(\\theta= arg(z)\\), then $$z=r\\cdot e^{\\theta i}$$ 本质上就是\\(z=r(\\cos\\theta +i\\sin\\theta)\\)，因为有Eulers\u0026rsquo; Formula Proposition 3.8 #\rFor any number and any integer k $$e^{(\\theta+2k\\pi)i}=e^{\\theta i}$$ Proof #\r从Euler\u0026rsquo;s Formula入手，已知\\(e^{(\\theta+2k\\pi )i}=e^{\\theta i}\\cdot e^{2k\\pi i}\\) 令\\(2k\\pi = \\theta\\)，有 $$e^{(\\theta+2k\\pi )i}=e^{\\theta}\\cdot(\\cos 2\\pi+i\\sin 2\\pi)=e^{\\theta}$$ 4. Roots of polynomials #\r4.1 The fundamental theorem of algebra #\r如果P(z)是一个次数为n \u0026gt; 0的多项式，其形式为： $$P(z) = c_n z^n + c_{n-1} z^{n-1} + \\cdots + c_1 z + c_0$$ 其中\\(c_n\\)为Complex Numbers 那么，The fundamental theorem of algebra 表明 \\(P(z) = 0\\) has a Solution in the Complex 一个例子便是对于实数系数多项式\\(P(x) = x^2 + 1\\)，其has no real solutions，但在Complex Number中有两个解\\(i和-i\\) Propisition 4.1 #\r对于任意次数\\(n \\geq 1\\)的复系数多项式\\(P(z)\\)，可以表示为： $$P(z) = c_n \\cdot (z - \\zeta_1)(z - \\zeta_2) \\cdots (z - \\zeta_n)$$ 与Real Number roots一样，并不是所有的根\\(\\zeta_1, \\dots, \\zeta_n\\)都是不同的，某些根可能会重复，称为Reapeated Root 一个例子便是\\(Q(z) = z^4 - 2z^3 + 2z^2 - 2z + 1\\)，其因式分解为： $$Q(z) = (z - 1)(z - 1)(z - i)(z + i)$$ Proposition 4.2 #\r如果 P(z)P(z) 是一个次数\\(n \\geq 1\\)且具有复系数的多项式，那么：\nP(z) 至少有一个根（The fundamental theorem of algebra） P(z) 最多有n个根（Included Repeated Roots) 4.2 Polynomials with real coefficients #\r4.1介绍了Coefficients为Complex Numbers的情况，由于Real Number是Complex Number的Subset，所以当Coeffcients为Real Number的时候，其也有Root 但即使是Real Number的Coefficient，其也不保证Root为Real Number Proposition 4.3 #\r如果\\(P(z) = a_n z^n + a_{n-1} z^{n-1} + \\cdots + a_1 z + a_0\\)是一个Real Number Coefficients Polynomial，并且\\(\\zeta\\)是P(z)的一个根，那么其Complex Conjugate\\(\\overline{\\zeta}\\)也是P(z)的一个根 Proof #\r假设\\(\\zeta\\)是P(z)的一个根，即： $$a_n \\zeta^n + a_{n-1} \\zeta^{n-1} + \\cdots + a_1 \\zeta + a_0 = 0$$ 对等式两边取共轭： $$\\overline{a_n \\zeta^n + a_{n-1} \\zeta^{n-1} + \\cdots + a_1 \\zeta + a_0} = 0$$ 利用共轭的性质 $$\\overline{a_k \\zeta^k} = \\overline{a_k} \\cdot \\overline{\\zeta^k} = a_k \\cdot (\\overline{\\zeta})^k$$ 因为\\(a_k\\)是实数，因此等式变为 $$a_n (\\overline{\\zeta})^n + a_{n-1} (\\overline{\\zeta})^{n-1} + \\cdots + a_1 \\overline{\\zeta} + a_0 = 0$$ 这说明\\(\\overline{\\zeta}\\)也是P(z)的一个根 Proposition 4.4 #\r如果多项式的系数是Real Number，那么其Complex Root必然成共轭对出现 Proposition 4.5 #\r对于一个Real Number Coefficient Polynomial： $$P(z) = a_n z^n + a_{n-1} z^{n-1} + \\cdots + a_1 z + a_0$$ 其可以表示为以下因式分解形式： $$P(z) = a_n (z - \\xi_1)(z - \\xi_2)\\cdots(z - \\xi_m) Q_1(z) Q_2(z) \\cdots Q_k(z)$$ 其中\\(\\xi_1, \\dots, \\xi_m\\)：是所有的Real Roots \\(Q_j(z) = z^2 - 2\\text{Re}(\\zeta_j)z + |\\zeta_j|^2\\)：是与复数根和其共轭对应的实系数二次多项式 4.3 Square roots and quadratic equations #\r想要求解General Quadratic Equation，需要先算出Complex Number的Square Roots Propposition 4.6 #\r如果\\(u \\neq 0\\)，那么复数方程\\(z^2 = u\\)的解是： $$\\zeta_1 = \\sqrt{|u|} e^{i\\theta/2}, \\quad \\zeta_2 = -\\zeta_1$$ Proof #\r已知任何非零复数u都可以表示为\\(u = |u| e^{i\\theta}\\) 于是可以得出其中的一个Root为\\(\\zeta_1 = \\sqrt{|u|} e^{i\\theta/2}\\) 另一个解则是\\(\\zeta_2 = -\\zeta_1\\) Proposition 4.7 #\r对于二次方程： $$az^2 + bz + c = 0$$ 其解的公式为： $$z_1 = \\frac{-b + \\sqrt{b^2 - 4ac}}{2a}, \\quad z_2 = \\frac{-b - \\sqrt{b^2 - 4ac}}{2a}$$ 其中：a, b, c 是复数（且\\(a \\neq 0\\)），公式中的平方根\\(\\sqrt{b^2 - 4ac}\\) 按复数的平方根规则计算。 Example 4.3 #\r$$z^2 + (1 - 2i)z - 2i = 0$$\n这里\\(a = 1，b = 1 - 2i，c = -2i\\) $$\\zeta_1 = \\frac{-(1 - 2i) + \\sqrt{(1 - 2i)^2 - 4(1)(-2i)}}{2}, \\quad \\zeta_2 = \\frac{-(1 - 2i) - \\sqrt{(1 - 2i)^2 - 4(1)(-2i)}}{2}$$ $$b^2 - 4ac = (1 - 2i)^2 - 4(-2i) = 1 - 4i + 4 - 8i = -3 - 4i + 8i = -3 + 4i$$ 根据公式\\(\\sqrt{|b^2 - 4ac|} e^{i\\theta/2}\\)计算其复数平方根\\(\\sqrt{-3 + 4i} = 1 - 2i\\) $$\\zeta_1 = \\frac{-b + \\sqrt{-3 + 4i}}{2} = \\frac{-(1 - 2i) + (1 - 2i)}{2} = 2i$$$$\\zeta_2 = \\frac{-b - \\sqrt{-3 + 4i}}{2} = \\frac{-(1 - 2i) - (1 - 2i)}{2} = -1$$ 4.4 The nth roots of a complex number #\r对于一个正实数\\(\\alpha \u0026gt; 0\\)和正整数n，\\(\\alpha\\)的n次根\\(\\beta\\)定义为： $$\\beta^n = \\alpha \\quad \\text{或} \\quad \\beta = \\alpha^{1/n}$$ 这是解决方程\\(z^n - \\alpha = 0\\)的一个特定解，通常选择正实数解作为主n次根 若\\(u \\neq 0\\)是一个复数，且n是正整数，那么方程\\(z^n = u\\)总共有n个不同的复数解，这些解可以记为\\(\\zeta_1, \\zeta_2, \\dots, \\zeta_n\\) $$z^n - u = (z - \\zeta_1)(z - \\zeta_2)\\cdots(z - \\zeta_n)$$ Proposition 4.8 #\r对于复数\\(u \\neq 0\\)，如果\\(\\theta = \\text{arg}(u)\\)，n是一个正整数，那么方程\\(z^n = u\\)的解为： $$\\zeta_k = \\sqrt[n]{|u|} e^{i\\left(\\frac{\\theta + 2k\\pi}{n}\\right)}, \\quad k = 0, 1, 2, \\dots, n-1$$ 其中总共有n个不同的解，这些解在复平面上均匀分布，构成一个以原点为中心、半径为\\(\\sqrt[n]{|u|}\\)的正n边形。 Proof #\r对于任意k来说，有 $$\\zeta_k = \\sqrt[n]{|u|} e^{i\\left(\\frac{\\theta + 2k\\pi}{n}\\right)}$$ 计算\\(\\zeta_k^n\\) $$\\zeta_k^n = \\left(\\sqrt[n]{|u|}\\right)^n \\cdot \\left(e^{i\\left(\\frac{\\theta + 2k\\pi}{n}\\right)}\\right)^n$$ $$\\left(\\sqrt[n]{|u|}\\right)^n = |u|，\\left(e^{i\\left(\\frac{\\theta + 2k\\pi}{n}\\right)}\\right)^n = e^{i\\left(\\theta + 2k\\pi\\right)} = e^{i\\theta}$$ 所以 $$\\zeta_k^n = |u| e^{i\\theta} = u$$ 这表明每个\\(\\zeta_k\\)都是\\(z^n = u\\)的解 在这之后还需要验证解是不同的\\(\\zeta_k \\neq \\zeta_j\\)，假设\\(\\zeta_k = \\zeta_j\\)，那么\\(\\frac{\\zeta_k}{\\zeta_j} = 1\\) $$\\frac{\\zeta_k}{\\zeta_j} = \\frac{\\sqrt[n]{|u|} e^{i\\left(\\frac{\\theta + 2k\\pi}{n}\\right)}}{\\sqrt[n]{|u|} e^{i\\left(\\frac{\\theta + $2j\\pi}{n}\\right)}} = e^{i\\left(\\frac{2(k-j)\\pi}{n}\\right)}$$ 若\\(\\frac{\\zeta_k}{\\zeta_j} = 1\\)，则必须有： $$\\frac{2(k-j)\\pi}{n} = 2m\\pi \\quad (m \\in \\mathbb{Z})$$ 这意味着： $$\\frac{k-j}{n} = m \\quad \\Rightarrow \\quad k-j = mn$$ 由于\\(0 \\leq k, j \u0026lt; n\\)，因此\\(|k-j| \u0026lt; n\\)，所以只有m = 0，即k = j。 这表明当\\(k \\neq j\\)时，\\(\\zeta_k \\neq \\zeta_j\\) ","date":"Jan 9 2025","externalUrl":null,"permalink":"/docs/uoft/24/calculus/calculus11.complexnumber/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/9/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e1.  Imaginary and complex numbers \r\n    \u003cdiv id=\"1--imaginary-and-complex-numbers\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#1--imaginary-and-complex-numbers\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eReal Number 实数，包含了Reation \u0026amp; Irrational Number一直以来拥有一个Fundamental Property就是 Square of any real number is always nonnegative\u003c/li\u003e\n\u003cli\u003e换句话来说，方程\\(x^2=-1\\)在实数域是无解的，但这并不代表这个方程无解\u003c/li\u003e\n\u003cli\u003e要分析这一问题，首先就需要定义\\(\\sqrt{-1}\\)\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eDefinition of Imaginary Number \r\n    \u003cdiv id=\"definition-of-imaginary-number\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#definition-of-imaginary-number\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003eAn imaginary number is a number of the form bi, where b is real and\n$$i=\\sqrt{-1}$$\u003c/li\u003e\n\u003cli\u003e定义指出Complex Number是形式为\\(bi\\)的数，其中b为Real Number\u003c/li\u003e\n\u003cli\u003e有了这定义，我们便可以为任意Real Number找到对应的Square Root，具体来说\n$$(bi)^2=b^2\\cdot i^2=b^2\\cdot -1=-b^2$$\u003c/li\u003e\n\u003cli\u003e例如\\((3i)^2=-9,\\sqrt{-9}=3i\\)\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eex. \r\n    \u003cdiv id=\"ex\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cp\u003eSolve the equation \\(x^2 +2x+2 = 0\\). Using the quadratic formula\n$$z_1 = \\frac{-2 + \\sqrt{4 - 8}}{2} = -1 + i \\quad \\text{and} \\quad z_2 = \\frac{-2 - \\sqrt{4 - 8}}{2} = -1 - i.\n$$\u003c/p\u003e","title":"CAL 11. Complex Number","type":"docs"},{"content":"","date":"Jan 9 2025","externalUrl":null,"permalink":"/tags/calulus/","section":"Tags","summary":"","title":"Calulus","type":"tags"},{"content":" Last Edit: 1/9/25\n2.1 Double data type for real numbers #\r在程序中用分数代表数字 2.1.1 Convert Inches to Centimeters #\r// Description: This program convert inches to centimeters #include \u0026lt;stdio.h\u0026gt; int main(void){ // Declare variables const double InchesToCm = 2.54; double inputInches, outputCm; // Prompt user for input printf(\u0026#34;Enter the number of inches to convert to cm: \u0026#34;); scanf(\u0026#34;%lf\u0026#34;, \u0026amp;inputInches); // Convert inches to centimeters outputCm = inputInches * InchesToCm; // Display output in 2 decimal places printf(\u0026#34;The number of centimeters is %.2lf\\n\u0026#34;, outputCm); return 0; } const是一个关键字，指示变量是常量。不能在整个代码中更改该变量 int main(void){ const double InchesToCm = 2.54; InchesToCm = 2.51; } 这样操作将会报错，因为InchesToCm是一个不可以更改的Constant\ndouble 是一种数据类型，指示变量是小数 What would happen if a number with decimal is stored in an int? 当赋值一个小数给int的时候，小数部分将被 Truncated 截断，只保留整数部分\n%lf 这是一个格式说明符，指示输入是小数 .2 表示该值应以 2 位小数打印 2.1.2 Summary #\rint：整数数据类型，Format Specifier是%d double：小数数据类型，Format Specifier是%lf 2.2 Data types and representation #\r不同的数据类型在Memory中的储存方式都不同 2.2.1 Integers #\rint使用32位存储，其中31位用于表示整数本身，一位为Sign Bit Sign bit为0是说明整数是正数，为1说明是负数 由于有整数可以有31位，其在正数的范围为0到$2^{31}-1$，在负数的范围为$-2^{31}$到-1 Other Integers Representation #\rshort：16位整数 unsigned int：使用32位，没有符号位，表示范围是0到$2^{32} - 1$ long：通常使用64位（8个字节） long long：也是使用64位（8个字节） 2.2.2. Floating point or real numbers #\rfloat的储存方法类似于科学计数法，其写成$m\\times 10^e$的形式 其中m是尾数，是一个介于1到10的数字，e是指数，表示数字的大小 Two float Representation #\rfloat使用32位，即4bytes double使用64位，即8bytes，由于精度是float的两倍，也叫Double data type双精度 2.2.3. Characters #\r要表示一个字符（如字母、符号或数字），可以使用 char 数据类型。常见的字符包括 A, B, 1, 9, @, # 等 #include \u0026lt;stdio.h\u0026gt; int main(void){ char firstInitial = \u0026#39;S\u0026#39;; printf(\u0026#34;My first initial is %c.\\n\u0026#34;, firstInitial); return 0; } The format specifier for char is %c char 类型使用8bits（1bytes）来存储每个字符 其可以于ASCII编码对应范围是0到$2^7-1$ ASCII 标准使用7位来表示字符，第8位是多余的，因此它被设置为0以兼容字节存储结构。这是因为ASCII最初设计时，只有7位用于字符表示，8位的字节结构是为了适应现代计算机的存储需求 2.2.4. Boolean #\r布尔类型用于表示逻辑值，即 true 或 false。在C语言中，true 被表示为 1，而 false 被表示为 0 尽管布尔类型只需要1个bit来表示其值，但由于内存的组织结构，每个内存单元（cell）通常存储1byte，因此布尔类型在内存中实际占用1byte #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(void){ bool isRaining = true; printf(\u0026#34;Is it raining? %d\\n\u0026#34;, isRaining); return 0; } Boolean没有专门针对的格式说明符，采用%d来打印值 使用布尔类型时，需要包含 \u0026lt;stdbool.h\u0026gt; 库。没有这个库，编译器无法识别 bool 类型 ex. #\r假设n是正整数 bool isPositive = n \u0026gt; 0; \u0026gt; True bool isPositive = n; \u0026gt; True or False,any non-zero number is considered as `true` bool isPositive = n \u0026gt; 0 != 0; \u0026gt; True bool isPositive = n \u0026lt;= 0 != 1; \u0026gt; n\u0026lt;=0 is 0, 0 != 1 -\u0026gt; 1 or True 2.2.5. Declaring Vs. Initializing Variables #\rDeclaring Variables是告诉编译器使用某个变量。在C语言中，声明一个变量的语法是int var; 这样，编译器知道了一个类型为 int 的变量，名为 var。此时，编译器为变量保留了内存空间，但此变量尚未被赋值 变量声明后如果没有赋值，它就是Uninitialized Variables 未初始化变量，这意味着变量没有存储任何有效的值，只是占据了一块内存 如果你声明了一个变量 var，但没有给它赋值，那么它的值可能是一个随机值，例如 174739296（这只是一个示例值，实际结果因每次运行而异）。每次运行时，这个值可能会不同 #include \u0026lt;stdio.h\u0026gt; int main(void) { int var; printf(\u0026#34;Value of uninitialized variable \\\u0026#34;var\\\u0026#34;: %d\\n\u0026#34;, var); int var2 = 0; printf(\u0026#34;Value of initialized variable \\\u0026#34;var\\\u0026#34;: %d\\n\u0026#34;, var2); return 0; } 编译器会发出警告，指出未初始化的变量 var 在使用时可能会导致不确定的行为。警告信息类似于：variable ‘var’ is uninitialized when used here [-Wuninitialized] 为了避免这种警告，最佳做法是声明变量并初始化它，例如：int var = 0; 2.2.6. Taking in input from the user using scanf #\rMutiple Numbers in mutiple variables #\r#include \u0026lt;stdio.h\u0026gt; int main(void) { int num1 = 0, num2 = 0; double dnum1 = 0, dnum2 = 0; printf(\u0026#34;Enter a number: \u0026#34;); scanf(\u0026#34;%d %lf %d %lf\u0026#34;, \u0026amp;num1, \u0026amp;dnum1, \u0026amp;num2, \u0026amp;dnum2); printf(\u0026#34;Numbers entered: %d %lf %d %lf\\n\u0026#34;, num1, dnum1, num2, dnum2); return 0; } \u0026gt; 1 1.2 3 3.4 \u0026gt; Enter a number: 1 1.2 3 3.4 Numbers entered: 1 1.200000 3 3.400000 可以使用 一个 scanf 来接收多个输入，并将它们分别存储在多个变量中。输入的各个数值通过分隔符（如空格、回车或制表符）分隔 Numbers and Characters #\r#include \u0026lt;stdio.h\u0026gt; int main(void) { char idChar; int idNum; printf(\u0026#34;Enter your ID: \u0026#34;); scanf(\u0026#34;%c %d\u0026#34;, \u0026amp;idChar, \u0026amp;idNum); printf(\u0026#34;ID entered: %c%d\\n\u0026#34;, idChar, idNum); return 0; } \u0026gt; S1321234 \u0026gt; Enter your ID: S1321234 ID entered: S1321234 你可以在同一行中使用 scanf 接收字符和数字。比如，用户输入一个以字符开头，后面跟随数字的ID。 使用 %c 来接收字符，接着用 %d 来接收数字。scanf 会自动区分字符和数字，不需要在字符和数字之间添加分隔符 Take in characters and ignoring leading spaces #\r#include \u0026lt;stdio.h\u0026gt; int main(void) { char c1, c2, c3, c4, c5, c6, c7; printf(\u0026#34;Enter license plate letters and numbers: \u0026#34;); scanf(\u0026#34;%c %c %c %c %c %c %c\u0026#34;, \u0026amp;c1, \u0026amp;c2, \u0026amp;c3, \u0026amp;c4, \u0026amp;c5, \u0026amp;c6, \u0026amp;c7); printf(\u0026#34;Licence plate entered: %c%c%c%c-%c%c%c\\n\u0026#34;, c1, c2, c3, c4, c5, c6,c7); return 0; } 在这段代码中，为了忽略输入字符之间的空格，使用了 scanf 函数中的 %c 格式说明符之间加入空格的方法。这样，scanf 在读取每个字符时会自动跳过空格 Common mistake: Spaces after format specifiers #\r#include \u0026lt;stdio.h\u0026gt; int main(void) { double dnum1 = 0; printf(\u0026#34;Enter a number: \u0026#34;); scanf(\u0026#34; %lf \u0026#34;, \u0026amp;dnum1); printf(\u0026#34;Number entered: %.2lf\\n\u0026#34;, dnum1); return 0; } scanf 使用了一个格式说明符 %lf 后跟一个空格。这种情况下，程序会在接收到一个数字输入后继续等待，直到遇到非空格的输入。这是因为 scanf 的行为是读取输入直到满足格式要求，而空格在格式说明符之后会导致它等待下一个非空白字符 2.3 Operations #\r通过已知的四种data types，int, double, char, bool来进行运算 2.3.1 Basic Arithmetic Operations #\r基础的算术运算还是通过 + - * / % 实现的 其中运算优先级根据括号，幂，乘，除，取模，加减的顺序，如果没有优先级，则从左到右的顺序运算 int x = 10 / 5 * 2; 先10/5=2再*2=4 2.3.2. The more accurate data type is contagious #\rint x = 10 * 5 / 3; 在数学中，这个的答案很明显是$16\\frac{2}{3}$，但是10，5和3都是int，所以他们运算的值也必须是一个int，也就是16在这个例子中 int x = 50 / 3.0; 在这个例子中，由于3.0是一个double，他们的结果将会是一个double，但是由于是储存在int中的，所以16后面的小数部分将被抛弃只剩下16 2.3.3. What happens when we divide by 0? #\r在程序中除以0可能导致奇怪的结果，如果是double运算的话也有可能是inf 2.3.4. Modulo operator #\r取得Remainder 余数的运算符 如 10%3=1，10%4=2 3 % 0 的结果是什么？ 会表现出和3/0类似的行为\n2.3.5. Assignment operators #\r赋值运算符，也就是 = ，其优先级小于所有Operations，确保了所有运算结束后才会赋值 赋值运算与其他运算不同，是从右往左结合的，如 x = y =z 先将z的值赋值给y，再将y的值给x Complex Assignment Operations #\r形如 +=, -=, *=, /=, %= 的为复合赋值运算符 x += 3 等价于 x = x + 3 ，剩下的同理 2.3.6. Increment and decrement operators #\r想表达一个值+1有很多种方法，包含了i += 1;, i++; and i++; 这第三个就是Increment Operator，其可以放在Variable前后，放在前面，如 ++i 代表了先将变量加一再更新值，而 i++ 则是先更新值再加一 ，等价于 j = i; i = i + 1; 2.3.7. Type casting #\r想要强制将一个数据类型转换为另一个也有很多做法 double x = 3 / 2; // x 的值是 1.0 因为 3 和 2 都是整数（int），所以 3 / 2 会执行整数除法，结果是 1，然后被存储为 1.0 如果希望 x 的结果是 1.5，需要将操作数之一转换为浮点数 double x = 3.0 / 2; // 或者 double x = (double) 3 / 2; // x 的值是 1.5 (double) 将整数 3 转换为浮点数 3.0，然后执行浮点除法 假设需要将 2.9 转换为整数 double x = 3 / (int) 2.9; // x 的值是 1.0 (int) 2.9 将 2.9 转换为整数 2，然后执行整数除法 3 / 2，结果是 1 2.3.8. sizeof() operator #\rsizeof 用来计算某种数据类型或变量在内存中占用的字节数 sizeof(int)：返回 int 类型的大小（通常为 4 字节） sizeof(double)：返回 double 类型的大小（通常为 8 字节） sizeof(char)：返回 char 类型的大小（通常为 1 字节） 2.4. Math library #\r运算符不只限于 +-*/，还包含了如 $\\sqrt{x}$ 等复杂运算，他们可以通过math librbary实现 #include \u0026lt;math.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(void) { double a = 0, b = 0, c = 0; printf(\u0026#34;Enter the lengths of the sides: \u0026#34;); scanf(\u0026#34;%lf %lf\u0026#34;, \u0026amp;a, \u0026amp;b); c = sqrt(a * a + b * b); printf(\u0026#34;The length of the hypotenuse is %.2lf\\n\u0026#34;, c); return 0; } 2.4.2. You can still use integer values #\r前面没提到的是，sqrt要求的输入实际上是 double 但是其实输入 int 也可以，系统会自动将其转换成 double 想要输出变成 int 也可以通过前面提到的 type casting 2.5. Random numbers #\r2.5.1. Generating a random number #\r需要先导入一个新的库叫做 stdlib.h，然后就可以用 int rand(); 生成随机数了，由于类型是一个 int 这使得生成的范围将再 $[0,2^{31}-1]$ 内取值 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(void) { printf(\u0026#34;Random number 1: %d\\n\u0026#34;, rand()); printf(\u0026#34;Random number 2: %d\\n\u0026#34;, rand()); printf(\u0026#34;Random number 3: %d\\n\u0026#34;, rand()); return 0; } 上述代码很简单，输出就是三个随机数，但是问题是当再一次运行这个程序的时候，会输出三个一样的随机值，这是因为C语言生成的是 Pseudo-random Numebrs 伪随机数，是通过某种算法得出的值，这就导致如果使用的是相同的随机种子时，每次运行程序都将得到一样的随机数 通过调用 srand(unsigned int seed) 可以设置伪随机数的种子，而这个种子会生成一个随机数的Sequence，调用了几次rand就会用到序列中的第几个数 这就导致了如果一个代码中重复的初始化了两次随机种子，随机数就会重置，下一次调用将从Sequence的第一个重新开始 2.5.2. Are we generating random numbers? #\r如果想得到一个真正的随机数，可以采用时间当作种子，调用 time.h 库便可以获取当前时间 Time overflow Problem #\r使用 time(NULL) 可以返回自 1970年1月1日（Unix 纪元）以来的秒数 但是time这个东西本身是一个 int ，这使得他的上限为 $2^{31}-1$， 也就是2038年1月19日03:14:07（UTC）后，这个值将会溢出，所以许多现代系统通过将int改为double解决了这个问题，使溢出的时间来到了2920亿年后 Nested rand #\r如果用 srand(rand()) 替代 srand(time(NULL))，是否会让种子变得随机？\n如果调用 srand(rand())，rand() 的结果依赖于之前的种子。 如果没有明确设置种子，rand() 使用默认种子（通常是 1）。 这意味着每次运行程序时，rand() 的第一个结果是固定的，例如可能是 16807。 因此，srand(rand()) 实际上等效于设置一个固定的种子（例如 16807） 2.5.3. Random numbers within a range #\r默认情况下，rand() 生成的伪随机数范围是从 0 到 RAND_MAX，其中 RAND_MAX 是一个常量 如果需要生成一个更小范围内的随机数（例如 0 和 1 之间的随机数），可以结合取模运算符 % 使用 不像其他语言可以更改这个上线，C语言采取的是取模的办法生成指定范围内的随机数 如果要生成 0 到 5 的随机数，有 int random_number = rand() % 6; // 结果范围是 [0, 5] 这是因为观察取模操作，他的输出将会是 0 % 5 = 0 1 % 5 = 1 2 % 5 = 2 3 % 5 = 3 4 % 5 = 4 5 % 5 = 0 (循环重复) 那么如果范围是1到6，则是 int random_number = (rand() % 6) + 1; // 结果范围是 [1, 6] 总结得出，要生成一个范围在 [MIN, MAX]（包括上下限）的随机数，可以使用公式 int random_number = rand() % (MAX - MIN + 1) + MIN; ","date":"Jan 9 2025","externalUrl":null,"permalink":"/docs/uoft/24/learning-programming-with-c/lpc2.dataoperations/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/9/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e2.1 Double data type for real numbers \r\n    \u003cdiv id=\"21-double-data-type-for-real-numbers\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#21-double-data-type-for-real-numbers\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e在程序中用分数代表数字\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e2.1.1 Convert Inches to Centimeters \r\n    \u003cdiv id=\"211-convert-inches-to-centimeters\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#211-convert-inches-to-centimeters\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// Description: This program convert inches to centimeters\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"cp\"\u003e#include\u003c/span\u003e \u003cspan class=\"cpf\"\u003e\u0026lt;stdio.h\u0026gt;\u003c/span\u003e\u003cspan class=\"cp\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"cp\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e\u003cspan class=\"p\"\u003e){\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// Declare variables\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"kt\"\u003edouble\u003c/span\u003e \u003cspan class=\"n\"\u003eInchesToCm\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e2.54\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"kt\"\u003edouble\u003c/span\u003e \u003cspan class=\"n\"\u003einputInches\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eoutputCm\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// Prompt user for input\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;Enter the number of inches to convert to cm: \u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nf\"\u003escanf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;%lf\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"n\"\u003einputInches\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// Convert inches to centimeters\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"n\"\u003eoutputCm\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einputInches\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"n\"\u003eInchesToCm\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"c1\"\u003e// Display output in 2 decimal places\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e  \u003cspan class=\"nf\"\u003eprintf\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;The number of centimeters is %.2lf\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eoutputCm\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003ccode\u003econst\u003c/code\u003e是一个关键字，指示变量是常量。不能在整个代码中更改该变量\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-c\" data-lang=\"c\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e\u003cspan class=\"p\"\u003e){\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"k\"\u003econst\u003c/span\u003e \u003cspan class=\"kt\"\u003edouble\u003c/span\u003e \u003cspan class=\"n\"\u003eInchesToCm\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e2.54\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"n\"\u003eInchesToCm\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e2.51\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cblockquote\u003e\n\u003cp\u003e这样操作将会报错，因为\u003ccode\u003eInchesToCm\u003c/code\u003e是一个不可以更改的Constant\u003c/p\u003e","title":"LPC 2. Data \u0026 Operations","type":"docs"},{"content":"","date":"Jan 8 2025","externalUrl":null,"permalink":"/tags/calculus/","section":"Tags","summary":"","title":"Calculus","type":"tags"},{"content":" Last Edit: 1/8/25\n10.1 Parametric Equations #\rIf x and y are continuous functions of t on an interval I, then the equations are called parametric equations and t is called the parameter $$x=x(t) andy=y(t)$$ Eliminating the Parameter 化简 #\r通过关系式直接得到x和y之间的函数 ex. #\r$$x(t) = t^2 - 3, \\quad y(t) = 2t + 1, \\quad -2 \\leq t \\leq 3.$$\n从第二个Equation中提出\\(t = \\frac{y - 1}{2}\\)后带入 $$x = \\left(\\frac{y - 1}{2}\\right)^2 - 3 \\ = \\frac{y^2 - 2y + 1}{4} - 3 \\ = \\frac{y^2 - 2y - 11}{4}$$ Use Trigonometrey to Eliminate Parameter #\r通过一些等式建立x和y之间的关系 例如\\(\\cos^2x+\\sin^2 x=1\\) ex. #\r有\\(x = 3 \\cos \\theta \\quad \\text{and} \\quad y = 4 \\sin \\theta, \\quad 0 \\leq \\theta \\leq 2\\pi\\) 通过\\(cos \\theta=\\frac{x}{3},sin\\theta=\\frac{y}{4}\\)替换原式，便有\\((\\frac{x}{3})^2+(\\frac{y}{4})^2=1\\) 10.2 Calculus of Parametric Curves #\rDerivatives of Parametric Equations #\rIf a smooth curve C is given by the equations $$x = f(t) \\quad \\text{and} \\quad y = g(t)$$ then the slope of C at (x, y) is $$\\frac{dy}{dx} = \\frac{\\frac{dy}{dt}}{\\frac{dx}{dt}}, \\quad \\frac{dx}{dt} \\neq 0 $$ Arc Length of a Parametric Curve #\r普通的Arc Length公式为\\(\\int^b_a\\sqrt{1+[f\u0026rsquo;(x)]^2}dx\\) 将Parametric Curve的Derivative带入，得到 $$\\int^b_a\\sqrt{1+(\\frac{dy/dt}{dx/dt})^2}dx=\\int^b_a\\sqrt{\\frac{(dx/dt)^2+(dy/dt)^2}{(dx/dt)^2}}\\frac{dx}{dt}dt$$ 也就是 $$=\\int^b_a\\sqrt{(\\frac{dx}{dt})^2+(\\frac{dy}{dt})^2}dt=\\int^b_a\\sqrt{[f\u0026rsquo;(x)]^2+[g\u0026rsquo;(t)]^2}dt$$ 10.3 Polar Coordinates 极坐标\nPolar Coordinates，一个新的坐标系，通过Radius和于Polar Axis的Directed Angle来表示点在坐标系中的位置 Converting Points between Coordinate Systems #\r想要把Cartesian Coordinates转换为Polar Coordinates，只需要找到\\(r=\\sqrt{x^2+y^2}\\) 和 \\(\\tan^{-1}\\frac{y}{x}\\)便可 而Polar 到 Cartesian的转换则是通过公式\\(x=r\\cos\\theta , y=r\\sin\\theta\\)得到 10.4 Area and Arc Length in Polar Coordinates #\rSlope of Polar Curve #\r对于Polar Coodinates来说，其Derivative可以通过一个简单的Chain Rule得到 $$\\frac{dy}{dx} = \\frac{\\frac{dy}{d\\theta}}{\\frac{dx}{d\\theta}} = \\frac{f(\\theta) \\cos \\theta + f\u0026rsquo;(\\theta) \\sin \\theta}{-f(\\theta) \\sin \\theta + f\u0026rsquo;(\\theta) \\cos \\theta}$$ Areas of Regions Bounded by Polar Curves #\r在之前都是采用多边形来近似面积，而在Polar Region中，采用了扇形的来近似 $$A = \\lim_{n \\to \\infty} \\frac{1}{2} \\sum_{i=1}^{n} [f(\\theta_i)]^2 \\Delta \\theta = \\frac{1}{2} \\int_{\\alpha}^{\\beta} [f(\\theta)]^2 d\\theta$$\n","date":"Jan 8 2025","externalUrl":null,"permalink":"/docs/uoft/24/calculus/calculus10.parametricequationsandpolarcoordinates/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/8/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e10.1 Parametric Equations \r\n    \u003cdiv id=\"101-parametric-equations\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#101-parametric-equations\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eIf x and y are continuous functions of t on an interval I, then the equations are called parametric equations and t is called the parameter\n$$x=x(t) andy=y(t)$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eEliminating the Parameter 化简 \r\n    \u003cdiv id=\"eliminating-the-parameter-%E5%8C%96%E7%AE%80\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#eliminating-the-parameter-%E5%8C%96%E7%AE%80\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e通过关系式直接得到x和y之间的函数\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eex. \r\n    \u003cdiv id=\"ex\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cp\u003e$$x(t) = t^2 - 3, \\quad y(t) = 2t + 1, \\quad -2 \\leq t \\leq 3.$$\u003c/p\u003e","title":"Calculus 10. Parametric Equations and Polar Coordinates","type":"docs"},{"content":" Last Edit: 1/8/25\n1.2 Binary representation in memory #\rBinary to Decimal Number 二进制转十进制 #\rBinary到Decimal Number的转换通过位数和值相乘得到 Decimal Number to Binary 十进制转二进制 #\rDecimal Number通过除法的余数得到二进制 Number of Bits to represent x #\r需要n个二进制位数来表达一个\\(2^n\\)的Decimal Number 要表示 256 个数字，我们需要 8 位。要表示 512 个数字，我们需要 9 位。要表示 1024 个数字，我们需要 10 位 Memory organized way 内存管理方式 #\rMemory通过Cells的方式管理，每一个Cell储存了一个byte 字节 而每一个Cell包换他的Address 地址，这使得Mmory Byte 内存字节是Byte-Addressable的 当采用32个Bits来表达Cell的Address的时候，我们可以储存\\(2^{32}\\)个Bytes 字节 A byte is a group of 8 bits. A kilobyte (KB) is 1024 bytes. A megabyte (MB) is 1024 kilobytes. A gigabyte (GB) is 1024 megabytes. A terabyte (TB) is 1024 gigabytes. \\(2^{32}\\) Bytes也就是4个Gigabytes 现代计算机是64-bits的，也就是说它们的Memory Length可以达到\\(2^{64}\\)位 Hexadecimal \u0026amp; Binary 十六进制和二进制 #\r已知Hexadecimal和Binary的对应表为 0 = 0000, 1 = 0001, 2 = 0010, 3 = 0011, 4 = 0100, 5 = 0101, 6 = 0110, 7 = 0111, 8 = 1000, 9 = 1001, A = 1010, B = 1011, C = 1100, D = 1101, E = 1110, F = 1111 一个Hexadecimal \\(c_1c_2\\)的本质为\\(16^1c_1+16^0c_2\\) 举例来说一个Hexadecimal \\(3A\\)的Decimal Number就是\\(316^1+A16^0=316+101=58\\) 更简单的Hexadecimal直接转换到Binary Number的办法就是拼接 3 转换为 0011 A 转换为 1010 将它们拼接：3A = 0011 + 1010 = 00111010 1.4 Write Simple C Programs 编写简单的 C 程序 #\r// This program prints the message \u0026#34;Hello World!\u0026#34; on the screen. ##include \u0026lt;stdio.h\u0026gt; int main(void){ printf(\u0026#34;Hello World!\\n\u0026#34;); return 0; } #include \u0026lt;stdio.h\u0026gt;允许访问与输入（如键盘）和输出（如监视器）设备接口的功能。这些函数包括 和 。printf``scanf main 是 C 程序的入口点。所有 C 程序都需要 main 函数 在执行程序时调用。它返回一个整数值。该值表示程序执行成功。任何其他值都表示程序失败 printf 是将字符串打印到屏幕的函数 \\ is called an escape character 转义字符 ，\\n is a special character that indicates a new line Input 输入 #\r##include \u0026lt;stdio.h\u0026gt; int main(void){ int numPizzas, numSlices; printf(\u0026#34;How many pizzas do you have?\\n\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;numPizzas); numSlices = numPizzas * 8; printf(\u0026#34;You have %d slices in %d pizza.\\n\u0026#34;, numSlices, numPizzas); return 0; } int numPizzas, numSlices;声明两个类型的变量int is a data type that represents integers scanf(\u0026quot;%d\u0026quot;, \u0026amp;numPizzas);将获取用户输入并将其分配给 variable \u0026amp; Address-of Operator（取地址符） 是为了将变量的地址传递给 scanf pass-by-value 按值传递 #\r在 C 语言中，函数的参数传递默认是按值传递（pass-by-value）。这意味着：\n当你调用一个函数时，传递的实际上是变量值的副本，而不是变量本身。 因此，如果不通过地址传递，函数无法直接修改原始变量的值。 Escape Sequences 转义序列 #\r转义字符是由反斜杠 \\ 开头的一组特殊字符，用于表示一些特殊含义。 \\n 表示换行。 \\t 表示制表符。 \\\\ 表示反斜杠本身。 \\\u0026quot; 表示双引号。 ","date":"Jan 8 2025","externalUrl":null,"permalink":"/docs/uoft/24/learning-programming-with-c/lpc1.introtoprogrammingcomputers/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 1/8/25\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e1.2 Binary representation in memory \r\n    \u003cdiv id=\"12-binary-representation-in-memory\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#12-binary-representation-in-memory\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eBinary to Decimal Number 二进制转十进制 \r\n    \u003cdiv id=\"binary-to-decimal-number-%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%BD%AC%E5%8D%81%E8%BF%9B%E5%88%B6\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#binary-to-decimal-number-%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%BD%AC%E5%8D%81%E8%BF%9B%E5%88%B6\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003eBinary到Decimal Number的转换通过位数和值相乘得到\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/uoft/24/learning-programming-with-c/lpc1.introtoprogrammingcomputers/LPC1.IntrotoProgrammingComputers_hu4440032987239514809.png 330w,\r\n        /docs/uoft/24/learning-programming-with-c/lpc1.introtoprogrammingcomputers/LPC1.IntrotoProgrammingComputers_hu15081779412421026257.png 660w,\r\n        /docs/uoft/24/learning-programming-with-c/lpc1.introtoprogrammingcomputers/LPC1.IntrotoProgrammingComputers_hu17787250618502931940.png 1024w,\r\n        /docs/uoft/24/learning-programming-with-c/lpc1.introtoprogrammingcomputers/LPC1.IntrotoProgrammingComputers_hu12766134372818378964.png 2x\"\r\n        src=\"/docs/uoft/24/learning-programming-with-c/lpc1.introtoprogrammingcomputers/LPC1.IntrotoProgrammingComputers_hu15081779412421026257.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"LPC 1. Intro to Programming Computers","type":"docs"},{"content":" Last Edit: 12/21/24\nLayer 层 #\r对于一个Layer来说，其接受一组输入（通常是矢量化的），通过调整参数后生成相应的输出 对于一个Softmax回归，其模型本身就是一个Layer Block 块 #\r在神经网络中，Block是一种通用的抽象概念，用来描述网络中的组件，可以是一个简单的单层，也可以是由多层组成的模块，甚至是整个模型本身 块的主要目的是对神经网络的结构进行分层抽象，方便构建和复用复杂的网络 MLP #\r一个MLP就可以组建成一个简单的Block，通过如下方式 import torch from torch import nn from torch.nn import functional as F net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10)) X = torch.rand(2, 20) net(X) 5.1.1 Custom block 自定义块 #\r其具体的实现方式是通过一个Python中的Class定义的 class MLP(nn.Module): # 用模型参数声明层。这里，我们声明两个全连接的层 def __init__(self): super().__init__() # 调用nn.Module的构造函数减少重新定义的代码 self.hidden = nn.Linear(20, 256) # 隐藏层 self.out = nn.Linear(256, 10) # 输出层 # 定义前向传播流程 def forward(self, X): #hidden -\u0026gt; relu -\u0026gt; out return self.out(F.relu(self.hidden(X))) 5.1.2 Sequence Block 顺序块 #\r简单定义一个Sequential类，实现 按顺序执行Block 一个前向传播函数 class MySequential(nn.Module): def __init__(self, *args): super().__init__() for idx, module in enumerate(args): self._modules[str(idx)] = module def forward(self, X): for block in self._modules.values(): X = block(X) return X for idx, module in enumerate(args) : 遍历所有传入的模块，并为每个模块分配一个从 0 开始的索引 比如传入了三个模块 MySequential( nn.Linear(10, 20), nn.ReLU(), nn.Linear(20, 10)) 那么 enumerate(args) 会依次返回 (0, nn.Linear(10, 20)), (1, nn.ReLU()), (2, nn.Linear(20, 10)) self._modules[str(idx)] = module self._modules 是 PyTorch 提供的一个内置容器（OrderedDict），用来存储子模块。 self._modules[str(idx)] = module 的作用是： X 先传入 _modules[\u0026quot;0\u0026quot;]（即 nn.Linear(10, 20)）中进行计算。 输出传入 _modules[\u0026quot;1\u0026quot;]（即 nn.ReLU()）中激活。 最后传入 _modules[\u0026quot;2\u0026quot;]（即 nn.Linear(20, 5)），得到最终结果。 str(idx)： Dict的Key要求使用可哈希值，所以需要转换为str 5.1.3 Control Flow in forward propagation #\r在网络中，可以加入一些不被更新的参数，即Constant Parameter，这一个参数不会在优化过程中被更新 class FixedHiddenMLP(nn.Module): def __init__(self): super().__init__() self.rand_weight = torch.rand((20, 20), requires_grad=False) self.linear = nn.Linear(20, 20) def forward(self, X): X = self.linear(X) X = F.relu(torch.mm(X, self.rand_weight) + 1) X = self.linear(X) while X.abs().sum() \u0026gt; 1: X /= 2 return X.sum() self.rand_weight = torch.rand((20, 20), requires_grad=False) requires_grad=False 指定该张量不会参与梯度计算，因此它是一个固定的权重，在训练过程中不会被优化。 它可以被视为一个网络中的“常量” ","date":"Dec 21 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.1layerblock/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 12/21/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eLayer 层 \r\n    \u003cdiv id=\"layer-%E5%B1%82\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#layer-%E5%B1%82\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于一个Layer来说，其接受一组输入（通常是矢量化的），通过调整参数后生成相应的输出\u003c/li\u003e\n\u003cli\u003e对于一个Softmax回归，其模型本身就是一个Layer\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eBlock 块 \r\n    \u003cdiv id=\"block-%E5%9D%97\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#block-%E5%9D%97\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e在神经网络中，Block是一种通用的抽象概念，用来描述网络中的组件，可以是一个简单的单层，也可以是由多层组成的模块，甚至是整个模型本身\u003c/li\u003e\n\u003cli\u003e块的主要目的是对神经网络的结构进行分层抽象，方便构建和复用复杂的网络\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg\r\n        class=\"my-0 rounded-md\"\r\n        loading=\"lazy\"\r\n        srcset=\"\r\n        /docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.1layerblock/D2L5.1Layer\u0026amp;Block_hu399865873791596830.png 330w,\r\n        /docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.1layerblock/D2L5.1Layer\u0026amp;Block_hu13772976285383848655.png 660w,\r\n        /docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.1layerblock/D2L5.1Layer\u0026amp;Block_hu17735818070818276903.png 1024w,\r\n        /docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.1layerblock/D2L5.1Layer\u0026amp;Block_hu13633986511892309580.png 2x\"\r\n        src=\"/docs/dive-into-deep-learning/d2l5.deeplearningcomputation/d2l5.1layerblock/D2L5.1Layer\u0026amp;Block_hu13772976285383848655.png\"\r\n        alt=\"Img\"\r\n      /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"D2 5.1 Layer \u0026 Block","type":"docs"},{"content":" Last Edit: 12/20/24\n“如果微妙的边界条件很重要，我们很可能是在研究数学而非工程”\nPerceptron 感知机 #\r一种单层神经网络模型，用于Binary Classification $$o = \\sigma\\left(\\langle w, x \\rangle + b\\right)~~~~ \\sigma(x) = \\begin{cases} 1 \u0026amp; \\text{if } x \u0026gt; 0 \\ -1 \u0026amp; \\text{otherwise} \\end{cases}$$ Binary Classification 二分类问题 #\r两个可能的值的问题，例如「正类」（1）和「负类」（0） Training 训练 #\rinitialize w = 0 and b = 0\rrepeat\rfor each (xi, yi) in the training data:\rif yi * (⟨w, xi⟩ + b) ≤ 0 then\rw ← w + yi * xi\rb ← b + yi\rend if\rend for\runtil all points are classified correctly initialize w = 0 and b = 0：初始化weight和bias if yi * (⟨w, xi⟩ + b) ≤ 0：如果分类与预测不符 在Perceptron中并没有明确的Optimize Method，但可以隐式定义一个仅与分类错误的点有关的数据的损失，也就是上面小于零情况下的 $$L(w, b) = -\\sum_{x_i \\in M} y_i (w \\cdot x_i + b)$$ 由于\\(y_i (w \\cdot x_i + b)\\)本身是负的，取负之后，这部分损失就变成了正 这意味着误分类样本对损失的贡献是增加的，因为我们希望最小化正的损失值 而对于weight和bias分别的Gradient为 $$\\nabla_w L(w, b) = -\\sum_{x_i \\in M} y_i x_i$$ $$\\nabla_b L(w, b) = -\\sum_{x_i \\in M} y_i$$ 对应了伪代码中的w ← w + yi * xi 与 b ← b + yi 完整代码如下 import numpy as np w = np.zeros(2) b = 0.0 n_epoch = 11 X = np.array([ [0.5, 1.5], [1.0, 1.0], [1.5, 0.5], [2.0, 1.0], [2.5, 1.5], [3.0, 3.0], [3.5, 3.5], [4.0, 4.5], [4.5, 5.0], [5.0, 5.5]]) y = np.array([-1, -1, -1, -1, -1, 1, 1, 1, 1, 1]) for epoch in range(n_epochs): for i in range(len(X)): if y[i] * (np.dot(w, X[i]) + b) \u0026lt;= 0: w += y[i] * X[i] b += y[i] else: continue def predict(X, w, b): return np.sign(np.dot(X, w) + b) predictions = predict(X, w, b) print(\u0026#34;Predictions:\u0026#34;, predictions) print(\u0026#34;Actual labels:\u0026#34;, y) \u0026gt; Predictions: [-1. -1. -1. -1. -1. 1. 1. 1. 1. 1.] \u0026gt; Actual labels: [-1 -1 -1 -1 -1 1 1 1 1 1] XOR Problem #\rXOR（异或）逻辑门是一个二输入逻辑门，其输出只在两个输入不同时为1（即当输入是(0,1)或(1,0)时）。其逻辑如下：\n0 XOR 0 = 0\n0 XOR 1 = 1\n1 XOR 0 = 1\n1 XOR 1 = 0\n线性模型，如感知机，是基于线性方程的，它试图找到一个权重向量和偏差，以便通过一个超平面来分割数据点。\n对于 XOR 问题，无论如何调整线性模型的参数，都无法得到一个能够将这四个点分开的单一直线\n为了解决XOR问题，我们可以使用非线性模型。最常见的方法是使用神经网络，尤其是多层感知机（MLP）。通过添加一个或多个隐藏层，神经网络能够学习非线性函数\n单调假设与线性模型的局限性 #\r单调假设：在一个线性模型中，特征与输出之间的关系是单调的 线性模型的局限：虽然线性模型简单且易于理解，但很多现实世界的关系是非线性的 Hidden Layer 隐藏层 #\r我们可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制 对于线性网络来说，每一层都是线性的Affine transformation 仿射变换 $$H = XW^{(1)} + b^{(1)}, O = HW^{(2)} + b^{(2)}$$\n这样即使构造了多层的模型，其实际上还是只等于一个Affine Transformation $$O = (XW^{(1)} + b^{(1)})W^{(2)} + b^{(2)} = XW^{(1)}W^{(2)} + b^{(1)}W^{(2)} + b^{(2)} = XW + b$$\n而为了发挥多层框架的潜力，就需要在Affine Transformation后应用一个Non-Linear的Activation Function激活Output\n一般来说在Activation之后便不能将其退化为Linear Model $$H = \\sigma(XW^{(1)} + b^{(1)}), O = HW^{(2)} + b^{(2)}$$\n为了构建更通用的多层感知机， 我们可以继续堆叠这样的隐藏层， 一层叠一层，从而产生更有表达能力的模型\nActivation Function 激活函数 #\rActivation function 通过计算加权和并加上偏置来确定神经元是否应该被激活， 它们将输入信号转换为输出的可微运算。 大多数激活函数都是非线性的 通过加入了更“DEEP”的层数，MLP理论可以拟合任意连续函数 Weierstrass Approximation Theorem #\r在知道了Weierstrass Approximation Theorem后，也就是证明该 $$B_n(x) = \\sum_{i=0}^n f\\left(\\frac{i}{n}\\right) \\binom{n}{i} x^i (1-x)^{n-i}$$ Bernstein Polynomial，\\(B_n(f, x)\\)在区间\\([0, 1]\\)上以任意精度逼近\\(f(x)\\) 通过说明MLP如何通过从Activation Function构造Polynomial，最终证明MLP如何实现函数的理论任意精度逼近 Activation Function that has Tyler Series #\rWeierstrass Approximation Theorem指出，任意定义在闭区间 \\([a, b]\\)上的连续函数\\(f\\)都可以被多项式函数以任意精度逼近。即，对于任意\\(\\varepsilon \u0026gt; 0\\)，存在一个多项式\\(P(x)\\)，使得 $$|f(x) - P(x)| \u0026lt; \\varepsilon \\quad \\forall x \\in [a, b]$$ 为了证明单隐层神经网络能够逼近任意多项式，我们考虑如下多项式： $$P(x) = \\sum_{k=0}^n a_k x^k$$ 其中\\(a_k\\)是多项式系数，n是多项式的次数。 目标是要构造一个单隐层神经网络\\(F(x) = \\sum_{j=1}^m \\alpha_j \\sigma(w_j x + b_j)\\)，使得\\(F(x)\\)能够逼近\\(P(x)\\)以任意精度 选择合适的非线性激活函数是关键。假设\\(\\sigma\\)在某个区间内具有泰勒展开： $$\\sigma(z) = \\sum_{k=0}^\\infty c_k z^k$$ 其中\\(c_k\\)是泰勒级数的系数。典型的激活函数如 sigmoid、tanh 等都满足在某个区间内可展开为幂级数 $$\\sigma(x) = \\frac{1}{2} + \\frac{x}{4} - \\frac{x^3}{48} + \\frac{x^5}{480} + \\cdots$$ $$\\tanh(x) = x - \\frac{x^3}{3} + \\frac{2x^5}{15} - \\frac{17x^7}{315} + \\cdots$$ 由于\\(P(x)\\)是多项式，我们需要构造网络的输出\\(F(x)\\)来逼近\\(P(x)\\)具体步骤如下： 对于每个高阶项\\(x^k\\)，利用激活函数的非线性性质，通过组合多个隐藏单元来逼近。具体来说，可以通过调整\\(w_j\\)和\\(b_j\\)，使得多个\\(\\sigma(w_j x + b_j)\\)的组合能够近似\\(x^k\\) 一个二次多项式的例子便是 $$F(x) = \\underbrace{\\sigma(b_1) \\cdot \\alpha_1}_{\\text{常数项}} + \\underbrace{\\sigma(w_2x + b_2) \\cdot \\alpha_2}_{\\text{线性项}} + \\underbrace{\\sigma(w_{3,1}x + b_{3,1}) \\cdot \\alpha_{3,1} + \\sigma(w_{3,2}x + b_{3,2}) \\cdot \\alpha_{3,2}}_{\\text{二次项}}$$\r由于多项式是各阶项的线性组合，单隐层网络通过线性组合隐藏层的输出即可实现对多项式的逼近 $$F(x) = \\sum_{j=1}^m \\alpha_j \\sigma(w_j x + b_j) \\approx \\sum_{k=0}^n a_k x^k = P(x)$$ 上述证明假设激活函数\\(\\sigma\\)能够通过适当组合逼近多项式项。某些激活函数（如ReLU）虽然非多项式，但由于其分段线性性质，也具备强大的逼近能力。 Activation Function that doesn\u0026rsquo;t have Tyler Series #\r首先要说明的就是上面所提到的那句话，\u0026ldquo;如果微妙的边界条件很重要，我们很可能是在研究数学而非工程.\u0026rdquo; ReLU函数定义为： $$\\sigma(z) = \\max(0, z)$$ $$\\sigma(z) = \\begin{cases} 0, \u0026amp; z \\leq 0 \\ z, \u0026amp; z \u0026gt; 0 \\end{cases}$$ 分段线性函数能够在不同的区间内表现出不同的线性特征 这种特性允许神经网络通过组合多个ReLU单元，在输入空间中划分出多个线性区域，每个区域内的网络输出都是一个线性函数 通过增加隐藏单元数，可以在输入空间中创建更多的线性区间，从而逼近复杂的非线性函数 $$F(x) = \\sum_{j=1}^m \\alpha_j \\sigma(w_j x + b_j) = \\sum_{j=1}^m \\alpha_j \\max(0, w_j x + b_j)$$ 每个隐藏单元\\(\\sigma(w_j x + b_j)\\)在\\(w_j x + b_j = 0\\)处产生一个“折点”，即输入\\(x = -\\frac{b_j}{w_j}\\)处 通过调整不同单元的权重\\(w_j\\)和偏置\\(b_j\\)，可以在输入空间中创建多个折点，将输入空间划分为多个线性区间。 5分钟理解激活函数让神经网络能拟合任何函数 - 知乎\n","date":"Dec 20 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.1multilayerperceptron/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 12/20/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e“如果微妙的边界条件很重要，我们很可能是在研究数学而非工程”\u003c/p\u003e","title":"D2L 4.1 Multilayer Perceptron","type":"docs"},{"content":" Last Edit: 12/20/24\n使用纯MLP参加https://www.kaggle.com/competitions/titanic的Competition\n# This Python 3 environment comes with many helpful analytics libraries installed # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python # For example, here\u0026#39;s several helpful packages to load import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) # Input data files are available in the read-only \u0026#34;../input/\u0026#34; directory # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory import os for dirname, _, filenames in os.walk(\u0026#39;/kaggle/input/d/heptapod/titanic/train_and_test2.csv\u0026#39;): for filename in filenames: print(os.path.join(dirname, filename)) # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \u0026#34;Save \u0026amp; Run All\u0026#34; # You can also write temporary files to /kaggle/temp/, but they won\u0026#39;t be saved outside of the current session train_path = \u0026#39;/kaggle/input/titanic/train.csv\u0026#39; test_path = \u0026#39;/kaggle/input/titanic/test.csv\u0026#39; train_data = pd.read_csv(train_path) test_data = pd.read_csv(test_path) data = pd.concat([train_data, test_data], sort=False).reset_index(drop=True) display(data) # 填补Age的缺失值 data[\u0026#39;Age\u0026#39;].fillna(data[\u0026#39;Age\u0026#39;].median(), inplace=True) # 填补Fare的缺失值 data[\u0026#39;Fare\u0026#39;].fillna(data[\u0026#39;Fare\u0026#39;].median(), inplace=True) display(data[\u0026#39;Fare\u0026#39;]) data = data[[\u0026#39;Survived\u0026#39;,\u0026#39;Pclass\u0026#39;,\u0026#39;Sex\u0026#39;,\u0026#39;Age\u0026#39;,\u0026#39;SibSp\u0026#39;,\u0026#39;Parch\u0026#39;,\u0026#39;Fare\u0026#39;]] data[\u0026#39;Sex\u0026#39;] = data[\u0026#39;Sex\u0026#39;].map({\u0026#39;male\u0026#39;: 0, \u0026#39;female\u0026#39;: 1}) print(data) train_data = data.iloc[:891].copy() test_data = data.iloc[891:].copy() X_train = train_data.drop(\u0026#39;Survived\u0026#39;, axis=1) y_train = train_data[\u0026#39;Survived\u0026#39;].astype(int) X_test = test_data.drop(\u0026#39;Survived\u0026#39;, axis=1).copy() print(X_test) from sklearn.neural_network import MLPClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score, classification_report # 将训练集分为训练子集和验证子集 X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42) # 初始化MLPClassifier mlp = MLPClassifier(hidden_layer_sizes=(100,), # 一个隐藏层，100个神经元 activation=\u0026#39;relu\u0026#39;, # 激活函数为ReLU solver=\u0026#39;adam\u0026#39;, # 优化器为Adam max_iter=1000, # 最大迭代次数 random_state=42) # 训练模型 mlp.fit(X_tr, y_tr) # 在验证集上进行预测 y_pred = mlp.predict(X_val) # 计算准确率 accuracy = accuracy_score(y_val, y_pred) print(f\u0026#34;\\n验证集准确率：{accuracy:.4f}\u0026#34;) # 查看分类报告 print(\u0026#34;\\n分类报告：\u0026#34;) print(classification_report(y_val, y_pred)) y_test = mlp.predict(X_test) result = mlp.predict(X_test) X_test[\u0026#39;Survived\u0026#39;] = result passenger_ids = np.arange(891, 1309) X_test[\u0026#39;Passengerid\u0026#39;] = passenger_ids X_test = X_test[\u0026#39;Survived\u0026#39;] print(X_test) X_test.to_csv(\u0026#39;submission.csv\u0026#39;, index=False) print(\u0026#34;提交文件 \u0026#39;submission.csv\u0026#39; 已生成。\u0026#34;) ","date":"Dec 20 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.2exampleofmlp/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 12/20/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e使用纯MLP参加https://www.kaggle.com/competitions/titanic的Competition\u003c/p\u003e","title":"D2L 4.2 Example of MLP","type":"docs"},{"content":" Last Edit: 12/19/24\nWeierstrass Approximation Theorem #\r每一个定义在闭区间\\([a,b]\\)上的实值连续函数都可以被多项式序列在整个区间上一致逼近。 换句话说，给定任意的连续函数\\(f: [a, b] \\to \\mathbb{R}\\)和任意小的正数\\(\\epsilon\\)，都存在一个多项式\\(P(x)\\)，使得对所有\\(x \\in [a, b]\\)都有\\(|f(x) - P(x)| \u0026lt; \\epsilon\\) Bernstein\u0026rsquo;s Proof 1912 #\r采用离散的Convolution $$f(x)\\approx\\sum^n_{i=0}f(x_i)w(x_i)$$ 其满足\\(\\sum_i(x_i)=1\\)，离\\(x\\)越近的地方\\(w(x_i)\\)越大 Binomial Distribution 二项分布 #\r一种离散概率分布，用于模型在固定次数的独立试验中每次试验成功的次数 其质量概率函数为 $$P(X=k) = \\binom{n}{k} p^k (1-p)^{n-k}$$ p：单次独立事件的成功概率 k：实验中事件成功的次数 n：实验的总事件的数量 Interpretation #\r这样理解，先不管\\(\\binom{n}{k}\\)，假设一个成功率为\\(60%\\)的事件，其总共实验次数为5次，也就是\\(p=0.6,n=5\\) 现在当\\(k=5\\)的时候，Binomial Distribution表示的概率为\\(0.6^5\\)，也就是说对于一个概率为0.6的事件，其独立测试五次后都成功的概率为\\(0.6^5\\)，这就是最简单的概率 当\\(k=3\\)时，概率质量函数为 $$\\binom{5}{3} 0.6^3 (1-0.6)^{5-3}$$ 也就是说，5次实验，每一个5次实验中3次成功的概率为\\(0.6^3 (1-0.6)^{5-3}\\) 而在5次实验中这些成功的和失败的实验都可能出现在不同的位置，而这些中的成功的事件的位置可以是 $$123,124,125,134,135,145,234,235,245,345$$ 这10种情况，也就是出现5次中3次的会有10中情况，所以乘以10 Bernstein Polynomial 伯恩斯坦多项式 #\r$$B_n(x) = \\sum_{i=0}^n f\\left(\\frac{i}{n}\\right) \\binom{n}{i} x^i (1-x)^{n-i}$$\n用加权平均的方式（基于二项分布）生成新的多项式\\(B_n(x)\\)，作为\\(f(x)\\)的近似，实际上就是一个离散的Convolution Similarity to Convolution #\r$$(f * g)(x) = \\sum_{k} f(k) g(x-k)$$\n可以发现两者的区别就在于Bernstein Poly的Weight是基于Binomial Distribution的 并且采样点不再是连续的输入而是离散且固定的值 Expectation #\r$$B_n(x) = \\mathbb{E}\\left[f\\left(\\frac{X}{n}\\right)\\right]$$\n最终可以得到Bernstein Polynomial的期望值在\\(n\\rightarrow \\infty\\)的情况下是就是\\(f(x)\\) 也就是说可以通过一致收敛性，说明\\(B_n(f, x)\\)在区间\\([0, 1]\\)上以任意精度逼近\\(f(x)\\) ","date":"Dec 19 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter4multilayerperceptron/weierstrassapproximation/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 12/19/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eWeierstrass Approximation Theorem \r\n    \u003cdiv id=\"weierstrass-approximation-theorem\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#weierstrass-approximation-theorem\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e每一个定义在闭区间\\([a,b]\\)上的实值连续函数都可以被多项式序列在整个区间上一致逼近。\u003c/li\u003e\n\u003cli\u003e换句话说，给定任意的连续函数\\(f: [a, b] \\to \\mathbb{R}\\)和任意小的正数\\(\\epsilon\\)，都存在一个多项式\\(P(x)\\)，使得对所有\\(x \\in [a, b]\\)都有\\(|f(x) - P(x)| \u0026lt; \\epsilon\\)\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eBernstein\u0026rsquo;s Proof 1912 \r\n    \u003cdiv id=\"bernsteins-proof-1912\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#bernsteins-proof-1912\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e采用离散的Convolution\n$$f(x)\\approx\\sum^n_{i=0}f(x_i)w(x_i)$$\u003c/li\u003e\n\u003cli\u003e其满足\\(\\sum_i(x_i)=1\\)，离\\(x\\)越近的地方\\(w(x_i)\\)越大\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eBinomial Distribution 二项分布 \r\n    \u003cdiv id=\"binomial-distribution-%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#binomial-distribution-%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e一种离散概率分布，用于模型在固定次数的独立试验中每次试验成功的次数\u003c/li\u003e\n\u003cli\u003e其质量概率函数为\n$$P(X=k) = \\binom{n}{k} p^k (1-p)^{n-k}$$\u003c/li\u003e\n\u003cli\u003ep：单次独立事件的成功概率\u003c/li\u003e\n\u003cli\u003ek：实验中事件成功的次数\u003c/li\u003e\n\u003cli\u003en：实验的总事件的数量\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eInterpretation \r\n    \u003cdiv id=\"interpretation\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#interpretation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e这样理解，先不管\\(\\binom{n}{k}\\)，假设一个成功率为\\(60%\\)的事件，其总共实验次数为5次，也就是\\(p=0.6,n=5\\)\u003c/li\u003e\n\u003cli\u003e现在当\\(k=5\\)的时候，Binomial Distribution表示的概率为\\(0.6^5\\)，也就是说对于一个概率为0.6的事件，其独立测试五次后都成功的概率为\\(0.6^5\\)，这就是最简单的概率\u003c/li\u003e\n\u003cli\u003e当\\(k=3\\)时，概率质量函数为\n$$\\binom{5}{3} 0.6^3 (1-0.6)^{5-3}$$\u003c/li\u003e\n\u003cli\u003e也就是说，5次实验，每一个5次实验中3次成功的概率为\\(0.6^3 (1-0.6)^{5-3}\\)\u003c/li\u003e\n\u003cli\u003e而在5次实验中这些成功的和失败的实验都可能出现在不同的位置，而这些中的成功的事件的位置可以是\n$$123,124,125,134,135,145,234,235,245,345$$\u003c/li\u003e\n\u003cli\u003e这10种情况，也就是出现5次中3次的会有10中情况，所以乘以10\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eBernstein Polynomial 伯恩斯坦多项式 \r\n    \u003cdiv id=\"bernstein-polynomial-%E4%BC%AF%E6%81%A9%E6%96%AF%E5%9D%A6%E5%A4%9A%E9%A1%B9%E5%BC%8F\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#bernstein-polynomial-%E4%BC%AF%E6%81%A9%E6%96%AF%E5%9D%A6%E5%A4%9A%E9%A1%B9%E5%BC%8F\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003e$$B_n(x) = \\sum_{i=0}^n f\\left(\\frac{i}{n}\\right) \\binom{n}{i} x^i (1-x)^{n-i}$$\u003c/p\u003e","title":"D2L Weierstrass Approximation Theorem","type":"docs"},{"content":" Last Edit: 12/15/24\nReal Number 实数 #\rRational Number 有理数 #\r整数，有限位小数，无限循环小数，分数 只要是能被表达为 $$\\frac{p}{q},p,q\\in \\mathbb z,q\\neq 0$$ 的数都叫做Rational Number 也就是说可以被任意两个Nature Number通过加减乘除所得到的数都被称为Rational Number（做除法的时候分母不能为零） Irrational Number 无理数 #\rPythagoras Theorem 毕达哥拉斯定理 #\r在一个直角三角形中，直角边对面的斜边（最长边）的平方等于两个直角边的平方和 Contradiction #\r在当时并没有Irrational Number的定义，但是表示一个两个直角边长度为一的直角三角形的斜边的时候却出现了问题，即\\(1^2+1^2=x^2\\)，无法通过一个Rational Number，也就是两个Nature Number的任意四则运算求出这个x Proof that sqrt 2 isn\u0026rsquo;t Rational Number #\rProof By Contradiction 假设\\(\\sqrt 2\\)是一个Rational Number，则有\\(2=(\\frac{p}{q})^2\\)，其中p和q是互素的 即\\(p^2=2q^2\\)，已知\\(2q^2\\)为一个Even Number，则等号另一边的\\(p\\)也必为一个Even Number（Odd Number的平方为Odd Number） 既然p是一个Even Number，则他可以被2整除，即\\(p^2\\)可以被4整除，同理可以得到\\(2|q^2\\) 那既然p和q都是偶数，很明显他们不可能互素，Contradict，故假设不成立 于是证明了Irrational Number的存在 Define Real Number #\r首先要知道的是，根号的本质是一个服务幂而创造出的代数运算，其能表达出的Irrational Number的个数几乎可以忽略不计 所以定义实数的第一步就是构造出所有Irrational Number，第二步则是定义全序列关系，第三步为定义代数运算，第四步研究拓扑结构（稠密性） Dedekind Cut #\r设数集的一个划分\\({\\alpha,\\beta }\\)，其中\n\\(\\alpha,\\beta\\neq \\emptyset\\)，即两个划分必须为有元素\n向下封闭：\\(\\forall x,y\\in k, x\u0026lt;y,y\\in \\alpha \\Rightarrow x\\in \\alpha\\)\n\\(\\alpha\\)中无最大元素：\\(\\forall x\\in \\alpha,\\exists y\\in \\alpha~ st.~y\u0026gt;x\\)\n满足以上条件的Cut则称为k上的一个Dedekind Cut，记做\\(\\alpha|\\beta\\) ，其中\\(\\alpha,\\beta\\)分别称为Dedekind Cut的Lower Set和Upper Set\n每一个Dedekind Cut都确定了一个Real Number，其为一个存在无限过程的集合，具体来说有对于一个Set，其无最大元素的定义便是一个无限的过程，所以即使Dedekind Cut的Lower Set是一个集合，其实际上表示的是一个Real Number\n再次对于上面的\\(x^2=2\\)做分析，假设其正根为\\(x_0\\)，令 $$\\alpha = {a \\in \\mathbb{Q} : a \u0026lt; x_0}~~~~~ \\beta = {a \\in \\mathbb{Q} : a \u0026gt; x_0}$$ ![[MA2.RealNumber.png]]\n则集合\\(\\alpha\\)便就是一个表达\\(\\sqrt2\\)的方法\nReal Number Set Definition #\r有理数集\\(\\mathbb Q\\)上的所有Dedekind Cut的Lower Set的Set称为Set of Real Numbers，记做\\(\\mathbb R\\) 其中的每一个Dedekind Cut的Lower Set表示一个Real Number Sequence Relationship #\r定义了Real Number后，需要将他们排列，具体来说需要将由Dedekind Cut所确定的Lower Sets做排列，有 $$\\alpha_1\\leq\\alpha_2=\\alpha1\\subseteq\\alpha _2$$ 但是左边是一个全序集，而右边是偏序集 证明右边是全序集可以通过向下封闭的性质，即 $$\\forall \\alpha_1\\leq \\alpha_2~\\exists\\forall x\\in\\alpha_1\\Rightarrow x \\in\\alpha_2$$ 则可以证明出Real Number Set\\(\\mathbb R\\)是一个全序集 Summation #\r通过两个Dedekind Cut相加定义出一个新的Dedekind Cut $$\\alpha+\\beta={a+b,a\\in\\alpha,b\\in\\beta}$$ 现在需要证明这个定义Well-defined Proof #\r只需证明\\(\\alpha + \\beta\\)是一个 Dedekind Cut的Lower Set，也就是证明其1.向下封闭，2.没有最大元素 (i) 显然\\(\\alpha + \\beta \\neq \\emptyset\\)。任取\\(c \\in (\\alpha + \\beta)\\)，令\\(c = a + b\\)，其中\\(a \\in \\alpha, b \\in \\beta\\)。若\\(c\u0026rsquo; \u0026lt; c\\)，则存在\\(d \u0026gt; 0\\)满足\\(c\u0026rsquo; = c - d = (a + b) - d = (a - d) + b\\)，由于\\(a - d \u0026lt; a\\)，故\\(a - d \\in \\alpha\\)。这表明\\(c\u0026rsquo; \\in (\\alpha + \\beta)\\)，于是可知\\(\\alpha + \\beta\\)向下封闭 (ii) 由于\\(\\alpha\\)和\\(\\beta\\)中都没有最大元素，因此一定存在\\(a\u0026rsquo; \\in \\alpha, b\u0026rsquo; \\in \\beta\\)满足\\(a\u0026rsquo; \u0026gt; a, b\u0026rsquo; \u0026gt; b\\)，于是\\((a\u0026rsquo; + b\u0026rsquo;) \\in (\\alpha + \\beta)\\)且\\(a\u0026rsquo; + b\u0026rsquo; \u0026gt; a + b\\)，于是可知\\(\\alpha + \\beta\\)中也没有最大元素。 综上可述\\(\\alpha+\\beta\\in \\mathbb R\\) Law of Operation #\r加法结合律 #\r对任意的\\(\\alpha, \\beta, \\gamma \\in \\mathbb{R}\\)，有\\((\\alpha + \\beta) + \\gamma = \\alpha + (\\beta + \\gamma)\\) 加法交换律 #\r对任意的\\(\\alpha, \\beta \\in \\mathbb{R}\\)，有\\(\\alpha + \\beta = \\beta + \\alpha\\) 加法零元 #\r对于任意的\\(\\alpha \\in \\mathbb{R}\\)，存在一个零元\\(0^\\)使得\\(\\alpha + 0^ = 0^* + \\alpha = \\alpha\\) 加法负元 #\r对于任意的\\(\\alpha \\in \\mathbb{R}\\)，存在一个负元\\(\\beta\\)使得\\(\\alpha + \\beta = \\beta + \\alpha = 0^*\\) Completeness of Real Number Field 实数域的完备性 #\rDense 稠密 #\r设S是一个集合，X是一个包含S的更大的空间。我们说S在X中稠密，如果对于X中任意的点x，在x的任意小的邻域中，总能找到至少一个属于S的点 $$\\forall x \\in X, \\forall \\epsilon \u0026gt; 0, \\exists s \\in S \\ \\text{st.} \\ |s - x| \u0026lt; \\epsilon$$\nReal Number Field\u0026rsquo;s Density 实数域的稠密性 #\r对于任意𝛼,𝛽∈R,若𝛼\u0026lt; 𝛽,则一定存在𝛾∈R满足\\(\\alpha \u0026lt; \\gamma \u0026lt;\\beta\\) Proof #\r令𝛾=(𝛼+𝛽)/2.由于𝛼 \u0026lt; 𝛽,故 $$2𝛼 \u0026lt; 𝛼+𝛽 \u0026lt;2𝛽 ⇐⇒ 𝛼\u0026lt; \\frac{𝛼+𝛽} {2} \u0026lt;𝛽 ⇐⇒ 𝛼\u0026lt;𝛾\u0026lt;\\beta$$ Dedekind Theorem In Rational Number Field 有理数的戴德金分割 #\r有理数域\\(\\mathbb Q\\)上的Dedekind Cut可能会出现Upper Set中无最小元素的情况.这说明有理数域存在空隙\nex. sqrt{2} 在 Q中的分割 #\r考虑实数\\(\\sqrt{2}\\)（它是无理数，不属于\\(\\mathbb{Q}\\)），我们定义：\n\\(A = { q \\in \\mathbb{Q} \\mid q^2 \u0026lt; 2 }\\) （所有小于\\(\\sqrt{2}\\) 的有理数） \\(B = { q \\in \\mathbb{Q} \\mid q^2 \u0026gt; 2 }\\) （所有大于\\(\\sqrt{2}\\) 的有理数） 可以验证：\n\\(A \\cup B = \\mathbb{Q}\\)且\\(A \\cap B = \\emptyset\\) \\(a \u0026lt; b\\) 对于任意\\(a \\in A, b \\in B\\) 但是Upper Set B中不存在最小元素，因为对于任意\\(b \\in B\\)，都可以找到一个更小的\\(b\u0026rsquo; \\in B\\)\n这说明在\\(\\mathbb{Q}\\)中，\\(\\sqrt{2}\\)这样的点无法被有理数表示，导致了“空隙”的存在。\nDedekind Theorem in Real Number Field 实数的戴德金分割 #\r对于实数域R上的任一Dedekind Cut \\(𝐴| 𝐵\\), Upper Set 𝐵中都有最小元素 Proof #\r简单来说，给定实数域上的一个Dedekind Cut(A|B)。\n若A有最大元，则这个最大元即属于B，因此B有最小元。 若A无最大元，则A中可找出一列有理数向上递增逼近分割点。若该分割点存在于A中，则逼近过程能产生一个最大元与分割矛盾；若分割点不在A中，就会落在B中，从而成为B的最小元。 总而言之，无论A是否有最大元，B中总能找到一个最小元\nThe limit principle 界 #\rDedekind Cut 𝐴 | 𝐵 中, Lower Set 𝐴的任一元素都小于𝐵中任一元素，从直观上看, 𝐴是有‘‘上界的”,而𝐵是有‘‘下界的”.\nBounded 有界的 #\r设非空集合𝐸⊆R.若存在𝑀\u0026gt;0使得|𝑥|\u0026lt;𝑀 (∀𝑥∈𝐸),则称𝐸是有界的(bounded) Supremum 上确界 #\r集合E的一个数M被称为其上确界（supremum），如果满足以下两个条件\nM是E的上界 Upper bound： $$\\forall x \\in E, \\quad x \\leq M$$ M是所有上界中的最小值，也就是上确界 Supremum： 对于任意\\(\\varepsilon \u0026gt; 0\\)，都存在\\(x_\\varepsilon \\in E\\)，使得\\(M - \\varepsilon \u0026lt; x_\\varepsilon \\leq M\\) Infimum 下确界 #\r集合E的一个数m被称为其下确界（infimum），如果满足以下两个条件：\nm是E的下界（lower bound）： $$\\forall x \\in E, \\quad m \\leq x$$ m是所有下界中的最大值： 对于任意\\(\\varepsilon \u0026gt; 0\\)，都存在\\(x_\\varepsilon \\in E\\)，使得\\(m\\leq x_\\varepsilon \u0026lt; m + \\varepsilon\\) Existence of Supremum \u0026amp; Infimum 上，下确界的存在性 #\r对于一个实数集的子集\\(E\\subseteq\\mathbb R\\)，其根据Real Number的 Completeness一定存在确界 ex. Supremum \u0026amp; Infimum #\r$$E ={ \\frac{1}{n} : n \\in \\mathbb{N}^* }$$\n对于E来说，\\(supE=1,infE=0\\) Least-upper-bound property, LUB 最小上界性 #\r定义：如果一个非空的实数集合S在实数集中有上界，那么S必定在实数集中有最小的上界（简称为确界）\nDedekind Theorem和确界原理是等价的 Heine-Borel Theorem #\r有限闭区间的任一开覆盖都存在一个有限子覆盖 Open Cover 开覆盖 #\r设Set \\(E\\subseteq \\mathbb R\\)和一族开区间\\({I_\\lambda:\\lambda\\in \\Lambda }\\)，\\(\\Lambda\\)是一个指标集，若 $$E \\subseteq \\bigcup_{\\lambda \\in \\Lambda} I_\\lambda.$$ 则\\({I_\\lambda:\\lambda\\in \\Lambda }\\)是E的一个Open Cover，也就是一个开区间的集合的并集能够覆盖满整个集合E，记作\\(C_E\\) 若E有一个Open Cover \\(C_E\u0026rsquo;\\subseteq C_E\\)，则称\\(C_E\u0026rsquo;\\)为\\(C_E\\)的Subcover 子覆盖 过这个Cover里只有有限个Open Set，则称他为Finite Subcover 有限子覆盖 Set\u0026rsquo;s Cardinality 集合的基数 #\rCardinality 基数 #\r对于一个Finite Set A来说，他的基数是一个可以数出来的数字，即可以在\\(\\mathbb Z\\)中找到一个数表示他的Cardinality，计作cardA或是\\(|A|\\) 我们约定\\(card \\emptyset =0\\) 同时也可以发现两个Card相同的Set之间一定存在一个Bijective 对于一个Infinite Set，即使无法直接数出他的Card，但可以通过Bijective的角度刻画 Equivalency of Set 集合的对等 #\r设集合A，B若存在一个A到B的双射 , 则称A与B对等 (equivalent), 记作A ∼ B Finite Set 有限集 #\r设集合A. 若A= ∅ , 或存在\\(n∈ N^∗\\), 使得集合 \\({ 1 , 2 , · · · , n}\\) ∼ A , 则称集合A为有限集 (finite set) Finite Set的任一Subset仍是一个Finite Set Equivalency of Integer Set and Nature Number Set 整数集和自然数集的对等 #\r考虑以下问题，自然数集和整数集的Cardinality是否相等？ 从直觉上看\\(\\mathbb N \\subset \\mathbb Z\\)，看似自然数的总数比整数少，但并非如此 前面说明了，如果两个Set之间可以建立一个Bijective的关系，则说明两个Set是Equivalent的，现在把Integer Set的所有元素排成一列 $$0,1,-1,2,-2,3,-3,\\cdots$$ 通过以下函数建立\\(f:\\mathbb N\\rightarrow \\mathbb Z\\) $$f(n) = \\begin{cases} -\\frac{n}{2}, \u0026amp; \\text{n is Even} \\ \\frac{n+1}{2}, \u0026amp; \\text{n is Odd} \\end{cases}$$ 可以发现 $$n = 1 \\to 0,n = 2 \\to -n,n = 3 \\to 1,n = 4 \\to -2,n = 5 \\to 2,n = 6 \\to -3 $$ 于是可知\\(\\mathbb N\\) ~ \\(\\mathbb Z\\) Countable Set 可数集 #\r设Infinite Set A，若\\(A\\) ~ \\(\\mathbb N\\)，集存在一个A到N的Bijective Relationship，则称A为Countable 可数的，这样的Set也被称为Countable Set Countable Set的Cardinality称为Countable Cardinality 可数基数，记做\\(\\aleph_0\\) Aleph 阿列夫\nRational Number Set is a Countable Set #\r同理只要将Rational Number通过\\(\\frac{p}{q}\\)那样排成一排然后和\\(\\mathbb N\\)建立Bijective Relationship就行 $$ \\left[ \\begin{array}{cccc} \\frac{1}{1} \u0026amp; \\frac{1}{2} \u0026amp; \\frac{1}{3} \u0026amp; \\cdots \\ \\frac{2}{1} \u0026amp; \\frac{2}{2} \u0026amp; \\frac{2}{3} \u0026amp; \\cdots \\ \\frac{3}{1} \u0026amp; \\frac{3}{2} \u0026amp; \\frac{3}{3} \u0026amp; \\cdots \\ \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \\end{array} \\right] $$ 具体排列方式不限，但可以知道Rational Number Set的Cardinality也同为\\(\\aleph_0\\) Uncountable Set 不可数集 #\r下面给出一个不可数集的例子，其实既然知道了有理数集是Infinite Countable Set，那Uncountable Set很明显就是Irrational Number或者的Subset了 ex. Interval \\([0,1)\\) is Uncountable Set #\r假设区间\\([0,1)\\)中的所有实数是可数的，那么我们可以将这些实数按序列排列如下： $$x_1, x_2, x_3, \\ldots$$\n每一个Real Number \\(x_i\\)都可以表示为小数形式 $$\\begin{align} x_1 = 0.a_{11}a_{12}a_{13}a_{14} \\cdots \\ x_2 = 0.a_{21}a_{22}a_{23}a_{24} \\cdots \\ x_3 = 0.a_{31}a_{32}a_{33}a_{34} \\cdots \\ \\vdots \\end{align} $$ 假设前三个实数 $$ \\begin{array}{c|cccc} \u0026amp; \\text{第1位} \u0026amp; \\text{第2位} \u0026amp; \\text{第3位} \u0026amp; \\text{第4位} \\ \\hline x_1 \u0026amp; 3 \u0026amp; 1 \u0026amp; 4 \u0026amp; 1 \\ x_2 \u0026amp; 5 \u0026amp; 9 \u0026amp; 2 \u0026amp; 6 \\ x_3 \u0026amp; 5 \u0026amp; 3 \u0026amp; 5 \u0026amp; 8 \\ \\end{array} $$ 康托尔的对角线论证法要求我们构造一个新的实数y，其小数部分的每一位都与列表中第i个数\\(x_i\\)的第i位不同，通过这样的构造，y与列表中的每个数\\(x_i\\)至少在第i位上不同，也就是说前面的假设：我们可以将实数按序列排列成一个序列不成立，因为永远存在一个y不在列表中 这证明了\\([0,1)\\)的实数集合是不可数的 这种证明方法也叫做Cantor的Diagonal Process Real Number Set is Uncountable 实数集是不可数集 #\r通过一个Bijective Relationship $$f(x)=-cot(\\pi x)$$ 其Domain为\\((0,1)\\)，Range为\\(\\mathbb R\\)，即f为\\((0,1)和\\mathbb R\\)的一个Bijective Relationship 因此\\((0,1)\\) ~ \\(\\mathbb R\\) 已知\\((0,1)\\)是一个Uncountable Set，即证\\(\\mathbb R\\)也是Uncountable的 Continuum 连续统 #\r和Real Number Set等势的Set称为continuum 连续统 Continuum的Cardinality为\\(\\aleph_1\\) Continuum hypothesis 连续统假设 #\r1874 年 Cantor 提出猜想 : 不存在基数介于\\(ℵ_0\\)和\\(ℵ_1\\)的集合 . 这就是著名的连续统假设 ","date":"Dec 15 2024","externalUrl":null,"permalink":"/docs/mathematicalanalysis/ma2.realnumber/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 12/15/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eReal Number 实数 \r\n    \u003cdiv id=\"real-number-%E5%AE%9E%E6%95%B0\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#real-number-%E5%AE%9E%E6%95%B0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eRational Number 有理数 \r\n    \u003cdiv id=\"rational-number-%E6%9C%89%E7%90%86%E6%95%B0\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#rational-number-%E6%9C%89%E7%90%86%E6%95%B0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e整数，有限位小数，无限循环小数，分数\u003c/li\u003e\n\u003cli\u003e只要是能被表达为\n$$\\frac{p}{q},p,q\\in \\mathbb z,q\\neq 0$$\u003c/li\u003e\n\u003cli\u003e的数都叫做Rational Number\u003c/li\u003e\n\u003cli\u003e也就是说可以被任意两个Nature Number通过加减乘除所得到的数都被称为Rational Number（做除法的时候分母不能为零）\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eIrrational Number 无理数 \r\n    \u003cdiv id=\"irrational-number-%E6%97%A0%E7%90%86%E6%95%B0\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#irrational-number-%E6%97%A0%E7%90%86%E6%95%B0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\r\n\r\n\u003ch4 class=\"relative group\"\u003ePythagoras Theorem 毕达哥拉斯定理 \r\n    \u003cdiv id=\"pythagoras-theorem-%E6%AF%95%E8%BE%BE%E5%93%A5%E6%8B%89%E6%96%AF%E5%AE%9A%E7%90%86\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#pythagoras-theorem-%E6%AF%95%E8%BE%BE%E5%93%A5%E6%8B%89%E6%96%AF%E5%AE%9A%E7%90%86\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e在一个直角三角形中，直角边对面的斜边（最长边）的平方等于两个直角边的平方和\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eContradiction \r\n    \u003cdiv id=\"contradiction\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#contradiction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003e在当时并没有Irrational Number的定义，但是表示一个两个直角边长度为一的直角三角形的斜边的时候却出现了问题，即\\(1^2+1^2=x^2\\)，无法通过一个Rational Number，也就是两个Nature Number的任意四则运算求出这个x\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003eProof that sqrt 2 isn\u0026rsquo;t Rational Number \r\n    \u003cdiv id=\"proof-that-sqrt-2-isnt-rational-number\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#proof-that-sqrt-2-isnt-rational-number\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003eProof By Contradiction\u003c/li\u003e\n\u003cli\u003e假设\\(\\sqrt 2\\)是一个Rational Number，则有\\(2=(\\frac{p}{q})^2\\)，其中p和q是互素的\u003c/li\u003e\n\u003cli\u003e即\\(p^2=2q^2\\)，已知\\(2q^2\\)为一个Even Number，则等号另一边的\\(p\\)也必为一个Even Number（Odd Number的平方为Odd Number）\u003c/li\u003e\n\u003cli\u003e既然p是一个Even Number，则他可以被2整除，即\\(p^2\\)可以被4整除，同理可以得到\\(2|q^2\\)\u003c/li\u003e\n\u003cli\u003e那既然p和q都是偶数，很明显他们不可能互素，Contradict，故假设不成立\u003c/li\u003e\n\u003cli\u003e于是证明了Irrational Number的存在\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eDefine Real Number \r\n    \u003cdiv id=\"define-real-number\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#define-real-number\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e首先要知道的是，根号的本质是一个服务幂而创造出的代数运算，其能表达出的Irrational Number的个数几乎可以忽略不计\u003c/li\u003e\n\u003cli\u003e所以定义实数的第一步就是构造出所有Irrational Number，第二步则是定义全序列关系，第三步为定义代数运算，第四步研究拓扑结构（稠密性）\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eDedekind Cut \r\n    \u003cdiv id=\"dedekind-cut\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#dedekind-cut\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e设数集的一个划分\\({\\alpha,\\beta }\\)，其中\u003c/p\u003e","title":"MA 2. RealNumber","type":"docs"},{"content":"","date":"Nov 25 2024","externalUrl":null,"permalink":"/tags/chemistry/","section":"Tags","summary":"","title":"Chemistry","type":"tags"},{"content":"","date":"Nov 25 2024","externalUrl":null,"permalink":"/series/ecms/","section":"Series","summary":"","title":"ECMS","type":"series"},{"content":"","date":"Nov 25 2024","externalUrl":null,"permalink":"/tags/ecms/","section":"Tags","summary":"","title":"ECMS","type":"tags"},{"content":" Last Edit: 11/25/24\nThe finger of time #\r在上一章中讨论了Solide Crystalline Nacl的形成，我们知道它在室温和压力下是稳定的 同理当我们看到手机从人手上掉下来并不会感到惊讶 通过The Second Law Of Thermodynamics，我们可以意识到时间的流逝 The Second Law of Thermodynamics 热力学第二定律 #\rThe entropy of the Universe increases during any spontaneous process Spontaneous 自发的 #\rSpontaneous, here, means that the process proceeds on its own, without the need for an input of energy 代表了该过程自行进行，不需要能量输入 例如在空气中点燃一张纸，他将会燃烧，我面对如此现象并不会感到惊讶 Entropy 熵 #\r前面反复的介绍的Second Law的重要性，而Entropy的存在将定义如何使用它 熵是一个衡量系统混乱程度的物理量，系统的熵越高，系统的无序程度就越高 $$\\Delta S = \\frac{q_{REV}}{T}$$ S is the entropy 熵 \\(q_{rev}\\)​ is the heat transferred 传递的热量 T is the thermodynamic temperature 热力学温度，单位为Kelvin The Thermodynamic Alphabet 热力学字母表 #\rReversibility 可逆性 #\r对于rev的下标，这代表了Heat is transferred reversibly 但实际上Reversibility仅存在于Concept中，因为真实的物理过程总会有一些不可逆的因素，如摩擦，热损失等 System Surroundings and the Universe #\r周围的一切都被叫做Surroundings 而System和Surrounding一起构成了Universe 带回到The Second law of thermodynamic中，有 $$\\Delta S_{universe} = \\Delta S_{system} + \\Delta S_{surroundings} \u0026gt; 0$$ 所以唯一的判断Spontaneous的要求即为当Entropy change for universe must be positive The First Law of Thermodynamics 热力学第一定律 #\r在一个孤立系统中，能量既不能被创造也不能被消灭，能量只能从一种形式转换为另一种形式，或者从一个物体传递到另一个物体 $$ΔU=q+w$$ Internal Energy 内能 #\rInternal Energy是一个System的总能量，包括所有可能的能量形式，如动能、势能、化学能等 在听到内能的时候，可能会联想到Fuel, battery or a Quantity of Nuclear Fuel，但他们都不是完全的 对于一个System其中存在着无数种能影响内能的能量形式，这也使得研究System的Internal Energy的Absolute Value变得难以测定以至于不具有实际意义 所以所研究的Internal Energy更多的是一种Change of Energy 而Change，是建立在所谓的控制变量法 Potential Energy - Water Bottle #\r考虑上面的水平，要计算它的Internal Energy，我们会本能的选择一个Obvious Reference Surface从而计算瓶子相对于该平面的Potential Energy 同时，我们不需要考虑其动能或者是燃烧瓶子所释放的能量 这强调了在特定问题中选择关注特定类型能量的重要性 Similarly, in thermodynamics we\u0026rsquo;ll need to define a logical reference point to measure changes in energy Logical Reference Point - The Standard State #\r在热力学和化学中，需要一个清晰、一致的基准来测量能量变化。比如，当讨论燃烧汽油（主要成分为辛烷）所需的能量时，我们需要一个基准状态作为起点 这段话在讨论热力学和化学中如何选择一个参考点，称为“Standard State”，来测量和比较化学反应和能量变化 标准状态是在特定条件下（通常是25°C和105帕斯卡压力），一种纯元素的最稳定形式 State Functions and Path Functions 状态和路径函数 #\r再次考虑前面水瓶的例子 $$Water Bottle_{on table} → Water Bottle_{on high shelf}$$ State Function 状态函数 #\rIt does not depend on how we got to the final state, all that matters is what that state is 它不取决于我们如何达到最终状态，重要的是那个状态是什么 另一个例子为Temperature，你不需要查阅过去的温度来计算现在的，只需要测量当前温度便可以， 这就是一种State Function 庆幸的是Internal Energy只能是一种State Function，这意味着内能的变化仅取决于系统的初始状态和最终状态。无论系统是通过何种过程从初始状态转变到最终状态，内能的变化总量是固定的 Path Function 路径函数 #\r如果问题变成了，把水瓶从桌子上移到高架子上有多困难 做的工作取决 how you got there - it depends on the path Closed Versus Isolated Systems 封闭系统与孤立系统 #\r我们可以研究Boundaries开放且物质穿过它们的系统，但这不是我们现在需要考虑的 我们需要考虑systems where matter is not allowed to pass the boundaries的系统 Isolated System 隔离式系统 #\rNo heat is exchanged with the surroundings $$ΔU=q+w,q=w=0\\RightarrowΔU=0$$ Closed system 封闭系统 #\rHeat may pass the boundaries $$ΔU=q+w$$ - q is the heat transferring into the system w is the work done on the system Sign convention在这里很重要，heat in and work on are positive Enthalpy 焓 #\r焓（Enthalpy），符号为H，是热力学中的一个重要概念，用于描述系统在一定压力下的总热含量 焓是一个状态函数，它与系统的内能、压力和体积关系密切。焓的定义是 $$H=U+PV$$ 其中U是内能，P是压力，V是体积 Enthalpy in Solid 固体中的焓 #\r在固态物理过程中，物质的体积变化通常非常小，因此PV工作相对于内能U的变化可以忽略不计 所以在在固态物理领域，人们可能会将“Enthalpy”或“Enthalpy Change”与“Energy”或“Energy Change”这些术语互换使用 The Gibbs Energy 吉布斯自由能 #\r$$G=H−TS$$\nG：吉布斯能量 H：焓（系统的总能量，包括内能和体积功） T：温度（开尔文，K） S：熵（系统的无序程度） 这个定义说明吉布斯自由能考虑了系统的能量状态（Enthalpy）和无序度（Entropy） Spontaneity for a system 系统的自发性 #\r如果\\(\\Delta G \u0026lt; 0\\)：过程是自发的（有利于发生）。 如果\\(\\Delta G = 0\\)：系统达到平衡。 如果\\(\\Delta G \u0026gt; 0\\)：过程是非自发的（需要外界能量输入） 自发过程的基本条件是整个宇宙的熵（包括系统和环境的熵）总和需要增加，这是在前面的The Second Law of Thermodynamics中定义的 $$\\Delta S_{\\text{system}} + \\Delta S_{\\text{surroundings}} \u0026gt; 0$$ 在恒温下，周围环境的熵变是进入周围环境的热量除以温度 $$\\Delta S_{\\text{Surroundings}} = \\frac{q_{\\text{Surroundings}}}{T}$$ 离开系统的任何热量都与周围环境吸收的热量相同，或者相反，因此有 $$\\Delta S_{\\text{Surrounding}} = \\frac{-q_{\\text{System}}}{T}$$ 于是就可以推出Spontaneous的同时由Entropy和Enthalpy定义的公式变为 $$\\Delta H_{\\text{system}}-T \\Delta S_{\\text{system}} \u0026lt; 0$$ Phase Transformations #\r图中为对不同阶段的水加热后的变化 固态（冰）升温：在冰的温度低于 0°C 时，输入热量会使冰的温度上升。 熔化（0°C 平台）：温度停止上升，因为输入的热量用于冰的相变（熔化），这个热量叫做熔化焓（enthalpy of fusion）。 液态（水）升温：冰完全融化后，输入热量使液态水的温度上升，此时温度上升速率（曲线的斜率）与冰时不同。 汽化（100°C 平台）：在 100°C 时，热量再次用于相变（汽化），这一阶段输入的热量叫做汽化焓（enthalpy of vaporization）。 气态（蒸汽）升温：水完全汽化后，输入热量让蒸汽升温 在图中的斜率定义为 $$\\text{Slope} = \\frac{\\Delta T}{q} , \\left[ = \\frac{K}{\\frac{J}{\\text{mol}}} \\right] $$ $$q = \\frac{1}{\\text{Slope}} \\Delta T$$ \\(\\frac{1}{\\text{Slope}}\\)其还有一个名字叫做Molar Heat Capacity \\(C_P\\)，也就是Specific Heat Capacity比热容 Molar Hear Capacity 摩尔热容 #\r$$q = \\frac{1}{\\text{Slope}} \\Delta T = n C_P \\Delta T$$\nq：热量 n：物质的摩尔数 \\(C_P\\)​：摩尔热容 \\(\\Delta T\\)：温度变化 Specific Heat Capacity 比热容 #\r$$q=mcΔT$$\nm：物质质量 c：比热容 ","date":"Nov 25 2024","externalUrl":null,"permalink":"/docs/uoft/24/engineering-chemistry--materials-science/ecms8.thermodynamics/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/25/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eThe finger of time \r\n    \u003cdiv id=\"the-finger-of-time\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#the-finger-of-time\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e在上一章中讨论了Solide Crystalline Nacl的形成，我们知道它在室温和压力下是稳定的\u003c/li\u003e\n\u003cli\u003e同理当我们看到手机从人手上掉下来并不会感到惊讶\u003c/li\u003e\n\u003cli\u003e通过The Second Law Of Thermodynamics，我们可以意识到时间的流逝\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eThe Second Law of Thermodynamics 热力学第二定律 \r\n    \u003cdiv id=\"the-second-law-of-thermodynamics-%E7%83%AD%E5%8A%9B%E5%AD%A6%E7%AC%AC%E4%BA%8C%E5%AE%9A%E5%BE%8B\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#the-second-law-of-thermodynamics-%E7%83%AD%E5%8A%9B%E5%AD%A6%E7%AC%AC%E4%BA%8C%E5%AE%9A%E5%BE%8B\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eThe entropy of the Universe increases during any spontaneous process\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eSpontaneous 自发的 \r\n    \u003cdiv id=\"spontaneous-%E8%87%AA%E5%8F%91%E7%9A%84\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#spontaneous-%E8%87%AA%E5%8F%91%E7%9A%84\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eSpontaneous\u003c/em\u003e, here, means that the process proceeds on its own, without the need for an input of energy 代表了该过程自行进行，不需要能量输入\u003c/li\u003e\n\u003cli\u003e例如在空气中点燃一张纸，他将会燃烧，我面对如此现象并不会感到惊讶\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eEntropy 熵 \r\n    \u003cdiv id=\"entropy-%E7%86%B5\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#entropy-%E7%86%B5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e前面反复的介绍的Second Law的重要性，而Entropy的存在将定义如何使用它\u003c/li\u003e\n\u003cli\u003e熵是一个衡量系统混乱程度的物理量，系统的熵越高，系统的无序程度就越高\n$$\\Delta S = \\frac{q_{REV}}{T}$$\u003c/li\u003e\n\u003cli\u003eS is the entropy 熵\u003c/li\u003e\n\u003cli\u003e\\(q_{rev}\\)​ is the heat transferred 传递的热量\u003c/li\u003e\n\u003cli\u003eT is the \u003cem\u003ethermodynamic\u003c/em\u003e temperature 热力学温度，单位为Kelvin\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eThe Thermodynamic Alphabet 热力学字母表 \r\n    \u003cdiv id=\"the-thermodynamic-alphabet-%E7%83%AD%E5%8A%9B%E5%AD%A6%E5%AD%97%E6%AF%8D%E8%A1%A8\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#the-thermodynamic-alphabet-%E7%83%AD%E5%8A%9B%E5%AD%A6%E5%AD%97%E6%AF%8D%E8%A1%A8\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS8.Thermodynamics/ECMS8.Thermodynamics.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"ECMS 8. Thermodynamics","type":"docs"},{"content":"","date":"Nov 25 2024","externalUrl":null,"permalink":"/tags/la/","section":"Tags","summary":"","title":"LA","type":"tags"},{"content":" Last Edit: 11/25/24\nEigenvectors and Eigenvalues #\r考虑Linear Transformation为一种Function，输入x而输出\\(Ax\\) Eigenvector即对于指定的Vector x，其Ax平行于x，有 $$Ax=\\lambda x$$ 其中x为A的Eigenvector，\\(\\lambda\\)为A的Eigenvalue 特征向量的定义要求\\(x \\neq 0\\) Zero Eigenvalue #\r如果0为Matrix的Eigenvalue，则有 $$Ax=0x=0$$ Eigenvalue 0所对应的Vector Span出了Matrix的Null Space 如果矩阵A为不可逆矩阵，则0是其特征值之一 ex. Projection Matrix #\r对于Projection Matrix P，其Column Space中的任意Vector都会是一个Eigenvector ![[LA8.DiagonalizationandEigenvalues.png]]\n因为当其投影到Subspace的时候并没有改变 因此x为Eigenvector，并且Eigenvalue为1 同时对于Orthogonal于Subspace的Vector，有\\(Px=0\\)，则这个x也是Eigenvector，其Eigenvalue为0 ex. Permutation Matrix #\r$$A = \\begin{bmatrix} 0 \u0026 1 \\\\ 1 \u0026 0 \\end{bmatrix}$$\r对于置换矩阵存在Eigenvector \\(x=[1,1]^T\\)，Eigenvalue为1 另一个Eigenvalue为\\(x=[-1,1]^T\\)，对应Eigenvalue为-1，\\(Ax=-x\\) Trace 迹 #\r\\(n\\times n\\) 的Matrix存在n个Eigenvalue 并且它们的和，即为Trace，等于矩阵对角线上的元素之和 对于二阶矩阵，在已知一个特征值的条件下， 可以据此得到另一个特征值 Solve Ax = lambdax #\r对于\\(Ax=\\lambda x\\)存在两个未知数，下面讨论求解的办法 Rewrite等式为\\((A-\\lambda I)x=0\\) 如果系数矩阵\\(A - \\lambda I\\)是非奇异矩阵（行列式不为零），那么方程组只有Trivial Solution \\(x=0\\) 而如果系数矩阵\\(A - \\lambda I\\)是奇异矩阵（行列式为零），那么方程组可能有非零解\\(x \\neq 0\\) 于是可以推出\\(det(A-\\lambda I)=0\\) 在这个没有x的“特征方程”中，可以解得n个特征值，但是有可能方程有Repeated Root，则会得到重复的Eigenvalue 得到特征值之后，用消元法解\\(A-\\lambda I\\)，这一矩阵零空间中的向量为矩阵 A的特征向量 ex. #\r对于Matirx $$A= \\begin{bmatrix}3 \u0026 1 \\\\1 \u0026 3\\end{bmatrix}$$\r$$\\det (A-\\lambda I) = \\begin{vmatrix} 3-\\lambda \u0026 1 \\\\ 1 \u0026 3-\\lambda \\end{vmatrix} = (3-\\lambda)^2 - 1 = \\lambda^2 - 6\\lambda + 8$$\r在一元二次方程中，6为Trace，8为Determinant 于是可以总结对于二阶矩阵的Eigenvalue为该方程的解 $$\\lambda^2 - \\text{trace}(A) \\lambda + \\det A = 0$$\r对于上面的Matrix则有Eigenvalue = 4 \u0026amp; 2 $$A-4I = \\begin{bmatrix} -1 \u0026 1 \\\\ 1 \u0026 -1 \\end{bmatrix}, \\quad (A-4I)x_1 = 0, \\quad x_1 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$$\r$$A-2I = \\begin{bmatrix} 1 \u0026 1 \\\\ 1 \u0026 1 \\end{bmatrix}, \\quad (A-2I)x_2 = 0, \\quad x_2 = \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}$$\r与前面的例子\\(A=\\begin{bmatrix} 0 \u0026amp; 1 \\ 1 \u0026amp; 0 \\end{bmatrix}\\)的特征值和特征向量相对比，可知两者为一组平移矩阵 在对角元素上分别加3，改变了特征值但是没有改变特征向量 $$Ax = \\lambda x, \\quad \\text{则有} (A+3I)x = \\lambda x + 3x = (\\lambda + 3)x$$\r所以当两个Matrix有相同的Eigenvectors的时候，他们是可以“相加”的 当然其中一个为Identity Matrix的情况除外 Trace Equal to Eigenvalue Summation 矩阵的迹等于特征值之和 #\r将\\(det(A-\\lambda I)=0\\)展开会得到\\(\\lambda\\)的n 阶多项式，多项式的解就是矩阵 A 的特征值 根据多项式根与系数的关系，解之和即特征值之和等于\\(\\lambda^{n-1}\\)的系数 而行列式展开式中只有对角线的积这一项包含的\\(\\lambda^{n-1}\\)（其它项最高是n-2次方），而其系数为矩阵A对角线元素之和即矩阵A的Trace，因此特征值之和与矩阵的迹相等 Symmetry Matrix\u0026rsquo;s Eigenvector Orthogonal 对称矩阵的特征向量正交 #\r\\(\\lambda_1,\\lambda_2\\)是对称矩阵的两个不同的特征值，对应的特征向量分别为x1和x2。 $$\\text{则有 } A\\mathbf{x}_1 = \\lambda_1 \\mathbf{x}_1, \\text{ 左乘 } \\mathbf{x}_2^\\top \\text{ 得 } \\mathbf{x}_2^\\top A\\mathbf{x}_1 = \\lambda_1 \\mathbf{x}_2^\\top \\mathbf{x}_1$$\r$$\\mathbf{x}_2^\\top A\\mathbf{x}_1 = (\\mathbf{A}^\\top \\mathbf{x}_2)^\\top \\mathbf{x}_1 = \\lambda_2 \\mathbf{x}_2^\\top \\mathbf{x}_1。\\\\\r\\text{因此有 } (\\lambda_1 - \\lambda_2) \\mathbf{x}_2^\\top \\mathbf{x}_1 = 0$$\r而两特征值不等，所以两特征向量正交 Complex eigenvalues 复数特征值 #\r$$Q = \\begin{bmatrix} 0 \u0026 -1 \\\\ 1 \u0026 0 \\end{bmatrix} = \\begin{bmatrix} \\cos 90^\\circ \u0026 -\\sin 90^\\circ \\\\ \\sin 90^\\circ \u0026 \\cos 90^\\circ \\end{bmatrix}$$\rQ是一个是一个90度Rotation Matrix 从矩阵的Trace和Determinant的值可以得到\\(\\lambda_1+\\lambda_2=0,\\lambda_1\\lambda_2=1\\) 仅观察Matrix可以发现他的Eigenvector只能是Zero Vector，因为其他Vector乘以Rotation Matrix，其方向将会改变而，不可逆平行于原向量，通过原来的计算可得 $$\\det (Q - \\lambda I) = \\begin{vmatrix} -\\lambda \u0026 -1 \\\\ 1 \u0026 -\\lambda \\end{vmatrix} = \\lambda^2 + 1 = 0$$\r可以解得\\(\\lambda_1=i,\\lambda_2=-i\\) 如果一个矩阵具有复数特征值a+bi则，它的共轭复数a-bi也是矩阵的特征值 实数特征值让特征向量伸缩而虚数让其旋转 Antisymmetric matrices 反对称矩阵 #\r即满足\\(A^T=-A\\)的矩阵 对称矩阵永远具有实数的特征值，而，具有纯虚数的特征值 Triangular matrices and repeated eigenvalues 三角阵和重特征值 #\r对于一个Uppertriangular Matrix $$A = \\begin{bmatrix}3 \u0026 1 \\\\0 \u0026 3\\end{bmatrix}$$\r$$\\det (A - \\lambda I) = \\begin{vmatrix} 3-\\lambda \u0026 1 \\\\ 0 \u0026 3-\\lambda \\end{vmatrix} = (3-\\lambda)(3-\\lambda) = 0\r$$\r即\\(\\lambda_1=\\lambda_2=3\\) $$(A-\\lambda I)x = \\begin{bmatrix} 0 \u0026 1 \\\\ 0 \u0026 0 \\end{bmatrix}x = 0, \\quad \\text{得到} \\quad x_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$$\r其并没有没有线性无关的x2，说明A是一个退化矩阵，对应相同的特征值，而特征向量短缺 Diagonalization 对角化 #\r如果矩阵A具有n个线性无关的特征向量，将它们作为列向量可以组成一个可逆方阵S，并且有 $$AS = A \\begin{bmatrix} \\mathbf{x}_1 \u0026 \\mathbf{x}_2 \u0026 \\cdots \u0026 \\mathbf{x}_n \\end{bmatrix} = \\begin{bmatrix} \\lambda_1 \\mathbf{x}_1 \u0026 \\lambda_2 \\mathbf{x}_2 \u0026 \\cdots \u0026 \\lambda_n \\mathbf{x}_n \\end{bmatrix} = S \\begin{bmatrix} \\lambda_1 \u0026 0 \u0026 \\cdots \u0026 0 \\\\ 0 \u0026 \\lambda_2 \u0026 \\cdots \u0026 0 \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ 0 \u0026 0 \u0026 \\cdots \u0026 \\lambda_n \\end{bmatrix} = S D$$\r根据上式可写出\\(AS=SD\\Rightarrow S^{-1}AS=D\\)，这就叫Diagonalization 同理也有\\(A=SDS^{-1}\\) Power of A 矩阵的幂 #\r特征值给矩阵的幂计算提供了方法。 $$\\text{如果 } A\\mathbf{x} = \\lambda \\mathbf{x}, \\text{ 则有 } A^2\\mathbf{x} = \\lambda A\\mathbf{x} = \\lambda^2 \\mathbf{x}。$$\r这说明了Matrix \\(A\\)与\\(A^2\\)拥有相同的Eigenvector $$A^2 = S D S^{-1} S D S^{-1} = S D^2 S^{-1}$$\r同理可以推广到k-th power的情况，有\\(A^k = S D^k S^{-1}\\) 这说明\\(A^k\\)有着和A一样的特征向量，而特征值为\\(\\lambda^k\\) 如果矩阵A具有n个线性无关的特征向量，并且特征值均满足\\(|\\lambda_i|\u0026lt;1\\)，则k→∞时，Ak→0 Repeated eigenvalues 重特征值 #\r如果矩阵A没有重特征值，则其一定具有n个线性无关的特征向量 如果矩阵A有重特征值，它有可能具有n个线性无关的特征向量，也可能没有 Identity Matrix #\r比如单位阵的特征值为重特征值1，但是其具有n个线性无关的特征向量 UpperTriangular Matrix #\r参考上面的例子 对于一个Uppertriangular Matrix $$A = \\begin{bmatrix}3 \u0026 1 \\\\0 \u0026 3\\end{bmatrix}$$\r$$\\det (A - \\lambda I) = \\begin{vmatrix} 3-\\lambda \u0026 1 \\\\ 0 \u0026 3-\\lambda \\end{vmatrix} = (3-\\lambda)(3-\\lambda) = 0$$\r即\\(\\lambda_1=\\lambda_2=3\\) $$(A-\\lambda I)x = \\begin{bmatrix} 0 \u0026 1 \\\\ 0 \u0026 0 \\end{bmatrix}x = 0, \\quad \\text{得到} \\quad x_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$$\r其存在Repeated Eigenvalue所以可能没有n个Linearly Independent的Eigenvector Difference equations 差分方程 #\r差分方程描述了离散变量之间的递推关系 简单来说，差分方程是用来研究一系列离散点上的函数值之间的关系 从给定的一个向量\\(u_0\\)出发，我们可以通过对前一项乘以矩阵A得到下一项的方式，得到一个向量序列：\\(u_{k+1}=Au_k\\) 这里的\\(u_k+1=Au_k\\)可以是一个一阶差分方程，而\\(u_k=A^ku_0\\)就是方程的解 其可以写出Eigenvector的Linear Combination $$\\mathbf{u}_0 = c_1 \\mathbf{x}_1 + c_2 \\mathbf{x}_2 + \\cdots + c_n \\mathbf{x}_n = S\\mathbf{c}$$\r$$A\\mathbf{u}_0 = c_1 \\lambda_1 \\mathbf{x}_1 + c_2 \\lambda_2 \\mathbf{x}_2 + \\cdots + c_n \\lambda_n \\mathbf{x}_n$$\r$$\\mathbf{u}_k = A^k \\mathbf{u}_0 = c_1 \\lambda_1^k \\mathbf{x}_1 + c_2 \\lambda_2^k \\mathbf{x}_2 + \\cdots + c_n \\lambda_n^k \\mathbf{x}_n = D^k S\\mathbf{c}$$\rFibonacci sequence 斐波那契数列 #\r斐波那契数列为0,1,1,2,3,4,8,13……其通项公式为\\(F_{k+2}=F_{k+1}+F_k\\) 令 $$\\mathbf{u}_k = \\begin{bmatrix} F_{k+2} \\\\ F_{k+1} \\end{bmatrix}$$\r$$F_{k+2} = F_{k+1} + F_k, \\quad F_{k+1} = F_{k+1} \\\\ \\text{写成矩阵形式为 } \\mathbf{u}_{k+1} = \\begin{bmatrix} 1 \u0026 1 \\\\ 1 \u0026 0 \\end{bmatrix} \\mathbf{u}_k$$\r所以现在A就是\\(\\begin{bmatrix} 1 \u0026amp; 1 \\ 1 \u0026amp; 0 \\end{bmatrix}\\)，求解其Eigenvalues有 $$\\det(A - \\lambda I) = \\begin{vmatrix} 1-\\lambda \u0026 1 \\\\ 1 \u0026 -\\lambda \\end{vmatrix} = \\lambda^2 - \\lambda - 1 = 0$$\r\\(\\text{解得 } \\lambda_1 = \\frac{1 + \\sqrt{5}}{2}, \\quad \\lambda_2 = \\frac{1 - \\sqrt{5}}{2}\\)，且\\(\\mathbf{u}_k = A^k \\mathbf{u}_0 = c_1 \\lambda_1^k \\mathbf{x}_1 + c_2 \\lambda_2^k \\mathbf{x}_2\\) 由于\\(\\lambda_1\\)大于零，\\(\\lambda_2\\)小于零，则在k趋于无线的时候，\\(\\lambda_2^k\\)趋于零 从特征值可以求得对应的特征向量\\(\\mathbf{x}_1 = \\begin{bmatrix} \\lambda_1 \\ 1 \\end{bmatrix} \\text{ 的和 } \\mathbf{x}_2 = \\begin{bmatrix} \\lambda_2 \\ 1 \\end{bmatrix}\\) 在因为是二阶方程，而且矩阵\\(A - \\lambda I\\)是奇异矩阵，所以只要符合其中一个方程即可，立刻可以看出\\(\\begin{bmatrix} \\lambda_1 \\ 1 \\end{bmatrix}\\)是解\n$$\\text{从 } \\mathbf{u}_0 = \\begin{bmatrix} F_1 \\\\ F_0 \\end{bmatrix} = c_1 \\mathbf{x}_1 + c_2 \\mathbf{x}_2, \\text{ 可以求得 } c_1 = -c_2 = \\frac{1}{\\sqrt{5}}$$$$\r\\begin{bmatrix} F_{100} \\\\ F_{99} \\end{bmatrix} = A^{99} \\begin{bmatrix} F_1 \\\\ F_0 \\end{bmatrix} = \\begin{bmatrix} \\lambda_1 \u0026 \\lambda_2 \\\\ 1 \u0026 1 \\end{bmatrix} \\begin{bmatrix} \\lambda_1^{99} \u0026 0 \\\\ 0 \u0026 \\lambda_2^{99} \\end{bmatrix} \\begin{bmatrix} c_1 \\\\ c_2 \\end{bmatrix} =\r\\begin{bmatrix} c_1 \\lambda_1^{100} + c_2 \\lambda_2^{100} \\\\ c_1 \\lambda_1^{99} + c_2 \\lambda_2^{99} \\end{bmatrix}. \\\\\r\\text{可知 } F_{100} \\approx c_1 \\lambda_1^{100}.\r$$\r","date":"Nov 25 2024","externalUrl":null,"permalink":"/docs/uoft/24/linearalgebra/la8.diagonalizationandeigenvalues/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/25/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eEigenvectors and Eigenvalues \r\n    \u003cdiv id=\"eigenvectors-and-eigenvalues\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#eigenvectors-and-eigenvalues\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e考虑Linear Transformation为一种Function，输入x而输出\\(Ax\\)\u003c/li\u003e\n\u003cli\u003eEigenvector即对于指定的Vector x，其Ax平行于x，有\n$$Ax=\\lambda x$$\u003c/li\u003e\n\u003cli\u003e其中x为A的Eigenvector，\\(\\lambda\\)为A的Eigenvalue\u003c/li\u003e\n\u003cli\u003e特征向量的定义要求\\(x \\neq 0\\)\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eZero Eigenvalue \r\n    \u003cdiv id=\"zero-eigenvalue\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#zero-eigenvalue\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e如果0为Matrix的Eigenvalue，则有\n$$Ax=0x=0$$\u003c/li\u003e\n\u003cli\u003eEigenvalue 0所对应的Vector Span出了Matrix的Null Space\u003c/li\u003e\n\u003cli\u003e如果矩阵A为不可逆矩阵，则0是其特征值之一\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eex. Projection Matrix \r\n    \u003cdiv id=\"ex-projection-matrix\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#ex-projection-matrix\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于Projection Matrix P，其Column Space中的任意Vector都会是一个Eigenvector\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e![[LA8.DiagonalizationandEigenvalues.png]]\u003c/p\u003e","title":"LA 8. Diagonalization and Eigenvalues","type":"docs"},{"content":"","date":"Nov 25 2024","externalUrl":null,"permalink":"/docs/uoft/24/linearalgebra/","section":"Docs","summary":"","title":"Linear Algebra","type":"docs"},{"content":" Last Edit 11/21/2024\n正交向量Orthogonal vectors #\r正交就是垂直（perpendicular）的另一种说法 两向量正交的判据之一是其点 积\\(x^Ty=y^Tx\\)=0 当两个向量的夹角为90度时，按照勾股定理（毕达哥拉斯定理 Pythagorean theorem）x，y满足 $$\\|\\mathbf{x}\\|^2 + \\|\\mathbf{y}\\|^2 = \\|\\mathbf{x} + \\mathbf{y}\\|^2 ,||\\mathbf{x}\\|^2 = \\mathbf{x}^T \\mathbf{x}$$\r零向量与所有向量都正交 Orthogonal Subspaces 正交子空间 #\r图中绘制空间成90度角，这是表示这两个空间正交 子空间S与子空间T正交，则S中的任意一个向量都和T中的任意向量正交 Nullspace is perpendicular to row space 零空间与行空间正交 #\r矩阵A的行空间和它的零空间正交。若x在零空间内，则有Ax=0 $$\\begin{bmatrix}\r\\text{row}_1 \\\\\r\\text{row}_2 \\\\\r\\vdots \\\\\r\\text{row}_m\r\\end{bmatrix} \\times \\mathbf{x} = \\begin{bmatrix}\r\\text{row}_1 \\cdot \\mathbf{x} \\\\\r\\text{row}_2 \\cdot \\mathbf{x} \\\\\r\\vdots \\\\\r\\text{row}_m \\cdot \\mathbf{x}\r\\end{bmatrix} = \\begin{bmatrix}\r0 \\\\\r0 \\\\\r\\vdots \\\\\r0\r\\end{bmatrix}\r$$\rx与矩阵A的行向量点积都等于0，则它和矩阵A行向量的线性组合进行点积也为0，所以x与A的行空间正交 同理可以证明列空间与左零空间正交 Orthogonal complements 正交补 #\r行空间和零空间不仅仅是正交，并且其维数之和等于n，我们称行空间和零空间为\\(R^n\\)空间内的正交补 Orthogonal complements Orthonormal #\r如果矩阵的列向量是互相垂直的单位向量，则它们一定是线性无关的 我们将这种向量称之为标准正交（orthonormal） $$例如\\begin{bmatrix}\r1 \\\\\r0 \\\\\r0 \\end{bmatrix}\r,\r\\begin{bmatrix}\r0 \\\\\r1\\\\\r0 \\end{bmatrix},\r\\begin{bmatrix}\r0 \\\\\r0 \\\\\r1 \\end{bmatrix}\r还有\r\\begin{bmatrix}\r\\cos \\theta \\\\\r\\sin \\theta\r\\end{bmatrix}\r,\r\\begin{bmatrix}\r\\cos \\theta \\\\\r\\sin \\theta\r\\end{bmatrix}$$\r## Orthonormal Vectors 标准正交向量\r$$q_i^T q_j = \\begin{cases} 0 \u0026 \\text{若 } i \\neq j \\\\\r1 \u0026 \\text{若 } i = j \\end{cases}$$\r指的是单位长度为1的（Unit Vector） ATA #\r下面讨论如何求解一个无解方程组Ax=b的解 它是一个\\(n\\times n\\)方阵，并且是对称阵\\((A^TA)^T=(A^TA)\\) 本章的核心内容就是当Ax=b无解的时候，求解\\(A^TAx\\)=\\(A^Tb\\)得到最优解 $$例：A = \\begin{bmatrix} 1 \u0026 1 \\\\ 1 \u0026 2 \\\\ 1 \u0026 5 \\end{bmatrix}, \\quad \\text{则} \\ A^T A = \\begin{bmatrix} 1 \u0026 1 \u0026 1 \\\\ 1 \u0026 2 \u0026 5 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 1 \\\\ 1 \u0026 2 \\\\ 1 \u0026 5 \\end{bmatrix} = \\begin{bmatrix} 3 \u0026 8 \\\\ 8 \u0026 30 \\end{bmatrix} \\text{是可逆的矩阵。}\r$$\r但是矩阵\\(A^TA\\)并不总是可逆 $$例：A = \\begin{bmatrix} 1 \u0026 3 \\\\ 1 \u0026 3 \\\\ 1 \u0026 3 \\end{bmatrix}, \\quad \\text{则} \\ A^T A = \\begin{bmatrix} 1 \u0026 1 \u0026 1 \\\\ 3 \u0026 3 \u0026 3 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 3 \\\\ 1 \u0026 3 \\\\ 1 \u0026 3 \\end{bmatrix} = \\begin{bmatrix} 3 \u0026 9 \\\\ 9 \u0026 27 \\end{bmatrix} \\text{是不可逆矩阵。}\r$$\rProjections in 2D 2D中的投影 #\r投影的几何解释便是：在向量a的方向上寻找与向量b距离最近的一 点 这个距离最近的点p就位于穿过b点并与向量a正交的直线 与向量a所在直线的交点上 则p就是b在a上的投影 如果我们将向量p视为b 的一种近似，则长度e=b-p就是这一近似的误差 于是便有方程\\(a^T(b-xa)=0\\) 因为向量a和b是列向量，在计算它们的点积（即内积）时，通常需要将其中一个向量转置成行向量，这样才能进行矩阵乘法并得到标量\n解得 $$\\begin{equation}\rx = \\frac{\\mathbf{a}^T \\mathbf{b}}{\\mathbf{a}^T \\mathbf{a}}, \\quad p = a x = \\mathbf{a} \\frac{\\mathbf{a}^T \\mathbf{b}}{\\mathbf{a}^T \\mathbf{a}}.\r\\end{equation}\r$$\r如果方程的自变量发生改变，p的改变量 如果b变为原来的2倍，则p也变为原来的2倍 而如果a变为原来的2倍， p不发生变化 （从几何角度考虑也很合理） Projection Matrix in 2D #\r$$proj_p=Pb$$\r其中P为投影矩阵 $$\\begin{equation}\rp = a x = a \\frac{\\mathbf{a}^T \\mathbf{b}}{\\mathbf{a}^T \\mathbf{a}}. \\quad \\text{则有} \\quad P = \\frac{\\mathbf{a} \\mathbf{a}^T}{\\mathbf{a}^T \\mathbf{a}}.\r\\end{equation}\r$$\r其分子\\(aa^T\\)是一个矩阵，而分母\\(a^Ta\\)是一个数 观察这个矩阵可知，矩阵P的列空间就是向量a所在的直线 矩阵的秩是1 (直线) Property of projection 投影的性质 #\rSymmetry 对称性 #\r对P做一次转置，其还是P 则P是对称矩阵 Apply Twice #\r如果做两次投影则有P2b=Pb，这是因为 第二次投影还在原来的位置。 因此矩阵P有如下性质：\\(P^T=P,P^2=P\\) Closest vector 最短向量 #\r方程Ax=b有可能无解 当出现比Unknown更多的Equations的时候，只能求解最优解 Ax一定在矩阵A的列空间之内，但是b不一定， p是b在Colunm Space上的Projection，所以其是最优解 将问题转化为求解\\(A\\hat x=p\\) Closest Vector Theorem #\rSuppose V is a subspace of Rn and \\(\\vec x ∈ R^n\\). The closest vector in V to \\(\\vec x\\) is given by \\(ProjV (\\vec x )\\) In other words, \\(|\\text{Proj}_V(\\vec{x}) - \\vec{x}| \\leq |\\vec{v} - \\vec{x}|~\\text{for any } \\vec{v} \\in V\\) 投影的方向到向量上最短的点就是其在改方向上的投影到向量的距离\nProof #\r$$\\|\\vec{v} - \\vec{x}\\|^2 = \\|\\vec{v} + \\text{Proj}_V(\\vec{x}) - \\text{Proj}_V(\\vec{x}) - \\vec{x}\\|^2 \\\\\r= \\|\\vec{v} - \\text{Proj}_V(\\vec{x}) + \\text{Proj}_V(\\vec{x}) - \\vec{x}\\|^2$$\r$$\\|\\vec{v} - \\vec{x}\\|^2 = \\|\\vec{v} - \\vec{x}^\\parallel + \\vec{x}^\\parallel - \\vec{x}\\|^2 \\\\\r= \\|\\vec{v} - \\vec{x}^\\parallel - \\vec{x}^\\perp\\|^2$$\r$$\\|\\vec{v} - \\vec{x}\\|^2 = \\|\\vec{v} - \\vec{x}^\\parallel\\|^2 + \\|-\\vec{x}^\\perp\\|^2 \\\\\r= \\|\\vec{v} - \\vec{x}^\\parallel\\|^2 + \\|\\vec{x}^\\perp\\|^2$$\r可以发现\\(|\\vec{v} - \\vec{x}|^2\\)最小的值出现在\\(\\vec{v} = \\vec{x}^\\parallel\\)的时候 Orthogonal projection 正交投影 #\r注意Orthogonal Projection和Orthogonal Linear Transformation是完全不同的东西 之所以叫Orthogonal Projection指的是这个Projection就是最一般的情况，就是一般所理解的正交于一个Subspace的投影\n在上面的\\(P = A (A^T A)^{-1} A^T\\)中，之所以不拆成\\(P=AA^{-1}(A^T)^{-1}A^T=I\\)，是因为A并不是Square Matrix，即不存在Inverse 当A为Square Matrix的时候，即m=n，Input dim = Output dim，这个Projection也就变成了Identity Matrix，即将自身Project Into自己的空间 但是即使是Projecct到自己的Space，其中仍会包含Linear Transformation Orthogonal Projection Formula 正交投影公式 #\r正交投影公式是通过公式计算一个正交的投影向量在目标子空间的投影，和Orthogonal Linear Transformation无关\n对于一组Orthogonal的Basis，将Vector投影到改Space的公式为 $$\\text{Proj}_V(\\vec{x}) = \\vec{u}_1 (\\vec{u}_1 \\cdot \\vec{x}) + \\vec{u}_2 (\\vec{u}_2 \\cdot \\vec{x})$$\r举例来说，对于一组Orthonormal Vector $$u = {\\begin{bmatrix}\\frac{1}{\\sqrt{2}} \\0 \\\\frac{1}{\\sqrt{2}}\\end{bmatrix},\\begin{bmatrix}-\\frac{1}{\\sqrt{2}} \\0 \\\\frac{1}{\\sqrt{2}}\\end{bmatrix}$$ \\([2,2,2]^T\\)的Projection为 $$\\begin{align*}\r\u0026= \\begin{bmatrix}\r\\frac{1}{\\sqrt{2}} \\\\\r0 \\\\\r\\frac{1}{\\sqrt{2}}\r\\end{bmatrix}\r\\left( \\begin{bmatrix}\r\\frac{1}{\\sqrt{2}} \\\\\r0 \\\\\r\\frac{1}{\\sqrt{2}}\r\\end{bmatrix} \\cdot\r\\begin{bmatrix}\r\\sqrt{2} \\\\\r0 \\\\\r\\sqrt{2}\r\\end{bmatrix} \\right)\r+\r\\begin{bmatrix}\r-\\frac{1}{\\sqrt{2}} \\\\\r0 \\\\\r\\frac{1}{\\sqrt{2}}\r\\end{bmatrix}\r\\left( \\begin{bmatrix}\r-\\frac{1}{\\sqrt{2}} \\\\\r0 \\\\\r\\frac{1}{\\sqrt{2}}\r\\end{bmatrix} \\cdot\r\\begin{bmatrix}\r\\sqrt{2} \\\\\r0 \\\\\r\\sqrt{2}\r\\end{bmatrix} \\right) \\\\\r\u0026= 2 \\begin{bmatrix}\r\\frac{1}{\\sqrt{2}} \\\\\r0 \\\\\r\\frac{1}{\\sqrt{2}}\r\\end{bmatrix}\r=\r\\begin{bmatrix}\r\\sqrt{2} \\\\\r0 \\\\\r\\sqrt{2}\r\\end{bmatrix}\r\\end{align*}$$\rProjection Matrix 正交投影矩阵 #\r正交投影矩阵，将向量正交投影到Subspace上的一个矩阵，A可以是任意矩阵，不是非得是Orthogonal Matrix，其和正交投影公式干的是一样的事，不过用了不同的表达方式\n在\\(R^3\\)空间内，如何将向量b投影到它距离平面最近的一点p？ 如果a1和a2构成了平面的一组基，则平面就是矩阵\\(A=[a1,a2]\\)的列空间 \\(e=b-p\\)是垂直于平面的 已知p在平面内，于是有\\(p=\\hat x_1a_1+\\hat x_2a_2=A\\hat x\\) 而\\(e=b-p=b- A\\hat x\\)正交于平面，因此e与\\(a_1\\),\\(a_2\\)均正交 因此可以得到：\\(a_1^T(b-A\\hat x )=0\\)并且\\(a_2^T(b-A\\hat x )=0\\) 因为a1和a2分别为矩阵A的列向量，即\\(a1^T\\)和\\(a2^T\\)为矩阵\\(A^T\\)的行向量 \\(A^T(b-A\\hat x)=0\\) 由于\\(b-A\\hat x\\)在于矩阵AT的零空间\\(N(A^T)\\)里，从上一讲讨论子空间的正交性可知，向量e与矩阵A的列空间正交，这也正是方程的意义 $$\\begin{align}\r\\hat{x} \u0026= (A^T A)^{-1} A^T b \\\\\rp \u0026= A \\hat{x} = A (A^T A)^{-1} A^T b \\\\\rP \u0026= A (A^T A)^{-1} A^T=\\frac{AA^T}{A^TA}\r\\end{align}$$\r注意区别大小写P\n对于上面的等式在dim = 1中则是\\(\\frac{\\mathbf{a} \\mathbf{a}^T}{\\mathbf{a}^T \\mathbf{a}}\\) 投影矩阵\\(P=A(A^TA)^{-1}A^T\\)，当它作用于向量b，相当于把b投影到矩阵A的列空间 Case when b is in column Space A #\r当b已经在A的列空间之中，有\\(Ax=b\\) $$\\begin{align*}\r\\mathbf{Pb} \u0026= \\mathbf{A}(\\mathbf{A}^\\top \\mathbf{A})^{-1} \\mathbf{A}^\\top \\mathbf{b} \\\\\r\u0026= \\mathbf{A}(\\mathbf{A}^\\top \\mathbf{A})^{-1} \\mathbf{A}^\\top \\mathbf{Ax} \\\\\r\u0026= \\mathbf{A}((\\mathbf{A}^\\top \\mathbf{A})^{-1} \\mathbf{A}^\\top \\mathbf{A}) \\mathbf{x} \\\\\r\u0026= \\mathbf{Ax} = \\mathbf{b}\r\\end{align*}$$\rCase when b orthorgal to column Space A #\r如果向量b与A的列空间正交，即向量b在矩阵A的左零空间N(A)中 在Left Null Space的意义在于\\(A^Tb=0\\)，所以\\(Pb=0\\) $$\\mathbf{Pb} = \\mathbf{A}(\\mathbf{A}^\\top \\mathbf{A})^{-1} \\mathbf{A}^\\top \\mathbf{b} = \\mathbf{A}(\\mathbf{A}^\\top \\mathbf{A})^{-1} (\\mathbf{A}^\\top \\mathbf{b}) = \\mathbf{A}(\\mathbf{A}^\\top \\mathbf{A})^{-1} 0 = 0$$\rI−P 的效果: I - P 则是从向量x中移除其在A的列空间上的分量，留下的部分即为x在A的列空间的正交补上的分量 这表明I - P将向量x投影到A的列空间的正交补空间上 Orthogonal Projection Matrix in Orthogonal Basis 矩阵为正交矩阵的正交投影矩阵 #\r正交矩阵的正交投影矩阵的正确读法是，当正交投影矩阵的矩阵为正交矩阵的情况下的正交投影，即改投影矩阵的A为Q的情况下，改投影将不体现“投影”的作用，而是在原空间中做Orthogonal Linear Transformation\nOrthogonal Projection Matrix必须是Square Matrix $$\\mathbf{P} = \\mathbf{Q} (\\mathbf{Q}^\\top \\mathbf{Q})^{-1} \\mathbf{Q}^\\top$$\r- 因为\\\\(Q^TQ=I\\Rightarrow P=QQ^T\\\\)\r如果Q为Square Matrix，则是一个投影到自身空间的Matrix，即\\(P=I\\)，因为Q的列向量张成了整个空间，投影过程不会对向量有任何改变 就上面的例子来说，其Projection在用了Matrix后可以得到 Orthogonal Matrix 正交矩阵 #\r注意这里定义的不再是投影了，而是前面提到的矩阵为正交矩阵的正交投影矩阵，是一个东西\nOrthogonal Matrix 正交矩阵 #\rConsider an n × n matrix A The matrix A is orthogonal if and only if \\(A^TA = I\\) or, equivalently, if \\(A^{−1} = A^T\\) Orthogonal Matrix的Column Vector需要Norm = 1 $$\\mathbf{Q} = \\begin{bmatrix} 0 \u0026 0 \u0026 1 \\\\ 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \\end{bmatrix}, \\quad\r\\text{则有 } \\mathbf{Q}^\\top = \\begin{bmatrix} 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\\\ 1 \u0026 0 \u0026 0 \\end{bmatrix}\r$$\r再比如\\(\\begin{bmatrix} 1 \u0026amp; 1 \\ 1 \u0026amp; -1 \\end{bmatrix} \\text{ 并不是正交矩阵}.\\) 因为其Norm为2，\\(\\mathbf{Q} = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \u0026amp; 1 \\ 1 \u0026amp; -1 \\end{bmatrix}\\)，调整后便可以了 一个例子便是Rotation Matrix $$T(\\vec{x}) = \\begin{bmatrix}\r\\cos(\\theta) \u0026 -\\sin(\\theta) \\\\\r\\sin(\\theta) \u0026 \\cos(\\theta)\r\\end{bmatrix} \\vec{x}$$\r对于Orthogonal Matrix来说，\\(Q^TQ=I\\) $$\\mathbf{Q} = \\begin{bmatrix} \\mathbf{q}_1 \u0026 \\cdots \u0026 \\mathbf{q}_n \\end{bmatrix}, \\quad \\mathbf{Q}^\\top \\mathbf{Q} = \\begin{bmatrix} \\mathbf{q}_1^\\top \\\\ \\vdots \\\\ \\mathbf{q}_n^\\top \\end{bmatrix} \\begin{bmatrix} \\mathbf{q}_1 \u0026 \\cdots \u0026 \\mathbf{q}_n \\end{bmatrix} = \\mathbf{I}$$\rOrthogonal transformations preserve orthogonality 角度不变性 #\rOrthogonal linear transformations不仅保持向量的长度，也保持向量间的角度和orthogonality 正交性 变换前后角度不变的变换是Orthogonal transformation\nProof #\r根据Pythoarorian Theorm $$||\\vec x^2+\\vec y^2||=||\\vec x^2||+||\\vec y^2||$$\r需要证明\\(|T(\\vec{v}) + T(\\vec{w})|^2 = |T(\\vec{v})|^2 + |T(\\vec{w})|^2\\) 对于两个Orthogonal Vector \\(\\vec v ~\u0026amp; ~\\vec w\\)，T是Linear Transformation，有 $$\\|T(\\vec{v}) + T(\\vec{w})\\|^2 = \\|T(\\vec{v} + \\vec{w})\\|^2$$\r由于Orthogonal Linear Transformation preserves the norm of vector $$\\|T(\\vec{v} + \\vec{w})\\|^2=||\\vec v+\\vec w||^2$$\r根据Pythoarorian Theorm $$||\\vec v+\\vec w||^2=||\\vec v^2||+||\\vec w||^2$$\r同理 $$||\\vec v^2||+||\\vec w||^2= \\|T(\\vec{v})\\|^2 + \\|T(\\vec{w})\\|^2$$\rOrthogonal linear transformations preserves dot product 点积不变性 #\rT : \\(\\mathbb{R}^n \\to \\mathbb{R}^n\\) is an orthogonal transformation if and only if $$ T(\\vec{v}) \\cdot T(\\vec{w}) = \\vec{v} \\cdot \\vec{w} \\text{ for all } \\vec{v}, \\vec{w} \\in \\mathbb{R}^n$$\rif \\(\\vec{u}\\) and \\(\\vec{v}\\) are orthogonal, then \\(T(\\vec{u})\\) and \\(T(\\vec{v})\\) are also orthogonal 变换前后dot product不变的变换就是Orthogonal Transformation\nProof #\rT : \\(R^n → R^n\\) is an orthogonal linear transformation $$T(\\vec{u}) \\cdot T(\\vec{v}) = (u_1 T(\\vec{e}_1) + \\dots + u_n T(\\vec{e}_n)) \\cdot (v_1 T(\\vec{e}_1) + \\dots + v_n T(\\vec{e}_n))$$\r根据\\(q_i^T q_j = \\begin{cases} 0 \u0026amp; \\text{若 } i \\neq j \\1 \u0026amp; \\text{若 } i = j \\end{cases}\\) $$T(\\vec{u}) \\cdot T(\\vec{v}) = u_1 v_1 T(\\vec{e}_1) \\cdot T(\\vec{e}_1) + \\ldots + u_n v_n T(\\vec{e}_n) \\cdot T(\\vec{e}_n)$$\r$$= u_1 v_1 \\|T(\\vec{e}_1)\\|^2 + \\ldots + u_n v_n \\|T(\\vec{e}_n)\\|^2 \\\\\r= u_1 v_1 + \\ldots + u_n v_n = \\vec{u} \\cdot \\vec{v}$$\rConverse statement of orthogonal linear transformation 逆命题的成立 #\rif a linear map preserves orthonormality, it should preserve length and hence is an orthogonal map Orthogonal transformations and orthonormal bases 正交基底保证正交变换 #\rA linear transformation T : \\(R^n → R^n\\) is an orthogonal transformation if and only if the vectors \\(T (\\vec e_1), T(\\vec e_2), . . . , T (\\vec e_n)\\) form an orthonormal basis for \\(R^n\\) 当Column Space为Orthogonal Vector的时候，Matrix为Orthogonal Transformation\nProof #\r$$\\|T(\\vec{x})\\|^2 = \\|T(x_1 \\vec{e}_1 + x_2 \\vec{e}_2 + x_3 \\vec{e}_3)\\|^2$$\r$$=\\|T(x_1 \\vec{e}_1) + T(x_2 \\vec{e}_2) + T(x_3 \\vec{e}_3)\\|^2 \\quad (\\text{by linearity of } T)$$\r$$= \\|T(x_1 \\vec{e}_1)\\|^2 + \\|T(x_2 \\vec{e}_2)\\|^2 + \\|T(x_3 \\vec{e}_3)\\|^2 \\quad (\\text{by Pythagoras})$$\r$$= x_1^2 \\|T(\\vec{e}_1)\\|^2 + x_2^2 \\|T(\\vec{e}_2)\\|^2 + x_3^2 \\|T(\\vec{e}_3)\\|^2 \\quad (\\text{by linearity of } T)$$\r$$= x_1^2 + x_2^2 + x_3^2 =||\\vec x||^2~(\\text{since columns are length } 1)$$\r$$\\mathbf{Q} = \\frac{1}{3} \\begin{bmatrix} 1 \u0026 -2\\\\ 2 \u0026 -1 \\\\ 2 \u0026 2\r\\end{bmatrix}, \\text{ 我们可以拓展其成为正交矩阵 } \\frac{1}{3} \\begin{bmatrix} 1 \u0026 -2 \u0026 2 \\\\ 2 \u0026 -1 \u0026 -2 \\\\ 2 \u0026 2 \u0026 1 \\end{bmatrix}$$\rHadamard Matrix #\r$$\\mathbf{Q} = \\frac{1}{2} \\begin{bmatrix} 1 \u0026 1 \u0026 1 \u0026 1 \\\\ 1 \u0026 -1 \u0026 1 \u0026 -1 \\\\ 1 \u0026 1 \u0026 -1 \u0026 -1 \\\\ 1 \u0026 -1 \u0026 -1 \u0026 1 \\end{bmatrix}$$\r仅包含-1和1的Orthogonal Matrix $$\\text{Proj}_V(\\vec{x}) = Q Q^T \\vec{x} =\r\\begin{bmatrix}\r\\frac{1}{\\sqrt{2}} \u0026 -\\frac{1}{\\sqrt{2}} \\\\\r0 \u0026 0 \\\\\r\\frac{1}{\\sqrt{2}} \u0026 \\frac{1}{\\sqrt{2}}\r\\end{bmatrix}\r\\begin{bmatrix}\r\\frac{1}{\\sqrt{2}} \u0026 0 \u0026 \\frac{1}{\\sqrt{2}} \\\\\r-\\frac{1}{\\sqrt{2}} \u0026 0 \u0026 \\frac{1}{\\sqrt{2}}\r\\end{bmatrix}\r\\begin{bmatrix}\r\\sqrt{2} \\\\\r\\sqrt{2} \\\\\r\\sqrt{2}\r\\end{bmatrix}\r=\r\\begin{bmatrix}\r1 \u0026 0 \u0026 0 \\\\\r0 \u0026 0 \u0026 0 \\\\\r1 \u0026 0 \u0026 0\r\\end{bmatrix}\r\\begin{bmatrix}\r\\sqrt{2} \\\\\r\\sqrt{2} \\\\\r\\sqrt{2}\r\\end{bmatrix}\r=\r\\begin{bmatrix}\r\\sqrt{2} \\\\\r0 \\\\\r\\sqrt{2}\r\\end{bmatrix}\r$$\rGram-Schmidt 施密特正交化 #\r一般来说，要获得Orthogonal Matrix，先要做一步化简到该形式，这一步的名字就 Gram-Schmidt 从两个线性无关的向量a和b开始，它们张成了一个空间 我们的目标是找到两个标准正交的向量q1，q2能张成同样的空间 Schmidt给出的结论是如果 我们有一组正交基A和B，那么我们令它们除以自己的长度就得到标准正交基 $$\\mathbf{q}_1 = \\frac{\\mathbf{A}}{\\|\\mathbf{A}\\|}, \\quad \\mathbf{q}_1 = \\frac{\\mathbf{A}}{\\|\\mathbf{A}\\|}\r$$\r当确认了一个方向后，要求出orthogonal于改方向的Vector则就是将b投影到a的方向，取B=b-p（e） $$\\mathbf{B} = \\mathbf{b} - \\frac{\\mathbf{A}^\\top \\mathbf{b}}{\\mathbf{A}^\\top \\mathbf{A}} \\mathbf{A}$$\r通过两边乘上\\(A^T\\)证明其Orthogonal性质 $$A^T\\mathbf{B} = A^T(\\mathbf{b} - \\frac{\\mathbf{A}^\\top \\mathbf{b}}{\\mathbf{A}^\\top \\mathbf{A}} \\mathbf{A})=0$$\rThird Vector #\r同理，由ABC三个Vector为 $$\\mathbf{q}_1 = \\frac{\\mathbf{A}}{\\|\\mathbf{A}\\|}, \\quad \\mathbf{q}_1 = \\frac{\\mathbf{A}}{\\|\\mathbf{A}\\|}\\quad \\mathbf{q}_3 = \\frac{\\mathbf{C}}{\\|\\mathbf{C}\\|}$$\r$$\\mathbf{C} = \\mathbf{c} - \\frac{\\mathbf{A}^\\top \\mathbf{c}}{\\mathbf{A}^\\top \\mathbf{A}} \\mathbf{A} - \\frac{\\mathbf{B}^\\top \\mathbf{c}}{\\mathbf{B}^\\top \\mathbf{B}} \\mathbf{B}\r$$\rex. Two Vectors #\r$$\\mathbf{a} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}, \\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix}, \\quad \\text{则有 } \\mathbf{A} = \\mathbf{a}, \\quad \\mathbf{B} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\end{bmatrix} - \\frac{3}{3} \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ -1 \\\\ 1 \\end{bmatrix}$$\r- 则有Orthonormal Matrix Q\r$$\\mathbf{Q} = \\begin{bmatrix} \\mathbf{q}_1 \u0026 \\mathbf{q}_2 \\end{bmatrix} = \\begin{bmatrix} 1 / \\sqrt{3} \u0026 0 \\\\ 1 / \\sqrt{3} \u0026 -1 / \\sqrt{2} \\\\ 1 / \\sqrt{3} \u0026 1 / \\sqrt{2} \\end{bmatrix}$$\rLeast Squares 最小二乘 #\rFitting a line，拟合曲线 假设有三个数据点{(1,1), (2,2), (3,2)} 假设直线方程 \\(b=Dt+C\\) 将三个点带入方程就有\\(C+D=1,C+2D=2,C+3D=2\\) $$\\left[\r\\begin{array}{cc}\r1 \u0026 1 \\\\\r1 \u0026 2 \\\\\r1 \u0026 3 \\\\\r\\end{array}\r\\right]\r\\left[\r\\begin{array}{c}\rC \\\\\rD \\\\\r\\end{array}\r\\right]\r=\r\\left[\r\\begin{array}{c}\r1 \\\\\r2 \\\\\r2 \\\\\r\\end{array}\r\\right]\r$$\r可以发现这个Equation是无解的，但目的在于找到最优解 即方程\\(A^TA\\hat x =A^Tb\\)的解 在这之前需要定义一个Error来判断那条直线为最优解，定义为\\(||e^2||=||Ax-b||^2={e_1}^2+{e_2}^2+{e_3}^2\\) 在不存在Outlier 离群值的时候是一种非常好的Regression way \\(C+Dt分别为p1，p2和p3\\)，它们是满足方程并最接近于b的结果 现在需要求解\\(\\hat x= \\left[\\begin{array}{c}C \\D \\\\end{array}\\right]\\)和p \\(A^TA\\hat x=A^Tb\\) 因为\\(A^T(b-A\\hat x)=0\\)\n$$A^TA=\\left[\r\\begin{array}{ccc}\r1 \u0026 1 \u0026 1 \\\\\r1 \u0026 2 \u0026 3 \\\\\r\\end{array}\r\\right]\r\\left[\r\\begin{array}{ccc}\r1 \u0026 1\\\\\r1 \u0026 2 \\\\\r1 \u0026 3\\\\\r\\end{array}\r\\right]\r=\r\\left[\r\\begin{array}{ccc}\r3 \u0026 6\\\\\r6 \u0026 14\\\\\r\\end{array}\r\\right], A^Tb=\\left[\r\\begin{array}{ccc}\r1 \u0026 1 \u0026 1 \\\\\r1 \u0026 2 \u0026 3 \\\\\r\\end{array}\r\\right]\r\\left[\r\\begin{array}{ccc}\r1\\\\\r2\\\\\r2\\\\\r\\end{array}\r\\right]\r=\\left[\r\\begin{array}{cc}\r5 \\\\\r11 \\\\\r\\end{array}\r\\right]$$\r$$\\quad \\text{则有}\r\\left[\r\\begin{array}{cc}\r3 \u0026 6 \\\\\r6 \u0026 14 \\\\\r\\end{array}\r\\right]\r\\left[\r\\begin{array}{c}\r\\hat{C} \\\\\r\\hat{D} \\\\\r\\end{array}\r\\right]\r=\r\\left[\r\\begin{array}{c}\r5 \\\\\r11 \\\\\r\\end{array}\r\\right]$$\r解得\\(\\hat C=2/3,\\hat D=1/2\\) 亦可以通过求Partical Derivative的方法 $$e1^2 + e2^2 + e3^2 = (C + D - 1)^2 + (C + 2D - 2)^2 + (C + 3D - 2)^2$$ $$展开结果为2 e =3C2+14D2+9-10C-22D+12CD$$ $$求偏导为12C-20+24D=0； 28D-22+12C=0。与A^TA\\hat x=A^Tb相同$$ 于是得到结果 可以验证p与e与A的Column Space Orthogonal 矩阵ATA #\r证明：若A的列向量线性无关时，矩阵\\(A^TA\\)为可逆矩阵 要证明此，假设存在x使得\\(A^TAx=0\\)，后证明x只能是Zero Vector 第一步将灯饰两边同时乘以\\(x^T\\)，有\\(x^TA^TAx=0\\) 可以重写成\\((Ax)^T(Ax)=0\\Rightarrow Ax=0\\) 由于A的Column Vector是Linearly Independent的，所以只有\\(x=0时有A^TAx=0\\) 即\\(A^TAx\\) is invertible ","date":"Nov 21 2024","externalUrl":null,"permalink":"/docs/uoft/24/linearalgebra/la7.orthogonalprojection/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit 11/21/2024\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e正交向量Orthogonal vectors \r\n    \u003cdiv id=\"%E6%AD%A3%E4%BA%A4%E5%90%91%E9%87%8Forthogonal-vectors\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%AD%A3%E4%BA%A4%E5%90%91%E9%87%8Forthogonal-vectors\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/LinearAlgebra_Static/LA7.Orthogonal\u0026amp;Projection/LA7.Orthogonal\u0026amp;Projection-3.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"LA 7. Orthogonal and Projection","type":"docs"},{"content":" Last Edit: 11/19/24\nSolution 解 #\r对于一个Vector \\(a=[1,2]^T\\)和一个直线\\(y=0\\) 要研究\\(c[1,2]^T=0\\)的问题的时候，很明显不存在Non-Trivial Solution 由于a在\\(R^2\\)中，而\\([1,0]^T\\)仅Span出了\\(R^2\\)中的一个Subspace，其Dim=1 Least Error Solution (Optimization) 最优解 #\r但是对于a到直线的距离仍存在Optimized Solution 最优解出现在\\([1,2]^T\\)的终点在\\([1,0]\\)方向上最短的情况，即一个Error最小的情况 可以从a出发找到无数个到达向量\\([1,0]^T\\)方向的向量 而其中最短的则是\\(\\vec {e}\\) 也可以说\\(\\vec e\\)是Equation Error最小的Solution R^3 Case #\r对于向量\\([1,1,3]^T\\)来说，要计算其到达平面\\(x+y-2z=0\\)的最短距离 \\(\\vec e\\) 则代表了这一个距离 则e的起点在Plane\\(x+y-2z=0\\)上的位置就是这一个最优解 Projection 投影 #\r可以发现，要找到最优解，一个合理的办法是从Projection开始 在上图中p就是a在\\([1,0]^T\\)方向上的投影 则有\\(e=b-p\\) 而最小化这个e就是目标，这个目标通过Orthogonal 正交实现 具体来说从A出发的orthogonal to p的vector e就是这个Optimized Solution \\(R^3\\)中同理，只不过是将投影的改为了Plane 于是便有\\(e=(b-A\\hat x)\\) 要让e垂直于Plane \\(A=[a1,a2]\\) 有\\(a_1^T(b-A\\hat x )=0\\)并且\\(a_2^T(b-A\\hat x )=0\\) 于是可以得到公式 $$A^T(b-A\\hat x)=0\\Rightarrow A^TA\\hat x=A^Tb$$ Least Squares 最小二乘 #\r直接进入例子 对于三个点{(1,1), (2,2), (3,2)} 构建方程\\(y=wx\\) 带入点后得到\\(1=w,2=2w,2=3w\\) 通过\\(A^TA\\hat x=A^Tb\\) $$A^T A = \\begin{bmatrix}\r1 \u0026 2 \u0026 3\r\\end{bmatrix}\r\\begin{bmatrix}\r1 \\\\\r2 \\\\\r3\r\\end{bmatrix}\r= 1^2 + 2^2 + 3^2\r= 1 + 4 + 9\r= 14$$\r$$A^T b = \\begin{bmatrix}\r1 \u0026 2 \u0026 3\r\\end{bmatrix}\r\\begin{bmatrix}\r1 \\\\\r2 \\\\\r2\r\\end{bmatrix}\r= 1 \\cdot 1 + 2 \\cdot 2 + 3 \\cdot 2\r= 1 + 4 + 6\r= 11\r$$\r便有\\(14w=11\\Rightarrow w=\\frac{11}{14}\\) 几何角度 #\r那么上面的公式在几何空间中干的事就是 找到了这个红色的Vector，也就是最小的e 同理运用到最经典的\\(y=wx+b\\)也是一样 \\(1=w+b,2=2w+b,2=3w+b\\) $$A^T A = \\begin{bmatrix} 1 \u0026 2 \u0026 3 \\\\ 1 \u0026 1 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 1 \\\\ 2 \u0026 1 \\\\ 3 \u0026 1 \\end{bmatrix} = \\begin{bmatrix} 1^2 + 2^2 + 3^2 \u0026 1 + 2 + 3 \\\\ 1 + 2 + 3 \u0026 3 \\end{bmatrix} = \\begin{bmatrix} 14 \u0026 6 \\\\ 6 \u0026 3 \\end{bmatrix}$$\r$$A^T \\mathbf{b} = \\begin{bmatrix} 1 \u0026 2 \u0026 3 \\\\ 1 \u0026 1 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 2 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 1 \\cdot 1 + 2 \\cdot 2 + 3 \\cdot 2 \\\\ 1 \\cdot 1 + 1 \\cdot 2 + 1 \\cdot 2 \\end{bmatrix} = \\begin{bmatrix} 11 \\\\ 5 \\end{bmatrix}$$\r$$\\begin{bmatrix} 14 \u0026 6 \\\\ 6 \u0026 3 \\end{bmatrix} \\begin{bmatrix} w \\\\ b \\end{bmatrix} = \\begin{bmatrix} 11 \\\\ 5 \\end{bmatrix} $$\r于是有\\(w=\\frac{1}{2},b=\\frac{2}{3}\\) 同理几何上找到了向量在Plane上的投影之间的最小Error 所以这就是\\(A^TA\\hat x=A^Tb\\) 在Linear Regression的作用 需要知道的是这个方法（Normal Equation）求得的是解析解，在一般在feature \u0026lt; 10000的时候采用，但是过程可能不可逆 ","date":"Nov 19 2024","externalUrl":null,"permalink":"/docs/uoft/24/linearalgebra/leastsquare/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/19/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eSolution 解 \r\n    \u003cdiv id=\"solution-%E8%A7%A3\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#solution-%E8%A7%A3\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于一个Vector \\(a=[1,2]^T\\)和一个直线\\(y=0\\)\u003c/li\u003e\n\u003cli\u003e要研究\\(c[1,2]^T=0\\)的问题的时候，很明显不存在Non-Trivial Solution\u003c/li\u003e\n\u003cli\u003e由于a在\\(R^2\\)中，而\\([1,0]^T\\)仅Span出了\\(R^2\\)中的一个Subspace，其Dim=1\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/LinearAlgebra_Static/LeastSquare/LeastSquare-1.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"LA Least Square","type":"docs"},{"content":"","date":"Nov 18 2024","externalUrl":null,"permalink":"/docs/displays/","section":"Docs","summary":"","title":"Displays","type":"docs"},{"content":" Last Edit: 18/11/24\nLight #\r当我们讨论为什么像聚甲基丙烯酸甲酯（PMMA）这样的材料能够透明，而像玻璃态金属或单晶金属（如硅和镍基合金）则是不透明的时候，理解光的本质及其与材料的交互作用是至关重要的。 材料是否透明，很大程度上取决于其电子结构，这决定了它如何吸收光 PMMA #\rPMMA we were able to have a transparent polymer because PMMA is 100 % amorphous 在非晶态的材料中，没有晶体和非晶体区域之间的界限，这种界限在晶体材料中可能会散射光线。 PMMA中不存在这样的晶界，光线可以自由穿过，从而保持材料的透明性 Electromagnetic Spectrum 电磁光谱 #\r可见光只是在包含了radio waves, microwaves, infrared radiation, ultraviolet radiation, x-rays, and gamma rays在内的大量辐射光谱中的极小部分 在# Electromagnetic Spectrum中，光子是Electromagnetic Radiation的基本粒子单位，承载能量和信息，跨越不同wave length的电磁波，包括无线电波、微波、红外线、可见光、紫外线、X射线和伽马射线 Electromagnetic Radiation 电磁辐射 #\rPhotons 光子 #\r光子可以在空间中传播，不需要介质，是能量从一个地点传到另一个地点的方式 光的能量不是连续的，而是Quantized 量子化的 $$E = \\frac{hC}{\\lambda}$$\n\\(h~(Plank~ ~Constant) = 6.626×10^{−34}J⋅s\\) \\(c~(Light~speed)=3\\times 10^8 m\\cdot s^{-1}\\) \\(λ~(Wavelength)~m\\cdot s^{-1}\\) 其更加常见的形式为 $$E=hv$$ \\(ν\\) : frequency of the light in Hertz \\((1 Hz = \\frac1s)​\\) Photoelectric effect 光电效应 #\r由Albert Einstein于1905年提出 当光照射到金属表面时，光子将其能量传递给金属内的电子，如果这些光子的能量足够高，超过了金属的逸出功，电子就会被释放出金属表面 由于每个光子的能量由其频率决定，其能量和频率的关系则由公式\\(E=hv\\)给出 逸出功（Work Function）：逸出功是指电子从固体表面逃逸到真空中所需的最小能量。不同材料有不同的逸出功。 光电子（Photoelectron）：如果光子的能量高于逸出功，电子就会被释放，成为光电子 电子的动能（Kinetic Energy）：释放的光电子将具有一个最大动能，这可以通过 \\(Kmax=hf−ϕK_{\\text{max}}\\)来计算，其中 \\(\\phi\\) 是逸出功 Wave-Particle Duality 波粒二象性 #\r指物质（如光和电子）在某些情况下表现为波动性，而在其他情况下表现为粒子性。 Photoelectric effect展示了光的粒子性，而光的波动性则通过其他实验如双缝实验（Double-slit Experiment）得到证明 Electron volt 电子伏特（eV） #\r计算光子能量：使用的公式是 \\(E = \\frac{hc}{\\lambda}\\)， 650纳米的红激光，将其转换成米\\(650 \\times 10^{-9} \\text{ m}\\)，计算得到的能量是 \\(3.06 \\times 10^{-19}\\)焦耳 虽然结果是正确的，但由于在量子力学和粒子物理中常常处理非常小的能量数值，使用焦耳（Joules）单位可能会显得笨拙和难以理解 于是引入了Electron Volt的概念 电子伏特是基于电子通过1伏特电势差加速后获得的能量。一个电子伏特定义为 \\(1.602 \\times 10^{-19}\\) 焦耳 \\(E_{\\text{Red Photon}} = \\frac{3.06 \\times 10^{-19} , \\text{J}}{1.602 \\times 10^{-19} , \\text{J/eV}} = 1.91 , \\text{eV}\\) Atom 原子 #\r一个基本的Atom Structure可以概括如下 Most of the mass of an atom comes from the nucleus 原子核 Isotopes 同位素 #\rNumber of proton in nucleus决定了原子是什么元素 所以# of Protones也称为Atomic Number 原子序数 如Carbon-14, 写作\\(C_{14}\\) 对于6个Proton来说是Carbon，5个是Boron 硼，7个是Nitrogen 氮气 The Bohr Model of the Atom 原子的玻尔模型 #\r历史上出现了许多个不同的Atom Structure 第一个取得了重大进展的则是Bohr Model 玻尔模型的基本特征是中心核和轨道电子，电子与原子核以固定的距离运行 能量跃迁：电子可以通过吸收或释放一个量子（quanta）的能量，从一个轨道跳跃到另一个轨道。这个能量的量正好等于两个轨道之间的能量差 Limitation 局限性 #\r适用范围：波尔模型只能准确地计算具有一个电子的原子，如氢原子（H）、氦离子（He⁺）和双电离锂离子（Li²⁺）的行为 The Quantum-Mechanical Model of the Atom 原子的量子力学模型 #\r在现代量子力学模型中，我们需要使用Four quantum numbers来完全描述一个电子的状态 而在尼尔斯·波尔（Niels Bohr）的早期模型中，只使用了一个量子数 Principal Quantum Number 主量子数 (n) #\rDescribes the size of the electron orbit 描述了电子轨道的大小 可以是any integer value beginning at 1 不同的壳层代表电子与原子核的平均距离不同，能量也不同。 K shell 是当 n=1 时的电子层，这是最接近原子核的电子层，也是能量最低的壳层 L shell 是当 n=2时的电子层 M shell 是当 n=3时的电子层 Angular Momentum Quantum Number 角动量量子数 ℓ #\r角动量量子数（有时也称为方位量子数）描述了电子**轨道的形状 角动量量子数可以具有比主量子数小 0 到 1 的任何值, that is \\(ℓ=0,1,2,\u0026hellip;n−1\\) 当ℓ=0 时，轨道是球形的（s-轨道） s亚层可容纳 2 个电子 当l=1时，亚层是 p 轨道，形状是偶极形（类似哑铃）p亚层可容纳 6 个电子 当l=2时，亚层是 d 轨道，形状更加复杂，通常有四叶或更多叶的形状 d亚层可容纳 10 个电子 当l=3时，亚层是 f 轨道，形状更为复杂 f亚层可容纳 14 个电子 当 ℓ=1 时，轨道呈哑铃形（p-轨道） 更高的ℓ值对应更复杂的轨道形状 The Magnetic Quantum Number 磁量子数 ml #\r磁量子数主要用于指定原子轨道在三维空间中的取向，并与外部磁场中的能级分裂有关 Describes how many different ways each subshell can be orientated 磁量子数 mℓ​ 可以取从−ℓ到+ℓ的整数值，包括零，其中 ℓ是角动量量子数。这表示对于给定的角动量量子数，存在2ℓ+1个可能的磁量子数。 例如，如果电子处于p轨道ℓ=1，那么mℓ可以是 -1, 0, 或 +1，对应轨道在空间中的三个不同取向。 Spin Quantum Number 自旋量子数 (s) #\r自旋量子数ms并不直观地描述电子的物理自旋，因为电子实际上并不是在空间中围绕某个轴物理旋转。 将电子描述为“旋转”的说法可能会引起误解 量子数值：自旋量子数的可能值为\\(\\frac{1}{2}\\)​ 或\\(-\\frac{1}{2}\\)​，通常表示为电子的自旋向上（up-spin）和自旋向下（down-spin） Eletron‘s Spin 电子的自旋 #\r电子的“自旋”这一术语实际上并不指电子在空间中像地球绕其轴旋转那样的物理旋转 电子自旋是一种量子力学性质，表现为一种内在的角动量 尽管这个性质被称为“自旋”，但它并不涉及电子在任何可见的或传统意义上的物理旋转 Summarize #\r大概总结一下，对于一个电子，有四个变量能决定他的属性，也就是四个Quantum Numbers 这四个变量的由来是由Pauil Exclusion Principle规定的 即同一层级，同一轨道类型，同一轨道编号下最多存在两个电子 当四个Quantum Nubers 全部相同的时候，则两个电子一致 1. Principle Quantum Number 主量子数 #\r以电子所作在的电子层级区分 n = 1 or 2 or 3 or 4 or 5 2. Angular Momentum Qunatum 角量子数 #\r通过同一层级下的不同轨道（以形状）区分 n = 2 \u0026amp; l = 1 or 2 3. Magnetic Quantum Number 磁量子数 #\r同一层级下，同一类型（形状）轨道，不同轨道编号区分 n = 2 \u0026amp; l = 2 \u0026amp; m = -1 4. Spin Quantum Number 自旋量子数 #\r同一层级，同一轨道类型，同一轨道编号的不同电子 根据Pauil Exclusion Principle，同一层级，同一轨道类型，同一轨道编号下最多存在两个电子，其中一个上旋为1/2，下旋为-1/2 n = 2 \u0026amp; l = 2 \u0026amp; m = -1 \u0026amp; s = 1/2 Electron Configuration #\r但是想要描述一个元素的Electron Configuration，只需要描述到亚层就够了，每一个亚层都有它能存在的固定电子数 The Electron Configuration of Carbon #\r元素周期表中可以确认，我们的老朋友碳的原子序数为 6， 这意味着一个碳原子的原子核中有六个质子 因此，要构建一个中性碳原子，我们需要将六个电子放入原子核周围的外壳和子壳中 要注意1s中的1是Pricipal Quantum Number，s是Angular Momentum Quantum Number 而且一个亚层是可以包含2个电子的，所以一个n = 2中的 l =1 的亚层p可以有6个电子，写作\\(2p^6\\) 那么对于Carbon来说就有 $$1s^2 , 2s^2 , 2p^2$$ 有的时候为了省略，可以从该元素的前一个Nobel Gas的Electron Configuration开始写起 对于Carbon来说则是Helium $$[\\text{He}] 2s^2 , 2p^2 $$ When 4s is Closer Than 3d Writting Format #\r在上面的Electron Configuration里可以看到4s层的能量实际上是低于3d的，这主要是因为电子层级不是主要只依靠其Primary Quantum Number决定 但是在书写时统一按照了国际惯例，即按照Primary Quantum Number顺序书写 Physical Reason Under #\r尽管在填充电子时，4s能量低于3d（因此4s轨道先填满），但在元素离子化或化学反应中，4s电子往往更容易被移除。 Titanium #\r所以Ti的完整规定写法是 $$1s^2 2s^2 2p^6 3s^2 3p^6 3d^2 4s^2 ~ and ~ [\\text{Ar}] 3d^2 4s^2$$ 可以发现前一个的3d应该是10个，但只写了2个就到s了 Few Exceptions 特例 #\r在3d亚层处于半满或全满状态时，即4，9时 系统可以通过重新分配电子来达到更稳定的状态 Vanadium #\r$$1s^2 2s^2 2p^6 3s^2 3p^6 3d^3 4s^2$$\n可以发现3d亚层只有3个，不处于即将Half-Filled or Completely Filled的水平 Chromium #\r$$1s^2 2s^2 2p^6 3s^2 3p^6 3d^5 4s^1$$\n4s（小于3d的层级）的电子被3d拿去了，以达到了Half-Filled的水平 Copper #\r$$1s^2 2s^2 2p^6 3s^2 3p^6 3d^{10} 4s^1$$\n4s（小于3d的层级）的电子被3d拿去了，以达到了Full-Filled的水平 Octet Stability #\r\\(He=1s^2\\) \\(Ne=1s^2 2s^2 2p^6\\) \\(Ar=1s^2 2s^2 2p^6 3s^2 3p^6\\) \\(Kr=1s^2 2s^2 2p^6 3s^2 3p^6 4s^2 4p^6\\) 可以发现，由于Nobel Gas的电子构型使其具有八电子（octet）结构，遵循八隅规则 所以他们的Electron Configuration通常可以表示为\\(ns^2 np^6\\)的形式 Ionic Bond #\r离子键的形成过程 #\rCl的Atomic Number是17，其电子构型为\\(1s^2 2s^2 2p^6 3s^2 3p^5\\) 它缺一个电子就可以达到Octet的稳定结构 Na的Atomic Number是11，电子构型为\\(1s^2 2s^2 2p^6 3s^1\\) 或简写为 \\([Ne]3s^1\\) 它如果失去一个电子，也可以达到类似稀有气体的稳定构型 电子转移与离子形成 #\r钠会失去一个电子，形成带正电的钠离子（Na⁺）。 氯会接受一个电子，形成带负电的氯离子（Cl⁻）。 这种电子的转移使得钠和氯都达到了稳定的电子构型，形成了Ionic Bond 离子键的特性 #\r这种静电吸引力是non-directional，即在所有相邻的正负离子之间普遍存在，使得离子晶体结构非常稳定 在晶体中，所有电子都被紧密束缚在各自的离子中，不自由移动，因此固态的NaCldo not conduct electricity 图中显示了NaCl晶体的结构，红色小球表示Na⁺，蓝色大球表示Cl⁻。 黄色箭头表示离子间的静电吸引力。 由于正负离子的规则排列，晶体内每个离子都被周围的异性离子包围，形成稳定的晶格结构 Colvaent Bond #\rColvaent Bond涉及Electron Sharing，即原子通过共享价电子来达到稳定的Octet结构 甲烷（CH₄）是一个简单的例子：碳和氢通过共价键结合，形成一个稳定的分子。 共价键只在Specific Atoms形成，例如在CH4中，Carbon仅与四个Hydrogen Bond形成共价键，而不会与其他原子相连。这种键称为Directional Bond 共价键的本质区别在于电子共享，而离子键则是电子转移 Metallic Bonding #\r金属键通常用两种模型描述：sea-of-electrons model, and the band theory of solids Sea of Electrons Model #\r电子海模型中，Valence electrons不固定在特定的原子核上，而是自由移动，形成一个电子的“海洋”（sea of electrons） 要注意Inner electrons (non-valence electrons)是不在Electron Sea中的，因为他们并不参与反应 Ion Core周围的蓝色区域全是电子 Valence electrons 价电子 #\r原子最外层的电子，直接参与化学反应和形成化学键。它们决定了元素的化学性质，例如其反应性、与其他元素形成的键类型等 这些自由移动的电子使得金属具有Conductivity和延展性，因为电子可以在整个晶体中自由流动 Ion core 离子核 #\r在金属或其他离子化合物结构中，不参与化学键的原子核和内层电子的组合 Conductivity of Sea of Electrons Model 导电性\n模型中，electrons are free to move past the ion cores (or so-called delocalized) 离域化 自由移动的电子可以在金属内传导电流 相较于Covalent Bond来说，其被局限在特定原子之间，因此像聚合物这样的材料通常是电的绝缘体 Ductility #\r金属晶体受到足够大的应力时，一个原子平面可以滑过另一个原子平面 在金属中，原子是按照晶体结构排列的，周围有自由移动的电子（电子海） 当对金属施加较大的力（如拉伸力或剪切力）时，金属中的一个原子平面会滑动到另一个原子平面之上 即使发生滑动，由于电子海的存在，这些自由电子能够迅速重新分布并填补原子之间的空隙，从而保持金属的整体结构稳定，不会断裂 Ceramic #\r而对于Ionic \u0026amp; Covalent Bonding来说，由于其结构性，导致一旦发生了滑动，其负电荷会和负电荷处于同一平面导致Repulsion 在陶瓷材料中正负离子交替排列形成晶体结构。 当试图使一个原子层滑过另一个时，同性电荷的离子（例如两个正离子或两个负离子）会短暂靠近。 同性电荷靠近时会产生强烈的静电排斥力。 结果：导致了陶瓷在变形前就会发生脆性断裂。 Polymer #\rDuality #\r聚合物主要通过covalent bonds将分子内部连接，而分子间的连接靠次级键（如范德华力或氢键）。 在塑性变形中，Secondary Bonds被克服，聚合物分子链滑动，而共价键不会断裂。 结果：聚合物表现出较大的可变形性（如韧性），而不会像陶瓷那样容易断裂。 Conductivity #\r聚合物中，all of the valence electrons are tightly bound in the strong covalent bonds due to the lack of any free electrons 聚合物是electrically insulating Form of Crystal of Salt #\rI know that NaCl forms an ordered solid, but why?\n这是因为物质趋向于从things tend to proceed from higher energy to lower energy 当某些事情发生（如盐形成晶体）是因为这样的状态对能量来说是更“有利”的，也就是“lower energy” $$Na_{(s)} + \\frac{1}{2}Cl_{2(g)} \\rightarrow NaCl_{(s)}$$ 对于上面的反应，我们将其拆分成子反应 Sublimation of Sodium 钠的升华 #\r$$Na(s)​→Na(g)​$$\n固态钠\\(Na_{(s)}\\)直接转化为气态钠原子\\(Na_{(g)}\\)，称为升华（sublimation） 这种物质从固体转变为气体的过程需要能量，称为升华焓\\(\\Delta H_{\\text{sublimation}}\\)，对于钠为\\(ΔHsublimation​=109kJ/mol\\) 这里正值代表了：系统需要吸收能量便反应从左向右进行 也就是说，需要能量来熔化然后煮沸钠 Ionization of Sodium Atom 钠原子电离 #\r气态钠原子\\(Na_{(g)}\\)进一步被电离为钠离子\\(Na^+_{(g)}\\)和一个电子\\(e^-\\) $$Na(g)​→Na(g)^+​+e^−$$ Ionization energy is \\(IENa​=497kJ/mol\\) 可以发现这目前还是一个Posititve，则代表还需要吸收能量 Bond Dissociation of Chlorine Molecule 氯的解离 #\r$$\\frac{1}{​2}Cl_2(g)​→Cl(g)​$$\n\\(BDE_{Cl_2} = 121 , \\frac{kJ}{mol}\\) 这仍然是吸热过程（需要能量输入） Formation of a chlorine anion #\r$$Cl(g)​+e^−→Cl(g)^−​$$\n这一过程中的Electron Affinity为\\(EACl​=−364\\frac{mol}{kJ}​\\) 可以发现能量第一次变为了负的，这是第一个释放能量的步骤 Forming the ionic crystal #\r$$Na(g)+​Cl(g)^−​→NaCl(s)$$\n这一个过程包含了Crystallization energy\\(Ecrystallization​=−777\\frac{mol}{kJ}​\\) 可以发现这一步消耗了很多能量 如果我们将这些能量项中的每一个相加，形成 NaCl 的总能量变化为−414 虽然第一步是吸热的，但整个反应通过后续的强烈放热步骤补偿了这一点。整体反应的自由能变化 (ΔG\\Delta GΔG) 是负的，因而是自发的。这解释了为什么钠和氯最终可以自然形成盐晶体\nThe Band Theory 能带效应 #\r电子能级由于相互的排斥作用发生分裂\n在孤立的原子中，电子能量被量子化，存在于离散的能级中（如s,p,d,f轨道） 这些能级之间的能量差是固定的，不会受到其他原子的影响。 对于每个原子原本的一个能级，靠近后会产生多个稍微不同的能级。 例如：对于两个原子，一个能级会分裂成两个能级；对于N个原子，会分裂成N个能级 在固体中，原子之间的距离非常近，并且一个晶格中会有\\(10^{23}\\)个原子 原子的数量极其庞大时，原本分裂的离散能级数量非常多，且间距变得极其微小，最终看起来像是连续的能量区域——这就是能带（Energy Band） 原子越多，能带越“密集” 当对于一个原子，其存在多个能级，但当多个原子组合在一起的时候，电子的能量状态不再是离散的，而是形成了一个几乎连续的能量区域 孤立原子：电子有固定的、离散的能量（如轨道能级 s,p,d） 固体中：原子靠得很近，电子能级由于相互的排斥作用发生分裂。 分裂后的能量状态数量非常多，间隔非常小，看起来像是连续的，这就形成了能带 Bonding in Metals Like Copper #\r用Copper的Electron Configuration举例 $$Cu =1s^2 , 2s^2 , 2p^6 , 3s^2 , 3p^6 , 3d^{10} , 4s^1$$ 在4s中的两个Sublayer中只存在一个电子 Conductivity #\r导电的本质是低能量跃迁的累积：导电依赖于大量电子在价带和导带之间进行低能量的跃迁。如果3s电子要跃迁到4s或4p，势必要消耗更多的能量，而这在常温下不容易实现。因此，这些高能跃迁对导电贡献很小，甚至可以忽略不计。 所以说当一个轨道中存在Empty States的时候，Valence Electron才能在其中跃迁 Bonding in Metals Like Magnesium #\r对于Mg来说\\(Mg=1s^2 , 2s^2 , 2p^6 , 3s^2\\)，从表面看，3s轨道已经完全填满，因此看起来它不应该有可用的电子来参与导电 但是可以发现3p轨道是空的，但它并不是不可用的 这就像在剧院里，空座位虽然没有人坐，但仍然在那里，可以被占用 可以被占用。3s轨道和3p轨道的能级相互重叠，因此电子可以从3s轨道很容易地被激发到3p轨道 Bonding in Ceramics and Polymers #\r回想一下，Ceramic往往通过Ionic Bond结合在一起，而Ionic Bond涉及Electron在Atom间的转移 还要记住，这种电子转移的发生是为了让每个原子都能获得填充的Valence Shell 由于Valence Shell是填充的，因此没有紧邻填充态的电子能态。此外，这些电子与原子核紧密结合，因此没有自由电子 Polymer也是如此，只是他是Covalent Bond Valence Band 价带 #\rValence Band是指电子填满的最高能量带 拿Si举例，其Electron Configuration为\\(1s^22s^22p^63s^23p^2\\) 其Valence Band即为\\(3s^2\\)，3p虽然是最高能量带，但他并没有填充满 导电性：满带的电子不能自由流动，因为能量状态已经填满，没有空位供电子移动 Full Band满带 #\rFull Band是指电子完全填满的能量带。 在硅（Si）的例子中，\\(1s^2 2s^2 2p^6\\) 层被完全填满，这些内层电子构成了满带 这些满带主要是低能级的核心电子带，电子在这些带中被完全填满，无法参与到导电过程中 导电性：满带的电子由于能态完全填满，没有额外的空间或能级供电子跃迁，因此不参与导电。这些带在正常条件下对材料的导电性几乎没有贡献 Conduction Band 导带 #\r导带是指紧邻满带之上的未填满能量带 拿Si举例，其Electron Configuration为\\(1s^22s^22p^63s^23p^2\\) 其Valence Band即为\\(3p^2\\) 当电子被激发到导带后，它们可以在材料中自由移动，从而参与导电 Conduction Band通常是空的，或者仅有少量电子占据（在导体中可能存在部分填充） 导带中的电子是Valence electrons AKA Free Electrons，可以在材料中移动并产生电流 Simiconductor 半导体 #\r一些材料，即半导体，具有的Bond Gap没有绝缘体那么大 这很重要，因为这意味着我们可以控制这些材料中的电子流动。这是太阳能光伏、LED 照明和我们所有现代电子产品的基础 但大约 4 eV 通常是一个不错的数字。如果材料的带隙大于 4 eV，我们可以将其视为绝缘体，如果带隙小于 4 eV（但不为零） Conductors, Insulators, and Semiconductors #\r重新根据导电效率定义这三种的区别 从左到右依次为 conductors semiconductors and insulators Back To Light #\r可见光由光子能量在 2-3 eV 之间的光子组成 如果材料的带隙大于 3 eV（例如 SiO₂，二氧化硅），那么可见光光子的能量不足以激发电子从价带跃迁到导带。 结果：光子通过材料时不会被吸收，因此材料对可见光是透明的。 举例：玻璃主要由 SiO₂ 构成，因此玻璃是透明的。 Energy efficiency of the building #\r光穿过窗户进入室内会导致热量积聚，从而增加空调的能耗 解决方案：在窗户上镀金属薄层 金属薄层可以反射部分阳光（尤其是紫外线光子）。 如果金属层够薄，它仍然允许大部分可见光通过，同时减少紫外线和热量的传递。 优点：提高建筑的能源效率，降低室内过热问题。 Light \u0026amp; Metal #\r金属的特点：没有明显的带隙（导带和价带重叠） 结果1：光子容易激发电子：\n可见光光子的能量足够将金属中的自由电子激发到更高能级\n因此，金属吸收光，并且是不透明的\n结果2：金属的光泽（反射性）：\n被光子激发的电子会迅速返回到较低能量状态，在这个过程中重新发射光子\n这种现象导致金属表面反射光，从而看起来有光泽（“金属光泽”）\nSilicon 硅 #\r实验表明，每个硅原子会形成 four identical bonds 但是，根据电子配置，3s 和 3p 轨道的能量不同，这意味着它们的性质不同 可以推出结论“Our model is limited. It can\u0026rsquo;t explain bonding in silicon” sp3 Hybridization 轨道杂化理论 #\r这里提出的解决方法是这样的：让我们只拿一个s轨道和3p轨道并将它们混合在一起 Diamond Cubic #\r现在我们有四个等效的轨道，这些轨道的分布是对称的，彼此之间具有等价性 it wouldn\u0026rsquo;t make sense for, say, three of them to be clumped close to one another and one bond to be all alone 也就是说，它们在空间中的位置分布是均匀的 Tetrahedral Configuration #\rSemiconductors #\r能够控制半导体的导电性对我们来说很重要 可以通过将杂质引入Semiconductors中以改变其导电性 Intrinsic Semiconductors 本征半导体 #\r拿Silicon举例，其在3p轨道上，存在了4个Valence Electron 不同的Silicon则和其他的通过Covalent Bond组合成如下 Intrinsic Semiconductors一种纯净的半导体，没有杂质掺杂 在Absolute Zero的时候可以形成如上图的结构 Hole 空穴 #\r当温度上升了之后，Electrons会被Promoted进入Conduction Band导带 电子从Valence Band跃迁到Conduction Band后，会在原来的位置留下一个hole，即一个缺少电子的位置 其中，Electron和Hole空穴（电子缺失造成的正电荷）的数量是平衡的 没多一个Electron被promote后，都会留下对应的Hole，亦可说他们是成对出现的 种类型的半导体称为Intrinsic Semiconductors，因为所有可用于导电的东西都来自半导体本身，而不是我们添加到其中的任何东西 Intrinsic Semiconductors在实践中并不是特别有用，因为我们几乎总是添加杂质来控制Conductivity 电导率 Conductivity 电导率 #\r计算一个Simiconductor的 Conductivity的公式为 $$\\sigma = nq\\mu_n + pq\\mu_p $$ 而对于Intrinsic Semiconductors的特殊情况来说，由于存在Concentration of holes = Concentration of electons，于是就有 $$\\sigma = nq(\\mu_n + \\mu_p)$$ Concentration of electrons 电子浓度 n #\rSince electrons carry a negative charge 所以可以通过\\(\\frac{noofelectorns}{m^3}\\) Concentration of holes 空穴浓度 #\r在本征半导体中，电子浓度（n）和空穴浓度（p）是相同的 这是因为Intrinsic Semiconductors中的电子和空穴都是由相同数量的价带电子激发到导带产生的 因此，在热平衡状态下，电子的生成和复合是平衡的，所以电子浓度和空穴浓度相等 Mobility 迁移率 #\r对于Mobility来说存在Electron Mobility和Hole Mobility，分别通过\\(\\mu_n和\\mu_p\\)来表示 其单位为\\(\\frac{m^2}{V_s}\\) Charge 电荷 #\rCharge指的是Magnitude of the fundamental charge \\(1.602\\times 10^{-19}C\\) Extrinsic Semiconductors 外延半导体 #\r本征半导体并不是特别实用，因为我们通常会向半导体中添加Impurities（称为dopants）以仔细控制其Conductivity 我们向半导体中添加Small amount of dopant的Dopants时，掺杂剂引入的电导率会压倒任何本征半导体，因此我们称之为Extrinsic Semiconductors 基本上存在两种加入Dopants的方式，使用额外的Electron或者Hole的方法 由于电子是Negataive Charged的，将添加Electron的叫做n- type Semiconductor 而Hole是Positive的（虽然其是Neutral的，但由于Hole存在于Electron的中间，所以看上去是“Positive”的），所以添加Hole的叫做p-type Semiconductor Extrinsic n-Type Semiconductors 外本征n型半导体 #\r想要在Intrinsic Semiconductor中添加Extra Electrons，可以通过Zero Dimension Inpurity的Point Defects来添加Inpurities Atoms，而添加的这一个Atom会带来额外的电子 已知对于Silicon来说其存在4个Valence Electrons：\\(3s^23p^2\\)，一种合适的做法便是将位于元素周期表右侧的Atom加入，即一个存在5个Valence Electron的Atom，这便是P，磷 已知磷的Atomic Number为15，其Electron Configuration为\\(1s^2 2s^2 2p^6 3s^2 3p^3\\) 因此添加到硅晶格中时，当与相邻的硅原子形成四个共价键时，将有一个额外的电子踢来踢去 如上图所示，元素中出现了一个多余的电子，由于没有足够的周围硅原子来形成稳定的共价键，因此这个电子不像其他共价键中的电子那样稳定地束缚 Donor Level供体能级 #\r在Gap Band内，接近导带底部的蓝色线表示磷原子提供的额外电子的能级 这个能级非常接近导带，因此只需很少的能量就可以将电子激发到导带中。 由于Impurity P为Simiconductor贡献的 Charge carriers，亦或者说是价带比通过本征促进产生的电荷载流子多得多 因此我们可以忽略\\(\\mu_p\\)，只用电子浓度和迁移率来计算 n 型半导体的电导率 $$σ_{n−type​}=nqμ_n​$$ Extrinsic p-Type Semiconductors #\r同理对于Silicon来说，选他左边的元素，B 在Extrinsic p-Type Semiconductors中，电子不需要被激发到Conduction Band才能导电 相反，价带中的电子可以轻易被激发到B提供的一个Hole上，从而填补那里的空穴，也就是Bnad Diagram上的Acceptor Level 同理可以忽略\\(\\mu_n\\)的大小 $$σ_{p−type}​=pqμ_p​$$ Solid Ionic Conductivity #\r当我们思考和谈论固体材料中的导电性时，我们会考虑电子的运动，就半导体而言，还会考虑“空穴”的运动 然而，导电性也可以通过Solid Ionic内的运动来实现 ","date":"Nov 18 2024","externalUrl":null,"permalink":"/docs/uoft/24/engineering-chemistry--materials-science/ecms7.lightquantum/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 18/11/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eLight \r\n    \u003cdiv id=\"light\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#light\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e当我们讨论为什么像聚甲基丙烯酸甲酯（PMMA）这样的材料能够透明，而像玻璃态金属或单晶金属（如硅和镍基合金）则是不透明的时候，理解光的本质及其与材料的交互作用是至关重要的。\u003c/li\u003e\n\u003cli\u003e材料是否透明，很大程度上取决于其电子结构，这决定了它如何吸收光\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003ePMMA \r\n    \u003cdiv id=\"pmma\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#pmma\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003ePMMA we were able to have a transparent polymer because PMMA is 100 % amorphous\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS7.Light\u0026amp;Quantum/ECMS7.LIGHT.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"ECMS 7. Light and Quantum","type":"docs"},{"content":"\rYour browser does not support the video tag.\rfrom manim import *\rimport numpy as np\rimport torch\rimport random\rclass LinearRegression(Scene):\rdef construct(self):\rdef data_generator(w, b, num):\rX = torch.normal(0, 1, (num, len(w)))\ry = torch.matmul(X, w) + b\ry += torch.normal(0, 0.01, y.shape)\rreturn X, y.reshape((-1, 1))\rtrue_w = torch.tensor([2, -3.4])\rtrue_b = 4.2\rfeatures, labels = data_generator(true_w, true_b, 1000)\rhead = Text(\u0026#34;Linear Regression Display - Buezwqwg\u0026#34;)\rhead.set_color(BLUE)\rself.play(Create(head))\rself.wait(1)\rself.play(Uncreate(head))\rfeature_one = features[:, [0]].tolist()\rfeature_two = features[:, [1]].tolist()\rlabels_list = labels.tolist()\raxes_1 = Axes(\rx_range=[min(feature_one)[0]-1, max(feature_one)[0]+1, 1],\ry_range=[min(labels_list)[0]-1, max(labels_list)[0]+1, 5],\rx_length=5,\ry_length=5,\raxis_config={\u0026#34;color\u0026#34;: BLUE},\r)\raxes_2 = Axes(\rx_range=[min(feature_two)[0]-1, max(feature_two)[0]+1, 1],\ry_range=[min(labels_list)[0]-1, max(labels_list)[0]+1, 5],\rx_length=5,\ry_length=5,\raxis_config={\u0026#34;color\u0026#34;: BLUE},\r)\raxes = VGroup(axes_1, axes_2)\raxes.arrange(RIGHT, buff=1)\rself.play(Create(axes))\rpoints_1 = []\rfor i in range(len(labels_list)):\rdot_position = axes_1.coords_to_point(feature_one[i][0], labels[i][0])\rpoints_1.append(Dot(point=dot_position, radius=0.03, color=YELLOW))\rpoints_2 = []\rfor i in range(len(labels_list)):\rdot_position = axes_2.coords_to_point(feature_two[i][0], labels[i][0])\rpoints_2.append(Dot(point=dot_position, radius=0.03, color=YELLOW))\rpoints_group_1 = VGroup(*points_1)\rpoints_group_2 = VGroup(*points_2)\rself.play(Create(points_group_1), Create(points_group_2))\r# Draw the true model lines\rtrue_line_1 = axes_1.plot(lambda x: true_w[0].item() * x + true_b, color=GREEN)\rtrue_line_2 = axes_2.plot(lambda x: true_w[1].item() * x + true_b, color=GREEN)\rself.play(Create(true_line_1), Create(true_line_2))\r# Initialize parameters\rw = torch.normal(0, 0.01, size=(2, 1), requires_grad=True)\rb = torch.zeros(1, requires_grad=True)\rw_1 = w.detach().numpy()[0][0]\rw_2 = w.detach().numpy()[1][0]\rb_0 = b.detach().numpy()[0]\rline_1 = axes_1.plot(lambda x: w_1 * x + b_0, color=BLUE)\rline_2 = axes_2.plot(lambda x: w_2 * x + b_0, color=BLUE)\rself.play(Create(line_1), Create(line_2))\r# Add text to display loss, w, b\rloss_text = MathTex(f\u0026#34;\\\\text{{Loss}} = {0:.4f}\u0026#34;)\rloss_text.to_edge(UP)\rw_text = MathTex(f\u0026#34;w_1 = {w_1:.4f},\\\\ w_2 = {w_2:.4f}\u0026#34;)\rw_text.next_to(loss_text, DOWN)\rb_text = MathTex(f\u0026#34;b = {b_0:.4f}\u0026#34;)\rb_text.next_to(w_text, DOWN)\rparam_text = VGroup(loss_text, w_text, b_text)\rself.play(Write(param_text))\rdef data_iter(batch_size, features, labels):\rnum = len(features)\rindex = list(range(num))\rrandom.shuffle(index)\rfor i in range(0, num, batch_size):\rbatch_index = torch.tensor(index[i:min(i+batch_size, num)])\ryield features[batch_index], labels[batch_index]\rbatch_size = 10\rdef linreg(X, w, b):\rreturn torch.matmul(X, w) + b\rdef squared_loss(y_hat, y):\rreturn (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\rdef sgd(params, lr, batch_size):\rwith torch.no_grad():\rfor param in params:\rparam -= lr * param.grad / batch_size\rparam.grad.zero_()\rlr = 0.03\rnum_epochs = 3 # Changed to 3 epochs\rnet = linreg\rloss = squared_loss\rupdate_interval = 1 # Update after every batch\rbatch_counter = 0\r# Start training and update after every backpropagation\rfor epoch in range(num_epochs):\rfor X, y in data_iter(batch_size, features, labels):\rl = loss(net(X, w, b), y)\rl.sum().backward()\rsgd([w, b], lr, batch_size)\rbatch_counter += 1\r# Get the latest parameters\rnew_w_1 = w.detach().numpy()[0][0]\rnew_w_2 = w.detach().numpy()[1][0]\rnew_b_0 = b.detach().numpy()[0]\r# Update lines\rnew_line_1 = axes_1.plot(lambda x: new_w_1 * x + new_b_0, color=BLUE)\rnew_line_2 = axes_2.plot(lambda x: new_w_2 * x + new_b_0, color=BLUE)\rself.play(\rTransform(line_1, new_line_1),\rTransform(line_2, new_line_2),\rrun_time=0.1 # Adjusted animation time for smoother update\r)\r# Update loss and parameter displays\rwith torch.no_grad():\rtrain_l = loss(net(features, w, b), labels)\rcurrent_loss = float(train_l.mean())\rnew_loss_text = MathTex(f\u0026#34;\\\\text{{Loss}} = {current_loss:.4f}\u0026#34;)\rnew_loss_text.to_edge(UP)\rnew_w_text = MathTex(f\u0026#34;w_1 = {new_w_1:.4f},\\\\ w_2 = {new_w_2:.4f}\u0026#34;)\rnew_w_text.next_to(new_loss_text, DOWN)\rnew_b_text = MathTex(f\u0026#34;b = {new_b_0:.4f}\u0026#34;)\rnew_b_text.next_to(w_text, DOWN)\rself.play(\rTransform(loss_text, new_loss_text),\rTransform(w_text, new_w_text),\rTransform(b_text, new_b_text),\rrun_time=0.1\r)\r# Output current epoch\u0026#39;s loss\rprint(f\u0026#39;epoch {epoch + 1}, loss {current_loss:f}\u0026#39;)\rself.wait(2) ","date":"Nov 18 2024","externalUrl":null,"permalink":"/docs/displays/linearregression_display/","section":"Docs","summary":"\u003cvideo width=\"640\" height=\"360\" controls\u003e\r\n  \u003csource src=\"LG_Display.mp4\" type=\"video/mp4\"\u003e\r\n  Your browser does not support the video tag.\r\n\u003c/video\u003e\r\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efrom manim import *\r\nimport numpy as np\r\nimport torch\r\nimport random\r\n\r\nclass LinearRegression(Scene):\r\n    def construct(self):\r\n        def data_generator(w, b, num):\r\n            X = torch.normal(0, 1, (num, len(w)))\r\n            y = torch.matmul(X, w) + b\r\n            y += torch.normal(0, 0.01, y.shape)\r\n            return X, y.reshape((-1, 1))\r\n\r\n        true_w = torch.tensor([2, -3.4])\r\n        true_b = 4.2\r\n        features, labels = data_generator(true_w, true_b, 1000)\r\n\r\n        head = Text(\u0026#34;Linear Regression Display - Buezwqwg\u0026#34;)\r\n        head.set_color(BLUE)\r\n        self.play(Create(head))\r\n        self.wait(1)\r\n        self.play(Uncreate(head))\r\n\r\n        feature_one = features[:, [0]].tolist()\r\n        feature_two = features[:, [1]].tolist()\r\n        labels_list = labels.tolist()\r\n        axes_1 = Axes(\r\n            x_range=[min(feature_one)[0]-1, max(feature_one)[0]+1, 1],\r\n            y_range=[min(labels_list)[0]-1, max(labels_list)[0]+1, 5],\r\n            x_length=5,\r\n            y_length=5,\r\n            axis_config={\u0026#34;color\u0026#34;: BLUE},\r\n        )\r\n        axes_2 = Axes(\r\n            x_range=[min(feature_two)[0]-1, max(feature_two)[0]+1, 1],\r\n            y_range=[min(labels_list)[0]-1, max(labels_list)[0]+1, 5],\r\n            x_length=5,\r\n            y_length=5,\r\n            axis_config={\u0026#34;color\u0026#34;: BLUE},\r\n        )\r\n        axes = VGroup(axes_1, axes_2)\r\n        axes.arrange(RIGHT, buff=1)\r\n        self.play(Create(axes))\r\n\r\n        points_1 = []\r\n        for i in range(len(labels_list)):\r\n            dot_position = axes_1.coords_to_point(feature_one[i][0], labels[i][0])\r\n            points_1.append(Dot(point=dot_position, radius=0.03, color=YELLOW))\r\n        points_2 = []\r\n        for i in range(len(labels_list)):\r\n            dot_position = axes_2.coords_to_point(feature_two[i][0], labels[i][0])\r\n            points_2.append(Dot(point=dot_position, radius=0.03, color=YELLOW))\r\n        points_group_1 = VGroup(*points_1)\r\n        points_group_2 = VGroup(*points_2)\r\n        self.play(Create(points_group_1), Create(points_group_2))\r\n\r\n        # Draw the true model lines\r\n        true_line_1 = axes_1.plot(lambda x: true_w[0].item() * x + true_b, color=GREEN)\r\n        true_line_2 = axes_2.plot(lambda x: true_w[1].item() * x + true_b, color=GREEN)\r\n        self.play(Create(true_line_1), Create(true_line_2))\r\n\r\n        # Initialize parameters\r\n        w = torch.normal(0, 0.01, size=(2, 1), requires_grad=True)\r\n        b = torch.zeros(1, requires_grad=True)\r\n        w_1 = w.detach().numpy()[0][0]\r\n        w_2 = w.detach().numpy()[1][0]\r\n        b_0 = b.detach().numpy()[0]\r\n        line_1 = axes_1.plot(lambda x: w_1 * x + b_0, color=BLUE)\r\n        line_2 = axes_2.plot(lambda x: w_2 * x + b_0, color=BLUE)\r\n        self.play(Create(line_1), Create(line_2))\r\n\r\n        # Add text to display loss, w, b\r\n        loss_text = MathTex(f\u0026#34;\\\\text{{Loss}} = {0:.4f}\u0026#34;)\r\n        loss_text.to_edge(UP)\r\n        w_text = MathTex(f\u0026#34;w_1 = {w_1:.4f},\\\\ w_2 = {w_2:.4f}\u0026#34;)\r\n        w_text.next_to(loss_text, DOWN)\r\n        b_text = MathTex(f\u0026#34;b = {b_0:.4f}\u0026#34;)\r\n        b_text.next_to(w_text, DOWN)\r\n        param_text = VGroup(loss_text, w_text, b_text)\r\n        self.play(Write(param_text))\r\n\r\n        def data_iter(batch_size, features, labels):\r\n            num = len(features)\r\n            index = list(range(num))\r\n            random.shuffle(index)\r\n            for i in range(0, num, batch_size):\r\n                batch_index = torch.tensor(index[i:min(i+batch_size, num)])\r\n                yield features[batch_index], labels[batch_index]\r\n\r\n        batch_size = 10\r\n\r\n        def linreg(X, w, b):\r\n            return torch.matmul(X, w) + b\r\n\r\n        def squared_loss(y_hat, y):\r\n            return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\r\n\r\n        def sgd(params, lr, batch_size):\r\n            with torch.no_grad():\r\n                for param in params:\r\n                    param -= lr * param.grad / batch_size\r\n                    param.grad.zero_()\r\n\r\n        lr = 0.03\r\n        num_epochs = 3  # Changed to 3 epochs\r\n        net = linreg\r\n        loss = squared_loss\r\n\r\n        update_interval = 1  # Update after every batch\r\n        batch_counter = 0\r\n\r\n        # Start training and update after every backpropagation\r\n        for epoch in range(num_epochs):\r\n            for X, y in data_iter(batch_size, features, labels):\r\n                l = loss(net(X, w, b), y)\r\n                l.sum().backward()\r\n                sgd([w, b], lr, batch_size)\r\n\r\n                batch_counter += 1\r\n                # Get the latest parameters\r\n                new_w_1 = w.detach().numpy()[0][0]\r\n                new_w_2 = w.detach().numpy()[1][0]\r\n                new_b_0 = b.detach().numpy()[0]\r\n\r\n                # Update lines\r\n                new_line_1 = axes_1.plot(lambda x: new_w_1 * x + new_b_0, color=BLUE)\r\n                new_line_2 = axes_2.plot(lambda x: new_w_2 * x + new_b_0, color=BLUE)\r\n                self.play(\r\n                    Transform(line_1, new_line_1),\r\n                    Transform(line_2, new_line_2),\r\n                    run_time=0.1  # Adjusted animation time for smoother update\r\n                )\r\n\r\n                # Update loss and parameter displays\r\n                with torch.no_grad():\r\n                    train_l = loss(net(features, w, b), labels)\r\n                    current_loss = float(train_l.mean())\r\n                new_loss_text = MathTex(f\u0026#34;\\\\text{{Loss}} = {current_loss:.4f}\u0026#34;)\r\n                new_loss_text.to_edge(UP)\r\n                new_w_text = MathTex(f\u0026#34;w_1 = {new_w_1:.4f},\\\\ w_2 = {new_w_2:.4f}\u0026#34;)\r\n                new_w_text.next_to(new_loss_text, DOWN)\r\n                new_b_text = MathTex(f\u0026#34;b = {new_b_0:.4f}\u0026#34;)\r\n                new_b_text.next_to(w_text, DOWN)\r\n                self.play(\r\n                    Transform(loss_text, new_loss_text),\r\n                    Transform(w_text, new_w_text),\r\n                    Transform(b_text, new_b_text),\r\n                    run_time=0.1\r\n                )\r\n\r\n            # Output current epoch\u0026#39;s loss\r\n            print(f\u0026#39;epoch {epoch + 1}, loss {current_loss:f}\u0026#39;)\r\n\r\n        self.wait(2)\n\u003c/code\u003e\u003c/pre\u003e","title":"Linear Regression Display","type":"docs"},{"content":"","date":"Nov 13 2024","externalUrl":null,"permalink":"/tags/econ/","section":"Tags","summary":"","title":"Econ","type":"tags"},{"content":" Last Edit: 11/13/2024\n交易量最大的市场\n货币 #\r行业标准，每种货币用三个字母来代替 一维理解 #\r假设什么都没有，借1.6mJPY去换10kUSD 这时候可以获得USD的利息，但同时需要支付JPY的利息 但如果USD/JPY涨了，而JPY没变，则赚了对应的JPY Forex的特殊性 #\r其覆盖面极广，同时涉及专业公司与市场中的每一个人 Decentralized 去中心化 #\r对于Stock Market可能存在Nasdaq这类的交易所 但是Foreign exchange没有一个中央的交易机构 Market Maker 做市商 #\r提供交易流动性的场所 由于Foreign Exchange是去中心化的，但为了保持资金的流通一般散户甚至公司都会去找到到Marker Marker来做交易 导致了Market Maker的交易量极大的前提下，参与人数极少 Hedge 对冲 #\r而这些Market Maker并不靠与客户的对赌赚钱 而是通过强大的风险管控能力去做对冲 Censorship 监管 #\r由于其Decentralized的特点，其Censorship一般都比较松 这也导致了在交易中动手脚的可能性上升 Fixing 定盘价 #\r在每天London 4PM的时候前后一分钟交易量算出来的均价 类似于Stock的收盘价 全球大量的衍生产品都将高度依赖于这一个价格 只要交易员每天在指定时间只做指定的一个货币，改货币价格直接就上升了 High Frequency Trading #\r依靠算法套利的公司 一笔赚的非常少但是量大 Foreign Payment #\r对于企业，Foreign Exchange的维度又引入了时间的概念 假设造手机，在成本投入的半年后才能开始实现收益，但未来的汇率是不稳定的 Foreign Exchange Forward Comtract 外汇远期合约 #\r在现在对冲掉未来的风险 对于实际情况可能复杂的多，对于供应链上的供应商来说存在更多的情况 债 #\r在当地企业景气的时候，可能存在外资的涌入 但是外资的投资将采用其货币，而为了规避汇率风险则需要引入Cross Currency Swap Cross Currency Swap 货币利率互换协议 #\r可以实现虽然借的是USD债 但通过互换协议相当于规避了Currency的风险 Swap #\r互换的主要交易时基于未来的 其主要是因为对于未来Currency的不确定性导致的 Forex Products by Trading Volume #\rCurrency #\r对于一个国家，货币就衡量了当下所有商品的标尺 但犹豫利率的存在，导致一个3%年利率的国家一年后的103等价于当下的100 （纯理论） 而将两个维度结合便可以形成一个Plane 而Foreign Exchange 则是不同坐标系的转换 即Basis Change Central Bank \u0026amp; Government 央行和政府 #\r央行可以通过一系列操作影响整个市场，但是其并不能起到做庄的效果 互换协议，双边政府互相给钱，促进双方货币在国际贸易上的占比 也是去美元化的一种方法 ","date":"Nov 13 2024","externalUrl":null,"permalink":"/docs/notes/foreignexchange/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/13/2024\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e交易量最大的市场\u003c/p\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e货币 \r\n    \u003cdiv id=\"%E8%B4%A7%E5%B8%81\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E8%B4%A7%E5%B8%81\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/Economic_Static/ForeignExchange/ForeignExchange%E5%A4%96%E6%B1%87.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"Foreign Exchange","type":"docs"},{"content":" Last Edit: 11/10/24\nPolymer 聚合物 #\r前缀“poly-”意指“很多”，暗示了这些聚合物分子结构中有许多重复的部分。 而“mer”指的是“重复单元”或“基元”，这是一种分子的基本单元 Basic Structure #\r与Crystal Structure不同，他们的基本结构是Cubics。并且其会在三维空间（即沿着三个方向）重复排列，形成一个规则的晶体结构 Polymer的结构则不同，它的基元通常只在One Dimnesion上重复，这种重复形成了一条长链 可以看到Polymer的内部结构为长线，而线其实是由很小的分子所组成的 Polyethylene and Polymer #\rPolymer #\r聚合物是一个广义术语，指的是由许多重复单元（基元）组成的长链分子。 聚合物的基元可以是各种各样的分子结构，不限于某一种类型。 Polyethylene #\r聚乙烯是一种具体的聚合物，由重复的乙烯单元（C₂H₄）构成。乙烯单元经过聚合反应形成长链，从而产生聚乙烯。 它是最常见的合成聚合物之一，但只是聚合物的一种类型。 放大上图可以发现 Polyethylene由String结构组成，而String则由分子组成 分子内部，如上图的Polyethylene则是由Hydrogen和Carbon Atoms组成，而Atom之间的作用力则为Intramolecular Bonds（作用在分子内部的相互作用力） Polymer\u0026rsquo;s Deformation #\r在观察超市购买了重物，并将它们放入一个塑料袋中后，可能会发现袋子的把手开始拉伸，甚至感到不适，因为它开始压入手中。随着重量的增加，把手继续拉伸，但在某个点，它似乎停止了延展。有时你甚至能在被拉伸的地方看到颜色的轻微变化 这一现象也可以通过String Model解释 Initial Stage #\r拉伸初期，由于Polymer内部结构仍是Randomly Oriented的Polymer chains没有按照拉伸的方向对齐 于是就可以像拉开松散的线一般将他们分开 Bonds #\rPrimary Bond #\rPrimary bond是 intramolecular bond，存在于一个分子内部的原子之间，例如Covelent Bond或Ionic Bond 这种键非常强，是构成Polymer Chians的基本骨架。 Secondary Bond #\rSecondary bond 是 intermolecular bond，即分子之间的作用力，比如范德华力或氢键 这种键相对较弱，存在于不同分子链之间，允许它们在一定条件下滑动或重新排列 Plastic Deformation Stage #\r随着拉伸的继续，Polymer chains开始发生滑动 滑动可以类比为面条互相滑动的情形 这就是分子间的“Friction”——在Polymer中我们称之为“Intermolecular Force”，也叫“secondary bond” （次级键） Alignment Stage #\r在Polymer Chain到位了之后，Secondary Bond（Inter Molecular Bond）的作用逐渐减小，变为了Primary Bond（Intra Molecular Bond） 所以Polymer的Plastic Deformation所需要的Stress反而会上升 Yield Strength #\r由于对于Polymer来说在发生了Plastic Deformation后其Polymer Chain将会变为Secondary Bond受力，其Stress反而上升了，所以将Curve在Plastic Deformation时候的峰值作为Yield Strength是合理的 The change of mer Units #\r已知Polymer由Polymer Chain组成，而Polymer Chain则是由很多Molecular (Mer)组成的 所以改变Molecular的元素便直接改变了Polymer Polypropylene 聚丙烯 #\r聚丙烯 (PP) 是一种非常常见且有用的聚合物。星巴克® 的那些漂亮的可重复使用杯子就是用 PP 制成的 在塑料瓶的底下可以看到其Recycling Code 为5 通常来说Polypropylene会比Polythylene更加坚固，其来自于额外的\\(CH_3\\) Polyvinylchloride (PVC) #\r出于某些原因，PVC的名字里就出现了Cl，所以其分子当然也包含Cl 而对于PVC中的V来说，其代表了Vinyl，是这种结构 Periodic Table 元素周期表 #\r对于周期表来说，其具有以下特性 周期（横向）趋势：当从左到右观察周期表时，原子半径逐渐减小，电子更接近原子核，因此核对外层电子的吸引力增强，Electronegativity增大 族（纵向）趋势：从周期表的顶端向底部移动时，原子半径增大，外层电子距离原子核更远，核对电子的吸引力减弱，因此Electronegativity减小 Electronegativity 电负性 #\r反应了Atom吸引电子的强弱程度 Bonding 分子键 #\rCovalent Bond 共价键 #\r十分熟悉的一种Bonding Type 一个Molecule中的两个Atom共享Electron Nonpolar Covalent Bond 非极性共价键 #\r当两个原子的Electronegativity几乎相等的时候，形成Nonpolar Covalent Bond 其特性为Electorn将均匀的分布于Atom之间 Polar Covalent Bond 极性共价键 #\r两个Atom的Electronegativity具有明显差异的时候 其仍然是Covalent Bond，但是Sharing的Atom会明显的偏向于其中一个Electronegative更大的Atom 可以发现Cl带有了部分的负电荷（Electron），所以其是具有更高Electronegativity的那个 并且Electrons在Covalent Bond中将会偏向于Cl Ionic Bond 离子键 #\r两个原子间的Electronegativity差极大时，一个Atom将会抢走另外一个的Electron形成Ionic Bond Polytetrafluoroethylene 聚四氟乙烯 #\r一种非反应性的Polymer 每一个Carbon Atom上都结合了大量的Floride，它们很大可以防止PTFE内部不被波坏 虽然Floride的electronegativity很高，但由于其Molecule中的对称性结构，所以形成了一个NonPolar Covalent Bond Hydrophobic 疏水性 #\rPTFE的特殊点在于其为一种Hydrophobic Polymer，具体来说Liquid无法通过其缝隙进入材料，而Gas却可以自由的通过 这就是户外服装在雨中保持干爽的愿意，一般称其为“Breathing\u0026quot; Polymethylmethacrylate 聚甲基丙烯酸甲酯 PMMA #\r一种透明的Polymer 每个合并单元上的大侧基团（通常称为 \u0026ldquo;笨重 \u0026ldquo;侧基）会阻止分子相互靠近组织。 这就确保了聚合物是完全无组织的，或者说是无定形的。 当聚合物结晶时，其折射率与无定形时不同。 如果聚合物中既有无定形的部分，也有结晶的部分（即所谓的半结晶），那么穿过聚合物的光线就不会沿着直接的路径传播，聚合物就会呈现半透明或不透明的状态。 因此，PMMA 之所以是透明的，部分原因是合并单元确保其保持 100% 透明 Length of Polymer Chain #\r前面提到过Polymer Chain是很长的，但却没有给出一个量化的办法 在合成Polymer的时候，控制其分子长度是很困难的 但可以得到一个其长度的分布图 假定一个理想的Polymer Sample，其Polymer Chain的存在需要通过一种分布来描述 描述这个分布的方式并不是通过长度而是重量 具体来说，假设有如下盒子，其里面包含了绳子 木盒子，里面有一段绳子。 你不能打开盒子，你需要确定盒子里绳子的长度。 给你一个空盒子的质量、一根一米长的绳子和一个天平。 你可以用质量来确定盒子里绳子的长度 发现可以通过绳子单位长度的质量计算盒子里绳子的长度 Number Average Molecular Weight 数均分子量 #\r$$\\overline{M}{\\text{number}} = \\frac{\\sum{n=1}^{i} M_n x_n}{\\sum x_n}$$\n所有分子的分子量加总后除以分子总数得到的平均分子量 \\(M_{number}\\)​：数均分子量 \\(M_n​\\)：第n类分子的分子量 \\(x_n\\)：第n类分子的数量比例（即该类别分子数占总分子数的比例） Analogy Candy Box #\rWeight Average Molecular Weight 重均分子量 #\r$$\\overline{M}{\\text{weight}} = \\sum{n=1}^{i} M_n w_n $$\n\\(M_{weight}\\)​：重均分子量 \\(M_n​\\)：第n类分子的分子量 \\(x_n\\)：第n类分子的质量分数（即该类别分子总质量占总所有分子总质量的比例） Analogy #\r用同样的模型说明 Dispersity 分散性 #\r$$\\mathcal{D} = \\frac{\\overline{M}{\\text{weight}}}{\\overline{M}{\\text{number}}} $$\n\\(\\mathcal{D}\\): 分散性 Dispersity \\(M_{weight}\\)​：重均分子量 \\(M_{number}\\)​：数均分子量 当\\(\\mathcal{D} \u0026gt;1\\)时：分子量分布较宽，即多分散（Polydisperse）。随着\\(\\mathcal{D}\\)值增大，分子量的差异越大，分布越宽 Why Molecular Weight Anyway? #\r当面条较长时，很难将一根面条从其他面条中分离出来。 聚合物也是如此，当然，这也是了解分子量如此重要的原因。 随着聚合物分子量的增加，强度也会增加，而且由于长分子的缠结增加，断裂应变通常也会增加。 Ways of molecules stack up #\r聚合物分子虽然通常是线性的，但并非直线。 也就是说，它们是曲线形的 但这并不意味着它们总是完全无序的。 我们还看到，当聚合物发生塑性变形( chain Orientation) 时，会产生一些有序性 Crystalline Polymer 半结晶聚合物 #\r在某些情况下，它们可以在没有任何外部负载的情况下自行有序化 聚乙烯等简单聚合物中的分子通常会在自身上来回折叠 但是由于分子非常长，聚合物永远不可能 100% 结晶 并且由于Crystal Region比Amorphous通过Secondary Bond更牢固地结合在一起，因此这些区域的强度更高 Change of Crystal Density of Polymer 改变聚合物的结晶度 #\r对于Polymer Chain来说，几乎总是有一些所谓的分支从主分子上延伸出来，其仍然是分子的一部分 事实上，我们经常会专门设计一种聚合物，使其具有分支。 低密度聚乙烯LDPE就是这种情况 低密度聚乙烯LDPE中更多和更长的分支降低了分子相互靠近排列的能力，降低了结晶度，从而降低了密度、强度甚至弹性模量 Change of the Intramolecular Bonds #\r想要通过mer unit 改变Polymer整体强度，则可以use elements that are very electronegative We could also ensure that they are bonded to something that is very easy to make positive 于是就可以想到Hydrogen Hydrogen #\r对于Hydrogen来说其有很低的Electronegativity，其Electron很容易被抢走，剩下其Proton 只需要一个有点电负性的元素，氢就会变成正元素 Hydrongen Bond #\r犹豫Hydrogen具有的特小的Electronegativity，导致了其极易产生一个High Strengh Polar Covalent Bond（强偶极子键），所以一种特殊的Bond则尤其命名：Hydrogen Bond Introducing Hydrogen Bond between Molecules #\r将分子之间引入氢键是一种增强分子间相互作用的方式 Cross Link 交联 #\r交联则是通过强的主键（即分子内的共价键）将聚合物分子永久地连接起来，从而显著增强聚合物的强度和弹性。交联聚合物的一个经典例子是天然乳胶橡胶。 在制作弹性体时，交联程度需要适中。如果交联过多，聚合物会变得硬且脆，失去弹性，不再适合作为弹性体 Temperature #\r聚合物的许多特性都是由分子间的弱键造成的 这些键（有时也称为相互作用）更容易被热能破坏，即使温度相对较低：接近室温 在金属或陶瓷中，大部分特性都是由将它们连接在一起的强键、主键的性质决定的（稍后将详细介绍），这些键的键能远远高于接近室温时的热能。 Melting Temperature 熔点温度（Tm​） #\r熔点温度指的是聚合物从固态转变为液态的温度 超过这个温度后，聚合物会像厚液体一样流动 Glass Transition Temperature 玻璃化转变温度 (Tg) #\r通常适用于非晶态或半晶态聚合物 表示的是聚合物从硬脆的“玻璃态”转变为柔软、易变形的“橡胶态”的温度 低于Tg的温度下，聚合物链段的运动受到限制，材料表现出类似玻璃的刚性 高于Tg的温度下，链段有更多的活动空间，材料变得柔软。 Melting Process #\r在加热过程中，热能将首先在Amorphous Region开始破坏分子间的键能。 随着持续加热，热能最终将足以破坏Crystal Region的分子间键 因此，Amorphous Region被破坏时的较低温度被称为Glass Transition Temperature 当Polymer低于Tg时，其像普通窗玻璃一样又硬又脆 Loading Time 施加负载的时间 #\r快速施加负荷：当它被快速拉伸时会像脆性材料一样断裂，且无永久变形。这是因为其分子链较短，在快速拉伸时分子之间没有足够的时间进行重新排列，导致聚合物直接破裂。 长时间施加负荷，聚合物会发生蠕变，即随着时间的延长，材料会逐渐变形 弹性变形（Elastic Deformation） #\r特点：弹性变形是瞬时的，即加载后立即产生变形，卸载后立即恢复原状。 变形性质：弹性变形是可逆的，即材料可以恢复到原始形状，不会有永久的变形残留。 应用场景：在桌子短暂放置在地毯上的情况下，地毯纤维受到压力后会产生弹性变形，但桌子移开后，地毯几乎立即恢复原状。 分子运动：在弹性变形中，聚合物分子链段的变形非常有限，分子间没有发生显著的滑动或重新排列。 粘性变形（Viscous Deformation） #\r特点：粘性变形是随时间累积的，即需要长时间加载才能显现。 变形性质：粘性变形是不可逆的，即变形在卸载后不完全恢复，会留下永久变形。 应用场景：当桌子长时间放置在地毯上（例如一年），地毯纤维会缓慢移动或滑动，导致永久变形，即使桌子移开后，地毯也无法完全恢复原状。 分子运动：在粘性变形中，聚合物分子链段逐渐滑动，重新排列，表现为类似液体流动的行为，这个过程不可逆。 粘弹性变形（Viscoelastic Deformation） #\r聚合物材料通常表现出粘弹性变形，即兼具弹性和粘性变形的特性。它们在短时间内表现为弹性变形，但在长时间加载下逐渐表现出粘性变形。不同聚合物在粘弹性方面有所差异：\nLimits of the noodle model #\r一个模型几乎总是有缺点的。 如果不是这样，我们就会称之为定律 再次考虑前面提到的Transparent Glass， 我们说过，部分原因是由于这种聚合物是完全无定形的，这是事实 但是，这并不能解释为什么Amorphous Polymer本身就应该是透明的 要真正理解这一点，我们需要进一步了解可见光的本质以及光与材料中电子的相互作用 这是因为材料的透明性主要取决于光在其中的传播方式 当可见光照射到材料上时，光会与材料中的电子发生相互作用，而这种相互作用的方式决定了光是被吸收、反射还是通过材料 在透明的非晶态聚合物（如Plexiglas®）中，分子的电子结构允许可见光穿过，而不会显著散射或吸收光，因此表现出透明性。 相比之下，在非晶态金属中，电子结构密集且自由度较高，能够大量吸收和反射光，从而使材料表现为不透明和反光 ","date":"Nov 10 2024","externalUrl":null,"permalink":"/docs/uoft/24/engineering-chemistry--materials-science/ecms6.plastics/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/10/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003ePolymer 聚合物 \r\n    \u003cdiv id=\"polymer-%E8%81%9A%E5%90%88%E7%89%A9\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#polymer-%E8%81%9A%E5%90%88%E7%89%A9\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e前缀“poly-”意指“很多”，暗示了这些聚合物分子结构中有许多重复的部分。\u003c/li\u003e\n\u003cli\u003e而“mer”指的是“重复单元”或“基元”，这是一种分子的基本单元\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eBasic Structure \r\n    \u003cdiv id=\"basic-structure\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#basic-structure\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e与Crystal Structure不同，他们的基本结构是Cubics。并且其会在三维空间（即沿着三个方向）重复排列，形成一个规则的晶体结构\u003c/li\u003e\n\u003cli\u003ePolymer的结构则不同，它的基元通常只在One Dimnesion上重复，这种重复形成了一条长链\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS6.Plastics/ECMS6.Plastics.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"MCMS 6. Plastics","type":"docs"},{"content":" Last Edit: 11/4/2024\nYour browser does not support the video tag. Full Code is Provided\nimport numpy as np import torch import random class LinearRegression(Scene): def construct(self): def data_generator(w,b,num): X = torch.normal(0, 1, (num, len(w))) y = torch.matmul(X, w) + b y += torch.normal(0, 0.01, y.shape) return X, y.reshape((-1, 1)) true_w = torch.tensor([2,-3.4]) true_b = 4.2 features, labels = data_generator(true_w,true_b,1000) normal_data = features[:,[0]].numpy() #plt.hist(normal_data,bins=100,density=True,color=\u0026#39;lightblue\u0026#39;) head = Text(\u0026#34;Linear Regression - Buezwqwg\u0026#34;) head.set_color(BLUE) self.play(Create(head)) head_0 = Text(\u0026#34;In one process of Linear Regression, there bascially includes 5 steps\u0026#34;,font_size=30) self.play(Uncreate(head),Write(head_0)) self.play(head_0.animate.move_to(UP*3.5)) head_1 = Text(\u0026#34;1. Initial Parameters\u0026#34;,font_size=30) head_2 = Text(\u0026#34;2. Defining Model and Loss Function\u0026#34;,font_size=30) head_3 = Text(\u0026#34;3. Optimization\u0026#34;,font_size=30) head_4 = Text(\u0026#34;4. Loop\u0026#34;,font_size=30) head = VGroup(head_1,head_2,head_3,head_4) head.arrange(DOWN) self.play(Write(head)) # -------------------------------------------------------------------------------------------- head_5 = Text(\u0026#34;In this animate, we start with generating the data\u0026#34;,font_size=30) head_5.move_to(UP*3.5) self.play(Uncreate(head),Uncreate(head_0),Write(head_5)) code_text = \u0026#39;\u0026#39;\u0026#39; def data_generator(w, b, num): X = torch.normal(0, 1, (num, len(w))) y = torch.matmul(X, w) + b y += torch.normal(0, 0.01, y.shape) return X, y.reshape((-1, 1)) true_w = torch.tensor([2,-3.4]) true_b = 4.2 features, labels = data_generator(true_w,true_b,1000) \u0026#39;\u0026#39;\u0026#39; code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;) self.play(Write(code),Uncreate(head_5),run_time=3) self.wait(3) self.play(Unwrite(code)) axes = Axes( x_range=[-4, 4, 1], y_range=[0, 0.5, 0.1], axis_config={\u0026#34;color\u0026#34;: BLUE}, ).add_coordinates() # 正态分布函数 y = (1/sqrt(2*pi)) * exp(-x^2 / 2) normal_curve = axes.plot( lambda x: (1 / (2 * PI) ** 0.5) * np.exp(-x**2 / 2), color=YELLOW ) # 绘制均值为0的竖线 mean_line = DashedLine( start=axes.c2p(0, 0), end=axes.c2p(0, (1 / (2 * PI) ** 0.5)), color=RED ) # 添加图形和标注 self.play(Create(axes)) self.play(Create(normal_curve), Create(mean_line)) # 标注均值和标准差 mean_label = MathTex(r\u0026#34;\\mu=0\u0026#34;).next_to(mean_line, DOWN) std_label = MathTex(r\u0026#34;\\sigma=1\u0026#34;).next_to(normal_curve, UP, buff=0.5) self.play(Write(mean_label), Write(std_label)) # 展示最终效果 self.wait(2) self.play(Unwrite(mean_label),Unwrite(std_label),Uncreate(axes),Uncreate(normal_curve),Uncreate(mean_line)) # -------------------------------------------------------------------------------------------- head = Text(\u0026#34;Displaying the distribution of features\u0026#34;) feature_one = features[:,[0]].tolist() feature_two = features[:,[1]].tolist() labels = labels.tolist() axes_1 = Axes( x_range=[min(feature_one)[0], max(feature_one)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=5, # x轴的长度 y_length=5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes_2 = Axes( x_range=[min(feature_two)[0], max(feature_two)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=5, # x轴的长度 y_length=5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes = VGroup(axes_1,axes_2) axes.arrange(RIGHT,buff=1) self.play(Create(axes)) points_1 = [] for i in range(len(labels)): dot_position = axes_1.coords_to_point(feature_one[i][0], labels[i][0]) points_1.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_1 = [Create(dot) for dot in points_1] points_2 = [] for i in range(len(labels)): dot_position = axes_2.coords_to_point(feature_two[i][0], labels[i][0]) points_2.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_2 = [Create(dot) for dot in points_2] self.play(Succession(*animations_1, lag_ratio=0.005),Succession(*animations_2, lag_ratio=0.005)) # 抽取样本-------------------------------------------------------------------------------------------- head = Text(\u0026#39;Shuffle the data and divided into samples(batches)\u0026#39;,font_size=30) self.play(Uncreate(axes),Write(head),Uncreate(VGroup(*points_1)),Uncreate(VGroup(*points_2))) head.move_to(UP*3.5) code_text = \u0026#39;\u0026#39;\u0026#39; def data_iter(batch_size,features,labels): num = len(features) index = list(range(num)) random.shuffle(index) for i in range(0,num,batch_size): batch_index = torch.tensor(index[i:min(i+batch_size,num)]) yield features[batch_index], labels[batch_index] \u0026#39;\u0026#39;\u0026#39; code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;) self.play(Write(code)) self.wait(2) self.play(Uncreate(code),Unwrite(head)) def data_iter(batch_size,features,labels): num = len(features) index = list(range(num)) random.shuffle(index) for i in range(0,num,batch_size): batch_index = torch.tensor(index[i:min(i+batch_size,num)]) return batch_index.tolist() axes_1 = Axes( x_range=[min(feature_one)[0], max(feature_one)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=2.5, # x轴的长度 y_length=2.5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes_2 = Axes( x_range=[min(feature_one)[0], max(feature_one)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=2.5, # x轴的长度 y_length=2.5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes_3 = Axes( x_range=[min(feature_one)[0], max(feature_one)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=2.5, # x轴的长度 y_length=2.5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes_4 = Axes( x_range=[min(feature_one)[0], max(feature_one)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=2.5, # x轴的长度 y_length=2.5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes_5 = Axes( x_range=[min(feature_one)[0], max(feature_one)[0], 1], # x轴范围：从-5到5，步长为1 y_range=[min(labels)[0], max(labels)[0], 5], # y轴范围：从-3到3，步长为1 x_length=2.5, # x轴的长度 y_length=2.5, # y轴的长度 axis_config={\u0026#34;color\u0026#34;: BLUE}, # 坐标轴的颜色 ) axes = VGroup(axes_1,axes_2,axes_3,axes_4,axes_5) axes.arrange(RIGHT) sample_1 = data_iter(10,features,labels) points_1 = [] for i in sample_1: dot_position = axes_1.coords_to_point(features[i][0],labels[i][0]) points_1.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_1 = [Create(dot) for dot in points_1] sample_2 = data_iter(10,features,labels) points_2 = [] for i in sample_2: dot_position = axes_2.coords_to_point(features[i][0],labels[i][0]) points_2.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_2 = [Create(dot) for dot in points_2] sample_3 = data_iter(10,features,labels) points_3 = [] for i in sample_3: dot_position = axes_3.coords_to_point(features[i][0],labels[i][0]) points_3.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_3 = [Create(dot) for dot in points_3] sample_4 = data_iter(10,features,labels) points_4 = [] for i in sample_4: dot_position = axes_4.coords_to_point(features[i][0],labels[i][0]) points_4.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_4 = [Create(dot) for dot in points_4] sample_5 = data_iter(10,features,labels) points_5 = [] for i in sample_5: dot_position = axes_5.coords_to_point(features[i][0],labels[i][0]) points_5.append(Dot(point=dot_position, radius=0.05, color=YELLOW)) animations_5 = [Create(dot) for dot in points_5] head = Text(\u0026#34;Display five of Sample Batches (Batch Size = 10)\u0026#34;,font_size=30) head.set_color(BLUE) head.move_to(UP*2.5) self.play(Write(head)) self.play(Create(axes),Succession(*animations_1, lag_ratio=0.05),Succession(*animations_2, lag_ratio=0.05),Succession(*animations_3, lag_ratio=0.05),Succession(*animations_4, lag_ratio=0.05),Succession(*animations_5, lag_ratio=0.05)) self.wait(3) self.play(Uncreate(axes),Uncreate(head),Uncreate(VGroup(*points_1)),Uncreate(VGroup(*points_2)),Uncreate(VGroup(*points_3)),Uncreate(VGroup(*points_4)),Uncreate(VGroup(*points_5))) # 定义模型-------------------------------------------------------------------------------------------- head_1 = Text(\u0026#39;Define the Function\u0026#39;) head_1.set_color(BLUE) code_text_1 = \u0026#39;\u0026#39;\u0026#39; def linreg(X, w, b): return torch.matmul(X, w) + b \u0026#39;\u0026#39;\u0026#39; code_1 = Code(code=code_text_1,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;) head_2 = Text(\u0026#39;Define the Loss Function\u0026#39;) head_2.set_color(BLUE) code_text_2 = \u0026#39;\u0026#39;\u0026#39; def squared_loss(y_hat, y): return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2 \u0026#39;\u0026#39;\u0026#39; code_2 = Code(code=code_text_2,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;) head = VGroup(head_1,code_1,head_2,code_2) head.arrange(DOWN,buff=1) self.play(Write(head)) self.wait(2) self.play(Unwrite(head)) # 展示MSE-------------------------------------------------------------------------------------------- head = MathTex(r\u0026#34;Lose~Function~MSE~:(y_i - \\hat{y}_i)^2\u0026#34;) head.set_color(BLUE) head.move_to(UP*3) self.play(Write(head)) axes = Axes( x_range=[-10, 10, 2.5], y_range=[0, 100, 20], x_length=10, y_length=5, axis_config={\u0026#34;color\u0026#34;: GREEN}, ) # 定义MSE函数 mse_curve = axes.plot(lambda x: (x**2), color=BLUE, x_range=[-10, 10]) mse_der = axes.plot(lambda x: (2*x), color=RED, x_range=[-10, 10]) # 将元素添加到场景中 self.play(Create(axes),Create(mse_curve)) self.wait(2) self.play(Uncreate(head)) head = Text(\u0026#34;The MSE Derivative indicates that loss will be increasing as it increase\u0026#34;,font_size=30) head.set_color(BLUE) head.move_to(UP*3) self.play(Write(head),Create(mse_der)) self.wait(3) self.play(Uncreate(head),Uncreate(mse_der),Uncreate(mse_curve),Uncreate(axes)) # 展示SGD-------------------------------------------------------------------------------------------- head = Text(\u0026#34;Now Conduct the Optimization Method\u0026#34;) head.move_to(UP*3) head.set_color(BLUE) code_text = \u0026#39;\u0026#39;\u0026#39; def sgd(params, lr, batch_size): with torch.no_grad(): for param in params: param -= lr * param.grad / batch_size param.grad.zero_() \u0026#39;\u0026#39;\u0026#39; code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;) head_2 = Text(\u0026#39;Apply this optimization method for each batch\u0026#39;) head_2.set_color(BLUE) sgd = MathTex(r\u0026#34;(w,b)\\leftarrow (w,b)-\\eta g\u0026#34;) main = VGroup(head,code,head_2,sgd) main.arrange(DOWN,buff=0.7) self.play(Write(main)) self.wait(2) self.play(Uncreate(main),run_time=0.1) # 计算梯度-------------------------------------------------------------------------------------------- head = Text(\u0026#34;Now Calculate the Gradient\u0026#34;) head.set_color(BLUE) head.move_to(UP*3) grad = MathTex(r\u0026#34;\\frac{\\partial \\text{MSE}}{\\partial w} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\partial}{\\partial w} \\left( y_i - (w x_i + b) \\right)^2\u0026#34;) grad_1 = MathTex(r\u0026#34;= \\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - (wx_i + b)) \\cdot (-x_i)\u0026#34;) grad_2 = MathTex(r\u0026#34;= -\\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - \\hat{y}_i) \\cdot x_i\u0026#34;) main = VGroup(head,grad,grad_1,grad_2) main.arrange(DOWN,buff=0.7) self.play(Write(main)) self.wait(2) self.play(Uncreate(main),run_time=0.01) head = Text(\u0026#34;Then apllies the formula for 1000/10=100 Times\u0026#34;,font_size=45) head.set_color(BLUE) grad = MathTex(r\u0026#39;w := w + \\eta \\cdot \\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - \\hat{y}_i) \\cdot x_i\u0026#39;) grad_1 = MathTex(r\u0026#34;b := b + \\eta \\cdot \\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - \\hat{y}_i)\u0026#34;) main = VGroup(head,grad,grad_1) main.arrange(DOWN,buff=0.7) self.play(Write(main)) self.wait(3) self.play(Uncreate(main),run_time=0.01) # 总结-------------------------------------------------------------------------------------------- code_text = \u0026#39;\u0026#39;\u0026#39; lr = 0.03 num_epochs = 3 net = linreg loss = squared_loss for epoch in range(num_epochs): for X, y in data_iter(batch_size, features, labels): l = loss(net(X, w, b), y) l.sum().backward() sgd([w, b], lr, batch_size) with torch.no_grad(): train_l = loss(net(features, w, b), labels) print(f\u0026#39;epoch {epoch + 1}, loss {float(train_l.mean()):f}\u0026#39;) \u0026#39;\u0026#39;\u0026#39; code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;) head = Text(\u0026#34;Then applies the whole process in epochs and that\u0026#39;s linear regression\u0026#34;,font_size=30) main = VGroup(head,code) main.arrange(DOWN,buff=1) self.play(Write(main)) --- ","date":"Nov 4 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/linearregression/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/4/2024\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cvideo width=\"640\" height=\"360\" controls\u003e\n  \u003csource src=\"LinearRegression.mp4\" type=\"video/mp4\"\u003e\n  Your browser does not support the video tag.\n\u003c/video\u003e\n\u003cp\u003eFull Code is Provided\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-from\" data-lang=\"from\"\u003eimport numpy as np\nimport torch\nimport random\n\nclass LinearRegression(Scene):\n    def construct(self):\n        def data_generator(w,b,num):\n            X = torch.normal(0, 1, (num, len(w)))\n            y = torch.matmul(X, w) + b\n            y += torch.normal(0, 0.01, y.shape)\n            return X, y.reshape((-1, 1))\n\n        true_w = torch.tensor([2,-3.4])\n        true_b = 4.2\n        features, labels = data_generator(true_w,true_b,1000)\n        normal_data = features[:,[0]].numpy()\n        #plt.hist(normal_data,bins=100,density=True,color=\u0026#39;lightblue\u0026#39;)  \n         \n\n        head = Text(\u0026#34;Linear Regression - Buezwqwg\u0026#34;)\n        head.set_color(BLUE)\n        self.play(Create(head))\n\n        head_0 = Text(\u0026#34;In one process of Linear Regression, there bascially includes 5 steps\u0026#34;,font_size=30)\n        self.play(Uncreate(head),Write(head_0))\n        self.play(head_0.animate.move_to(UP*3.5))\n        head_1 = Text(\u0026#34;1. Initial Parameters\u0026#34;,font_size=30)\n        head_2 = Text(\u0026#34;2. Defining Model and Loss Function\u0026#34;,font_size=30)\n        head_3 = Text(\u0026#34;3. Optimization\u0026#34;,font_size=30)\n        head_4 = Text(\u0026#34;4. Loop\u0026#34;,font_size=30)\n        head = VGroup(head_1,head_2,head_3,head_4)\n        head.arrange(DOWN)\n        self.play(Write(head))\n\n        # --------------------------------------------------------------------------------------------\n\n        head_5 = Text(\u0026#34;In this animate, we start with generating the data\u0026#34;,font_size=30)\n        head_5.move_to(UP*3.5)\n        self.play(Uncreate(head),Uncreate(head_0),Write(head_5))\n        code_text = \u0026#39;\u0026#39;\u0026#39;\n        def data_generator(w, b, num):\n            X = torch.normal(0, 1, (num, len(w)))\n            y = torch.matmul(X, w) + b\n            y += torch.normal(0, 0.01, y.shape)\n            return X, y.reshape((-1, 1))\n            \n        true_w = torch.tensor([2,-3.4])\n        true_b = 4.2\n        features, labels = data_generator(true_w,true_b,1000)\n        \u0026#39;\u0026#39;\u0026#39;\n        code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;)\n        self.play(Write(code),Uncreate(head_5),run_time=3)\n        self.wait(3)\n        self.play(Unwrite(code))\n        axes = Axes(\n            x_range=[-4, 4, 1],\n            y_range=[0, 0.5, 0.1],\n            axis_config={\u0026#34;color\u0026#34;: BLUE},\n        ).add_coordinates()\n\n        # 正态分布函数 y = (1/sqrt(2*pi)) * exp(-x^2 / 2)\n        normal_curve = axes.plot(\n            lambda x: (1 / (2 * PI) ** 0.5) * np.exp(-x**2 / 2),\n            color=YELLOW\n        )\n\n        # 绘制均值为0的竖线\n        mean_line = DashedLine(\n            start=axes.c2p(0, 0),\n            end=axes.c2p(0, (1 / (2 * PI) ** 0.5)),\n            color=RED\n        )\n\n        # 添加图形和标注\n        self.play(Create(axes))\n        self.play(Create(normal_curve), Create(mean_line))\n        \n        # 标注均值和标准差\n        mean_label = MathTex(r\u0026#34;\\mu=0\u0026#34;).next_to(mean_line, DOWN)\n        std_label = MathTex(r\u0026#34;\\sigma=1\u0026#34;).next_to(normal_curve, UP, buff=0.5)\n        self.play(Write(mean_label), Write(std_label))\n\n        # 展示最终效果\n        self.wait(2)\n        self.play(Unwrite(mean_label),Unwrite(std_label),Uncreate(axes),Uncreate(normal_curve),Uncreate(mean_line))\n\n        # --------------------------------------------------------------------------------------------\n\n        head = Text(\u0026#34;Displaying the distribution of features\u0026#34;)\n        feature_one = features[:,[0]].tolist()\n        feature_two = features[:,[1]].tolist()\n        labels = labels.tolist()\n        axes_1 = Axes(\n            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=5,  # x轴的长度\n            y_length=5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        axes_2 = Axes(\n            x_range=[min(feature_two)[0], max(feature_two)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=5,  # x轴的长度\n            y_length=5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        axes = VGroup(axes_1,axes_2)\n        axes.arrange(RIGHT,buff=1)\n        self.play(Create(axes))\n\n        points_1 = []\n        for i in range(len(labels)):\n            dot_position = axes_1.coords_to_point(feature_one[i][0], labels[i][0])\n            points_1.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_1 = [Create(dot) for dot in points_1]\n        points_2 = []\n        for i in range(len(labels)):\n            dot_position = axes_2.coords_to_point(feature_two[i][0], labels[i][0])\n            points_2.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_2 = [Create(dot) for dot in points_2]\n        self.play(Succession(*animations_1, lag_ratio=0.005),Succession(*animations_2, lag_ratio=0.005))\n\n        # 抽取样本-------------------------------------------------------------------------------------------- \n\n        head = Text(\u0026#39;Shuffle the data and divided into samples(batches)\u0026#39;,font_size=30)\n        self.play(Uncreate(axes),Write(head),Uncreate(VGroup(*points_1)),Uncreate(VGroup(*points_2)))\n        head.move_to(UP*3.5)\n        code_text = \u0026#39;\u0026#39;\u0026#39;\n        def data_iter(batch_size,features,labels):\n            num = len(features)\n            index = list(range(num))\n            random.shuffle(index)\n            for i in range(0,num,batch_size):\n                batch_index = torch.tensor(index[i:min(i+batch_size,num)])\n                yield features[batch_index], labels[batch_index]\n        \u0026#39;\u0026#39;\u0026#39;\n        code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;)\n        self.play(Write(code))\n        self.wait(2)\n        self.play(Uncreate(code),Unwrite(head))\n\n        def data_iter(batch_size,features,labels):\n            num = len(features)\n            index = list(range(num))\n            random.shuffle(index)\n            for i in range(0,num,batch_size):\n                batch_index = torch.tensor(index[i:min(i+batch_size,num)])\n                return batch_index.tolist()\n\n\n\n        axes_1 = Axes(\n            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=2.5,  # x轴的长度\n            y_length=2.5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        \n\n        axes_2 = Axes(\n            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=2.5,  # x轴的长度\n            y_length=2.5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        \n        axes_3 = Axes(\n            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=2.5,  # x轴的长度\n            y_length=2.5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        axes_4 = Axes(\n            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=2.5,  # x轴的长度\n            y_length=2.5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        axes_5 = Axes(\n            x_range=[min(feature_one)[0], max(feature_one)[0], 1],  # x轴范围：从-5到5，步长为1\n            y_range=[min(labels)[0], max(labels)[0], 5],  # y轴范围：从-3到3，步长为1\n            x_length=2.5,  # x轴的长度\n            y_length=2.5,  # y轴的长度\n            axis_config={\u0026#34;color\u0026#34;: BLUE},  # 坐标轴的颜色\n        )\n        axes = VGroup(axes_1,axes_2,axes_3,axes_4,axes_5)\n        axes.arrange(RIGHT)\n\n        sample_1 = data_iter(10,features,labels)\n        points_1 = []\n        for i in sample_1:\n            dot_position = axes_1.coords_to_point(features[i][0],labels[i][0])\n            points_1.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_1 = [Create(dot) for dot in points_1]\n\n        sample_2 = data_iter(10,features,labels)\n        points_2 = []\n        for i in sample_2:\n            dot_position = axes_2.coords_to_point(features[i][0],labels[i][0])\n            points_2.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_2 = [Create(dot) for dot in points_2]\n\n        sample_3 = data_iter(10,features,labels)\n        points_3 = []\n        for i in sample_3:\n            dot_position = axes_3.coords_to_point(features[i][0],labels[i][0])\n            points_3.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_3 = [Create(dot) for dot in points_3]\n\n        sample_4 = data_iter(10,features,labels)\n        points_4 = []\n        for i in sample_4:\n            dot_position = axes_4.coords_to_point(features[i][0],labels[i][0])\n            points_4.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_4 = [Create(dot) for dot in points_4]\n\n        sample_5 = data_iter(10,features,labels)\n        points_5 = []\n        for i in sample_5:\n            dot_position = axes_5.coords_to_point(features[i][0],labels[i][0])\n            points_5.append(Dot(point=dot_position, radius=0.05, color=YELLOW))\n        animations_5 = [Create(dot) for dot in points_5]   \n        head = Text(\u0026#34;Display five of Sample Batches (Batch Size = 10)\u0026#34;,font_size=30)\n        head.set_color(BLUE)\n        head.move_to(UP*2.5)\n        self.play(Write(head))\n        self.play(Create(axes),Succession(*animations_1, lag_ratio=0.05),Succession(*animations_2, lag_ratio=0.05),Succession(*animations_3, lag_ratio=0.05),Succession(*animations_4, lag_ratio=0.05),Succession(*animations_5, lag_ratio=0.05))\n        self.wait(3)\n        self.play(Uncreate(axes),Uncreate(head),Uncreate(VGroup(*points_1)),Uncreate(VGroup(*points_2)),Uncreate(VGroup(*points_3)),Uncreate(VGroup(*points_4)),Uncreate(VGroup(*points_5)))\n\n        # 定义模型-------------------------------------------------------------------------------------------- \n\n        head_1 = Text(\u0026#39;Define the Function\u0026#39;)\n        head_1.set_color(BLUE)\n        code_text_1 = \u0026#39;\u0026#39;\u0026#39;\n        def linreg(X, w, b):\n            return torch.matmul(X, w) + b\n        \u0026#39;\u0026#39;\u0026#39;\n        code_1 = Code(code=code_text_1,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;)\n        head_2 = Text(\u0026#39;Define the Loss Function\u0026#39;)\n        head_2.set_color(BLUE)\n        code_text_2 = \u0026#39;\u0026#39;\u0026#39;\n        def squared_loss(y_hat, y):\n            return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\n        \u0026#39;\u0026#39;\u0026#39;\n\n\n        code_2 = Code(code=code_text_2,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;)\n        head = VGroup(head_1,code_1,head_2,code_2)\n        head.arrange(DOWN,buff=1)\n        self.play(Write(head))\n        self.wait(2)\n        self.play(Unwrite(head))\n\n        # 展示MSE--------------------------------------------------------------------------------------------    \n        head = MathTex(r\u0026#34;Lose~Function~MSE~:(y_i - \\hat{y}_i)^2\u0026#34;)\n        head.set_color(BLUE)\n        head.move_to(UP*3)\n        self.play(Write(head))\n        axes = Axes(\n            x_range=[-10, 10, 2.5],\n            y_range=[0, 100, 20],\n            x_length=10,\n            y_length=5,\n            axis_config={\u0026#34;color\u0026#34;: GREEN},\n        )\n        \n        # 定义MSE函数\n        mse_curve = axes.plot(lambda x: (x**2), color=BLUE, x_range=[-10, 10])\n        mse_der = axes.plot(lambda x: (2*x), color=RED, x_range=[-10, 10])\n        # 将元素添加到场景中\n        self.play(Create(axes),Create(mse_curve))\n        self.wait(2)\n        self.play(Uncreate(head))\n        head = Text(\u0026#34;The MSE Derivative indicates that loss will be increasing as it increase\u0026#34;,font_size=30)\n        head.set_color(BLUE)\n        head.move_to(UP*3)\n        self.play(Write(head),Create(mse_der))\n        self.wait(3)\n        self.play(Uncreate(head),Uncreate(mse_der),Uncreate(mse_curve),Uncreate(axes))\n\n\n        # 展示SGD--------------------------------------------------------------------------------------------\n        head = Text(\u0026#34;Now Conduct the Optimization Method\u0026#34;)\n        head.move_to(UP*3)\n        head.set_color(BLUE)\n        code_text = \u0026#39;\u0026#39;\u0026#39;\n        def sgd(params, lr, batch_size):\n        with torch.no_grad():\n            for param in params:\n                param -= lr * param.grad / batch_size\n                param.grad.zero_()\n        \u0026#39;\u0026#39;\u0026#39;\n        code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;)\n        head_2 = Text(\u0026#39;Apply this optimization method for each batch\u0026#39;)\n        head_2.set_color(BLUE)\n        sgd = MathTex(r\u0026#34;(w,b)\\leftarrow (w,b)-\\eta g\u0026#34;)\n        main = VGroup(head,code,head_2,sgd)\n        main.arrange(DOWN,buff=0.7)\n        self.play(Write(main))\n        self.wait(2)\n        self.play(Uncreate(main),run_time=0.1)\n        \n        # 计算梯度--------------------------------------------------------------------------------------------\n        head = Text(\u0026#34;Now Calculate the Gradient\u0026#34;)\n        head.set_color(BLUE)\n        head.move_to(UP*3)\n        grad = MathTex(r\u0026#34;\\frac{\\partial \\text{MSE}}{\\partial w} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\partial}{\\partial w} \\left( y_i - (w x_i + b) \\right)^2\u0026#34;)\n        grad_1 = MathTex(r\u0026#34;= \\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - (wx_i + b)) \\cdot (-x_i)\u0026#34;)\n        grad_2 = MathTex(r\u0026#34;= -\\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - \\hat{y}_i) \\cdot x_i\u0026#34;)\n\n        main = VGroup(head,grad,grad_1,grad_2)\n        main.arrange(DOWN,buff=0.7)\n        self.play(Write(main))\n        self.wait(2)\n        self.play(Uncreate(main),run_time=0.01)\n        head = Text(\u0026#34;Then apllies the formula for 1000/10=100 Times\u0026#34;,font_size=45)\n        head.set_color(BLUE)\n        grad = MathTex(r\u0026#39;w := w + \\eta \\cdot \\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - \\hat{y}_i) \\cdot x_i\u0026#39;)\n        grad_1 = MathTex(r\u0026#34;b := b + \\eta \\cdot \\frac{1}{n} \\sum_{i=1}^{n} 2(y_i - \\hat{y}_i)\u0026#34;)\n        main = VGroup(head,grad,grad_1)\n        main.arrange(DOWN,buff=0.7)\n        self.play(Write(main))\n        self.wait(3)\n        self.play(Uncreate(main),run_time=0.01)\n\n        # 总结--------------------------------------------------------------------------------------------\n        code_text = \u0026#39;\u0026#39;\u0026#39;\n        lr = 0.03\n        num_epochs = 3\n        net = linreg\n        loss = squared_loss\n\n        for epoch in range(num_epochs):\n            for X, y in data_iter(batch_size, features, labels):\n                l = loss(net(X, w, b), y)\n                l.sum().backward()\n                sgd([w, b], lr, batch_size)\n            with torch.no_grad():\n                train_l = loss(net(features, w, b), labels)\n                print(f\u0026#39;epoch {epoch + 1}, loss {float(train_l.mean()):f}\u0026#39;)\n        \u0026#39;\u0026#39;\u0026#39;\n        code = Code(code=code_text,insert_line_no=False,language=\u0026#34;Python\u0026#34;,font=\u0026#34;Monospace\u0026#34;)\n        head = Text(\u0026#34;Then applies the whole process in epochs and that\u0026#39;s linear regression\u0026#34;,font_size=30)\n        main = VGroup(head,code)\n        main.arrange(DOWN,buff=1)\n        self.play(Write(main))\n---\n\u003c/code\u003e\u003c/pre\u003e","title":"Linear Regression","type":"docs"},{"content":" Last Edit: 10/24/24\nIntroduction to Determinate #\r行列式是一个每个方阵都具有的数值 Determinate measures the factor by which the area of a given region increases or decreases The \u0026ldquo;determinant\u0026rdquo; of a transformation Determinate in R^2 #\rDeterminant计算的是Linear Transformation改变的Basis Vector所围成的面积的大小\n而对于一个Linear Transformation，大部分情况下Basis Vector围成的面积都是一个长方形\n而[[MAT188 Chapter 2 Linear Transformations#2.2 Linear Transformations in Geometry]]中存在一种Sheer Transformation，即对于一个Basis Vector来说，其出现了不属于其方向上的分量\n如上图中的\\(\\vec e_2\\)来说，其为\u0026lt;2,2\u0026gt;，即产生了Sheer\n在这种情况下，所围成的面积便成为了Parallelogram\n于是就有了两种计算\\(\\mathbb R^2\\)行列式的办法 $$det(A)=|A||B|sin\\theta$$ 这个平行四边形同时适用于Cross Product于Determinate\n这一个公式同样也是[[Cross Product 向量叉乘]]的大小（Norm），同时也是一个3x3Determinate的大小（体积）\n如果说Cross Product要找的是一个向量，Determinate要找的则是一个体积\n总的来说，要找\\(R^2\\)中的Determinate的值，其本质在求Linear Transformation后Basis Vector围成的面积\n而这一个面积可以通过\\(|A||B|sin\\theta\\)求，其同时也可以通过\n两个向量的Position Vector上的点的差值求 其最后化简之后便有 $$\\text{det} \\left( \\begin{bmatrix} a \u0026amp; b \\ c \u0026amp; d \\end{bmatrix} \\right) = (a + b)(c + d) - ac - bd - 2bc = ad - bc $$ 这便是Determinate最初的定义 The Determinate of a 3x3 Matrix #\r$$A = \\begin{bmatrix} a_{11} \u0026amp; a_{12} \u0026amp; a_{13} \\ a_{21} \u0026amp; a_{22} \u0026amp; a_{23} \\ a_{31} \u0026amp; a_{32} \u0026amp; a_{33} \\end{bmatrix} = \\begin{bmatrix} | \u0026amp; | \u0026amp; | \\ \\vec{u} \u0026amp; \\vec{v} \u0026amp; \\vec{w} \\ | \u0026amp; | \u0026amp; | \\end{bmatrix} $$\n3x3的Matrix的Determinate的几何意义为在\\(\\mathbb R^3\\)中的Parallelepiped的Volume 而对于\\(\\mathbb R^3\\)中的三个向量来说，如果它们线性相关（如共面，即两个向量可以通过Lienar Conbination得到第三个向量的情况下），则他们在3x3Determinate的几何意义也是就是体积便不再存在，其是一个高度为0的长方体 具体来说判断的方法便是\\(\\vec{u} \\cdot (\\vec{v} \\times \\vec{w}) = 0\\)，见下图 Determinate为0的几何意义 #\r具体来说，当\\(det(A)=0\\)的时候，其相当于一个Linear Transformation至少压缩了一个维度 而在维度被压缩之后，此过程并不可逆，见下图 Definition 6.1.1 Determinant of a 3 × 3 matrix, in terms of the Columns #\r在上面提到过了行列式的几何意义为体积，而\\(\\vec u,\\vec v\\)并不会一直出现在xy Plane中，要计算其体积，基本上要用底面积乘以高的形式 而底面积则可以通过\\(\\vec c= \\vec v\\times \\vec w\\)的Cross Product，同时求出其大小与方向 具体来说，其大小即为\\(|u|\\)，而其方向应该是垂直于vw Plane的 而将\\(\\vec u\\cdot \\vec c\\)时，则可以得到Determinate中的第三个Vetor在一个垂直于vw Plane的同时具有方向和大小的向量\\(\\vec c\\)上的Projection长度乘以其向量\\(\\vec c\\)（本身Norm为vw所围成的平行四边形的面积） 则最终得到Determinate中的第三个向量\\(\\vec u\\)在一个垂直于vw Plane的方向上的分量，在几何意义上来说为平行六面体的高 和一个\\(\\vec v\\times \\vec w\\)所得到的两个向量围成的平行四边形的长度，即平行六面体的底面积 两者相乘便可以得到该3x3 Matrix Determinate的值，即这三个Vector所围成的Parallelepiped体积\\ $$\\begin{align}\\text{det} , A = \\vec{u} \\cdot (\\vec{v} \\times \\vec{w}) \\ = \\begin{bmatrix} a_{11} \\ a_{21} \\ a_{31} \\end{bmatrix} \\cdot \\left( \\begin{bmatrix} a_{12} \\ a_{22} \\ a_{32} \\end{bmatrix} \\times \\begin{bmatrix} a_{13} \\ a_{23} \\ a_{33} \\end{bmatrix} \\right) \\ = \\begin{bmatrix} a_{11} \\ a_{21} \\ a_{31} \\end{bmatrix} \\cdot \\begin{bmatrix} a_{22}a_{33} - a_{32}a_{23} \\ a_{32}a_{13} - a_{12}a_{33} \\ a_{12}a_{23} - a_{22}a_{13} \\end{bmatrix} \\ = a_{11}(a_{22}a_{33} - a_{32}a_{23}) + a_{21}(a_{32}a_{13} - a_{12}a_{33}) + a_{31}(a_{12}a_{23} - a_{22}a_{13}) \\ = a_{11}a_{22}a_{33} - a_{11}a_{32}a_{23} + a_{21}a_{32}a_{13} - a_{21}a_{12}a_{33} + a_{31}a_{12}a_{23} - a_{31}a_{22}a_{13}\\end{align} $$\n上述介绍的所有都是有助于理解Determinant的而非考试的重点，意义在于理解，正式的内容将从下面开始\nProperties of Determinant #\rLinearity of Determinant #\r行列式对任何一列或一行都是线性的 也就是说，当我们把一列（或一行）表示为两个向量的和或乘以一个标量时，行列式也可以相应地拆分为两个行列式的和，或乘以标量 当有如下Determinate时 $$L(\\vec{x}) = \\text{det} \\left( \\begin{bmatrix}\r- \u0026 \\vec{v}_1 \u0026 - \\\\\r- \u0026 \\vec{v}_2 \u0026 - \\\\\r- \u0026 \\vec{x}+\\vec y \u0026 -\r\\end{bmatrix}\r\\right)$$\r- Matrix23位置的值为一个Variable x，而因为det在任意一行，列中都是线性的，即其也满足Linear的两个定义\r$$L(\\vec{x} + \\vec{y}) = L(\\vec{x}) + L(\\vec{y}) \\quad \\text{and} \\quad L(k\\vec{x}) = kL(\\vec{x})$$\r- 在Determinate中有\r$$\\text{det} \\left( \\begin{bmatrix}\r- \u0026 \\vec{v}_1 \u0026 - \\\\\r- \u0026 \\vec{v}_2 \u0026 - \\\\\r- \u0026 \\vec{x} + \\vec{y} \u0026-\r\\end{bmatrix}\r\\right)\r= \\text{det} \\left( \\begin{bmatrix}\r- \u0026 \\vec{v}_1 \u0026 - \\\\\r- \u0026 \\vec{v}_2 \u0026 - \\\\\r- \u0026 \\vec{x} \u0026 -\r\\end{bmatrix}\r\\right)\r+ \\text{det} \\left( \\begin{bmatrix}\r- \u0026 \\vec{v}_1 \u0026 - \\\\\r- \u0026 \\vec{v}_2 \u0026 - \\\\\r- \u0026 \\vec{y} \u0026 -\r\\end{bmatrix}\r\\right)\r$$\r$$\\text{det} \\left( \\begin{bmatrix}\r- \u0026 \\vec{v}_1 \u0026 - \\\\\r- \u0026 \\vec{v}_2 \u0026 - \\\\\r- \u0026 k\\vec{x} \u0026 -\r\\end{bmatrix}\r\\right)\r= k \\, \\text{det} \\left( \\begin{bmatrix}\r- \u0026 \\vec{v}_1 \u0026 - \\\\\r- \u0026 \\vec{v}_2 \u0026 - \\\\\r- \u0026 \\vec{x} \u0026 -\r\\end{bmatrix}\r\\right)\r$$\r- 如果在矩阵的一行乘上 t而剩下的n-1行保持不变，则行列式的值就要乘上 t\r$$\\left| \\begin{array}{cc} ta \u0026 tb \\\\ c \u0026 d \\end{array} \\right| = t \\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|\r$$\r- 同理对于Linear Transformation的另外一个性质也通用 $$\\left| \\begin{array}{cc} a + a' \u0026 b + b' \\\\ c \u0026 d \\end{array} \\right| = \\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right| + \\left| \\begin{array}{cc} a' \u0026 b' \\\\ c \u0026 d \\end{array} \\right|\r$$\r- 需要知道的是，这并不是在说$$det(A+B)=det(A)+det(B)$$\r- 而是对于Square Matrxi的每一行来说是Linear的\rChange of matrix\u0026rsquo;s effect on Determinate #\r当交换矩阵的两行，Determinant的值将会变号 如果你交换一个3×3矩阵的两行，行列式的值也会反号 同理也能知道 $$\\left| \\begin{array}{cc} 0 \u0026 1 \\\\ 1 \u0026 0 \\end{array} \\right| = -1\r$$\rNon-Squre Matrix Can\u0026rsquo;t Have Determinate #\rNon-Squre的Matrix会出现在当有两行是完全相同的时候 其证明可以是，当交换了两个相同的Matrix的Row的时候，其根据[[#Change of matrix\u0026rsquo;s effect on Determinate]]会发生变号，而可以观察发现新的Matrix和原来的没有区别，有Det=-Det，所以det=0 Row Operation\u0026rsquo;s influence on Determinate #\r从矩阵的某行 k 减去另一行 i 的倍数，并不改变行列式的数值（消元的过程不改变行列式） $$\\left| \\begin{array}{cc} a \u0026 b \\\\ c - ta \u0026 d - tb \\end{array} \\right| = \\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right| - \\left| \\begin{array}{cc} a \u0026 b \\\\ ta \u0026 tb \\end{array} \\right|\r$$\r$$= \\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|\r- t \\left| \\begin{array}{cc} a \u0026 b \\\\ a \u0026 b \\end{array} \\right|\r$$\r- 根据[[#Change of matrix's effect on Determinate]]，后一项的Determinant为0，即整体Det不变\rZero Rows Determinant #\r矩阵 A 的某一行都是 0，则其行列式为 0 根据[[#Linearity of Determinate]]可以知道，当t=0的时候， $$\\left| \\begin{array}{cc} ta \u0026 tb \\\\ c \u0026 d \\end{array} \\right| = t \\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|$$\r- 有$$\\left| \\begin{array}{cc} 0\\cdot a \u0026 0\\cdot b \\\\ c \u0026 d \\end{array} \\right|= 0 \\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|$$\r即Determinant为0 Trangular Matrix\u0026rsquo;s Determinant #\r$$\\left| \\begin{array}{cccc} d_1 \u0026 * \u0026 \\cdots \u0026 * \\\\\r0 \u0026 d_2 \u0026 \\cdots \u0026 * \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 \\cdots \u0026 d_n \\end{array} \\right| = \\left| \\begin{array}{cccc} d_1 \u0026 0 \u0026 \\cdots \u0026 0 \\\\\r0 \u0026 d_2 \u0026 \\cdots \u0026 0 \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 \\cdots \u0026 d_n \\end{array} \\right|\r= d_1 d_2 \\cdots d_n\r\\left| \\begin{array}{cccc} 1 \u0026 0 \u0026 \\cdots \u0026 0 \\\\\r0 \u0026 1 \u0026 \\cdots \u0026 0 \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 \\cdots \u0026 1 \\end{array} \\right| = d_1 d_2 \\cdots d_n\r$$\r根据[[#Row Operation\u0026rsquo;s influence on Determinate]]，当是通过Row Operation得到Triangular Matrix的时候，正负号可能发生改变 对于非Diagonal上的元素，根据[[#Row Operation\u0026rsquo;s influence on Determinate]]可以做Row Operation在不改变Determinant的前提下将他们全部消掉，有 $$\\left| \\begin{array}{cccc} d_1 \u0026 * \u0026 \\cdots \u0026 * \\\\\r0 \u0026 d_2 \u0026 \\cdots \u0026 * \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 \\cdots \u0026 d_n \\end{array} \\right|= \\left| \\begin{array}{cccc} d_1 \u0026 0 \u0026 \\cdots \u0026 0 \\\\\r0 \u0026 d_2 \u0026 \\cdots \u0026 0 \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 \\cdots \u0026 d_n \\end{array} \\right|$$\r- 再通过[[#Linearity of Determinate]]提取出每个Row Pivot上的d\r$$= d_1 d_2 \\cdots d_n\r\\left| \\begin{array}{cccc} 1 \u0026 0 \u0026 \\cdots \u0026 0 \\\\\r0 \u0026 1 \u0026 \\cdots \u0026 0 \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 \\cdots \u0026 1 \\end{array} \\right| = d_1 d_2 \\cdots d_n$$\rSingular Matrix\u0026rsquo;s Determinant #\r对于Rank小于Row的Square Matrix，其Determinant为0 Numerial Approach of Determinant #\r当有一个Matrix的时候，想要计算其Determinant，即需要将其化为Triangular Matrix，最简单的方式即为化为Upper Triangular Matrix 而要消成Upper Triangular Matrix的方式即为将C化为0（拿2x2Matrix举例） $$\\left[ \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right] \\rightarrow \\left[ \\begin{array}{cc} a \u0026 b \\\\ 0 \u0026 d - \\frac{c}{a}b \\end{array} \\right]\r$$\r$$\\left| \\begin{array}{cc} a \u0026amp; b \\ c \u0026amp; d \\end{array} \\right| = a \\left( d - \\frac{c}{a}b \\right) = ad - bc $$\nDeterminant of Product #\r\\(det(AB)=det(A)\\cdot det(B)\\) \\(det(A+B)\\neq det(A)+det(B)\\) Determinant of Inverse #\r\\(det(A^{-1})\\) 已知\\(A^{-1}A=I\\)，即\\(det(A^{-1})det(A)=det(I)=1\\) 则有\\(det(A^{-1})=\\frac{1}{det(A)}\\) Determinant of Square #\r\\(det(A^2)=det(A)^2=det(A)\\cdot det(A)\\) Determinant of Coefficient before Matrix #\r\\(det(2A)=2^ndet(A)\\) 对于nxn Matrix来说，犹豫每一个Row都乘上的Coefficient 2，即存在\\(2^n\\)的总系数 Determinant of Transpose #\r\\(det(A^T)=det(A)\\) $$\\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|\r= \\left| \\begin{array}{cc} a \u0026 c \\\\ b \u0026 d \\end{array} \\right|\r= ad - bc\r$$\rFormular for Determinant #\r2x2 #\r$$\\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|\r=\r\\left| \\begin{array}{cc} a \u0026 0 \\\\ c \u0026 d \\end{array} \\right|\r+ \\left| \\begin{array}{cc} 0 \u0026 b \\\\ c \u0026 d \\end{array} \\right|\r=\r\\left| \\begin{array}{cc} a \u0026 0 \\\\ c \u0026 0 \\end{array} \\right|\r+ \\left| \\begin{array}{cc} 0 \u0026 d \\\\ 0 \u0026 d \\end{array} \\right|\r+ \\left| \\begin{array}{cc} 0 \u0026 b \\\\ 0 \u0026 d \\end{array} \\right|\r=\r0 + ad - cb + 0\r=\rad - bc\r$$\r3x3 #\r将每一行拆成3部分，每一部分都对应了不同的行上的不同元素 总共会得到\\(3^3\\)个Matrix即27个，而其中大部分Matrix由于行或列上全为0有Det=0 而其中的非零情况出现在每一列都有的情况下（因为我们是从行出发开始分解的，所以每一行都保证了有值） $$\\left| \\begin{array}{ccc} a_{11} \u0026 a_{12} \u0026 a_{13} \\\\ a_{21} \u0026 a_{22} \u0026 a_{23} \\\\ a_{31} \u0026 a_{32} \u0026 a_{33} \\end{array} \\right|\r=\r\\left| \\begin{array}{ccc} a_{11} \u0026 0 \u0026 0 \\\\ 0 \u0026 a_{22} \u0026 0 \\\\ 0 \u0026 0 \u0026 a_{33} \\end{array} \\right|\r+ \\left| \\begin{array}{ccc} a_{11} \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 a_{23} \\\\ 0 \u0026 a_{32} \u0026 0 \\end{array} \\right|\r+ \\left| \\begin{array}{ccc} 0 \u0026 a_{12} \u0026 0 \\\\ a_{21} \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 a_{33} \\end{array} \\right|\r+ \\left| \\begin{array}{ccc} 0 \u0026 a_{12} \u0026 0 \\\\ 0 \u0026 a_{22} \u0026 0 \\\\ a_{31} \u0026 0 \u0026 0 \\end{array} \\right|\r+ \\left| \\begin{array}{ccc} 0 \u0026 0 \u0026 a_{13} \\\\ a_{21} \u0026 0 \u0026 0 \\\\ 0 \u0026 a_{32} \u0026 0 \\end{array} \\right|\r+ \\left| \\begin{array}{ccc} 0 \u0026 0 \u0026 a_{13} \\\\ 0 \u0026 a_{22} \u0026 0 \\\\ a_{31} \u0026 0 \u0026 0 \\end{array} \\right|\r$$\r$$=\ra_{11}a_{22}a_{33} - a_{11}a_{23}a_{32} - a_{12}a_{21}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32} - a_{13}a_{22}a_{31}$$\r- 其中所有的负值，都是用了[[#Change of matrix's effect on Determinate]]将Matrix做Row Exchange成Uppertriangular Matrix而导致的Determinant的变号\r但这个做法再4x4中并不通用，所以需要从2x2，3x3中推导出nxn的公式 Big Formula A #\r$$det(A)=\\sum_{n!}\\pm a_{1\\alpha}a_{2\\beta}a_{3\\gamma}\\dots a_{n\\omega}$$\r\\(n!\\)：由于我们是用Row做的，即在Row1中有n个Column可以选，而到了Row2中，只有n-1个Column可以选，以此类推可能性即为\\(n!\\) \\(\\alpha,\\beta,\\gamma,\\omega\\)：列标号中的任何值 $$\\left| \\begin{array}{cccc} 0 \u0026 0 \u0026 1 \u0026 1 \\\\ 0 \u0026 1 \u0026 1 \u0026 0 \\\\ 1 \u0026 1 \u0026 0 \u0026 0 \\\\ 1 \u0026 0 \u0026 0 \u0026 1 \\end{array} \\right| =\r\\left| \\begin{array}{cccc} 0 \u0026 0 \u0026 0 \u0026 1 \\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \u0026 0 \\\\ 1 \u0026 0 \u0026 0 \u0026 0 \\end{array} \\right|\r+\r\\left| \\begin{array}{cccc} 0 \u0026 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \u0026 0 \\\\ 1 \u0026 0 \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{array} \\right|\r$$\r分解出的两个Matrix中，第一个需要做两次Row Exchange得到Identity，即为1，而第二个则需要1次Row Exchange就可以得到Identify，即为-1，1-1=0 Cofactor Formula 代数余子式 #\r3x3 #\r代数余子式是用较小的矩阵的行列式来写出 n 阶行列式的公式 $$\\text{det} \\left( \\mathbf{A} \\right) = a_{11} \\left( a_{22}a_{33} - a_{23}a_{32} \\right)\r+ a_{12} \\left( -a_{21}a_{33} + a_{23}a_{31} \\right)\r+ a_{13} \\left( a_{21}a_{32} - a_{22}a_{31} \\right)\r$$\r$$=\\left| \\begin{array}{ccc} a_{11} \u0026 0 \u0026 0 \\\\ 0 \u0026 a_{22} \u0026 a_{23} \\\\ 0 \u0026 a_{32} \u0026 a_{33} \\end{array} \\right|\r+\r\\left| \\begin{array}{ccc} 0 \u0026 a_{12} \u0026 0 \\\\ a_{21} \u0026 0 \u0026 a_{23} \\\\ a_{31} \u0026 0 \u0026 a_{33} \\end{array} \\right|\r+\r\\left| \\begin{array}{ccc} 0 \u0026 0 \u0026 a_{13} \\\\ a_{21} \u0026 a_{22} \u0026 0 \\\\ a_{31} \u0026 a_{32} \u0026 0 \\end{array} \\right|$$\r由于第二个Martri在化为Identity时只需要一次Row Exchange而其他的都需要两次，所以第二个Cofactor为减去 Cofactor Formula #\r将原公式中属于矩阵第一行的\\(a_{ij}\\)提出来，其系数即为代数余子式，是一个低阶行列式的值。这个低阶行列式是由原矩阵去掉\\(a_{ij}\\)所在的行和列组成的。 对矩阵中任意元素\\(a_{ij}\\)而言，其代数余子式\\(C_{ij}\\)j就是矩阵的行列式的公式中\\(a_{ij}\\)的系数 \\(C_{ij}\\)等于原矩阵移除第i行和第j列后剩余元素组成的n-1阶矩阵的行列式数值乘以\\((-1)^{i+j}\\) \\(C_{ij}\\)在 i+j 为偶数时为正，奇数时为负数 则可以总结对于n阶Square Matrix来说，有 $$\\text{det} \\left( \\mathbf{A} \\right) = a_{11} C_{11} + a_{12} C_{12} + \\cdots + a_{1n} C_{1n}\r$$\rex. in 2x2 #\rCofactor Formula最简单的应用即为在2x2 Matrix中，有 $$\\left| \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right|\r= ad + b(-c)$$\rex. 三对角阵（tridiagonal matrix） #\r只在Tridiagonal Matrix这种特殊结构中可行 $$\\mathbf{A_4} = \\left[ \\begin{array}{cccc} 1 \u0026 1 \u0026 0 \u0026 0 \\\\ 1 \u0026 1 \u0026 1 \u0026 0 \\\\ 0 \u0026 1 \u0026 1 \u0026 1 \\\\ 0 \u0026 0 \u0026 1 \u0026 1 \\end{array} \\right]\r$$\r![[LA6.Determinats-9.png]]\rFormula for A Inverse #\r已知2阶Matrix的Inverse为 $$\\left[ \\begin{array}{cc} a \u0026 b \\\\ c \u0026 d \\end{array} \\right]\r= \\frac{1}{ad - bc} \\left[ \\begin{array}{cc} d \u0026 -b \\\\ -c \u0026 a \\end{array} \\right]\r$$\r- 通过观察上2x2的例子可以得出\r$$\\mathbf{A}^{-1} = \\frac{1}{\\det(\\mathbf{A})} \\mathbf{C}^\\top$$\r通过观察可以发现d是a的C，-b是c的C，-c是b的C，a是d的C Adjoint Matrix 伴随矩阵 #\r此处的Cofactor的Transpose\\(C^T\\)便可以称为Adjoint Martirx，即伴随矩阵 对于Adjoint Matrix来说，其大小总是原Matrix的Dimension-1即为n-1 Proof of A Inverse #\r已知Gauss Jordan Elimination提到\\([A|I]\\)在A被消成I后，I会变成\\(A^{-1}\\) 同时\\(A^{-1}A=I\\)，现在将\\(\\mathbf{A}^{-1} = \\frac{1}{\\det(\\mathbf{A})} \\mathbf{C}^\\top\\)带入 $$A\\cdot \\mathbf{A}^{-1} = A\\cdot\\frac{1}{\\det(\\mathbf{A})} \\mathbf{C}^\\top=I$$\r$$A\\cdot C^T=det(A)\\cdot I$$\r如果上式成立，则\\(\\mathbf{A}^{-1} = \\frac{1}{\\det(\\mathbf{A})} \\mathbf{C}^\\top\\)为真命题 $$\\mathbf{AC}^T = \\begin{bmatrix} a_{11} \u0026 \\cdots \u0026 a_{1n} \\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ a_{n1} \u0026 \\cdots \u0026 a_{nn} \\end{bmatrix}\r\\begin{bmatrix} C_{11} \u0026 \\cdots \u0026 C_{n1} \\\\ \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ C_{1n} \u0026 \\cdots \u0026 C_{nn} \\end{bmatrix}\r$$\r- 对于所有结果矩阵对角线上的的元素来说都有\r$$\\sum_{j=1}^{n} a_{1j} C_{1j} = \\det(\\mathbf{A})$$\r即他们本身就是det(A)的展开式 而现在要研究结果矩阵非对角线上的内容 可以发现每一个非对角线上的元素都将为0 $$AC^T = \\begin{bmatrix}\r\\det A \u0026 0 \u0026 0 \u0026 \\cdots \u0026 0 \\\\\r0 \u0026 \\det A \u0026 0 \u0026 \\cdots \u0026 0 \\\\\r0 \u0026 0 \u0026 \\ddots \u0026 \\cdots \u0026 0 \\\\\r\\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\r0 \u0026 0 \u0026 0 \u0026 \\cdots \u0026 \\det A\r\\end{bmatrix} = \\det(A)I\r$$\rCramer’s Rule 克莱姆法则 #\r对于问题Ax=b来说，其解法很简单的就等于\\(x=A^{-1}B\\) 而在知道了\\(A^{-1}\\)的值之后有 $$\\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b} = \\frac{1}{\\det(\\mathbf{A})} \\mathbf{C}^T \\mathbf{b}$$\r选择乘上\\(C^T\\) 的不再是A而是b了，但一个Matrix乘以一个Cofactor Matrix的做法又令人想到了Determinant，可以发现 $$x_j = \\frac{\\det(\\mathbf{B}_j)}{\\det(\\mathbf{A})}\r$$\r其中每一个\\(B_i\\)都是一个第i列被\\(B_i\\)所替换的Matrix A，具体来说有 $$\\mathbf{B}_1 = \\begin{bmatrix}\rb_1 \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n} \\\\\rb_2 \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n} \\\\\rb_3 \u0026 a_{32} \u0026 \\ddots \u0026 \\vdots \\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 a_{n-1\\,n} \\\\\rb_n \u0026 a_{n2} \u0026 \\cdots \u0026 a_{nn}\r\\end{bmatrix}\r, \\quad\r\\mathbf{B}_n = \\begin{bmatrix}\ra_{11} \u0026 \\cdots \u0026 a_{1\\,n-1} \u0026 b_1 \\\\\ra_{21} \u0026 \\cdots \u0026 a_{2\\,n-1} \u0026 b_2 \\\\\r\\vdots \u0026 \\ddots \u0026 \\vdots \u0026 \\vdots \\\\\ra_{n-1\\,1} \u0026 \\cdots \u0026 a_{n-1\\,n-1} \u0026 b_{n-1} \\\\\ra_{n1} \u0026 \\cdots \u0026 a_{n2} \u0026 b_n\r\\end{bmatrix}\r$$\r可以发现等式中的\\(C^T_i \\cdot B_i\\)正好等于\\(B_i\\)的Determinant 其实相比于消元法，采用克莱姆法则计算方程的解效率较低。。。\n","date":"Oct 24 2024","externalUrl":null,"permalink":"/docs/uoft/24/linearalgebra/la6.determiants/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 10/24/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eIntroduction to Determinate \r\n    \u003cdiv id=\"introduction-to-determinate\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#introduction-to-determinate\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e行列式是一个每个方阵都具有的数值\u003c/li\u003e\n\u003cli\u003eDeterminate measures the factor by which the area of a given region increases or decreases\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/LinearAlgebra_Static/LA6.Determinants/LA6.Determinats.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"LA 6. Determinants","type":"docs"},{"content":"","date":"Oct 22 2024","externalUrl":null,"permalink":"/docs/mathematicalanalysis/","section":"Docs","summary":"","title":"Mathematical Analysis","type":"docs"},{"content":"\rYour browser does not support the video tag.\r","date":"Oct 22 2024","externalUrl":null,"permalink":"/docs/displays/projectilemotion/","section":"Docs","summary":"\u003cvideo width=\"640\" height=\"360\" controls\u003e\r\n  \u003csource src=\"Projectile.mp4\" type=\"video/mp4\"\u003e\r\n  Your browser does not support the video tag.\r\n\u003c/video\u003e","title":"Projectile Motion when air resisitance is propftional to velocity","type":"docs"},{"content":" “这种方法虽然简单，却展示了数学中的一种用随机的蛮力对抗精确逻辑的思想方法，一种用数量得到质量的计算思想” - 三体\nYour browser does not support the video tag.\r","date":"Oct 17 2024","externalUrl":null,"permalink":"/docs/displays/montecarlomethod/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003e“这种方法虽然简单，却展示了数学中的一种用随机的蛮力对抗精确逻辑的思想方法，一种用数量得到质量的计算思想” - 三体\u003c/p\u003e","title":"Monte Carlo Approach to Calculate π","type":"docs"},{"content":" Last Edit: 10/16/24\nStress-Strain Curve #\r当回头重新看Stress-Strain Curve的时候可以发现一些特殊的点 如Proportion Limit，Ultimate Tensile Strength两个点 Proportional Limit #\r在曲线的最初阶段，存在一个接近于Linear的区域，其代表了Linear Elastic的Region 而也必会存在一个点象征着Linear Elastic Region的结束 但犹豫一些测量的误差或者精度上的问题，将导致最终的这一个Linear Elastic结束的点无法被确定，所以需要一个约定俗成的方法 0.2% Offset Yield Strength #\r在\\(\\epsilon=0.002\\)的位置画一个平行于Linear Elastic Region的直线，其交于SS Curve的位置即为Yield Strength ex. #\rA hypothetical metal has a 0.2% offset yield strength of 358 MPa, an ultimate tensile strength of 522 MPa, and a fracture strength of 460 MPa. A sample of this metal, originally 1 m in length with a cross section of 2 mm × 2 mm is loaded along its long axis. Just before fracture, while the load is still applied, the length is 1.3 m and when the load is released, the length is 1.18 m. Calculate the modulus of elasticity in GPa.（这我做集贸啊）\n之前有公式\\(\\sigma=E\\epsilon\\) 现在需要将其推广到\\(E=\\frac{\\Delta \\sigma}{\\epsilon}\\)上 \\(\\Delta \\sigma\\)：有460MPa-0MPa=460MPa \\(\\epsilon\\)：有0.3-0.18=0.12 Uniform deformation #\r在经历了Linear Elastic Region后，出现的便是Uniform Platic区间 这个阶段内，材料的塑性变形均匀地分布在整个试样或构件中 其具体的Unifrom体现在了变形过程中结构的完整性上 在Non-Unifrom Region中，材料已经发生了局部的Fracture，即产生了Neck 这也解释了为什么在过了Ultimate Tensile strength后Stress开始下降，即当金属样品承受的应力值逐渐增大时，最终会开始失效。 在拉伸过程中，当金属原子间的一些键断裂时，就会出现这种情况 The Dislocation #\rDisloaction广泛存在于各种晶体材料中，不仅限于金属。 它们在不同类型材料中的运动机制和对材料性能的影响各不相同。 例如，在金属中位错运动相对容易，而在陶瓷和半导体中则较为困难，且其作用更为复杂 具体来说存在有4种不同的Imperfections，来自不同的维度 Dislocation Density #\rDislocation Density: 材料中单位体积内存在的位错数量 Dislocation Density越高，材料的强度和硬度可能会有所增加，但延展性会降低 Metal #\rDislocations are always present in metals. 可以通过加热的方式更改Metal的dislocation density Zero-Dimensional Imperfections or Point Defects #\r点缺陷（Point Defect）是指材料的晶体结构中，由于原子或离子位置上的异常，导致的局部晶体结构缺陷 Interstitial Impurities #\rInterstitial Impurities指的是一些较小的Atom（比如碳、氮等）进入了Crystal中本来空着的间隙位置 Substitutional Impurities #\r当一个外来原子取代了晶体中正常位置上的原子时，形成Substitutional Impurities。 这种缺陷在合金中常见，例如铜和锌形成的黄铜 Vacancies #\r在晶体中，一个本应有原子的位置上缺少了一个原子 它会导致周围的原子重新调整位置，影响材料的物理性质 但Vacancies的产生并不会导致Material的Strength发生改变s Zero-Dimension\u0026rsquo;s Influence on Higher Dimension #\r当Zero Dimension Impurity发生的时候，其会对周围的Crystal Structure产生一个Strain Fields 这个Strain Field将会Repel其他的Atom进入Dislocation 其通常会造成一种One-Dimensional Imperfection Ratio of the Number of Vacancies #\r$$\\frac{N_v}{N} = e^{\\frac{-Q_v}{kT}} \\tag{1}$$\nNv​：这是Crystal中Number of Vancancies，即晶体结构中缺失原子的位置数。\nN：Number of Atoms\nQv​：表示生成一个Vacancies所需的Energy，通常以电子伏特（eV）为单位。\nk：这是Boltzmann Constant，数值约为 \\(1.38\\times 10^{-23}J/K\\)，用于将温度与能量联系起来。\nT：这是Thermodynamic temperature，以开尔文（K）为单位，是热力学温度是根据热力学原理来衡量系统绝对温度的一个度量，其零点对应理论上的绝对零度，即系统的分子运动几乎完全停止、能量达到最低的状态。\n从本质上讲，原子在它们的晶格位点上拼命振动，试图跳出它们的位点。 它们真的很努力。 我的意思是说，每秒大约有 1013 次！ 在固态中，由于结合能强于热能，大多数情况下它们都不会成功（实际上，原子形成有序固体有很大的节能作用，但我们稍后会详细介绍）。 但偶尔也会有原子从其晶格位置成功跃迁，并移动到晶格的其他位置。 这就会留下一个缺失的原子或空位。 因此，我们可以将空位的形成看作是将原子固定在晶格位点上的结合能与将原子从晶格位点上挤出的热能之间的持续斗争\nThermodynamics 热力学 #\rThermodynamics说明了在一个物体中，能量是分布在Atoms上而不是对于所有Atom都具有相同能量的 因此，单个原子可能有足够的能量跳出其晶格位置，而其余大多数原子则没有，这是有道理的 如图 10 所示，随着温度的升高，我们发现有更多的原子进入了高能态。 同时，随着温度的降低，高能态原子的数量也在减少。 Boltzmann Distribution #\r在绝对零度（0 K）：所有原子都会处于最低能量状态，因为此时系统没有足够的能量让原子占据更高的能量状态。 在无限温度（∞ K）：系统的温度极高，粒子的能量足以占据任何能量状态。因此所有能量状态的粒子数都会趋于相等，也就是所有能量状态均等分布 在Boltzmann Distribution中，不会出现所有粒子只占据最高能量状态的情况，即使是在极高温度下 One-Dimensional Imperfections or Dislocations #\rCold Work #\r当我们对金属进行Plastic Deformation时，会产生新的Dislocation。 这增加了Dislocation Density，这将在未来中增加Dislocation的难度 当我们观察金属的Stress-Strain Curve，发现应力在Yield Strength之后继续增加时，我们首次观察到金属通过Plastic Deformation而得到强化。 事实上，如果我们Unload一个sample并重新load，其在stress水平达到我们在前一个循环中留下的Stress之前不会开始Plastic Deformation 这是一种通过塑性变形进行的强化，不过在工业上，我们通常是通过轧制或拉动金属零件，或将金属零件压入模具来实现塑性变形，而不是通过简单的拉伸来拉动零件 Hot Work #\r材料被加热到再结晶温度以上，这意味着减少了Dislocation Density Two-Dimensional Imperfections #\rFree Surfaces #\r自由表面（Free Surfaces） 是指材料的外部表面, 这些表面与外界环境直接接触 原子排列不规则：在材料的自由表面，原子周围的配位数（与其他原子结合的数量）比材料内部的原子要少 Grain Boundaries #\r是指多晶材料中不同Crystal Structure交界的地方 当Dislocation在Crystal中移动，其必定要穿过Grain Boundary，然而这对位错来说是一个挑战 如果我们减小金属的晶粒尺寸，就会产生更多的晶界和更多的位错运动障碍，从而有望提高金属的强度 This strengthening mechanism has a pretty self-explanatory name: grain size reduction. Three-Dimensional Imperfections or Second Phase Particles #\rThree-dimensional imperfections occur any time we have a second phase within a solid 从本质上讲，如果固体中存在晶体结构不同的区域，就会出现第二相或三维缺陷 ","date":"Oct 16 2024","externalUrl":null,"permalink":"/docs/uoft/24/engineering-chemistry--materials-science/ecms5.furtheronstressstrain/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 10/16/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eStress-Strain Curve \r\n    \u003cdiv id=\"stress-strain-curve\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#stress-strain-curve\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS5.FurtherOnStressStrain/MCMS5.FurtherOnStressStrain.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e当回头重新看Stress-Strain Curve的时候可以发现一些特殊的点\u003c/li\u003e\n\u003cli\u003e如Proportion Limit，Ultimate Tensile Strength两个点\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eProportional Limit \r\n    \u003cdiv id=\"proportional-limit\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#proportional-limit\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e在曲线的最初阶段，存在一个接近于Linear的区域，其代表了Linear Elastic的Region\u003c/li\u003e\n\u003cli\u003e而也必会存在一个点象征着Linear Elastic Region的结束\u003c/li\u003e\n\u003cli\u003e但犹豫一些测量的误差或者精度上的问题，将导致最终的这一个Linear Elastic结束的点无法被确定，所以需要一个约定俗成的方法\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003e0.2% Offset Yield Strength \r\n    \u003cdiv id=\"02-offset-yield-strength\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#02-offset-yield-strength\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS5.FurtherOnStressStrain/MCMS5.FurtherOnStressStrain-1.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"MCMS 5. Further On Stress Strain","type":"docs"},{"content":" Last Edit: 11/26/24\nSet Notation 集合 #\rSet is a collection of objects, called elements of the set $$A={t|t\\in R}$$ 这就是一个矩阵，其中A为t，而t可以取任意Real Number 这就是集合的表示方法，用这种方法便可以表示向量，直线和平面 Union of Sets 并集 #\r对于两个集合，其Union是另一个Set，其元素包含了all elements of A and B $$A \\cup B = { x \\in X \\mid x \\in A \\text{ or } x \\in B }$$ Intersection of Sets 交集 #\r对于Intersection来说，这个Set包含了任意同时出现在A与B中的元素 $$A \\cap B = { x \\in X \\mid x \\in A \\text{ and } x \\in B }.$$ Vector 向量 #\r思考一个问题，对于一个坐标轴上的点\\((2,1)\\)和一个向量\\(\\vec v =[2,1]^T\\)，他们的区别 Point：点是空间中的一个位置，用坐标表示，如P = (x, y, z)表示三维空间中的一个具体位置。点没有方向和大小。 Vector：向量是一个有大小和方向的数学对象，通常表示两个点之间的位移。例如，从点 A到点B的向量可以表示为\\(\\mathbf{v} = \\overrightarrow{AB}\\) 亦可以说Point是绝对位置，而向量是一个点到另外一个的有方向的距离 Norm 模 #\r对于\\(\\vec{v} = \\begin{bmatrix} v_1 \\ v_2 \\ \\vdots \\ v_n \\end{bmatrix} \\text{ be in } \\mathbb{R}^n\\) 它的Norm，也就是向量长度即为 $$\\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2}$$ Dot Product 点积 #\rDot Product，用来衡量两个Vector方向相似程度的一个Scalar 其值从-1到1（仅当两个Vector为Unit Vector的情况下），从方向相反，到同方向，在0的时候代表两个Vector Orthogonal 垂直 Definition #\r$$\\mathbf{a} \\cdot \\mathbf{b} = a_1 b_1 + a_2 b_2 + \\cdots + a_n b_n = \\sum_{i=1}^n a_i b_i$$\n公式中的每一项\\(a_i b_i\\)表示两个向量在某个维度上的大小相乘 点积实际上是在将a和b的方向分量进行逐一对比，累加得到两个向量在整个空间上的“相似性”，每一个维度的相似性都将累加到最终的空间相似性上 想要表达这个相似性，还存在另一种方式，即通过Projection $$\\mathbf{a} \\cdot \\mathbf{b} = |\\mathbf{a}| |\\mathbf{b}| \\cos \\theta$$ 其代表了b在a方向上Projection的长度再乘以a Angle Between Vectors #\r同理可以用Dot Product公式推导两个Vector之间的夹角 $$\\theta = \\cos^{-1} \\left( \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{AB} \\right) \\quad 0^\\circ \\leq \\theta \\leq 180^\\circ$$ Application #\rDot Product的一种用法便是Force Vector Directed Along a Line 对于一个在\\(\\vec u\\)方向上的Force F，有 $$\\vec F_u=\\vec F\\cdot \\vec u=(F\\times 1)\\cdot \\cos\\theta=F\\cdot \\cos\\theta$$ 而这一个\\(\\cos\\theta\\)则是 $$\\cos\\theta=\\frac{\\vec v\\cdot \\vec{w}}{|v|\\times|w|}$$ 当把其中一个Vector替换为Direction Vector时，便可以得到Axis-Force\u0026rsquo;s Direction Cosine $$\\cos\\theta = \\frac{{r_xi+r_yj+r_zk}}{\\sqrt{r_x^2+r_y^2+r_z^2}\\cdot 1}$$ 所以就有\\(F\\cdot \\cos \\theta=F\\cdot \\vec u\\)之后便可以得到Force在\\(\\vec u\\)方向上的力的Magnitude（注意Dot Product的结果是一个Scalar） 要想得到Force在\\(\\vec u\\)方向上的Cartesian Vector，需要再次乘以Direction Vector 最终公式 #\r$$\\vec F=F_u\\cdot \\vec u= (\\vec F\\cdot u\\cdot\\cos\\theta)\\cdot \\vec u=(F\\cdot\\frac{{r_xi+r_yj+r_zk}}{\\sqrt{r_x^2+r_y^2+r_z^2}\\cdot 1})\\cdot\\vec u$$\nLine 直线 #\r考虑一个问题Consider the two points P = (1, 2) and Q = (−1, 4)，find an equation for the line y = mx + b which passes through P and Q 通过Point-Point Formula可以算出 $$y_2-y_1=\\frac{y_2 - y_1}{x_2 - x_1}(x_2-x_1)$$ 解得 \\(y=−x+3\\) 现在考虑相似的问题 Suppose x and y satisfy the vector equation $$\\begin{bmatrix} x \\ y \\end{bmatrix} = \\begin{bmatrix} 1 \\ 2 \\end{bmatrix} + k \\begin{bmatrix} 1 \\ -1 \\end{bmatrix}, \\text{ where } k \\in \\mathbb{R}$$ 可以发现两个不同的形式表达了同一个Line，他们之所以等价是因为 \\([1,2​]^T\\)是直线上的一个固定点（在直线上）。 \\(k\\begin{bmatrix} 1 \\ -1 \\end{bmatrix}\\)是一个方向向量，表示直线的方向（斜率），而方程中的斜率为\\(m = \\frac{\\Delta y}{\\Delta x}\\)，用Direction Vector的y分量除以x分量就可以得到一样的结果 而对于Intersection来说，当k=-1的时候，有 $$\\begin{bmatrix} x \\ y \\end{bmatrix} = \\begin{bmatrix} 1 \\ 2 \\end{bmatrix} + \\begin{bmatrix} -1 \\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\ 3\\end{bmatrix}$$ 也就是截距 于是就可以定义如下的Line using Set Notation $$L = { \\vec{u} \\in \\mathbb{R}^2 \\mid \\vec{u} = \\vec{v} + t \\vec{d}, \\text{ for some } t \\in \\mathbb{R} }$$ 为什么需要两个向量 —\u0026gt; 因为需要Position Vector区分不同平行的直线\nPlane #\r同理对于一个Plane，可以通过两个Linearly Independent的Vector与一个Plane上的点表示 至于前面Line中所提到的Slope，在这里便是Partical Derivative $$\\mathcal{P} = { \\vec{u} \\in \\mathbb{R}^3 \\mid \\vec{u} = \\vec{p} + s \\vec{d}_1 + t \\vec{d}_2, \\text{ for some } s, t \\in \\mathbb{R} }$$ 可以发现u是一个\\(\\mathbb R^3\\)中的Subset，这代表了该Subset只含有两个Degree of Freedom，即为三维空间中的一个Plane 注意这里的Plane是一个Subset，不是Subspace，具体原因将在后面指出\nNormal Vector #\r对于平面\\(Ax+By+Cz=D\\)来说，其Normal Vecotr，也就是垂直于整个Plane的Vector即为\\(n=[A,B,C]^T\\) Proof #\r\\(P(x_1​,y_1​,z_1​)\\)和\\(Q(x_2, y_2, z_2)\\)都在平面上，那么它们的坐标满足平面方程 $$Ax_1+By_1+Cz_1=D，Ax_2+By_2+Cz_2=D$$ 则可以构建向量\\(\\vec{v} = \\begin{bmatrix} x_2 - x_1 \\ y_2 - y_1 \\ z_2 - z_1 \\end{bmatrix}\\) 结合方程组则有\\(A(x_2-x_1)+B(y_2-y_1)+C(z_2-z_1)=0\\) 也就是\\(\\vec v \\cdot \\vec n =0\\)，其中\\(\\vec{n} = \\begin{bmatrix} A \\ B \\ C \\end{bmatrix}\\) Second definition #\r结合上面的思想便可以得到Space的第二个Set Notation表达式 $$\\mathcal{P} = { \\vec{u} \\in \\mathbb{R}^3 \\mid \\vec{n} \\cdot (\\vec{u} - \\vec{p}) = 0 }$$ \\(u∈R^3\\)：表示平面上的任意点的坐标。 \\(\\vec{n} \\in \\mathbb{R}^3\\)：表示平面的法向量，即垂直于平面表面的向量。 \\(\\vec{p} \\in \\mathbb{R}^3\\)：表示平面上的一个固定点，用于确定平面的具体位置。 点积\\(\\vec{n} \\cdot (\\vec{u} - \\vec{p}) = 0\\)：表示向量\\((\\vec{u} - \\vec{p})\\)与法向量\\(\\vec{n}\\)正交。 \\(\\vec p\\)为Plane上一点，\\(\\vec n\\)为Plane的Normal Vector，剩下的就是点上的任意位置了，由于任意\\(\\vec u\\)都在平面中，\\(\\vec u-\\vec p\\) 将仍处于Plane中，而\\(\\vec n⋅(\\vec u−\\vec p​)=0\\)是限定他的条件 所有的Vector都为Position Vector，即以坐标系Origin为Head的Vector\nex. #\rFind the equation for a plane \\(\\mathcal{P}\\) which contains the three points P = (0, 1, 1), Q = (2, 0, 4), andR = (0, 0, 1)\nExpress \\(\\mathcal{P}\\) in vector form, in normal form, and as an equation ax + by + cz = d\n用三个点确定Plane上的两个Vector\n$$\\vec{v}_1 = \\begin{bmatrix} 2 - 0 \\\\ 0 - 1 \\\\ 4 - 1 \\end{bmatrix} = \\begin{bmatrix} 2 \\\\ -1 \\\\ 3 \\end{bmatrix}$$\r$$\\vec{v}_2 = \\begin{bmatrix} 0 - 0 \\\\ 0 - 1 \\\\ 1 - 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ -1 \\\\ 0 \\end{bmatrix}$$\r","date":"Oct 15 2024","externalUrl":null,"permalink":"/docs/uoft/24/linearalgebra/la1.vectorlineplane/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 11/26/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eSet Notation 集合 \r\n    \u003cdiv id=\"set-notation-%E9%9B%86%E5%90%88\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#set-notation-%E9%9B%86%E5%90%88\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003eSet is a collection of objects, called elements of the set\n$$A={t|t\\in R}$$\u003c/li\u003e\n\u003cli\u003e这就是一个矩阵，其中A为t，而t可以取任意Real Number\u003c/li\u003e\n\u003cli\u003e这就是集合的表示方法，用这种方法便可以表示向量，直线和平面\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eUnion of Sets 并集 \r\n    \u003cdiv id=\"union-of-sets-%E5%B9%B6%E9%9B%86\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#union-of-sets-%E5%B9%B6%E9%9B%86\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于两个集合，其Union是另一个Set，其元素包含了all elements of A and B\n$$A \\cup B = { x \\in X \\mid x \\in A \\text{ or } x \\in B }$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eIntersection of Sets 交集 \r\n    \u003cdiv id=\"intersection-of-sets-%E4%BA%A4%E9%9B%86\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#intersection-of-sets-%E4%BA%A4%E9%9B%86\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于Intersection来说，这个Set包含了任意同时出现在A与B中的元素\n$$A \\cap B = { x \\in X \\mid x \\in A \\text{ and } x \\in B }.$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eVector 向量 \r\n    \u003cdiv id=\"vector-%E5%90%91%E9%87%8F\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#vector-%E5%90%91%E9%87%8F\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e思考一个问题，对于一个坐标轴上的点\\((2,1)\\)和一个向量\\(\\vec v =[2,1]^T\\)，他们的区别\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePoint\u003c/strong\u003e：点是空间中的一个位置，用坐标表示，如P = (x, y, z)表示三维空间中的一个具体位置。点没有方向和大小。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVector\u003c/strong\u003e：向量是一个有大小和方向的数学对象，通常表示两个点之间的位移。例如，从点 A到点B的向量可以表示为\\(\\mathbf{v} = \\overrightarrow{AB}\\)\u003c/li\u003e\n\u003cli\u003e亦可以说\u003cstrong\u003ePoint是绝对位置，而向量是一个点到另外一个的有方向的距离\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eNorm 模 \r\n    \u003cdiv id=\"norm-%E6%A8%A1\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#norm-%E6%A8%A1\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e对于\\(\\vec{v} = \\begin{bmatrix} v_1 \\ v_2 \\ \\vdots \\ v_n \\end{bmatrix} \\text{ be in } \\mathbb{R}^n\\)\u003c/li\u003e\n\u003cli\u003e它的Norm，也就是向量长度即为\n$$\\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2}$$\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eDot Product 点积 \r\n    \u003cdiv id=\"dot-product-%E7%82%B9%E7%A7%AF\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#dot-product-%E7%82%B9%E7%A7%AF\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003eDot Product，用来衡量两个Vector方向相似程度的一个Scalar\u003c/li\u003e\n\u003cli\u003e其值从-1到1（仅当两个Vector为Unit Vector的情况下），从方向相反，到同方向，在0的时候代表两个Vector Orthogonal 垂直\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003eDefinition \r\n    \u003cdiv id=\"definition\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#definition\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cp\u003e$$\\mathbf{a} \\cdot \\mathbf{b} = a_1 b_1 + a_2 b_2 + \\cdots + a_n b_n = \\sum_{i=1}^n a_i b_i$$\u003c/p\u003e","title":"LA 1. Vector Line \u0026 Plane","type":"docs"},{"content":" Last Edit: 9/25/24\nYoung’s modulus change with Density #\rOrdered Solids #\r大多数固体材料都是Polycrystaline 多晶体的 尤其是Metal在原子尺度上是按照Crystal Structure排列的 Atomic scale尺度一般在\\(10^{-10}\\)的级别 Unit Cell #\r最小的Convenient Building Block Grains #\r多晶材料的这些晶体被称为晶粒（grains）。每个晶粒内部的原子排列是有序的，但不同晶粒之间的原子排列方向各不相同，这种微观结构对材料的机械性能和物理性质有重要影响 Short Range Order #\r指的是在局部区域内，原子或分子的排列是有规律的 玻璃、液体这样的材料，它们通常是Short Range Order的 Long Range Order #\r在整个材料中，原子或分子的排列是有规律的，并且这种规律性会一直延续到较大的尺度（远远超过单个原子的范围） 晶体材料，如金属和矿物，通常具有长程有序 Simple Cubic #\r简单的一个立方体上的八个角为Atoms的结构 其正方体的边长被定义为a n：1 Atom CN：6 Side Dimension: \\(a=2r\\) Hard Sphere Model #\r所有的Atoms都被当作一个球来模拟，主要是方便描述原子在晶体结构中的排列方式 Reduced Sphere Model #\rReal Graph #\r可以发现这样的Hard Shpere Model看着实在是Messy 所以就将所有Atoms简化为Reduced Sphere Model The Atomic Packing Factor 填充系数 #\r对于一个Unit Cell，APF描述了Atom对于体积的占有率，从100%完全占据到0%一点没有 $$APF=\\frac{Volume_{Spheres}}{Volumn_{Unit~Cell}}$$ 本质上就是一个百分比或者说分数 现在分别计算两个体积 对于Spheres来说，单个的体积为\\(\\frac{4}{3}\\pi R^3\\)，而将他乘上Number of Atoms后便可以得到所有的体积 对于Unit Cell来说，以a为边长，其体积自然为\\(a^3\\) Face Centred Cubic (FCC) Structure #\r结构特点：每个晶胞的八个顶点各有一个原子，此外每个面中心还有一个原子。 n：每个晶胞含有 4 个原子（8 个顶点原子各占 1/8，6 个面心原子各占 1/2）。 CN：12（每个原子有 12 个最近邻原子）。 APF：约 74%（原子占据的体积比例）。 例子：铝、铜、金、银等 在Simple Cubic的基础上加入一些Face Centred Atoms（在每个面中心的Atom） Number of Atoms in FCC #\r对于FCC来说，每一个角上都是\\(\\frac{1}{8}\\)个Atom 每一个面都有\\(\\frac{1}{2}\\)个Atom 所以一共就是\\(\\frac{1}{8}*8+\\frac{1}{2}*6=4\\)个Atom 即\\(n_{FCC}=4\\) Coordination Number of FCC #\r$$CN_{FCC}=12$$\nAtomic Packing Factor of FCC #\r则对于FCC Structure来说，其APF即为 $$APF=\\frac{4\\frac{4}{3}\\pi R^3}{a^3}$$ 现在要将Atom的radius与Unit Cell的边长a做替换好消掉其中一个 有\\(a^2+a^2=(4R)^2\\)，勾股定律 则有\\(2a^2=16R^2\\)，即\\(a_{FCC}=2\\sqrt{2}R\\) 将a带入后便有 $$APF = \\frac{4 \\left( \\frac{4}{3} \\pi R^3 \\right)}{(2\\sqrt{2}R)^3} \\ \\Rightarrow APF_{FCC} = 0.74$$ Avogadro\u0026rsquo;s constant 阿伏伽德罗常数 #\r通常用符号\\(N_A\\)表示，是指在1摩尔物质中包含的微观粒子（如原子、分子、离子等）的数量。其数值大约为： $$N_A=6.022×10^{23 }g\\cdot mol^{−1}$$\nTheoretical Density 理论密度 #\r$$\\text{Mass}{\\text{Atoms in Unit Cell}} = \\text{Number}{\\text{Atoms in Unit Cell}} \\cdot \\frac{\\text{Molar Mass of Atom}}{\\text{Avogadro\u0026rsquo;s Number}}$$\n$$m = n \\cdot \\frac{A}{N_A}$$ $$\\rho = \\frac{nA}{V_C N_A}$$\nDensity密度，即质量和体积的比值 \\(n\\)：Number of Atoms，一个Crystal里的完整分子个数 A: Molar Mass(g/mol)，原子相对质量 \\(V_c\\)：Unit Cell的体积 \\(N_A\\)：阿伏伽德罗常数\\(mol^{-1}\\) \\(\\frac{A}{N_A}\\)：\\(\\frac{g/mol}{mol^{-1}}=g\\)，等于一个Atom有几g，再乘上Atom Nuber得到全部的Mass Rock Salt Structure #\r是一个Common Ceramic的Crystal Structure 结构特点：这是离子晶体结构，通常由两种不同大小的离子（如Na⁺和Cl⁻）组成。大的离子（Cl⁻）形成一个面心立方（FCC）结构，小的离子（Na⁺）填充在八面体间隙中。 A：每个晶胞含有 4 个阳离子和阴离子。 CN：阳离子和阴离子的CN都为6。 APF：约 67%。 例子：氯化钠（NaCl）、氧化镁（MgO）等。 对于Ceramic Structure来说，其拥有多余一种的Atom类型，具体来说有Cation和Anion两种 其是Ionic Compound的一种特有的Crystal Structure 对于Rosk Salt Structure来说，其包含了两种Ion，即Anion（蓝色）与Cation（红色） Anions在Unit Cell的角上（Cation也可以在，他们描述的将是同一种结构，但一般来说体积大的Anion会先占据Unit Cell的角落，将小的Cation挤到中间去） 这个结构看起来像面心立方（FCC），但实际上不是纯粹的FCC，因为阳离子和阴离子之间有相互作用，会推开阴离子，使得阴离子不会像真正的FCC结构那样直接通过面对角线相互接触。 Number of Atoms in Rock Salt (Stoichiometry) #\r对于如NaCl这样的material，其Anion：Cation比都是1：1的，但上图中明显缺少了一个Cation 其正确的位置应该是整个Unit Cell的正中央 Coordination Number for Cations in Rock Salt #\r对于一个Rock Salt来说，拿最中间的Cation举例，可以发现与其接触的Atom有6个 于是就可以说\\(CationCoordinationNumber_{Rock~Salt} = 6\\) Density of Rock Salt #\r对于Rock Slat Structure来说，由于其Atom种类变为了Anion与Cation两个，其[[#Theoretical Density]]的分子也要对应的便为两个的和，即 $$\\rho=\\frac{n_CA_C+n_AA_A}{V_CN_A}$$ \\(n_CA_C\\)：Cation的Number和Moalr Mass，nA同理 对于Vc来说，其a变为了两个Atoms的Radus*2，有\\(V_C=(2R_A+2R_C)^3\\) Theoretical Density of Rock Salt #\r$$\\rho = \\frac{n_C A_C + n_A A_A}{V_C N_A}$$\nAnions #\r在Rock Salt Structure中的Anion看似处于FCC的位置中 但实际上由于附近的Cation和不同Anion之间的相互作用力导致Anion实际上不在精确的FCC位置上 Cations #\rthe cations will always touch their nearest neighbour anions The Body Centred Cubic Crystal (BCC) Structure #\r结构特点：每个晶胞的八个顶点各有一个原子，且晶胞中心还有一个原子。 n：每个晶胞含有 2 个原子（8 个顶点原子各占 1/8，中心原子占 1 个）。 CN：8（每个原子有 8 个最近邻原子）。 APF：约 68%。 例子：铁、钨、铬等。 Number of Atoms in BCC #\r$$\\frac{1}{2}*2+\\frac{1}{8}*8=2$$\nCoordination Number of BCC #\r$$CoordinationNumberBCC​=8$$\nAtomic Packing Factor for BCC #\r$$APF=\\frac{Volume_{Spheres}}{Volumn_{Unit~Cell}}$$\n对于BCC，要取其Unit Cell边长与Atom radius关系得用Cubic Diagonal，即 $$3a^2=16R^2，\\Rightarrow a_{BCC}=\\frac{4}{\\sqrt3}R$$ $$APF = \\frac{2 \\left( \\frac{4}{3} \\pi R^3 \\right)}{(\\frac{4}{\\sqrt3})^3} \\ \\Rightarrow APF_{BCC} = 0.68$$\nInterstitial Sites #\rSpace between other atoms 其体积就代表了Crystal Structure中的间隙的部分 By convention, we name interstitial sites according to the solid geometry that they create Octanhedron Interstitial Site #\r对于Rock Salt中的Anion的Interstitial Sites，将他们命名为Octanhedron Interstitial Site Coordination Number of a Interstitial Site #\r对于Interstitial Site来说，其CN代表了Interstitial Site中心点位置的Atom与最近Atom接触的个数 对于Rock Salt来说，Intersitital Site CN = 6 Simple Cubic Interstitial Site #\r结构特点：每个晶胞的八个顶点各有一个原子，顶点原子通过边连接，但面心和体心没有原子。 n：1Atom（8 个顶点原子各占 1/8）。 CN：6（每个原子有 6 个最近邻原子）。 APF：约 52%。 例子：钋（唯一的自然存在的例子）。 纯的简单立方晶格中，中心位置是空的（这个红点代表的就是Intersititial Site间隙位的大小 但在体心立方或其他某些间隙结构中，这一位置可以被其他原子或离子占据 Coordination Number of Simple Cubic #\r$$CoordinationNumberSimpleCubic​=8$$\nThe Size of Interstitial Sites #\r就Interstitial Site来说，其具有实际大小 前面Rock Salt中提到过Cations will always touch their nearest neighbour anions 阳离子总是会接触它们最近的阴离子，因此阳离子只有在足够大时才会占据晶体结构中的间隙位。如果阳离子太小，它将无法与最近的阴离子接触，因此不会稳定地占据间隙位 $$\\sin 45 = \\frac{2R_A}{2R_A + 2R_C} \\\n(2R_A + 2R_C)\\sin 45 = 2R_A \\\n2R_A\\sin 45 + 2R_C\\sin 45 = 2R_A \\\nR_A\\sin 45 + R_C\\sin 45 = R_A \\\n\\frac{R_A}{R_A}\\sin 45 + \\frac{R_C}{R_A}\\sin 45 = 1 \\\n\\sin 45 + \\frac{R_C}{R_A}\\sin 45 = 1 \\\n\\frac{R_C}{R_A}\\sin 45 = 1 - \\sin 45 \\\n\\frac{R_C}{R_A} = \\frac{1 - \\sin 45}{\\sin 45}=0.414$$\nHexagonal Close Packed (HCP) Structure #\r结构特点：原子以六边形排列，沿c轴有堆叠的结构。原子层是按照ABAB\u0026hellip;的顺序堆叠。 n：每个晶胞含有 6 个原子（从整体堆叠考虑）。 CN：12（类似于FCC，每个原子有12个最近邻原子）。 APF：约 74%。 ex.：镁、钛、锌等 Number of Atoms in HCP #\rCoordination Number of HCP #\rCN = 12 Atomic Packing Factor in HCP #\rHCP有着和FCC一样的APF（都为0.74）所以FCC有时会被称为CCP Different to FCC #\rFCC和HCP的主要区别在于原子的堆积顺序 FCC中的原子堆积顺序是ABCABC 而HCP中的堆积顺序是ABAB 尽管它们的堆积顺序不同，但由于原子排列非常紧密，它们的APF都是0.74 Close Packed #\r要想让Atom排列的更加紧密，需要有Close Packed的结构 当Atom在这种排列下，APF才能更高 在Not Close Packed下，这种排列的方式更加的松散 Closed Packed Plane #\rNot Closed Packed Plane in FCC #\r对于FCC的侧面上的Atom来说，其并不处于Closed Packed状态下 ","date":"Sep 25 2024","externalUrl":null,"permalink":"/docs/uoft/24/engineering-chemistry--materials-science/ecms4.thestructureproperty/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 9/25/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eYoung’s modulus change with Density \r\n    \u003cdiv id=\"youngs-modulus-change-with-density\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#youngs-modulus-change-with-density\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS4.TheStructureProperty/ECMS4.TheStructure-Property-24.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"ECMS 4. The Structure Property","type":"docs"},{"content":" Last Edit 9/24/24\nHooke’s Law #\r$$F=kx$$\nSpring constant (k): Spring Constant Material properties（材料性能） #\r主要指材料的基本机械性能，如弹性模量、屈服强度、抗拉强度等 它们的计算方式应当剔除几何尺寸的影响 Stress 应力 #\r物体在外力作用下，单位面积上承受的内力 $$Stress(\\sigma)=\\frac{F}{A_0}$$ \\(A_0\\): Initial Cross-Sectional Area 应力的单位通常是帕斯卡（Pa） Strain 应变 #\r应变是材料在外力作用下发生的变形程度 $$Strain(\\epsilon)=\\frac{\\Delta l}{l_0}$$\n\\(\\Delta l\\)：change of material\u0026rsquo;s length \\(l_0\\): Initial length of material Young\u0026rsquo;s Modulus 杨氏模量 #\r是固体在载荷下的刚度或对弹性变形的抵抗力的量度\n材料在压缩或拉伸时会发生Elastic Deformation，而在Unloaded之后则会回到之前的Equilibrium $$E=\\frac{\\sigma}{\\epsilon}=\\frac{\\frac{F}{A_0}}{\\frac{\\Delta l}{l_0}}=\\frac{F\\cdot l_0}{A_0\\cdot \\Delta l}$$\nYoung\u0026rsquo;s Modulus (E)\n单位是Pa\nStructure Independent #\r当说\u0026quot;XXX is xxx independent\u0026quot; 时，代表了某个事物不依赖于某个特定因素 这里则是Young\u0026rsquo;s Modulus是不依赖于Structure Young\u0026rsquo;s Modulus其只与材料有关，与形状无关 具体来说是取决与材料的原子级别的相互作用，而不是材料的宏观或微观结构 Micro Perspective of Stress and Strain #\r从微观角度来看，物体由Atoms组成，其中存在Inter Atomic Forces 当Applied External Force的时候，物体将处于Loaded状态，其Shape将会发生改变 具体来说，Shape发生的改变是由于Atoms之间的间距发生了改变 不过只要整个Stress小于Yield Strength，所有的Deformation都将是Elastic的 代表了，当External Force被撤去的时候，既Unloaded之后，Atoms将会回到他们原来的Equilibrium position 需要注意的是，Atom之间的间距将会回到一开始的\\(r=r_0\\) 所以可以得出一个结论：Elastic Strain is Reversible Stress-Strain Curve 应力-应变图 #\r本图实际上为F-r图，即拉力-原子间半径图，但与Stress-Strain图相似，便用SS图讲解\n对于一个材料，在对其施加Stress的时候，其Strain会出现如此的固定趋势 在Stress等于0的时候，物体处于Equilibrium状态，具体来说其Attractive Force = Repulsive Force 在持续施加Stress后，Atoms最终将到达一个Yield Strength（不可逆点）后将会产生Plastic Deformation（将在下一章提到） 将Stress-Strain图放大到\\(r_0\\)两边后观察 可以发现Stress随Strain(Atomic Spacing)基本呈现Linear Trend，便可以说 $$E\\propto \\frac{dF}{dr}|_r=r_0$$ Young\u0026rsquo;s Modulus is directly propotional to slope of interatomic force speration curve at equilibrium spacing 简单的理解便为：杨氏模量等于与Stress对于Strain的变化率 更具图可以看出Stress对Strain的变化速率越大，其Young\u0026rsquo;s Modulus越大 即在Plastic Deformation前，Stress（External Force）越大材料的Young\u0026rsquo;s Modulus越大 既抵抗Elastic Deformation的作用越大 The way to determine material properties #\rTensile(Tension) Test\n图中展示了拉伸测试的基本原理，即通过对材料施加拉力（Tension），使其伸长（elongating），从而获得应力-应变曲线等相关数据 Grip Region（夹持区）：这是样品被测试机夹持的地方，两端施加拉力 Reduced Section（缩小部分）：这是样品的中间区域，它的截面积被减少，以确保样品在这个区域发生断裂或变形。在该区域内，材料会受到均匀的拉伸应力。 通过拉伸测试，可以获得材料的关键参数，如杨氏模量 (Young\u0026rsquo;s Modulus)、屈服强度 (Yield Strength)、极限抗拉强度 (Ultimate Tensile Strength, UTS) 和断裂延伸率 (Fracture Elongation) Disadvantage of Tensile Test #\r这种测试方法仍然存在局限性，例如Ceramics \u0026amp; Glasses等都不能利用这种方式测试Material Properties，具体来说 Low strain to fracture, almost no deformation before breaking：在断裂之间，几乎不发生Elastic Deformation hard to grip：对于Tensile Test所必须的Grip Region，由于一些Material的特殊性，他们无法在Grip Region内被夹住，继而无法进一步测试 Hard to load on Axis: 当Grip Region滑动的时候，无法使力沿轴拉伸 关于为什么这些会发生，如为什么Ceramics会直接断裂等，参考[[ECMS 3. Plastic Deformations]] ","date":"Sep 24 2024","externalUrl":null,"permalink":"/docs/uoft/24/engineering-chemistry--materials-science/ecms2.elasticbehavior/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit 9/24/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003eHooke’s Law \r\n    \u003cdiv id=\"hookes-law\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#hookes-law\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003e$$F=kx$$\u003c/p\u003e","title":"ECMS 2. Elastic Behavior","type":"docs"},{"content":"","date":"Sep 23 2024","externalUrl":null,"permalink":"/tags/cover/","section":"Tags","summary":"","title":"Cover","type":"tags"},{"content":"\rLast Edit: 9/23/24\nPlastice Deformation (Permanent Deformation) #\rwe use the term plastic to describe permanent deformation 之所以是Plastic，是因为它derives from the Greek plastikos meaning to sculpt Changes After Plastic Deformation #\r在Plastic Deformation后，Atomic Spacing将保持\\(r=r_0\\) 但是Sequence of atoms将进入一个New Equilibrium 即在Marcro Perspective上发生Shape的Deform Tensile Strain将会保持一定非零大小 Micro Perspective of Plastic Deformation #\rDifferent between Elastic and Plastic Deformation #\rElastic #\r对于Elastic Deformation，开始前物理Atom之间间距应为\\(r_0\\) 泄力后仍应该是\\(r_0\\)，并且Atom将会到他们原有的Equilibrium 并且物体从Marco Perspective上并不发生Deformation Plastic #\r结束后Atom之间间距仍应该是\\(r_0\\) 泄力后Atom将进入一个新的Equilibrium 物体在泄力后，他的Tensile Strain将不会便为0而是保持在一定数 即Shape已经发生了Perminant Change Beyond Elastic Region #\r在Elastic Region外，便是完整的[[ECMS 2. Elastic Behavior#Young\u0026rsquo;s Modulus 杨氏模量]]的模型 Yield Strength: 屈服强度是指材料在发生永久变形之前，能够承受的最大应力。 当Strain到达Yield Strength之后，材料会从Elastic Deformation转变为Plastic Deformation，即Material发生Permanent Deformation 在过了Yield Strength之后Strain再增加后到了一定程度之后便会产生Fracture(Broken into pieces) Stress-Strain Curve for different materials #\rMetals #\r图中的绿色曲线 其特点有在一定位置之后开始产生Permanent Deformation 之后在持续的施加Stress之后其Strain变化率降低最后产生Fracture 相比于Ceramic和Polymer，其Young\u0026rsquo;s Modulus处于中间位置，高于Polymer但小于没有Permanent Deformation阶段的Ceramic Polymer #\r相对来说没有什么特点 具有较低的Young\u0026rsquo;s Modulus和Permanent Deformation区间 Ceramic #\r对于陶瓷类的物质，其没有Permanent Deformation的区间 对于他来说也存在Elastic Region 但可以看出整体Young\u0026rsquo;s Modulus非常高，并且呈现线性 在施加了一定的Stress后会直接Load enough and fracture Three-Point-Blending Test #\r底部两个点用作支撑，上方一个力将物体往下压 $$Stress(\\sigma)=\\frac{3FL}{2wh^2}$$\nTempered Glass 钢化玻璃 #\r![[ECMS 3. Plastic Deformations-5.png]]\n再高温下迅速向表面喷冷凝液将其降温 冷却将使玻璃表面收缩的比内部更快，产生了向心的Compress Stress 而内部由于受力将产生反作用力，向外产生张应力 整体的结构处于一个向内部收缩的趋势，导致当其受到了外力的时候，尝试使其Fracture的导致分子之间结构被破坏的力将被抵消 并且由于其内部存在Residual Stress（残余应力）导致了整体结构破坏的时候其Residual Stress将破坏结构至非常小的结构 ","date":"Sep 23 2024","externalUrl":null,"permalink":"/docs/uoft/24/engineering-chemistry--materials-science/ecms3.plasticdeformation/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit: 9/23/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch4 class=\"relative group\"\u003ePlastice Deformation (Permanent Deformation) \r\n    \u003cdiv id=\"plastice-deformation-permanent-deformation\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#plastice-deformation-permanent-deformation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h4\u003e\r\n\u003cul\u003e\n\u003cli\u003ewe use the term \u003cstrong\u003eplastic\u003c/strong\u003e to describe permanent deformation\u003c/li\u003e\n\u003cli\u003e之所以是Plastic，是因为它derives from the Greek \u003cstrong\u003eplastikos\u003c/strong\u003e meaning to sculpt\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch5 class=\"relative group\"\u003eChanges After Plastic Deformation \r\n    \u003cdiv id=\"changes-after-plastic-deformation\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#changes-after-plastic-deformation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h5\u003e\r\n\u003cul\u003e\n\u003cli\u003e在Plastic Deformation后，Atomic Spacing将保持\\(r=r_0\\)\u003c/li\u003e\n\u003cli\u003e但是Sequence of atoms将进入一个New Equilibrium\u003c/li\u003e\n\u003cli\u003e即在Marcro Perspective上发生Shape的Deform\u003c/li\u003e\n\u003cli\u003eTensile Strain将会保持一定非零大小\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch5 class=\"relative group\"\u003eMicro Perspective of Plastic Deformation \r\n    \u003cdiv id=\"micro-perspective-of-plastic-deformation\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#micro-perspective-of-plastic-deformation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h5\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS3.PlasticDeformations/ECMS3.PlasticDeformations.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\n\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS3.PlasticDeformations/ECMS3.PlasticDeformations-1.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\n\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/EMCS_Static/ECMS3.PlasticDeformations/ECMS3.PlasticDeformations-2.png\" alt=\"\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"ECMS 3. Plastic Deformation","type":"docs"},{"content":" Ramsay, S. (2024). Engineering Chemistry \u0026amp; Materials Science. Top Hat. https://app.tophat.com/e/797389/content/course-work/item/1213609::72131f51-0d59-4379-85f9-30182e840f9b. ","date":"Sep 23 2024","externalUrl":null,"permalink":"/docs/uoft/24/engineering-chemistry--materials-science/","section":"Docs","summary":"\u003cul\u003e\n\u003cli\u003eRamsay, S. (2024). Engineering Chemistry \u0026amp; Materials Science. Top Hat. \u003ca href=\"https://app.tophat.com/e/797389/content/course-work/item/1213609::72131f51-0d59-4379-85f9-30182e840f9b\" target=\"_blank\"\u003ehttps://app.tophat.com/e/797389/content/course-work/item/1213609::72131f51-0d59-4379-85f9-30182e840f9b\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e","title":"Engineering Chemistry \u0026 Materials Science","type":"docs"},{"content":"","date":"Aug 25 2024","externalUrl":null,"permalink":"/docs/uoft/24/","section":"Docs","summary":"","title":"U of T 24","type":"docs"},{"content":" Last Edit 7/4/24\n通货膨胀 #\r钱的贬值 CPI Consumer Price Index 消费者物价指数 #\r美国CPI #\r解释通货膨胀的理论 #\rKeynesian 凯恩斯主义 #\rNeo-Keynesian 新凯恩斯主义 #\rMonetarism 货币主义 #\r根本原因 #\r通货膨胀的可控性 #\r非常难以控制 通货膨胀的后果 #\r当把钱藏在床底下时，其购买力在不断的下降 逼迫人们不断的生产和消费 对于经济体来说，主要目标是提高GDP，人均消费水平 而通过适量的通货膨胀可以有助于提高人们的生产热情，提高GDP，对于整个经济体来说是好的 Misery Index 痛苦指数 #\rDeflation 通货紧缩 #\r今年的钱存着会比明年更加之前 90年代的日本就是典型例子 人们就不会消费，不花钱不生产，进入一个低欲望社会，GDP也就下降 HyperInflation 恶心通货膨胀 #\r对于经济的打击是毁灭性的 Target Inflation Rate 目标通胀 #\r保住通胀是底线，即使可能导致段时间的经济下降 导致Inflation的原因 #\r因素一：Demand-Pull 需求拉动 #\r刺激需求，导致产量的上升与价格的上升，形成一个对于经济上升的良心循环 但可以发现副作用是Inflation 政府可以通过直接发钱达到刺激需求，其可以直接刺激经济，但要面临通货膨胀的风险 可以总结出，Inflation和Economic Growth注定是会绑定在一块的 产能过剩 #\r产能直接影响了刺激需求后Inflation的变化 当产能过剩的情况下，即使总需求上升，由于能有产能，并不需要大幅度提高价格以达到供应需求的目的 相反，当产能不够的情况下，需求的价格必定会上涨导致Inflation的发生 判断产能的方式 - Unemployment Rate 失业率 #\r当失业率高的情况下，说明劳动力很多都在休息，既属于产能过剩的情况 所以一般Inflation发生前都会存在Low Unemployment Rate的情况 Philips Curve 菲利普斯曲线 #\r钱发不到实体经济中 #\r所以最简单的方式就是政府直接发钱，直接发到人手里 Cost-push 成本上涨 #\r成本上涨导致的价格上涨 反而抑制了需求，百害而无一益 俄罗斯通胀 #\r由于卢布的下跌导致的成本上升导致的Cost-push Inflation Money Supply 过量的货币供给 #\r几乎所有的HyperInflation都是政府过度印钱导致的 为什么要不断印钱 #\r政府既然看到了为什么不停止 因为陷入了恶性循环 一般都是外因导致的，如战争 政府无节制印钱后，货币量增加，大家需求也就上涨，来到了Demand-Pull中 但由于政府印钱速度太快，导致了实际上Demand-Pull的Inflation来到了不可抑制的情况，但这时候其实还没达到HyperInflation 这时候人民已经有了足够的钱，并且不会存钱，导致了大家都不再工作，导致产量的下降，导致成本的上升，最终进入恶性循环 预期的Inflation #\r当预期了Inflation时，大家都会超前消费，货币流通速度增加了 通货膨胀就自己发生了 ","date":"Jul 4 2024","externalUrl":null,"permalink":"/docs/notes/inflation/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit 7/4/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003e通货膨胀 \r\n    \u003cdiv id=\"%E9%80%9A%E8%B4%A7%E8%86%A8%E8%83%80\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E9%80%9A%E8%B4%A7%E8%86%A8%E8%83%80\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\u003cul\u003e\n\u003cli\u003e钱的贬值\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch1 class=\"relative group\"\u003eCPI Consumer Price Index 消费者物价指数 \r\n    \u003cdiv id=\"cpi-consumer-price-index-%E6%B6%88%E8%B4%B9%E8%80%85%E7%89%A9%E4%BB%B7%E6%8C%87%E6%95%B0\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#cpi-consumer-price-index-%E6%B6%88%E8%B4%B9%E8%80%85%E7%89%A9%E4%BB%B7%E6%8C%87%E6%95%B0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h1\u003e\r\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e美国CPI \r\n    \u003cdiv id=\"%E7%BE%8E%E5%9B%BDcpi\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%BE%8E%E5%9B%BDcpi\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cp\u003e\r\n    \u003cfigure\u003e\r\n      \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" src=\"/docs/Economic_Static/Inflation/Inflation%282%29.png\" alt=\"Img\" /\u003e\r\n      \r\n    \u003c/figure\u003e\r\n\u003c/p\u003e","title":"Inflation 通货膨胀","type":"docs"},{"content":" Last Edit 4/15/24\nRegression 回归，是能为一个或多个自变量与因变量之间关系建模的一种方式\n[[Regression 回归]] 3.1.1 线性回归的基本元素 #\rLinear Regression 线性回归可以追溯到19世纪，其基于几个基本的假设 假设自变量与因变量之间为线性关系 假设噪声正常，如遵循正态分布 3.1.1.1 线性模型 #\r[[线性模型]] 线性假设是指目标可以表示为特征的加权和，如下例子 E.X. $$Price=w_{area}\\cdot area+w_{age}\\cdot age+b$$\nw称为Weight权重 b称为Bias，Offset或者Intercept偏置，即特征为0时的预测值 严格来说，上式为输入特征的一个[[Affine Transformation 仿射变换]]\n给定一个数据集，我们的目标即为寻找模型的Weight和Offset 高维数据集 #\r在Deep Learning 领域，我们通常使用的是高纬数据集，建模时采用[[2.3 线性代数]]的表示方法会比较方便。 当我们的输入包含多个特征时，我们将预测结果表示为\\(\\hat{y}\\) 点积形式 #\r可以用点积形式来简洁的表达模型\\(x\\in R^d,w\\in R^d\\) $$\\hat{y}=w^Tx+b$$ Model Parameters 模型参数 #\r在开始寻找最好的模型参数前，我们还需要两个东西 一种模型质量的度量方式 #\r一种能更新模型以提高预测质量的方式 #\r3.1.1.2 损失函数 #\r在开始考虑如何用模型Fit 拟合数据之前，我们需要一个拟合程度的度量 Loss Function 损失函数 #\r量话目标的实际值和预测值之间的差距 通常选用非负数作为Cost，并且数值越小损失越小 平方误差函数 #\r回归问题中最常用的Cost Function是平方误差函数 $$l^{(i)}(w,b)=\\frac{1}{2}(\\hat{y}^{(i)}-y^{(i)})^2$$ 常数\\(\\frac{1}{2}\\)的存在不会带来本质的差别，但当我们对这一方程求导后由于\\(\\frac{1}{2}\\)的存在会使常数等于1 由于平方误差函数中的二次方项，会导致估计值和观测值之间较大的差异造成更大的损失。 为了度量模型在整个数据集上的质量，我们需要计算训练集上的样本损失均值 $$L(w,b)= \\frac{1}{n}\\Sigma^n_{i=1}l^{(i)}(w,b)=\\frac{1}{n}\\Sigma^n_{i=1}\\frac{1}{2}(w^Tx^{(i)}+b-y^{(i)})^2$$ 总的来说训练模型就是为了找到一组参数\\(w^,b^\\)，其 $$w^,b^=argmin~L(w,b)$$ 3.1.1.3 解析式 #\r线性回归是一个很简单的优化问题，与大部分模型不同，其解可以用一个公式简单的表达出来，这类解便称为Analytical Solution 解析解 3.1.1.4 随机梯度下降 #\r即使在无法得到解析解的情况下，我们可以有效的训练模型 Gradient Descent 梯度下降 #\r最简单的方法就是计算Cost Function关于模型参数的导数（梯度） 但由于每次操作前都需要遍历整个数据集，导致执行速度非常之慢 所以通常会在每次更新时候抽取一小批样本，即为Minibatch Stochastic Gradient Descent 小批量随机梯度下降 SGD #\rMinibatch Stochastic Gradient Descent 小批量随机梯度下降 每次迭代中，我们首先随机抽样一个小批量B， 它是由固定数量的训练样本组成的。 然后，我们计算小批量的平均损失关于模型参数的导数（也可以称为梯度）。 最后，我们将梯度乘以一个预先确定的正数，并从当前参数的值中减掉 $$(w,b)\\leftarrow(w,b)-\\frac{\\eta}{|B|}\\Sigma_{i\\in B}\\partial_{w,b}l^{(i)}(w,b)$$ 初始化模型参数的值 从数据集中随机抽取小批量样本在负梯度方向上更新参数，并一直迭代 \\(\\eta\\)表示Learning Rate 学习率 B表示Batch Size 批量大小 Hyperparameter 超参数 #\r这些可以调整但不在训练过程中更新的参数称为超参数 Hyperparameter Tuning为调整Hyperparameter的过程 而训练迭代结果是在独立的验证数据集（validation dataset）上评估得到的 收敛 #\rLinear Regression只会让预测值无限接近于实际值而却不能在有限的步数内非常精确地达到最小值 Generalization 泛化 #\r寻找到一组合适的Hyperparameter纵然困难，但更加困难的是找到一组参数，这组参数能够在我们从未见过的数据上实现较低的损失， 这一挑战被称为Generalization 泛化 3.1.1.5 用模型进行预测 #\r需要指出的是，Deep Learning对于实际值的接近更多是一种Prediction预测而非Inference推断 3.1.2 矢量化加速 #\r为了同时处理整个小批量的样本，同时防止在python中编写开销高昂的for循环 矢量化性能测试 #\r实例化两个全为1的10000维向量，采取两种处理方式，Python的for循环和对+的调用 ###初始化两个Tensor\rn = 10000\ra = torch.ones([n])\rb = torch.ones([n])\r###用for循环完成一次\rc = torch.zeros(n)\rtimer = Timer()\rfor i in range(n):\rc[i] = a[i] + b[i]\rf\u0026#39;{timer.stop():.5f} sec\u0026#39;\r###用线性代数完成矢量化运算\rtimer.start()\rd = a + b\rf\u0026#39;{timer.stop():.5f} sec\u0026#39; 得到的结果为 0.167sec 和0.00042 sec 3.1.3 正态分布与平方损失 #\r接下来，我们通过对噪声分布的假设来解读平方损失目标函数 正态分布 #\r[[Normal Distribution 正态分布]] 均方误差损失函数 #\r均方损失可以用于线性回归的一个原因是：我们假设了观测中包含噪声，其中噪声服从正态分布，如下 $$y=w^Tx+b+\\epsilon$$ \\(\\epsilon\\)代表了噪声 Likehood 似然 #\r[[Likehood 似然]] 通过给定的x观测到特定y的似然（likelihood） $$p(y|x)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp(-\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2)$$ 对于似然函数\\(L(\\theta|data)=P(data|\\theta)= \\Pi^N_{i=1}P(x_i|\\theta)\\) 已知x的正态分布密度函数，也就是x（\\(\\theta\\)取每个值的概率） 要求得给定x（\\(\\theta\\)）（其不固定，但遵循正态分布）观测到特点y的似然，得到公式 \\(L(x|y)=P(y|x)\\) 已知\\(p(y|x)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp(-\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2)\\) 由于\\(P(y|x)=\\Pi^N_{i=1}P(y^{(i)}|x^{(i)})\\)（由x的参数条件下观测到y的可能性为独立的N个子事件的乘积） 根据[[Maximum Likehood Estimation 极大似然估计]]，参数w和b的最优值是使整个数据集的[[Likehood 似然]]最大的值 但又因为乘积最大化问题十分复杂，并且由于历史遗留问题，优化常说的不是最大化，而是最小化 所以我们需要通过最小化对数似然\\(-logP(y|x)\\)，由此可以得到的数学公式为 $$-logP(y|x)=\\sum\\limits^n_{i=1}\\frac{1}{2}log(2\\pi\\sigma^2)+\\frac{1}{2\\sigma^2}(y^{(i)}-w^Tx^{(i)}-b)^2$$ 推导如下 \\(-logP(y|x)=-log\\sum\\limits^n_{i=1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp(-\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2)\\) \\(=-log\\sum\\limits^n_{i=1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}e^{(-\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2)}\\) \\(=-log(\\sum\\limits^n_{i=1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}})+\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2\\) \\(=-log\\sum\\limits^n_{i=1}(2\\pi\\sigma^2)^{-\\frac{1}{2}}+\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2\\) = \\(\\sum\\limits^n_{i=1}\\frac{1}{2}log(2\\pi\\sigma^2)+\\frac{1}{2\\sigma^2}(y-w^Tx-b)^2\\) 现在我们只需要假设�是某个固定常数就可以忽略第一项\\(\\sum\\limits^n_{i=1}\\frac{1}{2}log(2\\pi\\sigma^2)\\)，因为第一项不依赖于w和b 对于第二项，除了常数\\(\\frac{1}{\\sigma^2}\\)外，其余部分与[[#平方误差函数]]是一样的 平方误差函数 #\r$$l^{(i)}(w,b)=\\frac{1}{2}(\\hat{y}^{(i)}-y^{(i)})^2$$\n幸运的是，上面式子的解并不依赖于\\(\\sigma\\) 因此，在高斯噪声的假设下，最小化均方误差等价于对线性模型的极大似然估计 3.1.4 从线性回归到深度网络 #\r到目前，我只谈论了线性模型，而神经网络涵盖了更为丰富的模型，并且我们也可以用描述神经网络的方式来描述线性模型，从而把线性模型看作一个神经网络。可以用“层”符号来重写这个模型 3.1.4.1 神经网络图 #\r制图表可以可视化模型中正在发生的事情，但该图只显示了链接模式，而不包含权重和偏置的值 在上图中，输入为\\(x_1,\\dots x_d\\)，可知输入层的Feature Dimensionality 输入数（或称为特征维度）为d\n网络的输出层为\\(o_1\\)，因此输出层的输出数为1\n需要注意的是，输入值都是已经给定的，并且只有一个_计算_神经元。 由于模型重点在发生计算的地方，所以通常我们在计算层数时不考虑输入层。\nFully-Connected Layer 全连接层 #\r对于线性回归，每个输入都与每个输出（在本例中只有一个输出）相连， 我们将这种变换称为全连接层（Fully-connected layer）或称为稠密层（dense layer）。 3.1.4.2 生物学 #\r即使观察真实的神经元，但当今大多数深度学习的研究几乎没有直接从神经科学中获得灵感\n我们援引斯图尔特·罗素和彼得·诺维格在他们的经典人工智能教科书 Artificial Intelligence:A Modern Approach (Russell and Norvig, 2016) 中所说的：虽然飞机可能受到鸟类的启发，但几个世纪以来，鸟类学并不是航空创新的主要驱动力。 同样地，如今在深度学习中的灵感同样或更多地来自数学、统计学和计算机科学。\n","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.1_linearregression/","section":"Docs","summary":"\u003cblockquote\u003e\n\u003cp\u003eLast Edit 4/15/24\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eRegression 回归，是能为一个或多个自变量与因变量之间关系建模的一种方式\u003c/p\u003e","title":"D2L 3.1 Linear Regression","type":"docs"},{"content":"从零开始实现整个方法， 包括数据流水线、模型、损失函数和小批量随机梯度下降优化器。 虽然现代的深度学习框架几乎可以自动化地进行所有这些工作，但从零开始实现可以确保我们真正知道自己在做什么。\n3.2.1 生成数据集 #\r为了简单起见，我们将根据带有噪声的线性模型构造一个人造数据集 使用线性模型参数\\(w=[2,-3.4]^T,b=4.2\\)和噪声项\\(\\epsilon\\)生成数据集及其标签 $$y=Xw+b+\\epsilon$$ \\(\\epsilon\\)可以视为模型预测和标签时的潜在观测误差 3.2.2 读取数据集 #\r3.2.3 初始化模型参数 #\r通过从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重， 并将偏置初始化为0。 w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)\rb = torch.zeros(1, requires_grad=True) 在初始化参数之后，我们的任务是更新这些参数，直到这些参数足够拟合我们的数据 并运用[[2.5 自动微分]]来计算梯度 3.2.4 定义模型 #\r这里我们用的还是线性模型，即$$\\hat y=w^Tx+b$$ def linreg(X, w, b): #@save\r\u0026#34;\u0026#34;\u0026#34;线性回归模型\u0026#34;\u0026#34;\u0026#34;\rreturn torch.matmul(X, w) + b 3.2.5 定义损失函数 #\r模型建立后，开始使用对原函数的损失函数进行梯度下降 这里我们使用[[3.1_LinearRegression#平方误差函数]] 3.2.6 定义优化算法 #\r使用[[3.1_LinearRegression#Minibatch Stochastic Gradient Descent 小批量随机梯度下降]] 3.2.7 训练 #\r本质为执行一下循环 初始化参数 更新梯度，更新参数 ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.2_object-orienteddesignforimplementation/","section":"Docs","summary":"\u003cp\u003e从零开始实现整个方法， 包括数据流水线、模型、损失函数和小批量随机梯度下降优化器。 虽然现代的深度学习框架几乎可以自动化地进行所有这些工作，但从零开始实现可以确保我们真正知道自己在做什么。\u003c/p\u003e","title":"D2L 3.2 Object-Oriented Design for Implementation","type":"docs"},{"content":"本节将介绍如何通过使用深度学习框架来简洁地实现[[3.2_Object-OrientedDesignforImplementation]]中的线性回归模型\n3.3.1 生成数据集 #\rimport numpy as np\rimport torch\rfrom torch.utils import data\rfrom d2l import torch as d2l\rtrue_w = torch.tensor([2, -3.4])\rtrue_b = 4.2\rfeatures, labels = d2l.synthetic_data(true_w, true_b, 1000) d2l.synthetic_data(true_w, true_b, 1000) 是 d2l 库中的一个函数调用。这个函数用于生成合成数据，其中包括特征数据和对应的标签数据。 具体地，这个函数接受三个参数： true_w：真实的权重，用于生成特征数据。 true_b：真实的偏置，用于生成特征数据。 1000：生成数据的数量，这里是指生成1000个样本。 3.3.2 读取数据集 #\rdef load_array(data_arrays, batch_size, is_train=True): #@save\r\u0026#34;\u0026#34;\u0026#34;构造一个PyTorch数据迭代器\u0026#34;\u0026#34;\u0026#34;\rdataset = data.TensorDataset(*data_arrays)\rreturn data.DataLoader(dataset, batch_size, shuffle=is_train)\rbatch_size = 10\rdata_iter = load_array((features, labels), batch_size) 3.3.3 定义模型 #\r对于标准深度学习模型，我们可以使用框架的预定义好的层 ## nn是神经网络的缩写\rfrom torch import nn\rnet = nn.Sequential(nn.Linear(2, 1)) nn.Sequential：这是 PyTorch 中用于构建顺序神经网络模型的类。它允许用户按顺序堆叠多个层或模块，构建神经网络模型。 nn.Linear(2, 1)：这里创建了一个全连接层，其中 nn.Linear 是 PyTorch 中用于定义全连接层的类。构造函数 nn.Linear(in_features, out_features) 接受两个参数： in_features：输入特征的数量。在这个例子中，输入特征的数量为 2。 out_features：输出特征的数量。在这个例子中，输出特征的数量为 1。 因此，net 这个模型包含一个具有 2 个输入特征和 1 个输出特征的全连接层。 这样的模型可以用于简单的二分类问题，其中输入特征有 2 个，输出特征有 1 个，代表着模型对样本的分类结果。 3.3.4 初始化模型参数 #\rnet[0].weight.data.normal_(0, 0.01)\rnet[0].bias.data.fill_(0) 在网络的第一层输入参数 3.3.5 定义损失函数 #\r计算均方误差使用的是MSELoss类，也称为平方�2范数。 默认情况下，它返回所有样本损失的平均值。 loss = nn.MSELoss() 3.3.6 定义优化算法 #\rtrainer = torch.optim.SGD(net.parameters(), lr=0.03) 当我们实例化一个SGD实例时，我们要指定优化的参数 （可通过net.parameters()从我们的模型中获得）以及优化算法所需的超参数字典。 小批量随机梯度下降只需要设置lr值，这里设置为0.03。 3.3.7 训练 #\r通过深度学习框架的高级API来实现我们的模型只需要相对较少的代码。 我们不必单独分配参数、不必定义我们的损失函数，也不必手动实现小批量随机梯度下降。 当我们需要更复杂的模型时，高级API的优势将大大增加。 当我们有了所有的基本组件，训练过程代码与我们从零开始实现时所做的非常相似。\nnum_epochs = 3\rfor epoch in range(num_epochs):\rfor X, y in data_iter:\rl = loss(net(X) ,y)\rtrainer.zero_grad()\rl.backward()\rtrainer.step()\rl = loss(net(features), labels)\rprint(f\u0026#39;epoch {epoch + 1}, loss {l:f}\u0026#39;) num_epochs = 3：定义了训练的轮数，这里设置为 3 for epoch in range(num_epochs):：使用 for 循环迭代每个训练轮数 for X, y in data_iter:：使用 data_iter 迭代器遍历训练数据集，其中 X 是特征，y 是对应的标签 l = loss(net(X) ,y)：计算模型对当前批次数据的预测值，并计算与真实标签之间的损失 trainer.zero_grad()：梯度清零，以避免梯度累积 l.backward()：反向传播，计算损失函数相对于模型参数的梯度 trainer.step()：更新模型参数，采用优化算法更新参数 l = loss(net(features), labels)：计算当前训练轮数结束后整个训练集上的损失 print(f'epoch {epoch + 1}, loss {l:f}')：打印当前训练轮数和对应的损失值 ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.3_syntheticregressiondat/","section":"Docs","summary":"\u003cp\u003e本节将介绍如何通过使用深度学习框架来简洁地实现[[3.2_Object-OrientedDesignforImplementation]]中的线性回归模型\u003c/p\u003e","title":"D2L 3.3 A concise implementation of linear regression","type":"docs"},{"content":"回归可以用于预测_多少_的问题。 比如预测房屋被售出价格，或者棒球队可能获得的胜场数，又或者患者住院的天数。\n事实上，我们也对_分类_问题感兴趣：不是问“多少”，而是问“哪一个”\n3.4.1 分类问题 #\r[[One-hot encoding 独热编码]] 3.4.2 网格架构 #\r为了估计所有可能类别的条件概率，我们需要一个有多个输出的模型，每个类别对应一个输出。 为了解决线性模型的分类问题，我们需要和输出一样多的[[Affine Function 仿射函数]] E.X.\n假设现在有3个未规范化的预测(Logit)：\\(o_1,o_2和o_3\\) \\(o_1=x_1w_{11}+x_2w_{12}+x_3w_{13}+x_4w_{14}+b_1\\) \\(o_2=x_1w_{21}+x_2w_{22}+x_3w_{23}+x_4w_{24}+b_2\\) \\(o_1=x_1w_{31}+x_2w_{32}+x_3w_{33}+x_4w_{34}+b_3\\) 3.4.3 全连接层的参数开销 #\r对于任何具有d个输入和q个输出的全连接层[[3.1_LinearRegression#Fully-Connected Layer 全连接层]]，其参数开销为\\(O(dq)\\)，但可以通过超参数减少到\\(O(\\frac{dq}{n})\\) 3.4.4 softmax 运算 #\r我们希望模型的输出\\(\\hat y_j\\)可以视为属于类\\(j\\)的概率，然后选择具有最大输出值的类别\\(argmaxx_jy_j\\)作为我们的预测，例如\\(\\hat y_1,\\hat y_2\\)和\\(\\hat y_3\\)分别为\\(\\hat y={0.1,0.8,0.1}\\)那么我们的预测变为独热编码的\\(y={0,1,0}\\)，即为鸡 能否将未规范化的预测o直接视作我们感兴趣的输出呢 #\r不行 因为将线性层的输出直接视为概率时存在一些问题 我们没有限制这些输出数字的总和为1 根据输入的不同，它们可以为负值 其违反了[[概率论公理]] 概率论 #\r要将输出视为概率，我们必须保证在任何数据上的输出都是非负的且总和为1 此外，我们需要一个训练的目标函数，来激励模型精准地估计概率 Calibration 校准 #\r例如， 在分类器输出0.5的所有样本中，我们希望这些样本是刚好有一半实际上属于预测的类别 Softmax 函数 #\r社会科学家邓肯·卢斯于1959年在选择模型（choice model）的理论基础上发明的softmax函数 softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持 可导的性质 为了完成这一目标，我们首先对每个未规范化的预测求幂，这样可以确保输出非负 为了确保最终输出的概率值总和为1，我们再让每个求幂后的结果除以它们的总和。如下式$$\\hat y=softmax(o)，其中\\hat y_j=\\frac{exp(o_j)}{\\sum_kexp(o_k)}=\\frac{e^j}{\\sum_ke^k}$$ 这里，对于所有的j总有\\(0\\leq\\hat y_j\\leq1\\)，因此\\(\\hat y\\)可以视为一个正确的概率分布 尽管softmax是一个非线性函数，但softmax回归的输出仍然由输入特征的仿射变换决定。 因此，softmax回归是一个线性模型（linear model）。 3.4.5 小批量样本的矢量化 #\r为了提高计算效率并且充分利用GPU，我们通常会对小批量样本的数据执行矢量计算 3.4.6 损失函数 #\r使用[[Maximum Likehood Estimation 极大似然估计]] 3.4.6.1 对数似然 #\rsoftmax函数给出了一个向量\\(\\hat y\\)， 我们可以将其视为“对给定任意输入x的每个类的条件概率\n通过计算softmax的对数似然，可以推导出他的损失函数\n假设现在有一个数据集 \\({X,Y}\\)，其具有n个样本，其中索引i的样本由特征向量\\(x^{(i)}\\)和独热标签向量\\(y^{(i)}\\)组成，可以将估计值与实际值进行比较$$P(Y|X)=\\prod^n_{i=1}P(y^{(i)}|x^{(i)})$$\n根据[[3.1_LinearRegression#Likehood 似然]]，已知最大化$P(Y|X)，相当于最小化负对数似然 $$P(Y|X)=\\sum^n_{i=1}-logP(y^{(i)}|x^{(i)})=\\sum^n_{i=1}l(y^{(i)},\\hat y^{(i)})$$\n其中对于任何标签y和预测模型\\(\\hat y\\)，损失函数为$$l(y,\\hat y)=-\\sum^{q}_{j=1}y_j\\log \\hat y_j$$\n这个[[3.1_LinearRegression#Loss Function 损失函数]]并没有介绍过，他的名字为Cross-entropy Loss交叉熵损失，将在后面介绍到\n为什么要加入对数，而不是直接取负数 #\r数值稳定性： 在概率模型中，可能会有大量的乘法运算，这可能导致数值下溢或溢出问题，尤其是当概率很小的时候。通过取对数，可以将乘法运算转换为加法运算，从而提高计算的稳定性。 对数函数的导数相对于原函数来说更简单，这使得梯度的计算更加高效。特别是在梯度下降等优化算法中，简化的导数计算可以显著减少计算量。 对数函数的特性使得推导和分析变得更加简单，因为它可以将乘法转换为加法，并且有很多性质，例如对数函数的导数比原函数更容易处理 3.4.6.2 softmax及其导数 #\r由于softmax和相关的损失函数很常见， 因此我们需要更好地理解它的计算方式 将3.4.3带入Cross-entropy Loss Function中，得到 $$\\begin{align}l(y,\\hat y)=-\\sum^{q}{j=1}y_j\\log \\frac{e^{o_j}}{{\\sum^{q}{k=1}e^{o_k}}} \\=-\\sum_{j=1}^{q}y_j[\\ln e^{o_j}-\\ln \\sum^q_{k=1}e^{o_k}] \\=\\sum^q_{j=1}y_j\\log\\sum^q_{k=1}e^{o_k}-\\sum^q_{j=1}y_jo_j \\=\\log \\sum^q_{k=1}e^{o_k}-\\sum^q_{j=1}y_jo_j\\end{align}$$ Softmax结合Cross Entropy的求导过程 #\r已知Cross Entropy Function$$H(y_i,p_i)=-\\sum_iy_i\\log pi$$\n\\(y_i\\)为预测事件，\\(\\log p_i\\)为一个分布的最优编码\n得到[[Home Page]] 3.4.6.3 交叉熵损失 #\r[[Cross-Entropy 交叉熵]] 3.4.7.1 熵 #\r[[Cross-Entropy 交叉熵#2. 熵]] ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.4_softmaxregression/","section":"Docs","summary":"\u003cp\u003e回归可以用于预测_多少_的问题。 比如预测房屋被售出价格，或者棒球队可能获得的胜场数，又或者患者住院的天数。\u003c/p\u003e","title":"D2L 3.4 Softmax Regression","type":"docs"},{"content":"MNIST数据集 (LeCun et al., 1998) 是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单。 我们将使用类似但更复杂的Fashion-MNIST数据集 (Xiao et al., 2017)。\n在此引入这个数据集是因为之后对于算法的评估均给予这一数据集\n%matplotlib inline\rimport sys\rfrom mxnet import gluon\rfrom d2l import mxnet as d2l\rd2l.use_svg_display() 3.5.1 读取数据集 #\r## 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，\r## 并除以255使得所有像素的数值均在0～1之间\rtrans = transforms.ToTensor()\rmnist_train = torchvision.datasets.FashionMNIST(\rroot=\u0026#34;../data\u0026#34;, train=True, transform=trans, download=True)\rmnist_test = torchvision.datasets.FashionMNIST(\rroot=\u0026#34;../data\u0026#34;, train=False, transform=trans, download=True) Fshion-MNIST中包含的10个类别，分别为t-shirt（T恤）、trouser（裤子）、pullover（套衫）、dress（连衣裙）、coat（外套）、sandal（凉鞋）、shirt（衬衫）、sneaker（运动鞋）、bag（包）和ankle boot（短靴）。 以下函数用于在数字标签索引及其文本名称之间进行转换。 def get_fashion_mnist_labels(labels): #@save\r\u0026#34;\u0026#34;\u0026#34;返回Fashion-MNIST数据集的文本标签\u0026#34;\u0026#34;\u0026#34;\rtext_labels = [\u0026#39;t-shirt\u0026#39;, \u0026#39;trouser\u0026#39;, \u0026#39;pullover\u0026#39;, \u0026#39;dress\u0026#39;, \u0026#39;coat\u0026#39;,\r\u0026#39;sandal\u0026#39;, \u0026#39;shirt\u0026#39;, \u0026#39;sneaker\u0026#39;, \u0026#39;bag\u0026#39;, \u0026#39;ankle boot\u0026#39;]\rreturn [text_labels[int(i)] for i in labels] Plt 可视化样本 #\rdef show_images(imgs, num_rows, num_cols, titles=None, scale=1.5): #@save\r\u0026#34;\u0026#34;\u0026#34;绘制图像列表\u0026#34;\u0026#34;\u0026#34;\rfigsize = (num_cols * scale, num_rows * scale)\r_, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\raxes = axes.flatten()\rfor i, (ax, img) in enumerate(zip(axes, imgs)):\rif torch.is_tensor(img):\r# 图片张量\rax.imshow(img.numpy())\relse:\r# PIL图片\rax.imshow(img)\rax.axes.get_xaxis().set_visible(False)\rax.axes.get_yaxis().set_visible(False)\rif titles:\rax.set_title(titles[i])\rreturn axes\rX, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))\rshow_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y)); ![[Pasted image 20240331164614.png]]\n3.5.2 读取小批量 #\r为了使我们在读取训练集和测试集时更容易，我们使用内置的数据迭代器，而不是从零开始创建。 回顾一下，在每次迭代中，数据加载器每次都会读取一小批量数据，大小为batch_size。 通过内置数据迭代器，我们可以随机打乱了所有样本，从而无偏见地读取小批量。 batch_size = 256\rdef get_dataloader_workers(): #@save\r\u0026#34;\u0026#34;\u0026#34;使用4个进程来读取数据\u0026#34;\u0026#34;\u0026#34;\rreturn 4\rtrain_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,\rnum_workers=get_dataloader_workers()) 3.5.3. 整合所有组件 #\r现在我们定义load_data_fashion_mnist函数，用于获取和读取Fashion-MNIST数据集。 这个函数返回训练集和验证集的数据迭代器。 此外，这个函数还接受一个可选参数resize，用来将图像大小调整为另一种形状 def load_data_fashion_mnist(batch_size, resize=None): #@save\r\u0026#34;\u0026#34;\u0026#34;下载Fashion-MNIST数据集，然后将其加载到内存中\u0026#34;\u0026#34;\u0026#34;\rtrans = [transforms.ToTensor()]\rif resize:\rtrans.insert(0, transforms.Resize(resize))\rtrans = transforms.Compose(trans)\rmnist_train = torchvision.datasets.FashionMNIST(\rroot=\u0026#34;../data\u0026#34;, train=True, transform=trans, download=True)\rmnist_test = torchvision.datasets.FashionMNIST(\rroot=\u0026#34;../data\u0026#34;, train=False, transform=trans, download=True)\rreturn (data.DataLoader(mnist_train, batch_size, shuffle=True,\rnum_workers=get_dataloader_workers()),\rdata.DataLoader(mnist_test, batch_size, shuffle=False,\rnum_workers=get_dataloader_workers())) 下面，我们通过指定resize参数来测试load_data_fashion_mnist函数的图像大小调整功能。 train_iter, test_iter = load_data_fashion_mnist(32, resize=64)\rfor X, y in train_iter:\rprint(X.shape, X.dtype, y.shape, y.dtype)\rbreak 我们现在已经准备好使用Fashion-MNIST数据集，便于下面的章节调用来评估各种分类算法 ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.5_imageclassificationdatasets/","section":"Docs","summary":"\u003cp\u003eMNIST数据集 (\u003ca href=\"https://zh-v2.d2l.ai/chapter_references/zreferences.html#id90\"title=\"LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., \u0026amp; others. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278–2324.\" target=\"_blank\"\u003eLeCun \u003cem\u003eet al.\u003c/em\u003e, 1998\u003c/a\u003e) 是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单。 我们将使用类似但更复杂的Fashion-MNIST数据集 (\u003ca href=\"https://zh-v2.d2l.ai/chapter_references/zreferences.html#id189\"title=\"Xiao, H., Rasul, K., \u0026amp; Vollgraf, R. (2017). Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747.\" target=\"_blank\"\u003eXiao \u003cem\u003eet al.\u003c/em\u003e, 2017\u003c/a\u003e)。\u003c/p\u003e","title":"D2L 3.5 Image classification datasets","type":"docs"},{"content":"\r3.6.1 初始化模型参数 #\r和之前线性回归的例子一样，这里的每个样本都将用固定长度的向量表示。 原始数据集中的每个样本都是28×28的图像。 本节将展平每个图像，把它们看作长度为784的向量 在3.5中，我们选择了一个拥有10个类别的数据集，所以softmax网络的输出维度为10 初始化权重w #\r与线性回归一样，我们使用正态分布初始化权重w，偏置初始化为0 num_inputs = 784\rnum_outputs = 10\rW = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\rb = torch.zeros(num_outputs, requires_grad=True) 3.6.2 定义softmax操作 #\r实现softmax操作由三个步骤组成 对每个项求幂 对每一行求和，得到其规范化常数 每一行除以其规范化常数，保持结果的和为1 $$softmax(X){ij}=\\frac{exp(X{ij})}{\\sum_kexp(X_{ik})}$$ 分母或规范化常数，有时也称为_配分函数_（其对数称为对数-配分函数）。 该名称来自统计物理学中一个模拟粒子群分布的方程 def softmax(X):\rX_exp = torch.exp(X)\rpartition = X_exp.sum(1, keepdim=True)\rreturn X_exp / partition # 这里应用了广播机制 keepdim=True: 在进行张量操作时，保持原始张量的维度\ntorch.normal(0, 1, (2, 5)) 是用 PyTorch 生成一个服从均值为 0，标准差为 1 的正态分布的张量。\n其中的 (2, 5) 是指生成的张量的形状为 2 行 5 列的矩阵\n3.6.3 定义模型 #\r定义softmax操作后，我们可以实现softmax回归模型 def net(X):\rreturn softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b) 3.6.4 定义损失函数 #\r引入[[Cross-Entropy 交叉熵]]损失函数 深度学习中，交叉熵函数最为常见，因为分类问题的数量远远超过了回归问题 y = torch.tensor([0, 2])\ry_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\ry_hat[[0, 1], y] y_hat： 包含2个样本在3个类别的预测概率 y：真实类，0代表第一类，1代表第二类，2代表第三类 [[0,1],y]：一种tensor的高级引索功能，其选择了y_hat中的第一行和第二行 而y给予了列的位置，所以输出分别为第一行第0位和第二行第2位 3.6.5 分类精度 #\r给定预测概率分布\\(\\hat y\\)，当我们必须输出Hard Prediciton 硬预测时，我们通常选择概率最高的类 当预测和标签分类y一致时，即是正确的 分类精度指的就是正确预测数量与总预测数量之比 def accuracy(y_hat, y): #@save\r\u0026#34;\u0026#34;\u0026#34;计算预测正确的数量\u0026#34;\u0026#34;\u0026#34;\rif len(y_hat.shape) \u0026gt; 1 and y_hat.shape[1] \u0026gt; 1:\ry_hat = y_hat.argmax(axis=1)\rcmp = y_hat.type(y.dtype) == y\rreturn float(cmp.type(y.dtype).sum()) 扩展到任意数据迭代器data_iter可访问的数据集 #\rdef evaluate_accuracy(net, data_iter): #@save\r\u0026#34;\u0026#34;\u0026#34;计算在指定数据集上模型的精度\u0026#34;\u0026#34;\u0026#34;\rif isinstance(net, torch.nn.Module):\rnet.eval() # 将模型设置为评估模式\rmetric = Accumulator(2) # 正确预测数、预测总数, Accmulator在下面定义\rwith torch.no_grad():\rfor X, y in data_iter:\rmetric.add(accuracy(net(X), y), y.numel())\rreturn metric[0] / metric[1] 首先，如果 net 是 torch.nn.Module 的子类，就将模型设置为评估模式，即调用 net.eval()。在评估模式下，模型的行为可能会略有不同，比如 Dropout 层在评估模式下会关闭，以避免随机丢弃部分节点 创建了一个名为 metric 的累加器（Accumulator）。这个累加器用于记录正确预测数和总预测数，初始化为两个元素的列表 [0, 0] Accumulator：这个类在下面定义 使用 torch.no_grad() 上下文管理器，禁用梯度计算 最后就是将评估结果添加至metric中 Accumulator类 #\r这里定义一个实用程序类Accumulator，用于对多个变量进行累加。 在上面的evaluate_accuracy函数中， 我们在Accumulator实例中创建了2个变量， 分别用于存储正确预测的数量和预测的总数量。 当我们遍历数据集时，两者都将随着时间的推移而累加。 class Accumulator: #@save\r\u0026#34;\u0026#34;\u0026#34;在n个变量上累加\u0026#34;\u0026#34;\u0026#34;\rdef __init__(self, n):\rself.data = [0.0] * n\rdef add(self, *args):\rself.data = [a + float(b) for a, b in zip(self.data, args)]\rdef reset(self):\rself.data = [0.0] * len(self.data)\rdef __getitem__(self, idx):\rreturn self.data[idx] __init__(self, n): 这是类的构造函数，用于初始化累加器。它接受一个参数 n，表示要累加的变量的数量。在初始化时，创建了一个包含 n 个元素的列表，每个元素初始化为 0.0 add(self, *args): 这个方法用于将参数 args 中的值与累加器中的值相加。参数 args 是一个可变参数，可以接受任意数量的参数。通过 zip 函数，将 args 中的值逐个与累加器中对应位置的值相加，并更新累加器中的值 reset(self): 这个方法用于重置累加器的值 __getitem__(self, idx): 这个方法允许通过索引访问累加器中的值。给定一个索引 idx，它返回累加器中对应位置的值 3.6.6 训练 #\r首先，我们定义一个函数来训练一个迭代周期 updater是更新模型参数的常用函数，它接受批量大小作为参数 def train_epoch_ch3(net, train_iter, loss, updater): #@save\r\u0026#34;\u0026#34;\u0026#34;训练模型一个迭代周期（定义见第3章）\u0026#34;\u0026#34;\u0026#34;\r# 将模型设置为训练模式\rif isinstance(net, torch.nn.Module):\rnet.train()\r# 训练损失总和、训练准确度总和、样本数\rmetric = Accumulator(3)\rfor X, y in train_iter:\r# 计算梯度并更新参数\ry_hat = net(X)\rl = loss(y_hat, y)\rif isinstance(updater, torch.optim.Optimizer):\r# 使用PyTorch内置的优化器和损失函数\rupdater.zero_grad()\rl.mean().backward()\rupdater.step()\relse:\r# 使用定制的优化器和损失函数\rl.sum().backward()\rupdater(X.shape[0])\rmetric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\r# 返回训练损失和训练精度\rreturn metric[0] / metric[2], metric[1] / metric[2] if isinstance(net, torch.nn.Module):：检查变量 net 是否是 torch.nn.Module 类的实例 net.train(): 这一行将模型（net）设置为训练模式 metric = Accumulator(3): 创建一个长度为3的累加器 在计算梯度后，根据数据类型，如pytorch类或者自定义类累加处理结果 训练函数 #\rdef train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): #@save\r\u0026#34;\u0026#34;\u0026#34;训练模型（定义见第3章）\u0026#34;\u0026#34;\u0026#34;\ranimator = Animator(xlabel=\u0026#39;epoch\u0026#39;, xlim=[1, num_epochs], ylim=[0.3, 0.9],\rlegend=[\u0026#39;train loss\u0026#39;, \u0026#39;train acc\u0026#39;, \u0026#39;test acc\u0026#39;])\rfor epoch in range(num_epochs):\rtrain_metrics = train_epoch_ch3(net, train_iter, loss, updater)\rtest_acc = evaluate_accuracy(net, test_iter)\ranimator.add(epoch + 1, train_metrics + (test_acc,))\rtrain_loss, train_acc = train_metrics\rassert train_loss \u0026lt; 0.5, train_loss\rassert train_acc \u0026lt;= 1 and train_acc \u0026gt; 0.7, train_acc\rassert test_acc \u0026lt;= 1 and test_acc \u0026gt; 0.7, test_acc ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/3.6_implementationofsoftmaxregressionfromscratch/","section":"Docs","summary":"\u003ch2 class=\"relative group\"\u003e3.6.1 初始化模型参数 \r\n    \u003cdiv id=\"361-%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#361-%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e和之前线性回归的例子一样，这里的每个样本都将用固定长度的向量表示。 原始数据集中的每个样本都是28×28的图像。 本节将展平每个图像，把它们看作长度为784的向量\u003c/li\u003e\n\u003cli\u003e在3.5中，我们选择了一个拥有10个类别的数据集，所以softmax网络的输出维度为10\u003c/li\u003e\n\u003c/ul\u003e\n\r\n\r\n\u003ch3 class=\"relative group\"\u003e初始化权重w \r\n    \u003cdiv id=\"%E5%88%9D%E5%A7%8B%E5%8C%96%E6%9D%83%E9%87%8Dw\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%9D%83%E9%87%8Dw\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h3\u003e\r\n\u003cul\u003e\n\u003cli\u003e与线性回归一样，我们使用正态分布初始化权重w，偏置初始化为0\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003enum_inputs = 784\r\nnum_outputs = 10\r\n\r\nW = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\r\nb = torch.zeros(num_outputs, requires_grad=True)\n\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003ch2 class=\"relative group\"\u003e3.6.2 定义softmax操作 \r\n    \u003cdiv id=\"362-%E5%AE%9A%E4%B9%89softmax%E6%93%8D%E4%BD%9C\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#362-%E5%AE%9A%E4%B9%89softmax%E6%93%8D%E4%BD%9C\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e\r\n\u003cul\u003e\n\u003cli\u003e实现softmax操作由三个步骤组成\u003c/li\u003e\n\u003cli\u003e对每个项求幂\u003c/li\u003e\n\u003cli\u003e对每一行求和，得到其规范化常数\u003c/li\u003e\n\u003cli\u003e每一行除以其规范化常数，保持结果的和为1\n$$softmax(X)\u003cem\u003e{ij}=\\frac{exp(X\u003c/em\u003e{ij})}{\\sum_kexp(X_{ik})}$$\u003c/li\u003e\n\u003cli\u003e分母或规范化常数，有时也称为_配分函数_（其对数称为对数-配分函数）。 该名称来自\u003ca href=\"https://en.wikipedia.org/wiki/Partition_function_%28statistical_mechanics%29\" target=\"_blank\"\u003e统计物理学\u003c/a\u003e中一个模拟粒子群分布的方程\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edef softmax(X):\r\n    X_exp = torch.exp(X)\r\n    partition = X_exp.sum(1, keepdim=True)\r\n    return X_exp / partition  # 这里应用了广播机制\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ekeepdim=True: 在进行张量操作时，保持原始张量的维度\u003c/p\u003e","title":"D2L 3.6 Implementation of softmax regression from scratch","type":"docs"},{"content":"在了解多层感知机前，需要先了解[[Perceptron 感知机]]\n4.1.1 隐藏层 #\r在[[3.1_LinearRegression#3.1.1.1 线性模型]]中我们描述了[[Affine Transformation 仿射变换]]，如一次函数一般是一种带有偏置项的线性变换 如果预测值在仿射变换后确实与输入数据有线性关系，那么这种方式确实够用 可是大部分情况下，仿射变换中的线性是一个很强的假设 4.1.1.1 线性模型可能会出错 #\r线性意味着单调假设，权重w在正的情况下，任何特征的增大都会导致模型输出的增大 E.X.\n如果我们试图预测一个人是否会偿还贷款，我们可以认为收入较高的申请人比收入较低的申请人更有可能偿还贷款 但上述例子只阐明了单调性而非线性 收入从0到5万会带来比100万到105万更大的还款可能性 在上例中，我们任然可以通过[[2.2 数据预处理]]的方式使线性更加合理，如对数化处理 但一个违反单调性的例子比如体温和死亡率的关系 对于体温高于37度的人来说，温度越高风险越高 而对于体温低于37度的人来说，温度越低风险就越低 这种情况也可以使用理37度的距离作为特征 分类问题，如对于猫狗分类问题，在位置（13，17）处像素强度进行添加，是否整个图像描绘狗的[[Likehood 似然]]会增加？ 这一评估标准注定会失败，如倒置图像后，类别依然保留 对于上面两个例子来说，猫狗的分类问题无法通过简单的预处理解决 对于[[深度神经网络]]，我们将使用隐藏层 4.1.1.2 在网络中加入隐藏层 #\r我们可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制， 使其能处理更普遍的函数关系类型 有全连接层的多层感知机的参数开销可能会高得令人望而却步。 即使在不改变输入或输出大小的情况下， 可能在参数节约和模型有效性之间进行权衡\n4.1.1.3 从线性到非线性 #\r同之前的章节一样，我们通过矩阵\\(X\\in R^{n\\times d}\\)来表示n个样本的小批量，其中每个样本具有d个输入特征\n对于具有h个隐藏单元的单隐藏层多层感知机，用\\(H\\in R^{n\\times h}\\)表示隐藏层的输出，称为Hidden Representatiosn 隐藏表示\n因为隐藏层和输出层都是全连接的， 所以我们有隐藏层权重\\(W^{(1)}\\in R^{R\\times h}\\)和隐藏层偏置\\(b^{(1)}\\in R^{1\\times h}\\)以及输出层\\(W^{(2)}\\in R^{h\\times q}\\)和输出层偏置\\(b^{(2)}\\in R^{1\\times q}\\)\n所以形式上，对于单隐藏层的多层感知机的输出\\(O\\in R^{n\\times q}\\)，有 $$\\begin{align} \\ H=WX^{(1)}+b^{(1)} \\ O=HW^{(2)}+b^{(2)} \\end{align}$$\n现阶段，隐藏层为输入层的放射函数，而输出层为隐藏层的放射函数，即$$O=(XW^{(1)}+b^{(1)})W^{(2)}+b^{(2)}=XW+b$$\n注意到现在在多层感知机的单隐藏层下，模型依然只做到了线性的放射函数\n所以为了发挥多层架构的潜力，我们需要添加一个额外的关键要素：[[Activation Function 激活函数]]，激活函数的输出则称为Activations 活性值\n一般来说，有了激活函数，模型就不会退化成线性模型 $$\\begin{align} \\ H=\\sigma(XW^{(1)}+b^{(1)}) \\ O=HW^{(2)}+b^{(2)} \\end{align}$$\n为了构建更通用的多层感知机，我们可以继续堆叠这样的隐藏层，从而产生更有表达能力的模型\n4.1.1.4 通用近似定理 #\r多层感知机可以通过隐藏神经元，捕捉到输入之间复杂的相互作用， 这些神经元依赖于每个输入的值。 我们可以很容易地设计隐藏节点来执行任意计算 即使是网络只有一个隐藏层，给定足够的神经元和正确的权重， 我们可以对任意函数建模，尽管实际中学习该函数是很困难的 而且，虽然一个单隐层网络能学习任何函数， 但并不意味着我们应该尝试使用单隐藏层网络来解决所有问题。 事实上，通过使用更深（而不是更广）的网络，我们可以更容易地逼近许多函数。 我们将在后面的章节中进行更细致的讨论 4.1.2 激活函数 Activation Function #\r[[Activation Function 激活函数]] ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.3_simpleimplementationofmultilayerperceptron/","section":"Docs","summary":"\u003cp\u003e在了解多层感知机前，需要先了解[[Perceptron 感知机]]\u003c/p\u003e","title":"D2L 4.1 MultilayerPerceptron","type":"docs"},{"content":"深度学习的目的是发现Pattern，即做到模型的Generalization 泛化\n[[Overfitting Problem]] 原因很简单：当我们将来部署该模型时，模型需要判断从未见过的患者。 只有当模型真正发现了一种泛化模式时，才会作出有效的预测\n困难在于，当我们训练模型时，我们只能访问数据中的小部分样本。 最大的公开图像数据集包含大约一百万张图像。 而在大部分时候，我们只能从数千或数万个数据样本中学习。 在大型医院系统中，我们可能会访问数十万份医疗记录。 当我们使用有限的样本时，可能会遇到这样的问题： 当收集到更多的数据时，会发现之前找到的明显关系并不成立。\nOverfitting 过拟合 #\r模型在训练数据上拟合的比在潜在分布中更接近的现象称为过拟合 左： Underfitting 欠拟合 中：拟合 右：Overfitting 过拟合 Regularization 正则化 #\r对抗过拟合的技术称为正则化 [[Regularization 正则化]] 4.4.1 训练误差和泛化误差 #\rTraining Error 训练误差 #\r模型在训练数据集上计算得到的误差 Generalization Error 泛化误差 #\r同样分布样本的无限多个数据的模型误差期望 但问题是对于无限多个数据，我们不可能准确的计算出Genrelization Errorz 4.4.1.1 统计学习理论 #\r我们假设训练数据和测试数据都是从相同的分布中独立提取的。 这通常被称为_独立同分布假设_（i.i.d. assumption） 4.4.1.2 模型复杂性 #\r一个模型的复杂性取决于很多因素 如模型参数，取值范围 Early Stopping 早停 #\r早停（Early Stopping）：这是一种防止过拟合的技术，其中训练过程在验证集上的性能开始恶化时停止。这意味着，如果模型在验证集上的误差开始增加，表明模型可能开始过拟合训练数据，此时停止进一步训练可以避免这种情况。 4.4.2 模型选择 #\r在一个训练中，我们会选择几个候选模型对他们进行评估 4.4.2.1 验证集 #\r训练集，验证集，测试集分别是什么_训练集 验证集 测试集-CSDN博客\n总的来说，对于Superivised Training，一般讲整体划为3个区块 Training Set 训练集 #\r训练集用来训练模型，即确定模型的权重和偏置这些参数，通常我们称这些参数为学习参数 训练集中的参数直接参与到梯度下降中 Validation Set 验证集 #\rz\n而验证集用于模型的选择，更具体地来说，验证集并不参与学习参数的确定，也就是验证集并没有参与梯度下降的过程 验证集只是为了选择超参数，比如网络层数、网络节点数、迭代次数、学习率这些都叫超参数 Test Set 测试集 #\r测试集只使用一次，即在训练完成后评价最终的模型时使用。它既不参与学习参数过程，也不参数超参数选择过程，而仅仅使用于模型的评价 4.4.2.2 K-Fold Cross-Validation K折交叉验证 #\r训练数据稀缺时，我们甚至可能无法提供足够的数据来构成一个合适的验证集 过程描述 #\r数据分组：首先，整个数据集被随机分成K个大小大致相同的子集。 迭代训练与验证：每次迭代中，选择其中一个子集作为验证集，而其余的K-1个子集合并作为训练集。 性能评估：模型在训练集上训练，并在验证集上进行评估。这个过程重复K次，每次选择不同的子集作为验证集。 平均性能：最终模型的性能是所有K次迭代中验证性能的平均值。这样可以更全面地评估模型的性能。 4.4.3 欠拟合还是过拟合？ #\rGenerlization Error高的模型叫做Underfitting Train Error远低于Validation Error的模型叫做Overfitting 4.4.3.1 模型复杂性 #\r![[Pasted image 20240615153938.png]]\n简单来说，从左到右模型经历了从欠拟合到过拟合的一个过程，也是从高损失到高方差的过程 其是因为模型从没学习过参数到对于微小参数（甚至是随机噪声）严重敏感的一个过程 Lost 损失 #\r定义：偏差是指模型在预测中的系统误差，即模型对学习数据的一般性质的理解程度。 高偏差：通常表示模型过于简单（欠拟合），未能捕捉到数据的关键结构，通常会导致在训练集和测试集上都表现不佳。 Variance 方差 #\r定义：方差是指模型对于训练数据的微小变化的敏感度。 高方差：表示模型过于复杂（过拟合），对训练数据中的随机噪声也进行了学习，这可能使得模型在新的、未见过的数据上表现不佳。 4.4.3.2 数据集大小 #\r训练数据集中的样本越少，我们就越有可能（且更严重地）过拟合 而样本更过通常会减小Gerneralization Error 一般来说，更多的数据不会有什么坏处 4.4.4 多项式回归 #\r拟合一个多项式\n[[4.4 Overfitting Normal \u0026amp; Underfitting - Pytorch]]\n4.4.4.1 生成数据集 #\r![[Pasted image 20240616094316.png]]\n噪声值位均值0到标准差0.1的正态分布 在优化的过程中，我们通常希望避免非常大的梯度值或损失值。 这就是我们将特征从$x^i$调整为$\\frac{x^i}{i!}$的原因 max_degree = 20 # 多项式的最大阶数\rn_train, n_test = 100, 100 # 训练和测试数据集大小\rtrue_w = np.zeros(max_degree) # 分配大量的空间\rtrue_w[0:4] = np.array([5, 1.2, -3.4, 5.6])\rfeatures = np.random.normal(size=(n_train + n_test, 1))\rnp.random.shuffle(features)\rpoly_features = np.power(features, np.arange(max_degree).reshape(1, -1))\rfor i in range(max_degree):\rpoly_features[:, i] /= math.gamma(i + 1) # gamma(n)=(n-1)!\r# labels的维度:(n_train+n_test,)\rlabels = np.dot(poly_features, true_w)\rlabels += np.random.normal(scale=0.1, size=labels.shape) max_degree = 20 : 即使多项式仅为三阶，但我们需要用一个20纬的多项式去拟合它，这是复杂模型中的一种 features = np.random.normal(size=(n_train + n_test, 1)): 分配200个一维的特征 np.random.shuffle(features): 随机打乱数据 poly_features = np.power(features, np.arange(max_degree).reshape(1, -1))：分配每个特征的高阶数据 使用伽马正则化防止特征的迅速增大 最后点乘特征和真实权重得到Label，并将Label加上合适的噪声 # NumPy ndarray转换为tensor\rtrue_w, features, poly_features, labels = [torch.tensor(x, dtype=\rtorch.float32) for x in [true_w, features, poly_features, labels]]\rfeatures[:2], poly_features[:2, :], labels[:2] 转化为tensor def evaluate_loss(net, data_iter, loss): #@save\r\u0026#34;\u0026#34;\u0026#34;评估给定数据集上模型的损失\u0026#34;\u0026#34;\u0026#34;\rmetric = d2l.Accumulator(2) # 损失的总和,样本数量\rfor X, y in data_iter:\rout = net(X)\ry = y.reshape(out.shape)\rl = loss(out, y)\rmetric.add(l.sum(), l.numel())\rreturn metric[0] / metric[1] def train(train_features, test_features, train_labels, test_labels,\rnum_epochs=400):\rloss = nn.MSELoss(reduction=\u0026#39;none\u0026#39;)\rinput_shape = train_features.shape[-1]\r# 不设置偏置，因为我们已经在多项式中实现了它\rnet = nn.Sequential(nn.Linear(input_shape, 1, bias=False))\rbatch_size = min(10, train_labels.shape[0])\rtrain_iter = d2l.load_array((train_features, train_labels.reshape(-1,1)),\rbatch_size)\rtest_iter = d2l.load_array((test_features, test_labels.reshape(-1,1)),\rbatch_size, is_train=False)\rtrainer = torch.optim.SGD(net.parameters(), lr=0.01)\ranimator = d2l.Animator(xlabel=\u0026#39;epoch\u0026#39;, ylabel=\u0026#39;loss\u0026#39;, yscale=\u0026#39;log\u0026#39;,\rxlim=[1, num_epochs], ylim=[1e-3, 1e2],\rlegend=[\u0026#39;train\u0026#39;, \u0026#39;test\u0026#39;])\rfor epoch in range(num_epochs):\rd2l.train_epoch_ch3(net, train_iter, loss, trainer)\rif epoch == 0 or (epoch + 1) % 20 == 0:\ranimator.add(epoch + 1, (evaluate_loss(net, train_iter, loss),\revaluate_loss(net, test_iter, loss)))\rprint(\u0026#39;weight:\u0026#39;, net[0].weight.data.numpy() 欠拟合 #\r# 从多项式特征中选择前2个维度，即1和x\rtrain(poly_features[:n_train, :2], poly_features[n_train:, :2],\rlabels[:n_train], labels[n_train:]) 只给予了前两个特征值 ![[Pasted image 20240704160340.png]] 过拟合 #\r# 从多项式特征中选取所有维度\rtrain(poly_features[:n_train, :], poly_features[n_train:, :],\rlabels[:n_train], labels[n_train:], num_epochs=1500) 将w中的20列全部给到了模型导致了过拟合 ![[Pasted image 20240704160346.png]] ","date":"Apr 15 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter4multilayerperceptron/4.4_modelselectionunderfittingandoverfitting/","section":"Docs","summary":"\u003cp\u003e深度学习的目的是发现Pattern，即做到模型的Generalization 泛化\u003c/p\u003e","title":"D2L 4.4 Model Selection, Underfitting, and Overfitting","type":"docs"},{"content":" ","date":"Jan 23 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter3linearneuralnetwork/","section":"Docs","summary":"\u003chr\u003e","title":"Chapter 3. Linear Neural Network","type":"docs"},{"content":" ","date":"Jan 23 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/d2l_chapter4multilayerperceptron/","section":"Docs","summary":"\u003chr\u003e","title":"Chapter 4. Multilayer Perceptron","type":"docs"},{"content":"《动手学深度学习》 — 动手学深度学习 2.0.0 documentation. (2023). Zh-V2.D2l.ai. https://zh-v2.d2l.ai/index.html\n‌ #\r","date":"Jan 23 2024","externalUrl":null,"permalink":"/docs/dive-into-deep-learning/","section":"Docs","summary":"\u003cp\u003e《动手学深度学习》 — 动手学深度学习 2.0.0 documentation. (2023). Zh-V2.D2l.ai. \u003ca href=\"https://zh-v2.d2l.ai/index.html\" target=\"_blank\"\u003ehttps://zh-v2.d2l.ai/index.html\u003c/a\u003e\u003c/p\u003e\n\r\n\r\n\u003ch2 class=\"relative group\"\u003e‌ \r\n    \u003cdiv id=\"heading\" class=\"anchor\"\u003e\u003c/div\u003e\r\n    \r\n    \u003cspan\r\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\r\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\r\n            style=\"text-decoration-line: none !important;\" href=\"#heading\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\r\n    \u003c/span\u003e        \r\n    \r\n\u003c/h2\u003e","title":"Dive Into Deep Learning","type":"docs"},{"content":"","externalUrl":null,"permalink":"/zh-cn/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/zh-cn/","section":"Buezwqwg的博客","summary":"","title":"Buezwqwg的博客","type":"page"},{"content":"","externalUrl":null,"permalink":"/zh-cn/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"Special thanks to those for thier invaluable contributions\n","externalUrl":null,"permalink":"/credits/","section":"Credits","summary":"\u003cp\u003eSpecial thanks to those for thier invaluable contributions\u003c/p\u003e","title":"Credits","type":"credits"},{"content":"","externalUrl":null,"permalink":"/credits/faker/","section":"Credits","summary":"","title":"Faker","type":"credits"},{"content":"","externalUrl":null,"permalink":"/zh-cn/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/credits/ss/","section":"Credits","summary":"","title":"SS","type":"credits"},{"content":"","externalUrl":null,"permalink":"/zh-cn/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","externalUrl":null,"permalink":"/credits/%E9%82%93%E7%B4%AB%E6%A3%8B/","section":"Credits","summary":"","title":"邓紫棋","type":"credits"},{"content":"","externalUrl":null,"permalink":"/credits/%E6%B3%95%E8%80%81/","section":"Credits","summary":"","title":"法老","type":"credits"}]